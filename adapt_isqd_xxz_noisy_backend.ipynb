{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cd88d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from copy import deepcopy\n",
    "\n",
    "import collections\n",
    "\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcParams.update({\"font.family\": \"serif\"})\n",
    "\n",
    "import pyscf\n",
    "import pyscf.cc\n",
    "import pyscf.mcscf\n",
    "\n",
    "# To get molecular geometries.\n",
    "import openfermion as of\n",
    "from openfermion import MolecularData\n",
    "from openfermionpyscf import run_pyscf\n",
    "\n",
    "import qiskit\n",
    "from qiskit import QuantumCircuit, QuantumRegister\n",
    "from qiskit.primitives import BitArray\n",
    "from qiskit_aer import AerSimulator  # For MPS Simulator.\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "from qiskit_ibm_runtime import SamplerV2 as Sampler\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit.primitives import BackendEstimatorV2 as BackendEstimator\n",
    "from qiskit.transpiler.passes import RemoveFinalMeasurements\n",
    "from qiskit.qasm2 import dumps\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "\n",
    "import ffsim\n",
    "\n",
    "# To run on hardware.\n",
    "import qiskit_ibm_runtime\n",
    "from qiskit_ibm_runtime import SamplerV2 as Sampler\n",
    "\n",
    "from functools import partial, reduce\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from qiskit_addon_sqd.fermion import SCIResult, diagonalize_fermionic_hamiltonian, solve_sci_batch\n",
    "from qiskit_addon_sqd.qubit import solve_qubit, sort_and_remove_duplicates, project_operator_to_subspace\n",
    "\n",
    "from adaptvqe.pools import DVG_CEO, FullPauliPool, TiledPauliPool\n",
    "from adaptvqe.convert import cirq_pauli_sum_to_qiskit_pauli_op\n",
    "from adaptvqe.hamiltonians import XXZHamiltonian\n",
    "from adaptvqe.algorithms.adapt_vqe import LinAlgAdapt, TensorNetAdapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "268707c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qiskit_runtime_service.__init__:WARNING:2026-02-04 12:23:20,641: Instance was not set at service instantiation. Free and trial plan instances will be prioritized. Based on the following filters: (tags: None, region: us-east, eu-de), and available plans: (open), the available account instances are: open-instance. If you need a specific instance set it explicitly either by using a saved account with a saved default instance or passing it in directly to QiskitRuntimeService().\n",
      "qiskit_runtime_service.backends:WARNING:2026-02-04 12:23:20,641: Using instance: open-instance, plan: open\n"
     ]
    }
   ],
   "source": [
    "ibm_computer: str = \"ibm_fez\"\n",
    "\n",
    "service = QiskitRuntimeService(name=\"dalfaver@msu.edu\")\n",
    "backend = service.backend(ibm_computer)\n",
    "sampler = Sampler(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09186101",
   "metadata": {},
   "source": [
    "## Build a tiled pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aca34c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got DMRG energy -6.46410e+00\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [228]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499795\n",
      "(change of -1.2360679774997907)\n",
      "Current ansatz: [228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696158\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000003)]\n",
      "Initial energy: -4.236067977499795\n",
      "Optimizing energy with indices [228, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970451), np.float64(0.0)]\n",
      "\n",
      "Current energy: -5.999999999998185\n",
      "(change of -1.7639320224983894)\n",
      "Current ansatz: [228, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971140567\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-1.99999999999442)]\n",
      "Initial energy: -5.999999999998185\n",
      "Optimizing energy with indices [228, 74, 228]...\n",
      "Starting point: [np.float64(-0.7853985607314252), np.float64(-0.7853989420959435), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.12310562561065\n",
      "(change of -0.12310562561246563)\n",
      "Current ansatz: [228, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.91752214895575\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.4850687898689516)]\n",
      "Initial energy: -6.12310562561065\n",
      "Optimizing energy with indices [228, 74, 228, 210]...\n",
      "Starting point: [np.float64(-0.7853983869831829), np.float64(-0.7853991695302484), np.float64(0.12248869758310722), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154816652\n",
      "(change of -0.2041705292060021)\n",
      "Current ansatz: [228, 74, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964056413549\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.089491640733207)]\n",
      "Initial energy: -6.327276154816652\n",
      "Optimizing energy with indices [228, 74, 228, 210, 198]...\n",
      "Starting point: [np.float64(-0.7853984379181662), np.float64(-0.7853991591701309), np.float64(0.1635702892992542), np.float64(0.16356997348665914), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615069475\n",
      "(change of -0.1368254602528225)\n",
      "Current ansatz: [228, 74, 228, 210, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013629210389618307\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964056413549 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.000000000000001)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526199442337\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071047429203)]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 210]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819987\n",
      "(change of -0.20417052920234813)\n",
      "Current ansatz: [244, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964041846258\n",
      "Operator(s) added to ansatz: [108]\n",
      "Gradients: [np.float64(2.0894916434588646)]\n",
      "Initial energy: -6.327276154819987\n",
      "Optimizing energy with indices [244, 79, 228, 210, 108]...\n",
      "Starting point: [np.float64(0.7853981591889313), np.float64(0.7853981652005415), np.float64(0.16357028651334282), np.float64(0.1635699720499918), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072751\n",
      "(change of -0.13682546025276388)\n",
      "Current ansatz: [244, 79, 228, 210, 108]\n",
      "Performing final convergence check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 0.0001350560817700983\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964041846258 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [26]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 26]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000014\n",
      "(change of -1.7639320225002155)\n",
      "Current ansatz: [244, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132747\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000018)]\n",
      "Initial energy: -6.000000000000014\n",
      "Optimizing energy with indices [244, 26, 228]...\n",
      "Starting point: [np.float64(0.7853981718257763), np.float64(0.7853981815917102), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561763305)\n",
      "Current ansatz: [244, 26, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199440323\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071047428078)]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 26, 228, 210]...\n",
      "Starting point: [np.float64(0.7853981611549227), np.float64(0.7853981650265573), np.float64(0.1224892793431165), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.32727615481998\n",
      "(change of -0.20417052920233303)\n",
      "Current ansatz: [244, 26, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964040371926\n",
      "Operator(s) added to ansatz: [108]\n",
      "Gradients: [np.float64(2.0894916447538883)]\n",
      "Initial energy: -6.32727615481998\n",
      "Optimizing energy with indices [244, 26, 228, 210, 108]...\n",
      "Starting point: [np.float64(0.785398156811469), np.float64(0.785398154431449), np.float64(0.16357028642350993), np.float64(0.16356997171157828), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615015089\n",
      "(change of -0.13682546019510866)\n",
      "Current ansatz: [244, 26, 228, 210, 108]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0001694384918916013\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964040371926 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000004\n",
      "(change of -1.7639320225002084)\n",
      "Current ansatz: [241, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132728\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000027)]\n",
      "Initial energy: -6.000000000000004\n",
      "Optimizing energy with indices [241, 74, 228]...\n",
      "Starting point: [np.float64(-0.7853981634264042), np.float64(-0.7853981633494633), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617643\n",
      "(change of -0.12310562561763838)\n",
      "Current ansatz: [241, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327163\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.4850710484797025)]\n",
      "Initial energy: -6.123105625617643\n",
      "Optimizing energy with indices [241, 74, 228, 135]...\n",
      "Starting point: [np.float64(-0.7853981639976342), np.float64(-0.7853981625399249), np.float64(0.12248927961411428), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.3272761548199705\n",
      "(change of -0.2041705292023277)\n",
      "Current ansatz: [241, 74, 228, 135]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964056871159\n",
      "Operator(s) added to ansatz: [57]\n",
      "Gradients: [np.float64(2.089491630264901)]\n",
      "Initial energy: -6.3272761548199705\n",
      "Optimizing energy with indices [241, 74, 228, 135, 57]...\n",
      "Starting point: [np.float64(-0.7853981609143154), np.float64(-0.7853981725948302), np.float64(0.16357028742953827), np.float64(0.16356997549807345), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615069565\n",
      "(change of -0.13682546024959485)\n",
      "Current ansatz: [241, 74, 228, 135, 57]\n",
      "Performing final convergence check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 0.0001372794514110759\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964056871159 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [31]\n",
      "Gradients: [np.float64(4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 31]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000006\n",
      "(change of -1.7639320225002075)\n",
      "Current ansatz: [244, 31]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000027)]\n",
      "Initial energy: -6.000000000000006\n",
      "Optimizing energy with indices [244, 31, 225]...\n",
      "Starting point: [np.float64(0.7853981634264086), np.float64(-0.7853981633494667), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.1231056256176455\n",
      "(change of -0.12310562561763927)\n",
      "Current ansatz: [244, 31, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327167\n",
      "Operator(s) added to ansatz: [108]\n",
      "Gradients: [np.float64(2.4850710484797034)]\n",
      "Initial energy: -6.1231056256176455\n",
      "Optimizing energy with indices [244, 31, 225, 108]...\n",
      "Starting point: [np.float64(0.7853981639978266), np.float64(-0.7853981625399236), np.float64(-0.1224892796141142), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819971\n",
      "(change of -0.20417052920232592)\n",
      "Current ansatz: [244, 31, 225, 108]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964044770192\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.089491640892038)]\n",
      "Initial energy: -6.327276154819971\n",
      "Optimizing energy with indices [244, 31, 225, 108, 210]...\n",
      "Starting point: [np.float64(0.7853981488982182), np.float64(-0.7853982105488547), np.float64(-0.16357028669175525), np.float64(-0.16356997272084708), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614722433\n",
      "(change of -0.13682545990246187)\n",
      "Current ansatz: [244, 31, 225, 108, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0002850596421335381\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964044770192 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [225]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [225, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -5.999999999998188\n",
      "(change of -1.7639320224983894)\n",
      "Current ansatz: [225, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971140572\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(1.999999999994421)]\n",
      "Initial energy: -5.999999999998188\n",
      "Optimizing energy with indices [225, 79, 225]...\n",
      "Starting point: [np.float64(0.7853985607314237), np.float64(0.7853989420959421), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625610644\n",
      "(change of -0.12310562561245586)\n",
      "Current ansatz: [225, 79, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917522148955813\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.4850687898689876)]\n",
      "Initial energy: -6.123105625610644\n",
      "Optimizing energy with indices [225, 79, 225, 147]...\n",
      "Starting point: [np.float64(0.7853983869831812), np.float64(0.7853991695302517), np.float64(-0.12248869758311735), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154816632\n",
      "(change of -0.20417052920598788)\n",
      "Current ansatz: [225, 79, 225, 147]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964056413528\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.089491640733198)]\n",
      "Initial energy: -6.327276154816632\n",
      "Optimizing energy with indices [225, 79, 225, 147, 210]...\n",
      "Starting point: [np.float64(0.7853984379181668), np.float64(0.7853991591701291), np.float64(-0.16357028929925432), np.float64(-0.16356997348665928), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615069474\n",
      "(change of -0.13682546025284203)\n",
      "Current ansatz: [225, 79, 225, 147, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013629210368754747\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964056413528 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [228]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499795\n",
      "(change of -1.2360679774997907)\n",
      "Current ansatz: [228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696158\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000003)]\n",
      "Initial energy: -4.236067977499795\n",
      "Optimizing energy with indices [228, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970451), np.float64(0.0)]\n",
      "\n",
      "Current energy: -5.999999999998185\n",
      "(change of -1.7639320224983894)\n",
      "Current ansatz: [228, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971140567\n",
      "Operator(s) added to ansatz: [201]\n",
      "Gradients: [np.float64(-1.9999999999993707)]\n",
      "Initial energy: -5.999999999998185\n",
      "Optimizing energy with indices [228, 74, 201]...\n",
      "Starting point: [np.float64(-0.7853985607314252), np.float64(-0.7853989420959435), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625475225\n",
      "(change of -0.12310562547704063)\n",
      "Current ansatz: [228, 74, 201]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526155305602\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.485071021855692)]\n",
      "Initial energy: -6.123105625475225\n",
      "Optimizing energy with indices [228, 74, 201, 228]...\n",
      "Starting point: [np.float64(-0.7854038547370663), np.float64(-0.7854037258579853), np.float64(0.12248927291523236), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154553896\n",
      "(change of -0.20417052907867106)\n",
      "Current ansatz: [228, 74, 201, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240988012351095\n",
      "Operator(s) added to ansatz: [141]\n",
      "Gradients: [np.float64(2.0894918949972774)]\n",
      "Initial energy: -6.327276154553896\n",
      "Optimizing energy with indices [228, 74, 201, 228, 141]...\n",
      "Starting point: [np.float64(-0.7853981604388705), np.float64(-0.7853981095764203), np.float64(0.16357577726935094), np.float64(0.16357144252244624), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615061034\n",
      "(change of -0.13682546050713817)\n",
      "Current ansatz: [228, 74, 201, 228, 141]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00014295789237530517\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240988012351095 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002093)\n",
      "Current ansatz: [241, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132733\n",
      "Operator(s) added to ansatz: [216]\n",
      "Gradients: [np.float64(2.0000000000000036)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [241, 79, 216]...\n",
      "Starting point: [np.float64(-0.785398171825775), np.float64(0.7853981815917083), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617644\n",
      "(change of -0.12310562561763838)\n",
      "Current ansatz: [241, 79, 216]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526200767302\n",
      "Operator(s) added to ansatz: [201]\n",
      "Gradients: [np.float64(-2.4850710481676668)]\n",
      "Initial energy: -6.123105625617644\n",
      "Optimizing energy with indices [241, 79, 216, 201]...\n",
      "Starting point: [np.float64(-0.7853981624814353), np.float64(0.7853981626766198), np.float64(-0.12248927953370452), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819713\n",
      "(change of -0.20417052920206924)\n",
      "Current ansatz: [241, 79, 216, 201]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531864\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0894929267349696)]\n",
      "Initial energy: -6.327276154819713\n",
      "Optimizing energy with indices [241, 79, 216, 201, 225]...\n",
      "Starting point: [np.float64(-0.7853981639998062), np.float64(0.7853981647930687), np.float64(-0.16357019740839962), np.float64(0.16356963668286162), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615134677\n",
      "(change of -0.1368254603149639)\n",
      "Current ansatz: [241, 79, 216, 201, 225]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 2.8113106011161777e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531864 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [31]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 31]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000011\n",
      "(change of -1.7639320225002146)\n",
      "Current ansatz: [241, 31]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132743\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000018)]\n",
      "Initial energy: -6.000000000000011\n",
      "Optimizing energy with indices [241, 31, 228]...\n",
      "Starting point: [np.float64(-0.7853981718257756), np.float64(-0.7853981815917112), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.1231056256176366)\n",
      "Current ansatz: [241, 31, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199441852\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.4850710474289297)]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [241, 31, 228, 135]...\n",
      "Starting point: [np.float64(-0.7853981609748782), np.float64(-0.785398165605737), np.float64(0.12248927934333585), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154820001\n",
      "(change of -0.20417052920235346)\n",
      "Current ansatz: [241, 31, 228, 135]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964034720183\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.08949164971714)]\n",
      "Initial energy: -6.327276154820001\n",
      "Optimizing energy with indices [241, 31, 228, 135, 198]...\n",
      "Starting point: [np.float64(-0.7853981634928596), np.float64(-0.7853981639638683), np.float64(0.16357028607891516), np.float64(0.16356997041450977), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072796\n",
      "(change of -0.13682546025279496)\n",
      "Current ansatz: [241, 31, 228, 135, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.000135045259020095\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964034720183 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [31]\n",
      "Gradients: [np.float64(4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 31]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000006\n",
      "(change of -1.7639320225002075)\n",
      "Current ansatz: [244, 31]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000027)]\n",
      "Initial energy: -6.000000000000006\n",
      "Optimizing energy with indices [244, 31, 228]...\n",
      "Starting point: [np.float64(0.7853981634264086), np.float64(-0.7853981633494667), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617643\n",
      "(change of -0.1231056256176366)\n",
      "Current ansatz: [244, 31, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327163\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.485071048479703)]\n",
      "Initial energy: -6.123105625617643\n",
      "Optimizing energy with indices [244, 31, 228, 135]...\n",
      "Starting point: [np.float64(0.7853981639978813), np.float64(-0.7853981625399111), np.float64(0.12248927961411445), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819981\n",
      "(change of -0.20417052920233836)\n",
      "Current ansatz: [244, 31, 228, 135]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964044040272\n",
      "Operator(s) added to ansatz: [108]\n",
      "Gradients: [np.float64(2.089491641532528)]\n",
      "Initial energy: -6.327276154819981\n",
      "Optimizing energy with indices [244, 31, 228, 135, 108]...\n",
      "Starting point: [np.float64(0.7853981435358092), np.float64(-0.785398170851247), np.float64(0.16357028664718481), np.float64(0.163569972553437), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615071864\n",
      "(change of -0.1368254602518828)\n",
      "Current ansatz: [244, 31, 228, 135, 108]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013566218725941578\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964044040272 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-4.000000000000012)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [210]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -3.8284271247461956\n",
      "(change of -0.8284271247461912)\n",
      "Current ansatz: [210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.7820725201721\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-3.414213562369175)]\n",
      "Initial energy: -3.8284271247461956\n",
      "Optimizing energy with indices [210, 244]...\n",
      "Starting point: [np.float64(0.39269908170011103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.626284539634966\n",
      "(change of -0.7978574148887705)\n",
      "Current ansatz: [210, 244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 12.267802731192509\n",
      "Operator(s) added to ansatz: [26]\n",
      "Gradients: [np.float64(-3.7252880124495777)]\n",
      "Initial energy: -4.626284539634966\n",
      "Optimizing energy with indices [210, 244, 26]...\n",
      "Starting point: [np.float64(0.2651612350948417), np.float64(0.4454690516244888), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -5.999999999417229\n",
      "(change of -1.3737154597822627)\n",
      "Current ansatz: [210, 244, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958970181085\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-1.9999999998057474)]\n",
      "Initial energy: -5.999999999417229\n",
      "Optimizing energy with indices [210, 244, 26, 228]...\n",
      "Starting point: [np.float64(9.855378896905417e-06), np.float64(0.7853981714335029), np.float64(0.785398140734149), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625041491\n",
      "(change of -0.12310562562426242)\n",
      "Current ansatz: [210, 244, 26, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526200501841\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.4850710482493232)]\n",
      "Initial energy: -6.123105625041491\n",
      "Optimizing energy with indices [210, 244, 26, 228, 147]...\n",
      "Starting point: [np.float64(9.693301652770854e-06), np.float64(0.7853983074094893), np.float64(0.7853977639812497), np.float64(0.12248927961503848), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.32727615424246\n",
      "(change of -0.2041705292009688)\n",
      "Current ansatz: [210, 244, 26, 228, 147]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 6.240964474066229\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 8.917526200501841 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [228]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499795\n",
      "(change of -1.2360679774997907)\n",
      "Current ansatz: [228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696158\n",
      "Operator(s) added to ansatz: [26]\n",
      "Gradients: [np.float64(-4.000000000000003)]\n",
      "Initial energy: -4.236067977499795\n",
      "Optimizing energy with indices [228, 26]...\n",
      "Starting point: [np.float64(-0.5535743588970451), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -5.999999999929516\n",
      "(change of -1.7639320224297208)\n",
      "Current ansatz: [228, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971647986\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000193667)]\n",
      "Initial energy: -5.999999999929516\n",
      "Optimizing energy with indices [228, 26, 225]...\n",
      "Starting point: [np.float64(-0.7853947065773501), np.float64(0.785399377726245), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.12310562556249\n",
      "(change of -0.12310562563297367)\n",
      "Current ansatz: [228, 26, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201775827\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071048468285)]\n",
      "Initial energy: -6.12310562556249\n",
      "Optimizing energy with indices [228, 26, 225, 210]...\n",
      "Starting point: [np.float64(-0.785394706577256), np.float64(0.7853985308794286), np.float64(-0.12248927961669961), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.3272761547647445\n",
      "(change of -0.20417052920225487)\n",
      "Current ansatz: [228, 26, 225, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962581220499\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.089492926730276)]\n",
      "Initial energy: -6.3272761547647445\n",
      "Optimizing energy with indices [228, 26, 225, 210, 147]...\n",
      "Starting point: [np.float64(-0.7853947065771428), np.float64(0.7853982468607363), np.float64(-0.16357019741059867), np.float64(0.16356963668331784), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615080622\n",
      "(change of -0.13682546031587783)\n",
      "Current ansatz: [228, 26, 225, 210, 147]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 9.691226104213334e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962581220499 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002093)\n",
      "Current ansatz: [241, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132733\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(1.9999999999999996)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [241, 79, 225]...\n",
      "Starting point: [np.float64(-0.785398171825775), np.float64(0.7853981815917083), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [241, 79, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.91752619944251\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.485071047429297)]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [241, 79, 225, 135]...\n",
      "Starting point: [np.float64(-0.7853981627578538), np.float64(0.78539816425353), np.float64(-0.12248927934343061), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819701\n",
      "(change of -0.20417052920205414)\n",
      "Current ansatz: [241, 79, 225, 135]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531787\n",
      "Operator(s) added to ansatz: [57]\n",
      "Gradients: [np.float64(2.089492926734877)]\n",
      "Initial energy: -6.327276154819701\n",
      "Optimizing energy with indices [241, 79, 225, 135, 57]...\n",
      "Starting point: [np.float64(-0.7853981607742464), np.float64(0.7853981678304613), np.float64(-0.16357019740836676), np.float64(0.16356963668287383), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615009287\n",
      "(change of -0.13682546018958597)\n",
      "Current ansatz: [241, 79, 225, 135, 57]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00015614297040585928\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531787 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [31]\n",
      "Gradients: [np.float64(4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 31]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000006\n",
      "(change of -1.7639320225002075)\n",
      "Current ansatz: [244, 31]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operator(s) added to ansatz: [216]\n",
      "Gradients: [np.float64(2.000000000000004)]\n",
      "Initial energy: -6.000000000000006\n",
      "Optimizing energy with indices [244, 31, 216]...\n",
      "Starting point: [np.float64(0.7853981634264086), np.float64(-0.7853981633494667), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617655\n",
      "(change of -0.12310562561764904)\n",
      "Current ansatz: [244, 31, 216]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.91752620132718\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.485071048479707)]\n",
      "Initial energy: -6.123105625617655\n",
      "Optimizing energy with indices [244, 31, 216, 225]...\n",
      "Starting point: [np.float64(0.7853981646238432), np.float64(-0.7853981621539974), np.float64(-0.1224892796141143), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819991\n",
      "(change of -0.2041705292023357)\n",
      "Current ansatz: [244, 31, 216, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964042638306\n",
      "Operator(s) added to ansatz: [201]\n",
      "Gradients: [np.float64(-2.0894916427634773)]\n",
      "Initial energy: -6.327276154819991\n",
      "Optimizing energy with indices [244, 31, 216, 225, 201]...\n",
      "Starting point: [np.float64(0.7853981628939728), np.float64(-0.7853981669250067), np.float64(-0.16357028656166703), np.float64(-0.16356997223173272), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072744\n",
      "(change of -0.13682546025275322)\n",
      "Current ansatz: [244, 31, 216, 225, 201]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013507009758898745\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964042638306 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.000000000000001)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199442337\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.4850710474292033)]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 135]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819991\n",
      "(change of -0.20417052920235168)\n",
      "Current ansatz: [244, 79, 228, 135]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964041381248\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.0894916438672313)]\n",
      "Initial energy: -6.327276154819991\n",
      "Optimizing energy with indices [244, 79, 228, 135, 198]...\n",
      "Starting point: [np.float64(0.7853981553846432), np.float64(0.7853981604652992), np.float64(0.16357028648499042), np.float64(0.16356997194327144), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615069744\n",
      "(change of -0.13682546024975295)\n",
      "Current ansatz: [244, 79, 228, 135, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013698140305267725\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964041381248 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000018)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 225]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617651\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 79, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199444833\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071047430588)]\n",
      "Initial energy: -6.123105625617651\n",
      "Optimizing energy with indices [244, 79, 225, 210]...\n",
      "Starting point: [np.float64(0.7853981583089785), np.float64(0.785398168718093), np.float64(-0.12248927934376257), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819709\n",
      "(change of -0.20417052920205858)\n",
      "Current ansatz: [244, 79, 225, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580530028\n",
      "Operator(s) added to ansatz: [108]\n",
      "Gradients: [np.float64(2.089492926737888)]\n",
      "Initial energy: -6.327276154819709\n",
      "Optimizing energy with indices [244, 79, 225, 210, 108]...\n",
      "Starting point: [np.float64(0.7853981700346647), np.float64(0.7853981900506334), np.float64(-0.1635701974085294), np.float64(0.16356963668219085), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614821344\n",
      "(change of -0.13682546000163498)\n",
      "Current ansatz: [244, 79, 225, 210, 108]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0002699835157085497\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580530028 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000004\n",
      "(change of -1.7639320225002084)\n",
      "Current ansatz: [241, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132728\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000027)]\n",
      "Initial energy: -6.000000000000004\n",
      "Optimizing energy with indices [241, 74, 228]...\n",
      "Starting point: [np.float64(-0.7853981634264042), np.float64(-0.7853981633494633), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617643\n",
      "(change of -0.12310562561763838)\n",
      "Current ansatz: [241, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327163\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.4850710484797034)]\n",
      "Initial energy: -6.123105625617643\n",
      "Optimizing energy with indices [241, 74, 228, 210]...\n",
      "Starting point: [np.float64(-0.7853981639976342), np.float64(-0.7853981625399249), np.float64(0.12248927961411428), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819971\n",
      "(change of -0.2041705292023286)\n",
      "Current ansatz: [241, 74, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964057733311\n",
      "Operator(s) added to ansatz: [57]\n",
      "Gradients: [np.float64(2.089491629507777)]\n",
      "Initial energy: -6.327276154819971\n",
      "Optimizing energy with indices [241, 74, 228, 210, 57]...\n",
      "Starting point: [np.float64(-0.785398162447052), np.float64(-0.7853981711958521), np.float64(0.16357028748210503), np.float64(0.16356997569593643), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615067938\n",
      "(change of -0.13682546024796682)\n",
      "Current ansatz: [241, 74, 228, 210, 57]\n",
      "Performing final convergence check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 0.00013840069558915347\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964057733311 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [31]\n",
      "Gradients: [np.float64(4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 31]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000006\n",
      "(change of -1.7639320225002075)\n",
      "Current ansatz: [244, 31]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000027)]\n",
      "Initial energy: -6.000000000000006\n",
      "Optimizing energy with indices [244, 31, 228]...\n",
      "Starting point: [np.float64(0.7853981634264086), np.float64(-0.7853981633494667), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617643\n",
      "(change of -0.1231056256176366)\n",
      "Current ansatz: [244, 31, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327163\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.4850710484797025)]\n",
      "Initial energy: -6.123105625617643\n",
      "Optimizing energy with indices [244, 31, 228, 198]...\n",
      "Starting point: [np.float64(0.7853981639978813), np.float64(-0.7853981625399111), np.float64(0.12248927961411445), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819704\n",
      "(change of -0.20417052920206125)\n",
      "Current ansatz: [244, 31, 228, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.2409625805319635\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.089492926734877)]\n",
      "Initial energy: -6.327276154819704\n",
      "Optimizing energy with indices [244, 31, 228, 198, 135]...\n",
      "Starting point: [np.float64(0.7853981657346583), np.float64(-0.7853981589236085), np.float64(0.16357019740840617), np.float64(-0.16356963668288518), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016150194295\n",
      "(change of -0.1368254601997254)\n",
      "Current ansatz: [244, 31, 228, 198, 135]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0001446159283424376\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.2409625805319635 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000004\n",
      "(change of -1.7639320225002084)\n",
      "Current ansatz: [241, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132728\n",
      "Operator(s) added to ansatz: [216]\n",
      "Gradients: [np.float64(2.0000000000000036)]\n",
      "Initial energy: -6.000000000000004\n",
      "Optimizing energy with indices [241, 74, 216]...\n",
      "Starting point: [np.float64(-0.7853981634264042), np.float64(-0.7853981633494633), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.12310562561765\n",
      "(change of -0.12310562561764549)\n",
      "Current ansatz: [241, 74, 216]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327147\n",
      "Operator(s) added to ansatz: [30]\n",
      "Gradients: [np.float64(2.48507104847969)]\n",
      "Initial energy: -6.12310562561765\n",
      "Optimizing energy with indices [241, 74, 216, 30]...\n",
      "Starting point: [np.float64(-0.7853981642365402), np.float64(-0.7853981626303626), np.float64(-0.12248927961411066), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819992\n",
      "(change of -0.2041705292023419)\n",
      "Current ansatz: [241, 74, 216, 30]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964042692924\n",
      "Operator(s) added to ansatz: [201]\n",
      "Gradients: [np.float64(-2.089491642715508)]\n",
      "Initial energy: -6.327276154819992\n",
      "Optimizing energy with indices [241, 74, 216, 30, 201]...\n",
      "Starting point: [np.float64(-0.7853981637618467), np.float64(-0.7853981622244294), np.float64(-0.16357028656499617), np.float64(-0.16356997224426872), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072681\n",
      "(change of -0.13682546025268927)\n",
      "Current ansatz: [241, 74, 216, 30, 201]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013512004602194824\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964042692924 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [225]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [225, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -5.999999999998188\n",
      "(change of -1.7639320224983894)\n",
      "Current ansatz: [225, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971140572\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-1.9999999999944214)]\n",
      "Initial energy: -5.999999999998188\n",
      "Optimizing energy with indices [225, 79, 228]...\n",
      "Starting point: [np.float64(0.7853985607314237), np.float64(0.7853989420959421), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625610647\n",
      "(change of -0.12310562561245852)\n",
      "Current ansatz: [225, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917522148955765\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.4850687898689605)]\n",
      "Initial energy: -6.123105625610647\n",
      "Optimizing energy with indices [225, 79, 228, 135]...\n",
      "Starting point: [np.float64(0.7853983869831845), np.float64(0.7853991695302365), np.float64(0.12248869758311001), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154816635\n",
      "(change of -0.20417052920598877)\n",
      "Current ansatz: [225, 79, 228, 135]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964056416001\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.0894916407310418)]\n",
      "Initial energy: -6.327276154816635\n",
      "Optimizing energy with indices [225, 79, 228, 135, 198]...\n",
      "Starting point: [np.float64(0.7853984379184566), np.float64(0.7853991591701238), np.float64(0.1635702892994069), np.float64(0.163569973487224), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615069491\n",
      "(change of -0.13682546025285536)\n",
      "Current ansatz: [225, 79, 228, 135, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013629210901413015\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964056416001 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [225]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [26]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [225, 26]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -5.999999999998192\n",
      "(change of -1.763932022498393)\n",
      "Current ansatz: [225, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971140577\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-1.9999999999944222)]\n",
      "Initial energy: -5.999999999998192\n",
      "Optimizing energy with indices [225, 26, 228]...\n",
      "Starting point: [np.float64(0.7853985607314246), np.float64(0.7853989420959444), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625610641\n",
      "(change of -0.12310562561244964)\n",
      "Current ansatz: [225, 26, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917522148955772\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.4850687898689667)]\n",
      "Initial energy: -6.123105625610641\n",
      "Optimizing energy with indices [225, 26, 228, 198]...\n",
      "Starting point: [np.float64(0.7853983869831882), np.float64(0.7853991695302422), np.float64(0.12248869758311211), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154816351\n",
      "(change of -0.20417052920570988)\n",
      "Current ansatz: [225, 26, 228, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962567144909\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.0894929485633114)]\n",
      "Initial energy: -6.327276154816351\n",
      "Optimizing energy with indices [225, 26, 228, 198, 135]...\n",
      "Starting point: [np.float64(0.7853984388877605), np.float64(0.7853991591701964), np.float64(0.16357019849077953), np.float64(-0.16356963170305544), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016151321296\n",
      "(change of -0.13682546031577836)\n",
      "Current ansatz: [225, 26, 228, 198, 135]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 3.185585832160771e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962567144909 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [228]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499795\n",
      "(change of -1.2360679774997907)\n",
      "Current ansatz: [228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696158\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000003)]\n",
      "Initial energy: -4.236067977499795\n",
      "Optimizing energy with indices [228, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970451), np.float64(0.0)]\n",
      "\n",
      "Current energy: -5.999999999929518\n",
      "(change of -1.7639320224297226)\n",
      "Current ansatz: [228, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971647986\n",
      "Operator(s) added to ansatz: [201]\n",
      "Gradients: [np.float64(-1.9999999999522045)]\n",
      "Initial energy: -5.999999999929518\n",
      "Optimizing energy with indices [228, 79, 201]...\n",
      "Starting point: [np.float64(-0.7853947065773552), np.float64(0.7853993777262496), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625548017\n",
      "(change of -0.12310562561849903)\n",
      "Current ansatz: [228, 79, 201]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917506431665617\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.4850600293890643)]\n",
      "Initial energy: -6.123105625548017\n",
      "Optimizing energy with indices [228, 79, 201, 228]...\n",
      "Starting point: [np.float64(-0.7853977521525508), np.float64(0.7853977933716614), np.float64(0.1224864400623345), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154816648\n",
      "(change of -0.2041705292686311)\n",
      "Current ansatz: [228, 79, 201, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.2409625787176335\n",
      "Operator(s) added to ansatz: [216]\n",
      "Gradients: [np.float64(2.089492926747546)]\n",
      "Initial energy: -6.327276154816648\n",
      "Optimizing energy with indices [228, 79, 201, 228, 216]...\n",
      "Starting point: [np.float64(-0.7853977521525458), np.float64(0.7853988798879336), np.float64(0.16357019699115416), np.float64(0.16356963656316684), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615068975\n",
      "(change of -0.1368254602523269)\n",
      "Current ansatz: [228, 79, 201, 228, 216]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013734918227250974\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.2409625787176335 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002093)\n",
      "Current ansatz: [241, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132733\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(1.9999999999999996)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [241, 79, 225]...\n",
      "Starting point: [np.float64(-0.785398171825775), np.float64(0.7853981815917083), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [241, 79, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.91752619944251\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.4850710474292965)]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [241, 79, 225, 198]...\n",
      "Starting point: [np.float64(-0.7853981627578538), np.float64(0.78539816425353), np.float64(-0.12248927934343061), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819986\n",
      "(change of -0.20417052920233836)\n",
      "Current ansatz: [241, 79, 225, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964058377264\n",
      "Operator(s) added to ansatz: [45]\n",
      "Gradients: [np.float64(-2.089491628942172)]\n",
      "Initial energy: -6.327276154819986\n",
      "Optimizing energy with indices [241, 79, 225, 198, 45]...\n",
      "Starting point: [np.float64(-0.7853981662933148), np.float64(0.7853981545803549), np.float64(-0.16357028752134434), np.float64(-0.16356997584374114), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.464101615072489\n",
      "(change of -0.13682546025250364)\n",
      "Current ansatz: [241, 79, 225, 198, 45]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013521654489571786\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964058377264 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.000000000000001)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199442337\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071047429203)]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 210]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819987\n",
      "(change of -0.20417052920234813)\n",
      "Current ansatz: [244, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 6.240964041846258\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.0894916434588646)]\n",
      "Initial energy: -6.327276154819987\n",
      "Optimizing energy with indices [244, 79, 228, 210, 147]...\n",
      "Starting point: [np.float64(0.7853981591889313), np.float64(0.7853981652005415), np.float64(0.16357028651334282), np.float64(0.1635699720499918), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072685\n",
      "(change of -0.13682546025269726)\n",
      "Current ansatz: [244, 79, 228, 210, 147]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013508605784767053\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964041846258 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002093)\n",
      "Current ansatz: [241, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132733\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [241, 79, 228]...\n",
      "Starting point: [np.float64(-0.785398171825775), np.float64(0.7853981815917083), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617642\n",
      "(change of -0.1231056256176366)\n",
      "Current ansatz: [241, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199441697\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071047428846)]\n",
      "Initial energy: -6.123105625617642\n",
      "Optimizing energy with indices [241, 79, 228, 210]...\n",
      "Starting point: [np.float64(-0.785398162647287), np.float64(0.7853981641254796), np.float64(0.1224892793433147), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819982\n",
      "(change of -0.20417052920234013)\n",
      "Current ansatz: [241, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.24096404138082\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.0894916438682527)]\n",
      "Initial energy: -6.327276154819982\n",
      "Optimizing energy with indices [241, 79, 228, 210, 147]...\n",
      "Starting point: [np.float64(-0.7853982024976439), np.float64(0.7853981311150512), np.float64(0.1635702864850446), np.float64(0.16356997194303877), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614554787\n",
      "(change of -0.13682545973480487)\n",
      "Current ansatz: [241, 79, 228, 210, 147]\n",
      "Performing final convergence check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 0.00033002084338061577\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.24096404138082 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.000000000000001)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199442337\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.4850710474292024)]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 147]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819699\n",
      "(change of -0.20417052920205947)\n",
      "Current ansatz: [244, 79, 228, 147]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531783\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.089492926734874)]\n",
      "Initial energy: -6.327276154819699\n",
      "Optimizing energy with indices [244, 79, 228, 147, 135]...\n",
      "Starting point: [np.float64(0.7853981646904773), np.float64(0.7853981643651435), np.float64(0.16357019740836662), np.float64(-0.1635696366828739), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016151326465\n",
      "(change of -0.13682546031294773)\n",
      "Current ansatz: [244, 79, 228, 147, 135]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 3.3720329358920564e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531783 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 74]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002066)\n",
      "Current ansatz: [244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000004)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [244, 74, 225]...\n",
      "Starting point: [np.float64(0.7853981703433218), np.float64(-0.7853981783720295), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 74, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526200048677\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.4850710477671427)]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 74, 225, 135]...\n",
      "Starting point: [np.float64(0.7853981633976963), np.float64(-0.7853981633977503), np.float64(-0.12248927943049101), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819704\n",
      "(change of -0.2041705292020568)\n",
      "Current ansatz: [244, 74, 225, 135]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531842\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.0894929267348785)]\n",
      "Initial energy: -6.327276154819704\n",
      "Optimizing energy with indices [244, 74, 225, 135, 198]...\n",
      "Starting point: [np.float64(0.7853981633998764), np.float64(-0.785398163399414), np.float64(-0.16357019740837914), np.float64(0.1635696366828772), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016151353945\n",
      "(change of -0.13682546031569043)\n",
      "Current ansatz: [244, 74, 225, 135, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 2.5887659855916304e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531842 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000018)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 225]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617651\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 79, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526199444833\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.485071047430588)]\n",
      "Initial energy: -6.123105625617651\n",
      "Optimizing energy with indices [244, 79, 225, 135]...\n",
      "Starting point: [np.float64(0.7853981583089785), np.float64(0.785398168718093), np.float64(-0.12248927934376257), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819723\n",
      "(change of -0.2041705292020719)\n",
      "Current ansatz: [244, 79, 225, 135]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580529992\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.089492926737967)]\n",
      "Initial energy: -6.327276154819723\n",
      "Optimizing energy with indices [244, 79, 225, 135, 198]...\n",
      "Starting point: [np.float64(0.7853981707487593), np.float64(0.7853981900506324), np.float64(-0.16357019740853293), np.float64(0.16356963668217434), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016145584835\n",
      "(change of -0.1368254597387608)\n",
      "Current ansatz: [244, 79, 225, 135, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00030842479101542115\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580529992 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 74]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002066)\n",
      "Current ansatz: [244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000004)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [244, 74, 228]...\n",
      "Starting point: [np.float64(0.7853981703433218), np.float64(-0.7853981783720295), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.91752620004858\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.4850710477670868)]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 74, 228, 198]...\n",
      "Starting point: [np.float64(0.7853981659552435), np.float64(-0.7853981611613353), np.float64(0.12248927943047701), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819701\n",
      "(change of -0.20417052920205414)\n",
      "Current ansatz: [244, 74, 228, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531868\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.0894929267348714)]\n",
      "Initial energy: -6.327276154819701\n",
      "Optimizing energy with indices [244, 74, 228, 198, 210]...\n",
      "Starting point: [np.float64(0.7853981767050704), np.float64(-0.7853981525341414), np.float64(0.16357019740837964), np.float64(-0.16356963668287866), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614750662\n",
      "(change of -0.13682545993096085)\n",
      "Current ansatz: [244, 74, 228, 198, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0003109685923337023\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531868 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000004\n",
      "(change of -1.7639320225002084)\n",
      "Current ansatz: [241, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132728\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000027)]\n",
      "Initial energy: -6.000000000000004\n",
      "Optimizing energy with indices [241, 74, 225]...\n",
      "Starting point: [np.float64(-0.7853981634264042), np.float64(-0.7853981633494633), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617646\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [241, 74, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327169\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.485071048479704)]\n",
      "Initial energy: -6.123105625617646\n",
      "Optimizing energy with indices [241, 74, 225, 198]...\n",
      "Starting point: [np.float64(-0.785398163997711), np.float64(-0.7853981625399766), np.float64(-0.1224892796141143), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819995\n",
      "(change of -0.20417052920234902)\n",
      "Current ansatz: [241, 74, 225, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 6.240964035952707\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.0894916486344886)]\n",
      "Initial energy: -6.327276154819995\n",
      "Optimizing energy with indices [241, 74, 225, 198, 210]...\n",
      "Starting point: [np.float64(-0.7853981669996093), np.float64(-0.7853981627952086), np.float64(-0.16357028615401242), np.float64(-0.16356997069742418), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072774\n",
      "(change of -0.13682546025277897)\n",
      "Current ansatz: [241, 74, 225, 198, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013505199547288632\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964035952707 > 1e-05)\n",
      "Pool will be tiled from 19 ops\n"
     ]
    }
   ],
   "source": [
    "max_mpo_bond = 300\n",
    "dmrg_mps_bond = 30\n",
    "adapt_mps_bond = 30\n",
    "l = 4\n",
    "\n",
    "j_xy = 1\n",
    "j_z = 1\n",
    "h = XXZHamiltonian(j_xy, j_z, l, diag_mode=\"quimb\", max_mpo_bond=max_mpo_bond, max_mps_bond=dmrg_mps_bond)\n",
    "dmrg_energy = h.ground_energy\n",
    "print(f\"Got DMRG energy {dmrg_energy:4.5e}\")\n",
    "pool = FullPauliPool(n=l, max_mpo_bond=max_mpo_bond)\n",
    "\n",
    "# Run 200 iterations of ADAPT-VQE for small problem instance, selecting randomly among degenerate gradients.\n",
    "# Form a list of all unique operators ever selected for this small instance.\n",
    "ixs = []\n",
    "for _ in range(30):\n",
    "    my_adapt = TensorNetAdapt(\n",
    "        pool=pool,\n",
    "        custom_hamiltonian=h,\n",
    "        verbose=False,\n",
    "        threshold=10**-5,\n",
    "        max_adapt_iter=5,\n",
    "        max_opt_iter=10000,\n",
    "        sel_criterion=\"gradient\",\n",
    "        recycle_hessian=False,\n",
    "        rand_degenerate=True,\n",
    "        max_mpo_bond=100,\n",
    "        max_mps_bond = 20\n",
    "    )\n",
    "    my_adapt.run()\n",
    "    data = my_adapt.data\n",
    "    for i in data.result.ansatz.indices:\n",
    "        if i not in ixs:\n",
    "            ixs.append(i)\n",
    "\n",
    "print(f\"Pool will be tiled from {len(ixs)} ops\")\n",
    "source_ops = [pool.operators[index].operator for index in ixs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f9939",
   "metadata": {},
   "source": [
    "## Run ADAPT at larger size to get a sequence of circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8a9715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neel_circuit(nq, start_zero=True):\n",
    "    circuit = QuantumCircuit(nq)\n",
    "    for i in range(nq):\n",
    "        if (i % 2 == 0 and start_zero) or (i % 2 != 0 and not start_zero):\n",
    "            circuit.x(i)\n",
    "        else:\n",
    "            circuit.id(i)\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fb433a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_l = 20\n",
      "No pre-computed energy for given parameters.\n",
      "Solving by DMRG with quimb.\n",
      "Got DMRG energy -3.47299e+01-3.37508e-14j\n",
      "Tiled pool has 261 operators.\n",
      "\n",
      "tensor-net-adapt prepared with the following settings:\n",
      "> Pool: tiled_pauli_pool\n",
      "> Custom Hamiltonian: XXZ_1_1\n",
      "> Orbital Optimization: False\n",
      "> Selection method: gradient\n",
      "> Convergence criterion: total_g_norm\n",
      "> Recycling Hessian: False\n",
      "> Tetris: False (progressive optimization: False)\n",
      "> Convergence threshold (gradient norm):  1e-05\n",
      "> Maximum number of iterations:  30\n",
      "> Candidates per iteration:  1\n",
      "> Swap-based circuits for LNN connectivity:  False\n",
      "> Qiskit-transpiler-based circuits for LNN connectivity:  False\n",
      "\n",
      "Initial energy: -19.00000000000003\n",
      "On iteration 0.\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 3.9999999999999996\n",
      "Operator 1: 4.000000000000045\n",
      "Operator 2: 4.000000000000009\n",
      "Operator 3: 3.99999999999999\n",
      "Operator 4: 4.000000000000025\n",
      "Operator 5: 4.000000000000014\n",
      "Operator 6: 4.00000000000002\n",
      "Operator 7: 4.0000000000000115\n",
      "Operator 8: 4.000000000000016\n",
      "Operator 9: 4.000000000000035\n",
      "Operator 10: 4.000000000000042\n",
      "Operator 11: 4.00000000000003\n",
      "Operator 12: 4.0000000000000515\n",
      "Operator 13: 4.00000000000003\n",
      "Operator 14: 4.000000000000028\n",
      "Operator 15: 4.000000000000019\n",
      "Operator 16: 4.000000000000017\n",
      "Operator 17: 4.000000000000009\n",
      "Operator 18: -4.000000000000006\n",
      "Operator 19: 3.9999999999999996\n",
      "Operator 20: -4.000000000000045\n",
      "Operator 21: 4.000000000000009\n",
      "Operator 22: -3.99999999999999\n",
      "Operator 23: 4.000000000000025\n",
      "Operator 24: -4.000000000000014\n",
      "Operator 25: 4.00000000000002\n",
      "Operator 26: -4.0000000000000115\n",
      "Operator 27: 4.000000000000016\n",
      "Operator 28: -4.000000000000035\n",
      "Operator 29: 4.000000000000042\n",
      "Operator 30: -4.00000000000003\n",
      "Operator 31: 4.0000000000000515\n",
      "Operator 32: -4.00000000000003\n",
      "Operator 33: 4.000000000000028\n",
      "Operator 34: -4.000000000000006\n",
      "Operator 35: -3.9999999999999996\n",
      "Operator 36: -4.000000000000045\n",
      "Operator 37: -4.000000000000009\n",
      "Operator 38: -3.99999999999999\n",
      "Operator 39: -4.000000000000025\n",
      "Operator 40: -4.000000000000014\n",
      "Operator 41: -4.00000000000002\n",
      "Operator 42: -4.0000000000000115\n",
      "Operator 43: -4.000000000000016\n",
      "Operator 44: -4.000000000000035\n",
      "Operator 45: -4.000000000000042\n",
      "Operator 46: -4.00000000000003\n",
      "Operator 47: -4.0000000000000515\n",
      "Operator 48: -4.00000000000003\n",
      "Operator 49: -4.000000000000028\n",
      "Operator 50: -4.000000000000019\n",
      "Operator 51: 4.000000000000006\n",
      "Operator 52: 3.9999999999999996\n",
      "Operator 53: 4.000000000000045\n",
      "Operator 54: 4.000000000000009\n",
      "Operator 55: 3.99999999999999\n",
      "Operator 56: 4.000000000000025\n",
      "Operator 57: 4.000000000000014\n",
      "Operator 58: 4.00000000000002\n",
      "Operator 59: 4.0000000000000115\n",
      "Operator 60: 4.000000000000016\n",
      "Operator 61: 4.000000000000035\n",
      "Operator 62: 4.000000000000042\n",
      "Operator 63: 4.00000000000003\n",
      "Operator 64: 4.0000000000000515\n",
      "Operator 65: 4.00000000000003\n",
      "Operator 66: 4.000000000000028\n",
      "Operator 67: 4.000000000000019\n",
      "Operator 68: -3.9999999999999996\n",
      "Operator 69: 4.000000000000045\n",
      "Operator 70: -4.000000000000009\n",
      "Operator 71: 3.99999999999999\n",
      "Operator 72: -4.000000000000025\n",
      "Operator 73: 4.000000000000014\n",
      "Operator 74: -4.00000000000002\n",
      "Operator 75: 4.0000000000000115\n",
      "Operator 76: -4.000000000000016\n",
      "Operator 77: 4.000000000000035\n",
      "Operator 78: -4.000000000000042\n",
      "Operator 79: 4.00000000000003\n",
      "Operator 80: -4.0000000000000515\n",
      "Operator 81: 4.00000000000003\n",
      "Operator 82: -4.000000000000028\n",
      "Operator 83: 4.000000000000019\n",
      "Operator 84: -4.000000000000017\n",
      "Operator 85: -4.000000000000009\n",
      "Operator 86: 4.000000000000006\n",
      "Operator 104: -4.000000000000009\n",
      "Operator 105: 4.000000000000006\n",
      "Operator 106: -3.9999999999999996\n",
      "Operator 107: 4.000000000000045\n",
      "Operator 108: -4.000000000000009\n",
      "Operator 109: 3.99999999999999\n",
      "Operator 110: -4.000000000000025\n",
      "Operator 111: 4.000000000000014\n",
      "Operator 112: -4.00000000000002\n",
      "Operator 113: 4.0000000000000115\n",
      "Operator 114: -4.000000000000016\n",
      "Operator 115: 4.000000000000035\n",
      "Operator 116: -4.000000000000042\n",
      "Operator 117: 4.00000000000003\n",
      "Operator 118: -4.0000000000000515\n",
      "Operator 119: 4.00000000000003\n",
      "Operator 120: -4.000000000000028\n",
      "Operator 121: 3.9999999999999996\n",
      "Operator 122: -4.000000000000045\n",
      "Operator 123: 4.000000000000009\n",
      "Operator 124: -3.99999999999999\n",
      "Operator 125: 4.000000000000025\n",
      "Operator 126: -4.000000000000014\n",
      "Operator 127: 4.00000000000002\n",
      "Operator 128: -4.0000000000000115\n",
      "Operator 129: 4.000000000000016\n",
      "Operator 130: -4.000000000000035\n",
      "Operator 131: 4.000000000000042\n",
      "Operator 132: -4.00000000000003\n",
      "Operator 133: 4.0000000000000515\n",
      "Operator 134: -4.00000000000003\n",
      "Operator 135: 4.000000000000028\n",
      "Operator 136: -4.000000000000019\n",
      "Operator 137: 4.000000000000017\n",
      "Operator 138: -4.000000000000006\n",
      "Operator 139: -3.9999999999999996\n",
      "Operator 140: -4.000000000000045\n",
      "Operator 141: -4.000000000000009\n",
      "Operator 142: -3.99999999999999\n",
      "Operator 143: -4.000000000000025\n",
      "Operator 144: -4.000000000000014\n",
      "Operator 145: -4.00000000000002\n",
      "Operator 146: -4.0000000000000115\n",
      "Operator 147: -4.000000000000016\n",
      "Operator 148: -4.000000000000035\n",
      "Operator 149: -4.000000000000042\n",
      "Operator 150: -4.00000000000003\n",
      "Operator 151: -4.0000000000000515\n",
      "Operator 152: -4.00000000000003\n",
      "Operator 153: -4.000000000000028\n",
      "Operator 154: -4.000000000000019\n",
      "Operator 172: 4.000000000000009\n",
      "Operator 173: -4.000000000000006\n",
      "Operator 174: -4.000000000000017\n",
      "Operator 175: 4.000000000000006\n",
      "Operator 227: -4.000000000000009\n",
      "Operator 228: -4.000000000000006\n",
      "Operator 229: -3.9999999999999996\n",
      "Operator 230: -4.000000000000045\n",
      "Operator 231: -4.000000000000009\n",
      "Operator 232: -3.99999999999999\n",
      "Operator 233: -4.000000000000025\n",
      "Operator 234: -4.000000000000014\n",
      "Operator 235: -4.00000000000002\n",
      "Operator 236: -4.0000000000000115\n",
      "Operator 237: -4.000000000000016\n",
      "Operator 238: -4.000000000000035\n",
      "Operator 239: -4.000000000000042\n",
      "Operator 240: -4.00000000000003\n",
      "Operator 241: -4.0000000000000515\n",
      "Operator 242: -4.00000000000003\n",
      "Operator 243: -4.000000000000028\n",
      "Total gradient norm: 50.438080851674236\n",
      "Operators under consideration (1):\n",
      "[237]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000016)]\n",
      "Operator(s) added to ansatz: [237]\n",
      "Gradients: [np.float64(-4.000000000000016)]\n",
      "Initial energy: -19.00000000000003\n",
      "Optimizing energy with indices [237]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -19.828427\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "Current energy: -19.828427124746206\n",
      "(change of -0.8284271247461774)\n",
      "Current ansatz: [237]\n",
      "On iteration 1.\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 4.000000000000002\n",
      "Operator 1: 4.000000000000047\n",
      "Operator 2: 4.000000000000011\n",
      "Operator 3: 3.999999999999991\n",
      "Operator 4: 4.000000000000026\n",
      "Operator 5: 4.000000000000013\n",
      "Operator 6: 4.0000000000000195\n",
      "Operator 7: 3.4142135623691896\n",
      "Operator 9: 3.4142135623692083\n",
      "Operator 10: 2.8284271247383925\n",
      "Operator 11: 4.000000000000027\n",
      "Operator 12: 4.000000000000046\n",
      "Operator 13: 4.000000000000025\n",
      "Operator 14: 4.000000000000025\n",
      "Operator 15: 4.000000000000013\n",
      "Operator 16: 4.000000000000009\n",
      "Operator 17: 4.00000000000001\n",
      "Operator 18: -4.000000000000008\n",
      "Operator 19: 4.000000000000002\n",
      "Operator 20: -4.000000000000047\n",
      "Operator 21: 4.000000000000011\n",
      "Operator 22: -3.999999999999991\n",
      "Operator 23: 4.000000000000026\n",
      "Operator 24: -2.8284271247383765\n",
      "Operator 25: 4.0000000000000195\n",
      "Operator 26: -3.4142135623691905\n",
      "Operator 28: -3.4142135623692105\n",
      "Operator 29: 4.000000000000041\n",
      "Operator 30: -4.000000000000027\n",
      "Operator 31: 4.000000000000046\n",
      "Operator 32: -4.000000000000025\n",
      "Operator 33: 4.000000000000025\n",
      "Operator 34: -4.000000000000008\n",
      "Operator 35: -4.000000000000002\n",
      "Operator 36: -4.000000000000047\n",
      "Operator 37: -4.000000000000011\n",
      "Operator 38: -3.999999999999991\n",
      "Operator 39: -4.000000000000026\n",
      "Operator 40: -4.000000000000013\n",
      "Operator 41: -2.82842712473838\n",
      "Operator 42: -3.4142135623691905\n",
      "Operator 44: -3.4142135623692105\n",
      "Operator 45: -4.000000000000041\n",
      "Operator 46: -4.000000000000027\n",
      "Operator 47: -4.000000000000046\n",
      "Operator 48: -4.000000000000025\n",
      "Operator 49: -4.000000000000025\n",
      "Operator 50: -4.000000000000013\n",
      "Operator 51: 4.000000000000008\n",
      "Operator 52: 4.000000000000002\n",
      "Operator 53: 4.000000000000047\n",
      "Operator 54: 4.000000000000011\n",
      "Operator 55: 3.999999999999991\n",
      "Operator 56: 4.000000000000026\n",
      "Operator 57: 4.000000000000013\n",
      "Operator 58: 2.82842712473838\n",
      "Operator 59: 3.4142135623691896\n",
      "Operator 61: 3.4142135623692083\n",
      "Operator 62: 4.000000000000041\n",
      "Operator 63: 4.000000000000027\n",
      "Operator 64: 4.000000000000046\n",
      "Operator 65: 4.000000000000025\n",
      "Operator 66: 4.000000000000025\n",
      "Operator 67: 4.000000000000013\n",
      "Operator 68: -4.000000000000002\n",
      "Operator 69: 4.000000000000047\n",
      "Operator 70: -4.000000000000011\n",
      "Operator 71: 3.999999999999991\n",
      "Operator 72: -4.000000000000026\n",
      "Operator 73: 4.000000000000013\n",
      "Operator 74: -4.0000000000000195\n",
      "Operator 75: 3.4142135623691896\n",
      "Operator 77: 3.4142135623692105\n",
      "Operator 78: -4.000000000000041\n",
      "Operator 79: 4.000000000000027\n",
      "Operator 80: -4.000000000000046\n",
      "Operator 81: 4.000000000000025\n",
      "Operator 82: -4.000000000000025\n",
      "Operator 83: 4.000000000000013\n",
      "Operator 84: -4.000000000000009\n",
      "Operator 85: -4.00000000000001\n",
      "Operator 86: 4.000000000000008\n",
      "Operator 104: -4.00000000000001\n",
      "Operator 105: 4.000000000000008\n",
      "Operator 106: -4.000000000000002\n",
      "Operator 107: 4.000000000000047\n",
      "Operator 108: -4.000000000000011\n",
      "Operator 109: 3.999999999999991\n",
      "Operator 110: -4.000000000000026\n",
      "Operator 111: 2.8284271247383765\n",
      "Operator 112: -4.0000000000000195\n",
      "Operator 113: 3.4142135623691896\n",
      "Operator 115: 3.4142135623692083\n",
      "Operator 116: -4.000000000000041\n",
      "Operator 117: 4.000000000000027\n",
      "Operator 118: -4.000000000000046\n",
      "Operator 119: 4.000000000000025\n",
      "Operator 120: -4.000000000000025\n",
      "Operator 121: 4.000000000000002\n",
      "Operator 122: -4.000000000000047\n",
      "Operator 123: 4.000000000000011\n",
      "Operator 124: -3.999999999999991\n",
      "Operator 125: 4.000000000000026\n",
      "Operator 126: -4.000000000000013\n",
      "Operator 127: 4.0000000000000195\n",
      "Operator 128: -3.4142135623691905\n",
      "Operator 130: -3.4142135623692083\n",
      "Operator 131: 4.000000000000041\n",
      "Operator 132: -4.000000000000027\n",
      "Operator 133: 4.000000000000046\n",
      "Operator 134: -4.000000000000025\n",
      "Operator 135: 4.000000000000025\n",
      "Operator 136: -4.000000000000013\n",
      "Operator 137: 4.000000000000009\n",
      "Operator 138: -4.000000000000008\n",
      "Operator 139: -4.000000000000002\n",
      "Operator 140: -4.000000000000047\n",
      "Operator 141: -4.000000000000011\n",
      "Operator 142: -3.999999999999991\n",
      "Operator 143: -4.000000000000026\n",
      "Operator 144: -4.000000000000013\n",
      "Operator 145: -4.0000000000000195\n",
      "Operator 146: -3.4142135623691905\n",
      "Operator 148: -3.4142135623692105\n",
      "Operator 149: -2.8284271247383925\n",
      "Operator 150: -4.000000000000027\n",
      "Operator 151: -4.000000000000046\n",
      "Operator 152: -4.000000000000025\n",
      "Operator 153: -4.000000000000025\n",
      "Operator 154: -4.000000000000013\n",
      "Operator 172: 4.00000000000001\n",
      "Operator 173: -4.000000000000008\n",
      "Operator 174: -4.000000000000009\n",
      "Operator 175: 4.000000000000008\n",
      "Operator 184: -1.4142135623770082\n",
      "Operator 185: 1.41421356237702\n",
      "Operator 201: 1.4142135623770118\n",
      "Operator 202: -1.4142135623770151\n",
      "Operator 218: 1.4142135623770118\n",
      "Operator 219: -1.4142135623770151\n",
      "Operator 227: -4.00000000000001\n",
      "Operator 228: -4.000000000000008\n",
      "Operator 229: -4.000000000000002\n",
      "Operator 230: -4.000000000000047\n",
      "Operator 231: -4.000000000000011\n",
      "Operator 232: -3.999999999999991\n",
      "Operator 233: -4.000000000000026\n",
      "Operator 234: -2.8284271247383765\n",
      "Operator 235: -2.82842712473838\n",
      "Operator 236: -3.4142135623691905\n",
      "Operator 238: -3.4142135623692083\n",
      "Operator 239: -4.000000000000041\n",
      "Operator 240: -4.000000000000027\n",
      "Operator 241: -4.000000000000046\n",
      "Operator 242: -4.000000000000025\n",
      "Operator 243: -4.000000000000025\n",
      "Total gradient norm: 47.642663406763035\n",
      "Operators under consideration (1):\n",
      "[243]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000025)]\n",
      "Operator(s) added to ansatz: [243]\n",
      "Gradients: [np.float64(-4.000000000000025)]\n",
      "Initial energy: -19.828427124746206\n",
      "Optimizing energy with indices [237, 243]...\n",
      "Starting point: [np.float64(0.3926990817001075), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -20.656854\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "Current energy: -20.65685424949241\n",
      "(change of -0.8284271247462058)\n",
      "Current ansatz: [237, 243]\n",
      "On iteration 2.\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 4.000000000000008\n",
      "Operator 1: 4.0000000000000515\n",
      "Operator 2: 4.000000000000017\n",
      "Operator 3: 3.9999999999999956\n",
      "Operator 4: 4.00000000000003\n",
      "Operator 5: 4.000000000000018\n",
      "Operator 6: 4.000000000000024\n",
      "Operator 7: 3.4142135619223577\n",
      "Operator 9: 3.4142135619223772\n",
      "Operator 10: 2.828427123844725\n",
      "Operator 11: 4.00000000000003\n",
      "Operator 12: 4.000000000000048\n",
      "Operator 13: 3.414213562369186\n",
      "Operator 15: 3.414213562369177\n",
      "Operator 16: 2.828427124738334\n",
      "Operator 17: 4.000000000000015\n",
      "Operator 18: -4.000000000000013\n",
      "Operator 19: 4.000000000000008\n",
      "Operator 20: -4.0000000000000515\n",
      "Operator 21: 4.000000000000017\n",
      "Operator 22: -3.9999999999999956\n",
      "Operator 23: 4.00000000000003\n",
      "Operator 24: -2.8284271238447083\n",
      "Operator 25: 4.000000000000024\n",
      "Operator 26: -3.414213561922358\n",
      "Operator 28: -3.4142135619223786\n",
      "Operator 29: 4.000000000000043\n",
      "Operator 30: -2.8284271247383472\n",
      "Operator 31: 4.000000000000048\n",
      "Operator 32: -3.414213562369184\n",
      "Operator 34: -4.000000000000013\n",
      "Operator 35: -4.000000000000008\n",
      "Operator 36: -4.0000000000000515\n",
      "Operator 37: -4.000000000000017\n",
      "Operator 38: -3.9999999999999956\n",
      "Operator 39: -4.00000000000003\n",
      "Operator 40: -4.000000000000018\n",
      "Operator 41: -2.8284271238447105\n",
      "Operator 42: -3.414213561922358\n",
      "Operator 44: -3.4142135619223786\n",
      "Operator 45: -4.000000000000043\n",
      "Operator 46: -4.00000000000003\n",
      "Operator 47: -2.828427124738359\n",
      "Operator 48: -3.414213562369184\n",
      "Operator 50: -3.4142135623691745\n",
      "Operator 51: 4.000000000000013\n",
      "Operator 52: 4.000000000000008\n",
      "Operator 53: 4.0000000000000515\n",
      "Operator 54: 4.000000000000017\n",
      "Operator 55: 3.9999999999999956\n",
      "Operator 56: 4.00000000000003\n",
      "Operator 57: 4.000000000000018\n",
      "Operator 58: 2.8284271238447105\n",
      "Operator 59: 3.4142135619223577\n",
      "Operator 61: 3.4142135619223772\n",
      "Operator 62: 4.000000000000043\n",
      "Operator 63: 4.00000000000003\n",
      "Operator 64: 2.828427124738359\n",
      "Operator 65: 3.414213562369186\n",
      "Operator 67: 3.414213562369177\n",
      "Operator 68: -4.000000000000008\n",
      "Operator 69: 4.0000000000000515\n",
      "Operator 70: -4.000000000000017\n",
      "Operator 71: 3.9999999999999956\n",
      "Operator 72: -4.00000000000003\n",
      "Operator 73: 4.000000000000018\n",
      "Operator 74: -4.000000000000024\n",
      "Operator 75: 3.4142135619223577\n",
      "Operator 77: 3.4142135619223786\n",
      "Operator 78: -4.000000000000043\n",
      "Operator 79: 4.00000000000003\n",
      "Operator 80: -4.000000000000048\n",
      "Operator 81: 3.414213562369186\n",
      "Operator 83: 3.4142135623691745\n",
      "Operator 84: -4.00000000000001\n",
      "Operator 85: -4.000000000000015\n",
      "Operator 86: 4.000000000000013\n",
      "Operator 104: -4.000000000000015\n",
      "Operator 105: 4.000000000000013\n",
      "Operator 106: -4.000000000000008\n",
      "Operator 107: 4.0000000000000515\n",
      "Operator 108: -4.000000000000017\n",
      "Operator 109: 3.9999999999999956\n",
      "Operator 110: -4.00000000000003\n",
      "Operator 111: 2.8284271238447083\n",
      "Operator 112: -4.000000000000024\n",
      "Operator 113: 3.4142135619223577\n",
      "Operator 115: 3.4142135619223772\n",
      "Operator 116: -4.000000000000043\n",
      "Operator 117: 2.8284271247383472\n",
      "Operator 118: -4.000000000000048\n",
      "Operator 119: 3.414213562369186\n",
      "Operator 121: 4.000000000000008\n",
      "Operator 122: -4.0000000000000515\n",
      "Operator 123: 4.000000000000017\n",
      "Operator 124: -3.9999999999999956\n",
      "Operator 125: 4.00000000000003\n",
      "Operator 126: -4.000000000000018\n",
      "Operator 127: 4.000000000000024\n",
      "Operator 128: -3.414213561922358\n",
      "Operator 130: -3.4142135619223772\n",
      "Operator 131: 4.000000000000043\n",
      "Operator 132: -4.00000000000003\n",
      "Operator 133: 4.000000000000048\n",
      "Operator 134: -3.414213562369184\n",
      "Operator 136: -3.414213562369177\n",
      "Operator 137: 4.00000000000001\n",
      "Operator 138: -4.000000000000013\n",
      "Operator 139: -4.000000000000008\n",
      "Operator 140: -4.0000000000000515\n",
      "Operator 141: -4.000000000000017\n",
      "Operator 142: -3.9999999999999956\n",
      "Operator 143: -4.00000000000003\n",
      "Operator 144: -4.000000000000018\n",
      "Operator 145: -4.000000000000024\n",
      "Operator 146: -3.414213561922358\n",
      "Operator 148: -3.4142135619223786\n",
      "Operator 149: -2.828427123844725\n",
      "Operator 150: -4.00000000000003\n",
      "Operator 151: -4.000000000000048\n",
      "Operator 152: -3.414213562369184\n",
      "Operator 154: -3.4142135623691745\n",
      "Operator 172: 4.000000000000015\n",
      "Operator 173: -4.000000000000013\n",
      "Operator 174: -2.828427124738334\n",
      "Operator 175: 4.000000000000013\n",
      "Operator 184: -1.4142135628238448\n",
      "Operator 185: 1.4142135628238561\n",
      "Operator 190: -1.414213562377037\n",
      "Operator 191: 1.41421356237703\n",
      "Operator 201: 1.414213562823848\n",
      "Operator 202: -1.414213562823852\n",
      "Operator 207: 1.4142135623770347\n",
      "Operator 208: -1.4142135623770355\n",
      "Operator 218: 1.4142135628238481\n",
      "Operator 219: -1.4142135628238517\n",
      "Operator 224: 1.4142135623770347\n",
      "Operator 225: -1.4142135623770355\n",
      "Operator 227: -4.000000000000015\n",
      "Operator 228: -4.000000000000013\n",
      "Operator 229: -4.000000000000008\n",
      "Operator 230: -4.0000000000000515\n",
      "Operator 231: -4.000000000000017\n",
      "Operator 232: -3.9999999999999956\n",
      "Operator 233: -4.00000000000003\n",
      "Operator 234: -2.8284271238447083\n",
      "Operator 235: -2.8284271238447105\n",
      "Operator 236: -3.414213561922358\n",
      "Operator 238: -3.4142135619223772\n",
      "Operator 239: -4.000000000000043\n",
      "Operator 240: -2.8284271247383472\n",
      "Operator 241: -2.828427124738359\n",
      "Operator 242: -3.414213562369184\n",
      "Total gradient norm: 44.81825733051242\n",
      "Operators under consideration (1):\n",
      "[230]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.0000000000000515)]\n",
      "Operator(s) added to ansatz: [230]\n",
      "Gradients: [np.float64(-4.0000000000000515)]\n",
      "Initial energy: -20.65685424949241\n",
      "Optimizing energy with indices [237, 243, 230]...\n",
      "Starting point: [np.float64(0.3926990818580877), np.float64(0.39269908170011425), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -21.485281\n",
      "         Iterations: 5\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n",
      "\n",
      "Current energy: -21.485281374238657\n",
      "(change of -0.8284271247462449)\n",
      "Current ansatz: [237, 243, 230]\n",
      "On iteration 3.\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 3.4142135603243906\n",
      "Operator 2: 3.4142135603243977\n",
      "Operator 3: 2.8284271206487577\n",
      "Operator 4: 4.000000000000037\n",
      "Operator 5: 4.000000000000025\n",
      "Operator 6: 4.000000000000029\n",
      "Operator 7: 3.414213560632173\n",
      "Operator 9: 3.4142135606321937\n",
      "Operator 10: 2.8284271212643493\n",
      "Operator 11: 4.00000000000004\n",
      "Operator 12: 4.000000000000057\n",
      "Operator 13: 3.4142135623578866\n",
      "Operator 15: 3.4142135623578778\n",
      "Operator 16: 2.8284271247157258\n",
      "Operator 17: 2.82842712064877\n",
      "Operator 18: -4.000000000000019\n",
      "Operator 19: 3.414213560324388\n",
      "Operator 21: 3.4142135603243995\n",
      "Operator 22: -3.9999999999999973\n",
      "Operator 23: 4.000000000000037\n",
      "Operator 24: -2.828427121264333\n",
      "Operator 25: 4.000000000000029\n",
      "Operator 26: -3.4142135606321737\n",
      "Operator 28: -3.4142135606321955\n",
      "Operator 29: 4.000000000000053\n",
      "Operator 30: -2.8284271247157395\n",
      "Operator 31: 4.000000000000057\n",
      "Operator 32: -3.414213562357885\n",
      "Operator 34: -2.8284271206487688\n",
      "Operator 35: -3.414213560324388\n",
      "Operator 37: -3.4142135603243995\n",
      "Operator 38: -3.9999999999999973\n",
      "Operator 39: -4.000000000000037\n",
      "Operator 40: -4.000000000000025\n",
      "Operator 41: -2.8284271212643355\n",
      "Operator 42: -3.4142135606321737\n",
      "Operator 44: -3.4142135606321955\n",
      "Operator 45: -4.000000000000053\n",
      "Operator 46: -4.00000000000004\n",
      "Operator 47: -2.828427124715752\n",
      "Operator 48: -3.414213562357885\n",
      "Operator 50: -3.4142135623578747\n",
      "Operator 51: 2.8284271206487688\n",
      "Operator 52: 3.4142135603243906\n",
      "Operator 54: 3.4142135603243977\n",
      "Operator 55: 3.9999999999999973\n",
      "Operator 56: 4.000000000000037\n",
      "Operator 57: 4.000000000000025\n",
      "Operator 58: 2.8284271212643355\n",
      "Operator 59: 3.4142135606321746\n",
      "Operator 61: 3.4142135606321937\n",
      "Operator 62: 4.000000000000053\n",
      "Operator 63: 4.00000000000004\n",
      "Operator 64: 2.828427124715752\n",
      "Operator 65: 3.4142135623578866\n",
      "Operator 67: 3.4142135623578778\n",
      "Operator 68: -3.4142135603243906\n",
      "Operator 70: -3.4142135603243995\n",
      "Operator 71: 3.9999999999999973\n",
      "Operator 72: -4.000000000000037\n",
      "Operator 73: 4.000000000000025\n",
      "Operator 74: -4.000000000000029\n",
      "Operator 75: 3.414213560632173\n",
      "Operator 77: 3.4142135606321955\n",
      "Operator 78: -4.000000000000053\n",
      "Operator 79: 4.00000000000004\n",
      "Operator 80: -4.000000000000057\n",
      "Operator 81: 3.4142135623578866\n",
      "Operator 83: 3.4142135623578747\n",
      "Operator 84: -4.0000000000000195\n",
      "Operator 85: -4.000000000000023\n",
      "Operator 86: 4.000000000000019\n",
      "Operator 104: -2.82842712064877\n",
      "Operator 105: 4.000000000000019\n",
      "Operator 106: -3.4142135603243906\n",
      "Operator 108: -3.4142135603243977\n",
      "Operator 109: 3.9999999999999973\n",
      "Operator 110: -4.000000000000037\n",
      "Operator 111: 2.828427121264333\n",
      "Operator 112: -4.000000000000029\n",
      "Operator 113: 3.4142135606321746\n",
      "Operator 115: 3.4142135606321937\n",
      "Operator 116: -4.000000000000053\n",
      "Operator 117: 2.8284271247157395\n",
      "Operator 118: -4.000000000000057\n",
      "Operator 119: 3.4142135623578866\n",
      "Operator 121: 3.414213560324388\n",
      "Operator 123: 3.4142135603243977\n",
      "Operator 124: -3.9999999999999973\n",
      "Operator 125: 4.000000000000037\n",
      "Operator 126: -4.000000000000025\n",
      "Operator 127: 4.000000000000029\n",
      "Operator 128: -3.4142135606321737\n",
      "Operator 130: -3.4142135606321937\n",
      "Operator 131: 4.000000000000053\n",
      "Operator 132: -4.00000000000004\n",
      "Operator 133: 4.000000000000057\n",
      "Operator 134: -3.4142135623578858\n",
      "Operator 136: -3.4142135623578778\n",
      "Operator 137: 4.0000000000000195\n",
      "Operator 138: -4.000000000000019\n",
      "Operator 139: -3.414213560324388\n",
      "Operator 141: -3.4142135603243995\n",
      "Operator 142: -2.8284271206487577\n",
      "Operator 143: -4.000000000000037\n",
      "Operator 144: -4.000000000000025\n",
      "Operator 145: -4.000000000000029\n",
      "Operator 146: -3.4142135606321737\n",
      "Operator 148: -3.4142135606321955\n",
      "Operator 149: -2.8284271212643493\n",
      "Operator 150: -4.00000000000004\n",
      "Operator 151: -4.000000000000057\n",
      "Operator 152: -3.4142135623578858\n",
      "Operator 154: -3.4142135623578747\n",
      "Operator 172: 4.000000000000023\n",
      "Operator 173: -4.000000000000019\n",
      "Operator 174: -2.8284271247157258\n",
      "Operator 175: 4.000000000000019\n",
      "Operator 177: -1.414213564421818\n",
      "Operator 178: 1.414213564421821\n",
      "Operator 184: -1.414213564114038\n",
      "Operator 185: 1.4142135641140499\n",
      "Operator 190: -1.414213562388347\n",
      "Operator 191: 1.4142135623883392\n",
      "Operator 194: 1.4142135644218135\n",
      "Operator 195: -1.414213564421818\n",
      "Operator 201: 1.4142135641140412\n",
      "Operator 202: -1.4142135641140454\n",
      "Operator 207: 1.4142135623883445\n",
      "Operator 208: -1.4142135623883447\n",
      "Operator 211: 1.4142135644218137\n",
      "Operator 212: -1.4142135644218177\n",
      "Operator 218: 1.4142135641140414\n",
      "Operator 219: -1.4142135641140456\n",
      "Operator 224: 1.4142135623883445\n",
      "Operator 225: -1.4142135623883447\n",
      "Operator 227: -2.82842712064877\n",
      "Operator 228: -2.8284271206487688\n",
      "Operator 229: -3.414213560324388\n",
      "Operator 231: -3.4142135603243977\n",
      "Operator 232: -3.9999999999999973\n",
      "Operator 233: -4.000000000000037\n",
      "Operator 234: -2.828427121264333\n",
      "Operator 235: -2.8284271212643355\n",
      "Operator 236: -3.4142135606321737\n",
      "Operator 238: -3.4142135606321937\n",
      "Operator 239: -4.000000000000053\n",
      "Operator 240: -2.8284271247157395\n",
      "Operator 241: -2.828427124715752\n",
      "Operator 242: -3.4142135623578858\n",
      "Total gradient norm: 41.64732363522267\n",
      "Operators under consideration (1):\n",
      "[239]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000053)]\n",
      "Operator(s) added to ansatz: [239]\n",
      "Gradients: [np.float64(-4.000000000000053)]\n",
      "Initial energy: -21.485281374238657\n",
      "Optimizing energy with indices [237, 243, 230, 239]...\n",
      "Starting point: [np.float64(0.39269908231423856), np.float64(0.39269908170411216), np.float64(0.3926990824230555), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -22.420152\n",
      "         Iterations: 6\n",
      "         Function evaluations: 56\n",
      "         Gradient evaluations: 51\n",
      "\n",
      "Current energy: -22.420152078047067\n",
      "(change of -0.9348707038084108)\n",
      "Current ansatz: [237, 243, 230, 239]\n",
      "On iteration 4.\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 3.4142135915607605\n",
      "Operator 1: 1.1675064702076733e-07\n",
      "Operator 2: 3.4142135915607663\n",
      "Operator 3: 2.828427183121494\n",
      "Operator 4: 4.000000000000041\n",
      "Operator 5: 4.000000000000027\n",
      "Operator 6: 4.000000000000034\n",
      "Operator 7: 3.2645854456342907\n",
      "Operator 9: 2.7995881746527407\n",
      "Operator 10: -0.9299945419499538\n",
      "Operator 11: 3.2645854456306553\n",
      "Operator 12: 2.529170891261288\n",
      "Operator 13: 3.414213562755344\n",
      "Operator 15: 3.4142135627553327\n",
      "Operator 16: 2.828427125510638\n",
      "Operator 17: 2.828427183121507\n",
      "Operator 18: -4.000000000000023\n",
      "Operator 19: 3.4142135915607574\n",
      "Operator 20: -1.1675064702076733e-07\n",
      "Operator 21: 3.4142135915607694\n",
      "Operator 22: -4.000000000000003\n",
      "Operator 23: 4.000000000000041\n",
      "Operator 24: -2.529170891268564\n",
      "Operator 25: 4.000000000000034\n",
      "Operator 26: -2.0641736202833467\n",
      "Operator 28: -2.7995881746527407\n",
      "Operator 30: -2.3084105069922365\n",
      "Operator 31: 4.000000000000055\n",
      "Operator 32: -3.414213562755342\n",
      "Operator 34: -2.8284271831215047\n",
      "Operator 35: -3.4142135915607574\n",
      "Operator 36: -1.1675064702076733e-07\n",
      "Operator 37: -3.4142135915607694\n",
      "Operator 38: -4.000000000000003\n",
      "Operator 39: -4.000000000000041\n",
      "Operator 40: -4.000000000000027\n",
      "Operator 41: -2.5291708912685675\n",
      "Operator 42: -3.2645854456342915\n",
      "Operator 43: 0.9299945419422866\n",
      "Operator 44: -2.7995881746527407\n",
      "Operator 46: -3.264585445630659\n",
      "Operator 47: -2.8284271255106637\n",
      "Operator 48: -3.414213562755342\n",
      "Operator 50: -3.414213562755331\n",
      "Operator 51: 2.8284271831215047\n",
      "Operator 52: 3.4142135915607605\n",
      "Operator 53: 1.1675064742196116e-07\n",
      "Operator 54: 3.4142135915607663\n",
      "Operator 55: 4.000000000000003\n",
      "Operator 56: 4.000000000000041\n",
      "Operator 57: 4.000000000000027\n",
      "Operator 58: 2.5291708912685675\n",
      "Operator 59: 3.2645854456342907\n",
      "Operator 60: -0.9299945419422879\n",
      "Operator 61: 2.7995881746527407\n",
      "Operator 63: 3.2645854456306553\n",
      "Operator 64: 2.8284271255106637\n",
      "Operator 65: 3.4142135627553434\n",
      "Operator 67: 3.4142135627553327\n",
      "Operator 68: -3.4142135915607605\n",
      "Operator 69: 1.1675064702076733e-07\n",
      "Operator 70: -3.4142135915607694\n",
      "Operator 71: 4.000000000000003\n",
      "Operator 72: -4.000000000000041\n",
      "Operator 73: 4.000000000000027\n",
      "Operator 74: -4.000000000000034\n",
      "Operator 75: 3.2645854456342907\n",
      "Operator 77: 2.529170891264928\n",
      "Operator 79: 3.264585445630659\n",
      "Operator 80: -4.000000000000055\n",
      "Operator 81: 3.414213562755344\n",
      "Operator 83: 3.414213562755331\n",
      "Operator 84: -4.000000000000017\n",
      "Operator 85: -4.000000000000026\n",
      "Operator 86: 4.000000000000023\n",
      "Operator 97: 1.2004118253473046\n",
      "Operator 104: -2.828427183121507\n",
      "Operator 105: 4.000000000000023\n",
      "Operator 106: -3.4142135915607605\n",
      "Operator 107: 1.1675064742196116e-07\n",
      "Operator 108: -3.4142135915607663\n",
      "Operator 109: 4.000000000000003\n",
      "Operator 110: -4.000000000000041\n",
      "Operator 111: 2.529170891268564\n",
      "Operator 112: -4.000000000000034\n",
      "Operator 113: 2.064173620283346\n",
      "Operator 115: 2.7995881746527407\n",
      "Operator 117: 2.308410506992235\n",
      "Operator 118: -4.000000000000055\n",
      "Operator 119: 3.4142135627553434\n",
      "Operator 121: 3.4142135915607574\n",
      "Operator 122: -1.1675064742196116e-07\n",
      "Operator 123: 3.4142135915607663\n",
      "Operator 124: -4.000000000000003\n",
      "Operator 125: 4.000000000000041\n",
      "Operator 126: -4.000000000000027\n",
      "Operator 127: 4.000000000000034\n",
      "Operator 128: -3.2645854456342915\n",
      "Operator 130: -2.5291708912649242\n",
      "Operator 132: -3.2645854456306553\n",
      "Operator 133: 4.000000000000055\n",
      "Operator 134: -3.414213562755342\n",
      "Operator 136: -3.4142135627553327\n",
      "Operator 137: 4.000000000000017\n",
      "Operator 138: -4.000000000000023\n",
      "Operator 139: -3.4142135915607574\n",
      "Operator 140: -1.1675064742196116e-07\n",
      "Operator 141: -3.4142135915607694\n",
      "Operator 142: -2.828427183121494\n",
      "Operator 143: -4.000000000000041\n",
      "Operator 144: -4.000000000000027\n",
      "Operator 145: -4.000000000000034\n",
      "Operator 146: -3.2645854456342915\n",
      "Operator 148: -2.7995881746527407\n",
      "Operator 149: 0.9299945419499538\n",
      "Operator 150: -3.264585445630659\n",
      "Operator 151: -2.529170891261288\n",
      "Operator 152: -3.414213562755342\n",
      "Operator 154: -3.414213562755331\n",
      "Operator 165: 1.2004118253473046\n",
      "Operator 172: 4.000000000000026\n",
      "Operator 173: -4.000000000000023\n",
      "Operator 174: -2.828427125510638\n",
      "Operator 175: 4.000000000000023\n",
      "Operator 177: -1.4142135331854506\n",
      "Operator 178: 1.414213533185455\n",
      "Operator 184: -1.5494591477964135\n",
      "Operator 185: 1.5494591477964252\n",
      "Operator 186: -1.5494591477994022\n",
      "Operator 187: 1.5494591477994017\n",
      "Operator 190: -1.41421356199089\n",
      "Operator 191: 1.414213561990882\n",
      "Operator 194: 1.4142135331854462\n",
      "Operator 195: -1.4142135331854508\n",
      "Operator 201: 1.5494591477964161\n",
      "Operator 202: -0.9797117434512915\n",
      "Operator 203: 1.5494591477993989\n",
      "Operator 204: -0.9797117434559997\n",
      "Operator 207: 1.4142135619908875\n",
      "Operator 208: -1.4142135619908878\n",
      "Operator 211: 1.4142135331854466\n",
      "Operator 212: -1.4142135331854508\n",
      "Operator 218: 1.5494591477964161\n",
      "Operator 219: -1.5494591477964232\n",
      "Operator 220: 1.5494591477993986\n",
      "Operator 221: -1.5494591477993929\n",
      "Operator 224: 1.4142135619908875\n",
      "Operator 225: -1.4142135619908875\n",
      "Operator 227: -2.828427183121507\n",
      "Operator 228: -2.8284271831215047\n",
      "Operator 229: -3.4142135915607574\n",
      "Operator 230: -1.1675064742196116e-07\n",
      "Operator 231: -3.4142135915607663\n",
      "Operator 232: -4.000000000000003\n",
      "Operator 233: -4.000000000000041\n",
      "Operator 234: -2.529170891268564\n",
      "Operator 235: -2.5291708912685675\n",
      "Operator 236: -2.0641736202833467\n",
      "Operator 237: 0.9299945419422879\n",
      "Operator 238: -2.5291708912649242\n",
      "Operator 240: -2.308410506992235\n",
      "Operator 241: -2.8284271255106637\n",
      "Operator 242: -3.414213562755342\n",
      "Operator 254: -1.2004118253473042\n",
      "Total gradient norm: 38.64324486463792\n",
      "Operators under consideration (1):\n",
      "[173]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000023)]\n",
      "Operator(s) added to ansatz: [173]\n",
      "Gradients: [np.float64(-4.000000000000023)]\n",
      "Initial energy: -22.420152078047067\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173]...\n",
      "Starting point: [np.float64(0.44314364577819504), np.float64(0.3926990815635902), np.float64(0.3926990713793306), np.float64(0.44314364577937193), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -23.355023\n",
      "         Iterations: 7\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 11\n",
      "\n",
      "Current energy: -23.355022781855467\n",
      "(change of -0.9348707038084001)\n",
      "Current ansatz: [237, 243, 230, 239, 173]\n",
      "On iteration 5.\n",
      "\n",
      "*** ADAPT-VQE Iteration 6 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 2.799588174967827\n",
      "Operator 1: -0.9299945408779817\n",
      "Operator 2: 3.2645854460235575\n",
      "Operator 3: 2.5291708920470763\n",
      "Operator 4: 4.000000000000039\n",
      "Operator 5: 4.000000000000027\n",
      "Operator 6: 4.0000000000000355\n",
      "Operator 7: 3.2645854454512055\n",
      "Operator 9: 2.7995881746711544\n",
      "Operator 10: -0.9299945414885868\n",
      "Operator 11: 3.264585445842862\n",
      "Operator 12: 2.5291708916856988\n",
      "Operator 13: 3.4142135621985106\n",
      "Operator 15: 3.4142135621984995\n",
      "Operator 16: 2.8284271243969696\n",
      "Operator 17: 2.0641736209913617\n",
      "Operator 19: 2.7995881749678286\n",
      "Operator 21: 3.2645854460235584\n",
      "Operator 22: -4.000000000000001\n",
      "Operator 23: 4.000000000000039\n",
      "Operator 24: -2.5291708909023933\n",
      "Operator 25: 4.0000000000000355\n",
      "Operator 26: -2.0641736205139627\n",
      "Operator 28: -2.7995881746711544\n",
      "Operator 30: -2.308410506233374\n",
      "Operator 31: 4.000000000000058\n",
      "Operator 32: -3.414213562198509\n",
      "Operator 34: 0.9299945414759916\n",
      "Operator 35: -2.7995881749678286\n",
      "Operator 37: -3.2645854460235584\n",
      "Operator 38: -4.000000000000001\n",
      "Operator 39: -4.000000000000039\n",
      "Operator 40: -4.000000000000027\n",
      "Operator 41: -2.5291708909023978\n",
      "Operator 42: -3.2645854454512073\n",
      "Operator 43: 0.929994542313769\n",
      "Operator 44: -2.7995881746711544\n",
      "Operator 46: -3.2645854458428656\n",
      "Operator 47: -2.828427124396998\n",
      "Operator 48: -3.414213562198509\n",
      "Operator 50: -3.4142135621984977\n",
      "Operator 51: -0.9299945414759916\n",
      "Operator 52: 2.799588174967827\n",
      "Operator 54: 3.2645854460235584\n",
      "Operator 55: 4.000000000000001\n",
      "Operator 56: 4.000000000000039\n",
      "Operator 57: 4.000000000000027\n",
      "Operator 58: 2.5291708909023978\n",
      "Operator 59: 3.2645854454512055\n",
      "Operator 60: -0.9299945423137672\n",
      "Operator 61: 2.7995881746711544\n",
      "Operator 63: 3.264585445842862\n",
      "Operator 64: 2.828427124396998\n",
      "Operator 65: 3.4142135621985106\n",
      "Operator 67: 3.414213562198499\n",
      "Operator 68: -2.529170891763263\n",
      "Operator 70: -3.2645854460235584\n",
      "Operator 71: 4.000000000000001\n",
      "Operator 72: -4.000000000000039\n",
      "Operator 73: 4.000000000000027\n",
      "Operator 74: -4.0000000000000355\n",
      "Operator 75: 3.2645854454512055\n",
      "Operator 77: 2.529170891294049\n",
      "Operator 79: 3.2645854458428656\n",
      "Operator 80: -4.000000000000058\n",
      "Operator 81: 3.4142135621985106\n",
      "Operator 83: 3.4142135621984977\n",
      "Operator 84: -4.000000000000016\n",
      "Operator 85: -3.264585445739736\n",
      "Operator 88: 1.200411825032195\n",
      "Operator 97: 1.2004118253288933\n",
      "Operator 104: -2.064173620991363\n",
      "Operator 106: -2.799588174967827\n",
      "Operator 108: -3.2645854460235584\n",
      "Operator 109: 4.000000000000001\n",
      "Operator 110: -4.000000000000039\n",
      "Operator 111: 2.5291708909023933\n",
      "Operator 112: -4.0000000000000355\n",
      "Operator 113: 2.064173620513962\n",
      "Operator 115: 2.7995881746711544\n",
      "Operator 117: 2.3084105062333724\n",
      "Operator 118: -4.000000000000058\n",
      "Operator 119: 3.4142135621985106\n",
      "Operator 121: 2.529170891763259\n",
      "Operator 123: 3.2645854460235584\n",
      "Operator 124: -4.000000000000001\n",
      "Operator 125: 4.000000000000039\n",
      "Operator 126: -4.000000000000027\n",
      "Operator 127: 4.0000000000000355\n",
      "Operator 128: -3.2645854454512078\n",
      "Operator 130: -2.5291708912940436\n",
      "Operator 132: -3.264585445842862\n",
      "Operator 133: 4.000000000000058\n",
      "Operator 134: -3.4142135621985097\n",
      "Operator 136: -3.414213562198499\n",
      "Operator 137: 4.000000000000016\n",
      "Operator 139: -2.7995881749678286\n",
      "Operator 140: 0.9299945408779818\n",
      "Operator 141: -3.2645854460235584\n",
      "Operator 142: -2.5291708920470763\n",
      "Operator 143: -4.000000000000039\n",
      "Operator 144: -4.000000000000027\n",
      "Operator 145: -4.0000000000000355\n",
      "Operator 146: -3.2645854454512078\n",
      "Operator 148: -2.7995881746711544\n",
      "Operator 149: 0.9299945414885871\n",
      "Operator 150: -3.2645854458428656\n",
      "Operator 151: -2.5291708916856988\n",
      "Operator 152: -3.4142135621985097\n",
      "Operator 154: -3.4142135621984977\n",
      "Operator 156: 1.200411825032195\n",
      "Operator 165: 1.2004118253288933\n",
      "Operator 172: 3.264585445739736\n",
      "Operator 174: -2.8284271243969696\n",
      "Operator 176: 1.5494591477103632\n",
      "Operator 177: -1.5494591474787214\n",
      "Operator 178: 1.549459147478722\n",
      "Operator 184: -1.5494591479458377\n",
      "Operator 185: 1.5494591479458502\n",
      "Operator 186: -1.5494591476262132\n",
      "Operator 187: 1.5494591476262136\n",
      "Operator 190: -1.4142135625477246\n",
      "Operator 191: 1.4142135625477157\n",
      "Operator 193: -0.9797117437012679\n",
      "Operator 194: 1.5494591474787187\n",
      "Operator 195: -0.9797117433349264\n",
      "Operator 201: 1.549459147945841\n",
      "Operator 202: -0.979711743710173\n",
      "Operator 203: 1.5494591476262096\n",
      "Operator 204: -0.9797117432046529\n",
      "Operator 207: 1.4142135625477221\n",
      "Operator 208: -1.4142135625477215\n",
      "Operator 210: -1.5494591477103556\n",
      "Operator 211: 1.5494591474787183\n",
      "Operator 212: -1.549459147478719\n",
      "Operator 218: 1.5494591479458408\n",
      "Operator 219: -1.549459147945848\n",
      "Operator 220: 1.5494591476262096\n",
      "Operator 221: -1.5494591476262045\n",
      "Operator 224: 1.4142135625477221\n",
      "Operator 225: -1.4142135625477212\n",
      "Operator 227: -2.0641736209913617\n",
      "Operator 228: 0.9299945414759914\n",
      "Operator 229: -2.529170891763259\n",
      "Operator 231: -3.2645854460235584\n",
      "Operator 232: -4.000000000000001\n",
      "Operator 233: -4.000000000000039\n",
      "Operator 234: -2.5291708909023933\n",
      "Operator 235: -2.5291708909023978\n",
      "Operator 236: -2.0641736205139627\n",
      "Operator 237: 0.9299945423137672\n",
      "Operator 238: -2.5291708912940436\n",
      "Operator 240: -2.3084105062333724\n",
      "Operator 241: -2.828427124396998\n",
      "Operator 242: -3.4142135621985097\n",
      "Operator 245: -1.2004118250321962\n",
      "Operator 254: -1.200411825328893\n",
      "Total gradient norm: 36.27498684176697\n",
      "Operators under consideration (1):\n",
      "[233]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000039)]\n",
      "Operator(s) added to ansatz: [233]\n",
      "Gradients: [np.float64(-4.000000000000039)]\n",
      "Initial energy: -23.355022781855467\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233]...\n",
      "Starting point: [np.float64(0.4431436458372755), np.float64(0.39269908176046087), np.float64(0.44314364565258135), np.float64(0.44314364571089504), np.float64(0.4431436457441695), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -24.183450\n",
      "         Iterations: 5\n",
      "         Function evaluations: 70\n",
      "         Gradient evaluations: 58\n",
      "\n",
      "Current energy: -24.183449906601798\n",
      "(change of -0.8284271247463302)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233]\n",
      "On iteration 6.\n",
      "\n",
      "*** ADAPT-VQE Iteration 7 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 2.799588166905677\n",
      "Operator 1: -0.9299945612422822\n",
      "Operator 2: 3.2645854393226537\n",
      "Operator 3: 2.158782371075444\n",
      "Operator 4: -4.923025773806863e-08\n",
      "Operator 5: 3.414213550065579\n",
      "Operator 6: 2.828427100131115\n",
      "Operator 7: 3.2645854454001446\n",
      "Operator 9: 2.7995881740383552\n",
      "Operator 10: -0.9299945439798922\n",
      "Operator 11: 3.2645854448931315\n",
      "Operator 12: 2.5291708897862173\n",
      "Operator 13: 3.4142135601957015\n",
      "Operator 15: 3.41421356019569\n",
      "Operator 16: 2.828427120391328\n",
      "Operator 17: 2.0641736062282887\n",
      "Operator 18: 1.4899734460066626e-08\n",
      "Operator 19: 2.7995881669056795\n",
      "Operator 20: 1.1602441933827724e-08\n",
      "Operator 21: 3.2645854393226554\n",
      "Operator 22: -3.414213550065556\n",
      "Operator 23: -4.923025773806863e-08\n",
      "Operator 24: -2.1587823814503837\n",
      "Operator 25: 4.000000000000055\n",
      "Operator 26: -2.0641736189314104\n",
      "Operator 28: -2.7995881740383544\n",
      "Operator 30: -2.3084105022926096\n",
      "Operator 31: 4.000000000000083\n",
      "Operator 32: -3.4142135601957\n",
      "Operator 34: 0.9299945604683526\n",
      "Operator 35: -2.7995881669056795\n",
      "Operator 36: 1.6408330669969782e-08\n",
      "Operator 37: -2.3084104818183797\n",
      "Operator 38: -3.414213550065556\n",
      "Operator 39: 4.923025773806863e-08\n",
      "Operator 40: -3.4142135500655786\n",
      "Operator 41: -2.5291708908002524\n",
      "Operator 42: -3.2645854454001464\n",
      "Operator 43: 0.9299945429116574\n",
      "Operator 44: -2.7995881740383544\n",
      "Operator 46: -3.2645854448931377\n",
      "Operator 47: -2.828427120391356\n",
      "Operator 48: -3.4142135601957\n",
      "Operator 50: -3.4142135601956873\n",
      "Operator 51: -0.9299945604683526\n",
      "Operator 52: 2.7995881669056772\n",
      "Operator 53: -1.6408330669969782e-08\n",
      "Operator 54: 2.3084104818183775\n",
      "Operator 55: 3.414213550065556\n",
      "Operator 56: -4.923025773806863e-08\n",
      "Operator 57: 3.414213550065579\n",
      "Operator 58: 2.5291708908002524\n",
      "Operator 59: 3.2645854454001446\n",
      "Operator 60: -0.9299945429116558\n",
      "Operator 61: 2.7995881740383552\n",
      "Operator 63: 3.2645854448931315\n",
      "Operator 64: 2.828427120391356\n",
      "Operator 65: 3.4142135601957015\n",
      "Operator 67: 3.4142135601956896\n",
      "Operator 68: -2.529170879012594\n",
      "Operator 69: -1.6408330779101642e-08\n",
      "Operator 70: -3.2645854393226554\n",
      "Operator 71: 3.414213550065556\n",
      "Operator 72: 4.923025773806863e-08\n",
      "Operator 73: 3.4142135500655786\n",
      "Operator 74: -4.000000000000055\n",
      "Operator 75: 3.2645854454001446\n",
      "Operator 77: 2.5291708902932353\n",
      "Operator 79: 3.2645854448931377\n",
      "Operator 80: -4.000000000000083\n",
      "Operator 81: 3.4142135601957015\n",
      "Operator 83: 3.4142135601956873\n",
      "Operator 84: -4.000000000000041\n",
      "Operator 85: -3.264585439689989\n",
      "Operator 86: -1.489973452265206e-08\n",
      "Operator 88: 1.2004118330943645\n",
      "Operator 97: 1.200411825961716\n",
      "Operator 104: -2.0641736062282883\n",
      "Operator 105: -1.4899734453013475e-08\n",
      "Operator 106: -2.7995881669056772\n",
      "Operator 107: -1.1602442197295338e-08\n",
      "Operator 108: -3.264585439322653\n",
      "Operator 109: 3.414213550065556\n",
      "Operator 110: 4.923025773806863e-08\n",
      "Operator 111: 2.1587823814503837\n",
      "Operator 112: -4.000000000000055\n",
      "Operator 113: 2.0641736189314095\n",
      "Operator 115: 2.7995881740383552\n",
      "Operator 117: 2.308410502292606\n",
      "Operator 118: -4.000000000000083\n",
      "Operator 119: 3.4142135601957015\n",
      "Operator 121: 2.529170879012587\n",
      "Operator 122: 1.6408330669969782e-08\n",
      "Operator 123: 3.264585439322653\n",
      "Operator 124: -3.414213550065556\n",
      "Operator 125: -4.923025773806863e-08\n",
      "Operator 126: -3.414213550065579\n",
      "Operator 127: 4.000000000000055\n",
      "Operator 128: -3.2645854454001464\n",
      "Operator 130: -2.5291708902932317\n",
      "Operator 132: -3.2645854448931315\n",
      "Operator 133: 4.000000000000083\n",
      "Operator 134: -3.4142135601957\n",
      "Operator 136: -3.4142135601956896\n",
      "Operator 137: 4.000000000000041\n",
      "Operator 138: 1.4899734380583625e-08\n",
      "Operator 139: -2.7995881669056795\n",
      "Operator 140: 0.9299945612422824\n",
      "Operator 141: -3.2645854393226554\n",
      "Operator 142: -2.1587823710754446\n",
      "Operator 143: 4.923025773806863e-08\n",
      "Operator 144: -3.4142135500655786\n",
      "Operator 145: -2.828427100131115\n",
      "Operator 146: -3.2645854454001464\n",
      "Operator 148: -2.799588174038354\n",
      "Operator 149: 0.9299945439798922\n",
      "Operator 150: -3.2645854448931373\n",
      "Operator 151: -2.5291708897862173\n",
      "Operator 152: -3.4142135601957\n",
      "Operator 154: -3.4142135601956873\n",
      "Operator 156: 1.2004118330943645\n",
      "Operator 165: 1.200411825961716\n",
      "Operator 172: 3.264585439689989\n",
      "Operator 173: 1.4899734380583625e-08\n",
      "Operator 174: -2.828427120391328\n",
      "Operator 175: -1.489973452265206e-08\n",
      "Operator 176: 1.5494591526478625\n",
      "Operator 177: -1.549459152947659\n",
      "Operator 178: 1.5494591529476607\n",
      "Operator 180: -1.4142135746806623\n",
      "Operator 181: 1.4142135746806688\n",
      "Operator 184: -1.5494591479875346\n",
      "Operator 185: 1.5494591479875468\n",
      "Operator 186: -1.549459148401356\n",
      "Operator 187: 1.5494591484013558\n",
      "Operator 190: -1.414213564550563\n",
      "Operator 191: 1.4142135645505542\n",
      "Operator 193: -0.9797117416318132\n",
      "Operator 194: 1.5494591529476571\n",
      "Operator 195: -0.9797117421059656\n",
      "Operator 197: 0.8941969473167766\n",
      "Operator 198: -1.4142135746806717\n",
      "Operator 201: 1.549459147987537\n",
      "Operator 202: -0.979711743000739\n",
      "Operator 203: 1.5494591484013525\n",
      "Operator 204: -0.9797117436551968\n",
      "Operator 207: 1.4142135645505602\n",
      "Operator 208: -1.4142135645505596\n",
      "Operator 210: -1.5494591526478563\n",
      "Operator 211: 1.5494591529476571\n",
      "Operator 212: -1.549459152947657\n",
      "Operator 214: 1.4142135746806597\n",
      "Operator 215: -1.4142135746806717\n",
      "Operator 218: 1.549459147987537\n",
      "Operator 219: -1.549459147987545\n",
      "Operator 220: 1.5494591484013525\n",
      "Operator 221: -1.549459148401347\n",
      "Operator 224: 1.4142135645505607\n",
      "Operator 225: -1.4142135645505596\n",
      "Operator 227: -2.0641736062282887\n",
      "Operator 228: 0.9299945604683526\n",
      "Operator 229: -2.529170879012587\n",
      "Operator 230: 1.1602442197295338e-08\n",
      "Operator 231: -2.3084104818183775\n",
      "Operator 232: -3.414213550065556\n",
      "Operator 233: 4.923025773806863e-08\n",
      "Operator 234: -2.1587823814503837\n",
      "Operator 235: -2.5291708908002524\n",
      "Operator 236: -2.0641736189314104\n",
      "Operator 237: 0.9299945429116558\n",
      "Operator 238: -2.5291708902932317\n",
      "Operator 240: -2.308410502292606\n",
      "Operator 241: -2.828427120391356\n",
      "Operator 242: -3.4142135601957\n",
      "Operator 245: -1.200411833094366\n",
      "Operator 254: -1.2004118259617154\n",
      "Total gradient norm: 32.947613931214725\n",
      "Operators under consideration (1):\n",
      "[137]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000041)]\n",
      "Operator(s) added to ansatz: [137]\n",
      "Gradients: [np.float64(4.000000000000041)]\n",
      "Initial energy: -24.183449906601798\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137]...\n",
      "Starting point: [np.float64(0.4431436458537585), np.float64(0.3926990824685679), np.float64(0.44314364781492405), np.float64(0.4431436460173722), np.float64(0.443143647696387), np.float64(0.3926990860501033), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -25.650058\n",
      "         Iterations: 13\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 18\n",
      "\n",
      "Current energy: -25.65005834003748\n",
      "(change of -1.466608433435681)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137]\n",
      "On iteration 7.\n",
      "\n",
      "*** ADAPT-VQE Iteration 8 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 2.7995881746411055\n",
      "Operator 1: -0.929994542975662\n",
      "Operator 2: 3.2645854451480565\n",
      "Operator 3: 2.1587823888022926\n",
      "Operator 5: 3.4142135623735044\n",
      "Operator 6: 2.828427124747006\n",
      "Operator 7: 3.264585445332452\n",
      "Operator 9: 2.799588174709558\n",
      "Operator 10: -0.9299945410806373\n",
      "Operator 11: 3.2645854460223434\n",
      "Operator 12: 2.529170892044681\n",
      "Operator 13: 3.064340040958016\n",
      "Operator 15: 2.273682090844181\n",
      "Operator 16: -1.3853852953593098\n",
      "Operator 17: 2.064173619789158\n",
      "Operator 19: 2.7995881746411078\n",
      "Operator 21: 3.2645854451480583\n",
      "Operator 22: -3.414213562373482\n",
      "Operator 24: -2.1587823891170927\n",
      "Operator 25: 4.000000000000016\n",
      "Operator 26: -2.064173620731868\n",
      "Operator 28: -2.799588174709557\n",
      "Operator 30: -1.7373145036651587\n",
      "Operator 31: 4.00000000000004\n",
      "Operator 32: -0.7879577552227188\n",
      "Operator 34: 0.9299945409731646\n",
      "Operator 35: -2.7995881746411078\n",
      "Operator 37: -2.308410506027754\n",
      "Operator 38: -3.414213562373482\n",
      "Operator 40: -3.4142135623735044\n",
      "Operator 41: -2.529170890664906\n",
      "Operator 42: -3.264585445332454\n",
      "Operator 43: 0.929994542534178\n",
      "Operator 44: -2.799588174709557\n",
      "Operator 46: -3.2645854460223473\n",
      "Operator 47: -2.1286800819160216\n",
      "Operator 48: -3.0643400409580135\n",
      "Operator 49: 1.5813159002623531\n",
      "Operator 50: -2.2736820908441806\n",
      "Operator 51: -0.9299945409731643\n",
      "Operator 52: 2.7995881746411064\n",
      "Operator 54: 2.3084105060277533\n",
      "Operator 55: 3.414213562373484\n",
      "Operator 57: 3.4142135623735053\n",
      "Operator 58: 2.529170890664906\n",
      "Operator 59: 3.264585445332453\n",
      "Operator 60: -0.9299945425341778\n",
      "Operator 61: 2.799588174709559\n",
      "Operator 63: 3.2645854460223434\n",
      "Operator 64: 2.1286800819160216\n",
      "Operator 65: 3.064340040958016\n",
      "Operator 66: -1.5813159002623531\n",
      "Operator 67: 2.273682090844181\n",
      "Operator 68: -2.5291708912465487\n",
      "Operator 70: -3.2645854451480583\n",
      "Operator 71: 3.414213562373484\n",
      "Operator 73: 3.4142135623735044\n",
      "Operator 74: -4.000000000000016\n",
      "Operator 75: 3.264585445332452\n",
      "Operator 77: 2.5291708913547946\n",
      "Operator 79: 3.2645854460223473\n",
      "Operator 80: -4.00000000000004\n",
      "Operator 81: 3.064340040958016\n",
      "Operator 83: 1.5786157053365382\n",
      "Operator 85: -3.264585446098504\n",
      "Operator 88: 1.2004118253588976\n",
      "Operator 97: 1.2004118252904714\n",
      "Operator 103: 1.6363382000950741\n",
      "Operator 104: -2.064173619789158\n",
      "Operator 106: -2.7995881746411064\n",
      "Operator 108: -3.2645854451480565\n",
      "Operator 109: 3.414213562373484\n",
      "Operator 111: 2.1587823891170927\n",
      "Operator 112: -4.000000000000016\n",
      "Operator 113: 2.064173620731867\n",
      "Operator 115: 2.799588174709559\n",
      "Operator 117: 1.7373145036651567\n",
      "Operator 118: -4.00000000000004\n",
      "Operator 119: 0.7879577552227197\n",
      "Operator 121: 2.5291708912465434\n",
      "Operator 123: 3.2645854451480565\n",
      "Operator 124: -3.4142135623734835\n",
      "Operator 126: -3.4142135623735053\n",
      "Operator 127: 4.000000000000016\n",
      "Operator 128: -3.264585445332454\n",
      "Operator 130: -2.5291708913547906\n",
      "Operator 132: -3.2645854460223434\n",
      "Operator 133: 4.00000000000004\n",
      "Operator 134: -3.0643400409580135\n",
      "Operator 136: -1.5786157053365422\n",
      "Operator 139: -2.7995881746411078\n",
      "Operator 140: 0.929994542975662\n",
      "Operator 141: -3.264585445148059\n",
      "Operator 142: -2.1587823888022926\n",
      "Operator 144: -3.4142135623735026\n",
      "Operator 145: -2.828427124747006\n",
      "Operator 146: -3.264585445332454\n",
      "Operator 148: -2.799588174709558\n",
      "Operator 149: 0.9299945410806358\n",
      "Operator 150: -3.2645854460223473\n",
      "Operator 151: -2.529170892044681\n",
      "Operator 152: -3.0643400409580135\n",
      "Operator 154: -2.2736820908441806\n",
      "Operator 156: 1.2004118253588976\n",
      "Operator 165: 1.200411825290471\n",
      "Operator 171: 1.6363382000950741\n",
      "Operator 172: 3.264585446098504\n",
      "Operator 174: 1.3853852953593098\n",
      "Operator 176: 1.5494591474175368\n",
      "Operator 177: -1.5494591481932385\n",
      "Operator 178: 1.5494591481932405\n",
      "Operator 180: -1.4142135623726892\n",
      "Operator 181: 1.4142135623726948\n",
      "Operator 184: -1.5494591480427395\n",
      "Operator 185: 1.5494591480427513\n",
      "Operator 186: -1.5494591474797104\n",
      "Operator 187: 1.549459147479711\n",
      "Operator 190: -1.6932750152333649\n",
      "Operator 191: 1.6932750152333558\n",
      "Operator 192: -1.932749477047665\n",
      "Operator 193: -0.9797117428378515\n",
      "Operator 194: 1.5494591481932367\n",
      "Operator 195: -0.9797117440646714\n",
      "Operator 197: 0.8941969436537378\n",
      "Operator 198: -1.414213562372698\n",
      "Operator 201: 1.549459148042742\n",
      "Operator 202: -0.9797117439105045\n",
      "Operator 203: 1.5494591474797068\n",
      "Operator 204: -0.9797117430200286\n",
      "Operator 207: 1.6932750152333618\n",
      "Operator 208: -0.4354050667173588\n",
      "Operator 209: 1.9327494770476652\n",
      "Operator 210: -1.5494591474175303\n",
      "Operator 211: 1.5494591481932367\n",
      "Operator 212: -1.5494591481932367\n",
      "Operator 214: 1.414213562372686\n",
      "Operator 215: -1.4142135623726984\n",
      "Operator 218: 1.5494591480427427\n",
      "Operator 219: -1.5494591480427495\n",
      "Operator 220: 1.5494591474797064\n",
      "Operator 221: -1.5494591474797015\n",
      "Operator 224: 1.6932750152333618\n",
      "Operator 225: -1.6932750152333593\n",
      "Operator 226: 1.9327494770476652\n",
      "Operator 227: -2.064173619789157\n",
      "Operator 228: 0.9299945409731643\n",
      "Operator 229: -2.5291708912465434\n",
      "Operator 231: -2.3084105060277533\n",
      "Operator 232: -3.4142135623734835\n",
      "Operator 234: -2.1587823891170927\n",
      "Operator 235: -2.529170890664906\n",
      "Operator 236: -2.064173620731868\n",
      "Operator 237: 0.9299945425341789\n",
      "Operator 238: -2.5291708913547906\n",
      "Operator 240: -1.7373145036651567\n",
      "Operator 241: -2.1286800819160216\n",
      "Operator 242: -0.7879577552227188\n",
      "Operator 243: 1.5813159002623531\n",
      "Operator 245: -1.2004118253588993\n",
      "Operator 254: -1.2004118252904705\n",
      "Operator 260: -1.6363382000950715\n",
      "Total gradient norm: 31.0213829240278\n",
      "Operators under consideration (1):\n",
      "[118]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.00000000000004)]\n",
      "Operator(s) added to ansatz: [118]\n",
      "Gradients: [np.float64(-4.00000000000004)]\n",
      "Initial energy: -25.65005834003748\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118]...\n",
      "Starting point: [np.float64(0.4431436458755917), np.float64(0.5048173577214158), np.float64(0.4431436459350957), np.float64(0.44314364565297254), np.float64(0.4431436456283925), np.float64(0.3926990816985817), np.float64(-0.6553685269411308), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -26.924006\n",
      "         Iterations: 13\n",
      "         Function evaluations: 55\n",
      "         Gradient evaluations: 44\n",
      "\n",
      "Current energy: -26.924006383691122\n",
      "(change of -1.2739480436536432)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118]\n",
      "On iteration 8.\n",
      "\n",
      "*** ADAPT-VQE Iteration 9 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 2.799588178732206\n",
      "Operator 1: -0.9299942270533468\n",
      "Operator 2: 3.2645855935889223\n",
      "Operator 3: 2.1587826424971457\n",
      "Operator 5: 3.414213562832952\n",
      "Operator 6: 2.8284271256658595\n",
      "Operator 7: 3.1403585173694406\n",
      "Operator 8: -7.135151537327892e-07\n",
      "Operator 9: 2.4425822154012433\n",
      "Operator 10: -1.243986486744714\n",
      "Operator 11: 2.211174427418179\n",
      "Operator 12: -1.6346701769511438\n",
      "Operator 13: 2.096488816706413\n",
      "Operator 14: -1.8226186683415566\n",
      "Operator 15: 2.0313239394894245\n",
      "Operator 16: -1.9295364591823945\n",
      "Operator 17: 2.0641737723210793\n",
      "Operator 18: 5.861328436904986e-07\n",
      "Operator 19: 2.7995881787322077\n",
      "Operator 20: -4.2614503311424137e-07\n",
      "Operator 21: 3.264585593588923\n",
      "Operator 22: -3.4142135628329306\n",
      "Operator 24: -1.946713758247352\n",
      "Operator 25: 4.000000000000055\n",
      "Operator 26: -1.2187981311154348\n",
      "Operator 27: -7.135151537662791e-07\n",
      "Operator 28: -0.6645198717479157\n",
      "Operator 29: -1.8787108842985872e-07\n",
      "Operator 30: -0.39211296829393727\n",
      "Operator 31: -3.077861638557602e-07\n",
      "Operator 32: -0.185161516009403\n",
      "Operator 33: 7.444576186621532e-07\n",
      "Operator 34: 0.9299948369243085\n",
      "Operator 35: -2.7995881787322077\n",
      "Operator 36: -6.026600868520089e-07\n",
      "Operator 37: -2.308410611741192\n",
      "Operator 38: -3.4142135628329306\n",
      "Operator 40: -3.414213562832951\n",
      "Operator 41: -2.280717034738845\n",
      "Operator 42: -3.140358517369442\n",
      "Operator 43: 1.3955533174515786\n",
      "Operator 44: -2.4425822154012424\n",
      "Operator 45: 1.7068020627108407\n",
      "Operator 46: -2.2111744274181793\n",
      "Operator 47: 1.8640413983746629\n",
      "Operator 48: -2.0964888167064117\n",
      "Operator 49: 1.9529484227755198\n",
      "Operator 50: -2.031323939489423\n",
      "Operator 51: -0.9299948369243084\n",
      "Operator 52: 2.799588178732206\n",
      "Operator 53: 6.026600861270806e-07\n",
      "Operator 54: 2.3084106117411904\n",
      "Operator 55: 3.4142135628329306\n",
      "Operator 57: 3.414213562832952\n",
      "Operator 58: 2.280717034738845\n",
      "Operator 59: 3.1403585173694397\n",
      "Operator 60: -1.3955533174515775\n",
      "Operator 61: 2.4425822154012433\n",
      "Operator 62: -1.7068020627108407\n",
      "Operator 63: 2.211174427418179\n",
      "Operator 64: -1.8640413983746629\n",
      "Operator 65: 2.096488816706413\n",
      "Operator 66: -1.9529484227755198\n",
      "Operator 67: 2.0313239394894245\n",
      "Operator 68: -2.5291708977168064\n",
      "Operator 69: 6.026600863121638e-07\n",
      "Operator 70: -3.264585593588923\n",
      "Operator 71: 3.4142135628329306\n",
      "Operator 73: 3.414213562832951\n",
      "Operator 74: -4.000000000000055\n",
      "Operator 75: 3.1403585173694406\n",
      "Operator 76: 7.135151537327892e-07\n",
      "Operator 77: 1.91657443308366\n",
      "Operator 78: 1.8787108842985872e-07\n",
      "Operator 79: 1.3203285089837027\n",
      "Operator 80: 3.077861657380296e-07\n",
      "Operator 81: 0.8987774839554419\n",
      "Operator 82: -7.444576186621532e-07\n",
      "Operator 83: 0.5313045317218736\n",
      "Operator 84: -3.6181167573090534e-07\n",
      "Operator 85: -3.26458530412794\n",
      "Operator 86: -5.861328433578421e-07\n",
      "Operator 88: 1.2004118212678043\n",
      "Operator 97: 1.5142490949128882\n",
      "Operator 99: 1.7737037455090952\n",
      "Operator 101: 1.8940602928391121\n",
      "Operator 103: 1.9606102217714354\n",
      "Operator 104: -2.0641737723210793\n",
      "Operator 105: -5.861328436323134e-07\n",
      "Operator 106: -2.799588178732206\n",
      "Operator 107: 4.2614503250420146e-07\n",
      "Operator 108: -3.2645855935889223\n",
      "Operator 109: 3.4142135628329306\n",
      "Operator 111: 1.9467137582473533\n",
      "Operator 112: -4.000000000000055\n",
      "Operator 113: 1.2187981311154337\n",
      "Operator 114: 7.135151537662791e-07\n",
      "Operator 115: 0.6645198717479157\n",
      "Operator 116: 1.8787108842985872e-07\n",
      "Operator 117: 0.3921129682939371\n",
      "Operator 118: 3.077861638557602e-07\n",
      "Operator 119: 0.185161516009403\n",
      "Operator 120: -7.444576186621532e-07\n",
      "Operator 121: 2.529170897716801\n",
      "Operator 122: -6.026600869041789e-07\n",
      "Operator 123: 3.2645855935889223\n",
      "Operator 124: -3.4142135628329306\n",
      "Operator 126: -3.414213562832952\n",
      "Operator 127: 4.000000000000055\n",
      "Operator 128: -3.1403585173694415\n",
      "Operator 129: -7.135151537327892e-07\n",
      "Operator 130: -1.9165744330836552\n",
      "Operator 131: -1.8787108842985872e-07\n",
      "Operator 132: -1.3203285089836942\n",
      "Operator 133: -3.077861657380296e-07\n",
      "Operator 134: -0.8987774839554392\n",
      "Operator 135: 7.444576186621532e-07\n",
      "Operator 136: -0.5313045317218786\n",
      "Operator 137: 3.6181167573090534e-07\n",
      "Operator 138: 5.861328432747328e-07\n",
      "Operator 139: -2.7995881787322077\n",
      "Operator 140: 0.9299942270533468\n",
      "Operator 141: -3.264585593588923\n",
      "Operator 142: -2.158782642497145\n",
      "Operator 144: -3.41421356283295\n",
      "Operator 145: -2.8284271256658595\n",
      "Operator 146: -3.1403585173694415\n",
      "Operator 147: 7.135151537327892e-07\n",
      "Operator 148: -2.442582215401242\n",
      "Operator 149: 1.2439864867447132\n",
      "Operator 150: -2.211174427418179\n",
      "Operator 151: 1.6346701769511438\n",
      "Operator 152: -2.0964888167064117\n",
      "Operator 153: 1.822618668341559\n",
      "Operator 154: -2.031323939489423\n",
      "Operator 156: 1.2004118212678043\n",
      "Operator 165: 1.5142490949128873\n",
      "Operator 167: 1.773703745509095\n",
      "Operator 169: 1.8940602928391121\n",
      "Operator 171: 1.9606102217714354\n",
      "Operator 172: 3.264585304127939\n",
      "Operator 173: 5.861328432747328e-07\n",
      "Operator 174: 1.9295364591823945\n",
      "Operator 175: -5.861328433578421e-07\n",
      "Operator 176: 1.5494592632863298\n",
      "Operator 177: -1.549459027043799\n",
      "Operator 178: 1.5494590270438013\n",
      "Operator 180: -1.4142135619132907\n",
      "Operator 181: 1.414213561913296\n",
      "Operator 184: -1.6430406117509988\n",
      "Operator 185: 1.6430406117510126\n",
      "Operator 186: -1.8432278351283806\n",
      "Operator 187: 1.843227835128377\n",
      "Operator 188: -1.9245626739198958\n",
      "Operator 189: 1.9245626739198889\n",
      "Operator 190: -1.9683020132375035\n",
      "Operator 191: 1.9683020132374964\n",
      "Operator 192: -1.9921843381612034\n",
      "Operator 193: -0.9797119311023552\n",
      "Operator 194: 1.5494590270437978\n",
      "Operator 195: -0.9797115574739499\n",
      "Operator 197: 0.8941970483267807\n",
      "Operator 198: -1.414213561913299\n",
      "Operator 201: 1.6430406117510024\n",
      "Operator 202: -0.6376771365029775\n",
      "Operator 203: 1.843227835128376\n",
      "Operator 204: -0.2859230824187756\n",
      "Operator 205: 1.9245626739198936\n",
      "Operator 206: -0.1324563578675564\n",
      "Operator 207: 1.9683020132375022\n",
      "Operator 208: -0.04729428851683434\n",
      "Operator 209: 1.9921843381612014\n",
      "Operator 210: -1.5494592632863224\n",
      "Operator 211: 1.5494590270437978\n",
      "Operator 212: -1.5494590270437978\n",
      "Operator 214: 1.4142135619132872\n",
      "Operator 215: -1.4142135619132996\n",
      "Operator 218: 1.6430406117510024\n",
      "Operator 219: -1.6430406117510108\n",
      "Operator 220: 1.843227835128376\n",
      "Operator 221: -1.8432278351283733\n",
      "Operator 222: 1.924562673919894\n",
      "Operator 223: -1.9245626739198902\n",
      "Operator 224: 1.9683020132375022\n",
      "Operator 225: -1.9683020132374995\n",
      "Operator 226: 1.9921843381612014\n",
      "Operator 227: -2.0641737723210793\n",
      "Operator 228: 0.9299948369243084\n",
      "Operator 229: -2.529170897716801\n",
      "Operator 230: -4.2614503278660987e-07\n",
      "Operator 231: -2.3084106117411904\n",
      "Operator 232: -3.4142135628329306\n",
      "Operator 234: -1.9467137582473533\n",
      "Operator 235: -2.280717034738845\n",
      "Operator 236: -1.2187981311154346\n",
      "Operator 237: 1.3955533174515775\n",
      "Operator 238: -0.5214161424895462\n",
      "Operator 239: 1.7068020627108407\n",
      "Operator 240: -0.23413708315413442\n",
      "Operator 241: 1.8640413983746629\n",
      "Operator 242: -0.07937986606852049\n",
      "Operator 243: 1.9529484227755198\n",
      "Operator 245: -1.200411821267806\n",
      "Operator 254: -1.514249094912887\n",
      "Operator 256: -1.7737037455090965\n",
      "Operator 258: -1.8940602928391104\n",
      "Operator 260: -1.9606102217714327\n",
      "Total gradient norm: 28.642140375481\n",
      "Operators under consideration (1):\n",
      "[127]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000055)]\n",
      "Operator(s) added to ansatz: [127]\n",
      "Gradients: [np.float64(4.000000000000055)]\n",
      "Initial energy: -26.924006383691122\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127]...\n",
      "Starting point: [np.float64(0.4820361422523884), np.float64(0.6962605273370729), np.float64(0.4431435980342412), np.float64(0.5861092949282597), np.float64(0.4431436914413436), np.float64(0.39269908153615557), np.float64(-0.7411806399170796), np.float64(0.6476335206285008), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -28.100488\n",
      "         Iterations: 17\n",
      "         Function evaluations: 35\n",
      "         Gradient evaluations: 34\n",
      "\n",
      "Current energy: -28.100488056691674\n",
      "(change of -1.176481673000552)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127]\n",
      "On iteration 9.\n",
      "\n",
      "*** ADAPT-VQE Iteration 10 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 2.7995881746450584\n",
      "Operator 1: -0.9299945419665229\n",
      "Operator 2: 3.264585445625611\n",
      "Operator 3: 1.9896386739826337\n",
      "Operator 5: 2.45822388804865\n",
      "Operator 6: -1.2306865113111989\n",
      "Operator 7: 2.238546720517039\n",
      "Operator 8: -1.6040276630136205\n",
      "Operator 9: 2.13483875253428\n",
      "Operator 10: -1.774735247021828\n",
      "Operator 11: 2.0746524996986584\n",
      "Operator 12: -1.8718669794365206\n",
      "Operator 13: 2.036103307687843\n",
      "Operator 14: -1.9337417647298016\n",
      "Operator 15: 2.0119149723738987\n",
      "Operator 16: -1.9731935303851305\n",
      "Operator 17: 2.064173620270626\n",
      "Operator 19: 2.799588174645061\n",
      "Operator 21: 3.264585445625613\n",
      "Operator 22: -1.257424880474114\n",
      "Operator 24: -0.7337343826500253\n",
      "Operator 26: -0.5056307263063249\n",
      "Operator 28: -0.35278664968564666\n",
      "Operator 30: -0.226628902859898\n",
      "Operator 32: -0.11104344346693273\n",
      "Operator 34: 0.9299945419631588\n",
      "Operator 35: -2.799588174645061\n",
      "Operator 37: -1.87175823095715\n",
      "Operator 38: -3.146705002600091\n",
      "Operator 39: 1.3769622291039716\n",
      "Operator 40: -2.458223888048649\n",
      "Operator 41: 1.6700408463744147\n",
      "Operator 42: -2.2385467205170366\n",
      "Operator 43: 1.811443598979165\n",
      "Operator 44: -2.13483875253428\n",
      "Operator 45: 1.895107752693061\n",
      "Operator 46: -2.0746524996986597\n",
      "Operator 47: 1.9489653634581403\n",
      "Operator 48: -2.036103307687841\n",
      "Operator 49: 1.9821184353576773\n",
      "Operator 50: -2.0119149723738965\n",
      "Operator 51: -0.9299945419631588\n",
      "Operator 52: 2.7995881746450584\n",
      "Operator 54: 1.87175823095715\n",
      "Operator 55: 3.146705002600094\n",
      "Operator 56: -1.3769622291039711\n",
      "Operator 57: 2.45822388804865\n",
      "Operator 58: -1.670040846374416\n",
      "Operator 59: 2.238546720517039\n",
      "Operator 60: -1.8114435989791655\n",
      "Operator 61: 2.13483875253428\n",
      "Operator 62: -1.895107752693061\n",
      "Operator 63: 2.074652499698658\n",
      "Operator 64: -1.9489653634581394\n",
      "Operator 65: 2.036103307687843\n",
      "Operator 66: -1.9821184353576786\n",
      "Operator 67: 2.0119149723738987\n",
      "Operator 68: -2.5291708912527806\n",
      "Operator 70: -3.264585445625613\n",
      "Operator 71: 3.146705002600094\n",
      "Operator 73: 1.94590599502558\n",
      "Operator 75: 1.3961640161901574\n",
      "Operator 77: 1.0487121176496088\n",
      "Operator 79: 0.782253352594743\n",
      "Operator 81: 0.5489783433025925\n",
      "Operator 83: 0.327548553503728\n",
      "Operator 85: -3.264585445627218\n",
      "Operator 88: 1.2004118253549834\n",
      "Operator 93: 1.5021033727065938\n",
      "Operator 95: 1.749804977657039\n",
      "Operator 97: 1.8594997697276012\n",
      "Operator 99: 1.9215261348366255\n",
      "Operator 101: 1.9606987168257428\n",
      "Operator 103: 1.9850727445511613\n",
      "Operator 104: -2.064173620270626\n",
      "Operator 106: -2.7995881746450584\n",
      "Operator 108: -3.264585445625613\n",
      "Operator 109: 1.2574248804741142\n",
      "Operator 111: 0.7337343826500256\n",
      "Operator 113: 0.5056307263063259\n",
      "Operator 115: 0.35278664968564727\n",
      "Operator 117: 0.22662890285989773\n",
      "Operator 119: 0.11104344346693318\n",
      "Operator 121: 2.529170891252775\n",
      "Operator 123: 3.264585445625613\n",
      "Operator 124: -3.146705002600091\n",
      "Operator 126: -1.9459059950255821\n",
      "Operator 128: -1.3961640161901632\n",
      "Operator 130: -1.0487121176496035\n",
      "Operator 132: -0.7822533525947336\n",
      "Operator 134: -0.5489783433025902\n",
      "Operator 136: -0.327548553503733\n",
      "Operator 139: -2.799588174645061\n",
      "Operator 140: 0.9299945419665232\n",
      "Operator 141: -3.2645854456256145\n",
      "Operator 142: -1.989638673982632\n",
      "Operator 144: -2.458223888048649\n",
      "Operator 145: 1.2306865113111989\n",
      "Operator 146: -2.2385467205170366\n",
      "Operator 147: 1.6040276630136194\n",
      "Operator 148: -2.1348387525342796\n",
      "Operator 149: 1.7747352470218283\n",
      "Operator 150: -2.0746524996986597\n",
      "Operator 151: 1.8718669794365206\n",
      "Operator 152: -2.0361033076878408\n",
      "Operator 153: 1.9337417647298016\n",
      "Operator 154: -2.0119149723738965\n",
      "Operator 156: 1.200411825354983\n",
      "Operator 161: 1.5021033727065936\n",
      "Operator 163: 1.7498049776570397\n",
      "Operator 165: 1.8594997697276017\n",
      "Operator 167: 1.9215261348366257\n",
      "Operator 169: 1.960698716825743\n",
      "Operator 171: 1.9850727445511613\n",
      "Operator 172: 3.264585445627217\n",
      "Operator 174: 1.9731935303851305\n",
      "Operator 176: 1.549459147802213\n",
      "Operator 177: -1.5494591478035238\n",
      "Operator 178: 1.549459147803526\n",
      "Operator 180: -1.6386175993843075\n",
      "Operator 181: 1.6386175993843133\n",
      "Operator 182: -1.8333787862049107\n",
      "Operator 183: 1.8333787862049054\n",
      "Operator 184: -1.9088308328025856\n",
      "Operator 185: 1.9088308328026002\n",
      "Operator 186: -1.9483127973131698\n",
      "Operator 187: 1.9483127973131658\n",
      "Operator 188: -1.972502708483512\n",
      "Operator 189: 1.9725027084835052\n",
      "Operator 190: -1.988031457085484\n",
      "Operator 191: 1.9880314570854765\n",
      "Operator 192: -1.9970234751328948\n",
      "Operator 193: -0.9797117434510316\n",
      "Operator 194: 1.5494591478035222\n",
      "Operator 195: -0.9797117434531154\n",
      "Operator 197: 1.0360859835636549\n",
      "Operator 198: -0.6547924058169055\n",
      "Operator 199: 1.8333787862049107\n",
      "Operator 200: -0.31375550120354534\n",
      "Operator 201: 1.9088308328025851\n",
      "Operator 202: -0.1722902712450664\n",
      "Operator 203: 1.948312797313167\n",
      "Operator 204: -0.0960999547771699\n",
      "Operator 205: 1.9725027084835123\n",
      "Operator 206: -0.04866927035028269\n",
      "Operator 207: 1.9880314570854818\n",
      "Operator 208: -0.017916923019966335\n",
      "Operator 209: 1.9970234751328926\n",
      "Operator 210: -1.549459147802207\n",
      "Operator 211: 1.5494591478035222\n",
      "Operator 212: -1.549459147803523\n",
      "Operator 214: 1.638617599384303\n",
      "Operator 215: -1.6386175993843146\n",
      "Operator 216: 1.8333787862049107\n",
      "Operator 217: -1.83337878620491\n",
      "Operator 218: 1.9088308328025851\n",
      "Operator 219: -1.908830832802599\n",
      "Operator 220: 1.948312797313167\n",
      "Operator 221: -1.9483127973131629\n",
      "Operator 222: 1.9725027084835123\n",
      "Operator 223: -1.972502708483507\n",
      "Operator 224: 1.9880314570854818\n",
      "Operator 225: -1.9880314570854798\n",
      "Operator 226: 1.997023475132893\n",
      "Operator 227: -2.064173620270626\n",
      "Operator 228: 0.9299945419631588\n",
      "Operator 229: -2.529170891252775\n",
      "Operator 231: -1.87175823095715\n",
      "Operator 232: -1.257424880474114\n",
      "Operator 233: 1.3769622291039711\n",
      "Operator 234: -0.58081696337613\n",
      "Operator 235: 1.6700408463744154\n",
      "Operator 236: -0.31535791461432494\n",
      "Operator 237: 1.811443598979167\n",
      "Operator 238: -0.17330191052188326\n",
      "Operator 239: 1.895107752693061\n",
      "Operator 240: -0.08545104256388558\n",
      "Operator 241: 1.9489653634581392\n",
      "Operator 242: -0.029939760619669742\n",
      "Operator 243: 1.9821184353576786\n",
      "Operator 245: -1.2004118253549851\n",
      "Operator 250: -1.5021033727065929\n",
      "Operator 252: -1.7498049776570368\n",
      "Operator 254: -1.8594997697276003\n",
      "Operator 256: -1.921526134836628\n",
      "Operator 258: -1.9606987168257408\n",
      "Operator 260: -1.9850727445511587\n",
      "Total gradient norm: 25.650081252938946\n",
      "Operators under consideration (1):\n",
      "[123]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.264585445625613)]\n",
      "Operator(s) added to ansatz: [123]\n",
      "Gradients: [np.float64(3.264585445625613)]\n",
      "Initial energy: -28.100488056691674\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123]...\n",
      "Starting point: [np.float64(0.6338475416444311), np.float64(0.7306704300967015), np.float64(0.4431436457810027), np.float64(0.6714778179648208), np.float64(0.4431436457804823), np.float64(0.48010221833031314), np.float64(-0.7581160104919691), np.float64(0.7023913384211472), np.float64(-0.579857666827413), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -28.686229\n",
      "         Iterations: 17\n",
      "         Function evaluations: 128\n",
      "         Gradient evaluations: 113\n",
      "\n",
      "Current energy: -28.6862289418695\n",
      "(change of -0.5857408851778274)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123]\n",
      "On iteration 10.\n",
      "\n",
      "*** ADAPT-VQE Iteration 11 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 3.06541315263269\n",
      "Operator 1: -0.6683051854957116\n",
      "Operator 2: -1.2212369836082001e-08\n",
      "Operator 3: 2.1810750001395984\n",
      "Operator 4: -0.7432799730075721\n",
      "Operator 5: 2.3429108333005138\n",
      "Operator 6: -1.429839743845426\n",
      "Operator 7: 2.1898973771125103\n",
      "Operator 8: -1.6862365619449857\n",
      "Operator 9: 2.110527152173037\n",
      "Operator 10: -1.815735520598642\n",
      "Operator 11: 2.062030692451601\n",
      "Operator 12: -1.8936134158599827\n",
      "Operator 13: 2.0301649335861622\n",
      "Operator 14: -1.9446495030846744\n",
      "Operator 15: 2.0099714429733195\n",
      "Operator 16: -1.9775658068313937\n",
      "Operator 17: 2.6594928722287534\n",
      "Operator 19: 3.0654131526326927\n",
      "Operator 20: -0.6191622564104492\n",
      "Operator 21: 1.1807835484163083\n",
      "Operator 22: -0.9660385528992383\n",
      "Operator 23: 1.0512185887553787e-08\n",
      "Operator 24: -0.6301454885030557\n",
      "Operator 26: -0.44996390502481615\n",
      "Operator 28: -0.3185764464387183\n",
      "Operator 30: -0.20603679388178647\n",
      "Operator 31: 1.2698749603573446e-08\n",
      "Operator 32: -0.101300054335562\n",
      "Operator 33: 1.0527628768741693e-08\n",
      "Operator 34: 0.5425987124360889\n",
      "Operator 35: -2.3241613739987725\n",
      "Operator 36: -1.2748443515619612\n",
      "Operator 37: 0.22074235527225855\n",
      "Operator 38: -2.7364691656603934\n",
      "Operator 39: 1.530396637727342\n",
      "Operator 40: -2.342910833300513\n",
      "Operator 41: 1.735866656221434\n",
      "Operator 42: -2.1898973771125068\n",
      "Operator 43: 1.8449770118239606\n",
      "Operator 44: -2.110527152173036\n",
      "Operator 45: 1.9127284400414992\n",
      "Operator 46: -2.062030692451603\n",
      "Operator 47: 1.9573449335908428\n",
      "Operator 48: -2.0301649335861605\n",
      "Operator 49: 1.985036484310347\n",
      "Operator 50: -2.009971442973317\n",
      "Operator 51: -0.5425987124360893\n",
      "Operator 52: 2.3241613739987708\n",
      "Operator 54: -0.9964639306835243\n",
      "Operator 55: 2.736469165660395\n",
      "Operator 56: -1.530396637727342\n",
      "Operator 57: 2.3429108333005138\n",
      "Operator 58: -1.735866656221434\n",
      "Operator 59: 2.1898973771125094\n",
      "Operator 60: -1.8449770118239606\n",
      "Operator 61: 2.110527152173037\n",
      "Operator 62: -1.9127284400414992\n",
      "Operator 63: 2.062030692451602\n",
      "Operator 64: -1.9573449335908428\n",
      "Operator 65: 2.0301649335861622\n",
      "Operator 66: -1.985036484310347\n",
      "Operator 67: 2.0099714429733195\n",
      "Operator 68: -2.9307922309410515\n",
      "Operator 70: -1.180783548416308\n",
      "Operator 71: 2.487730736100211\n",
      "Operator 72: -1.0512185799119858e-08\n",
      "Operator 73: 1.6774009528736464\n",
      "Operator 75: 1.2439642090367031\n",
      "Operator 77: 0.9488619457578411\n",
      "Operator 79: 0.7128379697072671\n",
      "Operator 80: -1.2698749603573446e-08\n",
      "Operator 81: 0.5017314988369026\n",
      "Operator 82: -1.0527628768741693e-08\n",
      "Operator 83: 0.29963362764164914\n",
      "Operator 85: -3.3367125113449956\n",
      "Operator 88: 0.8984512760239589\n",
      "Operator 89: -0.7875630396275464\n",
      "Operator 90: -0.38250105441013926\n",
      "Operator 91: 0.9085762458428552\n",
      "Operator 93: 1.635713060440458\n",
      "Operator 95: 1.8022773285263098\n",
      "Operator 97: 1.8852018109349138\n",
      "Operator 99: 1.9348986034301792\n",
      "Operator 101: 1.9671896605660013\n",
      "Operator 103: 1.9875122366301432\n",
      "Operator 104: -2.659492872228752\n",
      "Operator 106: -3.06541315263269\n",
      "Operator 108: 1.2212369990543287e-08\n",
      "Operator 109: 0.9660385528992382\n",
      "Operator 110: -1.0512185887553787e-08\n",
      "Operator 111: 0.6301454885030561\n",
      "Operator 113: 0.44996390502481654\n",
      "Operator 115: 0.31857644643871863\n",
      "Operator 117: 0.2060367938817862\n",
      "Operator 118: -1.2698749603573446e-08\n",
      "Operator 119: 0.101300054335562\n",
      "Operator 120: -1.0527626215228736e-08\n",
      "Operator 121: 2.930792230941047\n",
      "Operator 122: -1.2748443515619616\n",
      "Operator 123: -1.2212370204748268e-08\n",
      "Operator 124: -2.4877307361002075\n",
      "Operator 125: 1.0512185799119858e-08\n",
      "Operator 126: -1.6774009528736475\n",
      "Operator 128: -1.243964209036708\n",
      "Operator 130: -0.9488619457578349\n",
      "Operator 132: -0.7128379697072581\n",
      "Operator 133: 1.2698749603573446e-08\n",
      "Operator 134: -0.5017314988368999\n",
      "Operator 135: 1.0527626215228736e-08\n",
      "Operator 136: -0.2996336276416546\n",
      "Operator 139: -3.065413152632694\n",
      "Operator 140: -0.34534880870481804\n",
      "Operator 141: -1.1807835484163078\n",
      "Operator 142: -2.1810750001395975\n",
      "Operator 143: 0.7432799730075734\n",
      "Operator 144: -2.342910833300513\n",
      "Operator 145: 1.4298397438454278\n",
      "Operator 146: -2.1898973771125068\n",
      "Operator 147: 1.6862365619449862\n",
      "Operator 148: -2.110527152173036\n",
      "Operator 149: 1.8157355205986427\n",
      "Operator 150: -2.0620306924516028\n",
      "Operator 151: 1.8936134158599822\n",
      "Operator 152: -2.0301649335861605\n",
      "Operator 153: 1.9446495030846727\n",
      "Operator 154: -2.009971442973317\n",
      "Operator 156: 0.6811955348861927\n",
      "Operator 157: -0.5263726842715002\n",
      "Operator 158: -0.7875630396275415\n",
      "Operator 159: 1.1399382787117909\n",
      "Operator 161: 1.635713060440458\n",
      "Operator 163: 1.8022773285263103\n",
      "Operator 165: 1.8852018109349142\n",
      "Operator 167: 1.9348986034301794\n",
      "Operator 169: 1.9671896605660013\n",
      "Operator 171: 1.9875122366301436\n",
      "Operator 172: 3.3367125113449956\n",
      "Operator 174: 1.9775658068313937\n",
      "Operator 176: 1.4876826482868983\n",
      "Operator 177: -0.9157807085679368\n",
      "Operator 178: 1.4823929037060353\n",
      "Operator 179: 1.304070570939606\n",
      "Operator 180: -1.748276978431396\n",
      "Operator 181: 1.7482769784314027\n",
      "Operator 182: -1.8712287362018318\n",
      "Operator 183: 1.8712287362018265\n",
      "Operator 184: -1.9263036032511374\n",
      "Operator 185: 1.9263036032511511\n",
      "Operator 186: -1.9573257380126012\n",
      "Operator 187: 1.9573257380125977\n",
      "Operator 188: -1.9770839016247155\n",
      "Operator 189: 1.9770839016247077\n",
      "Operator 190: -1.989991076200102\n",
      "Operator 191: 1.989991076200094\n",
      "Operator 192: -1.9975086927779913\n",
      "Operator 193: -1.1857423694145446\n",
      "Operator 194: 0.9157807085679347\n",
      "Operator 195: 1.04153561531818\n",
      "Operator 196: -0.504810576447718\n",
      "Operator 197: 1.3934464377770843\n",
      "Operator 198: -0.46794132589690546\n",
      "Operator 199: 1.8712287362018314\n",
      "Operator 200: -0.24443267424457543\n",
      "Operator 201: 1.9263036032511365\n",
      "Operator 202: -0.13972771291881517\n",
      "Operator 203: 1.9573257380125995\n",
      "Operator 204: -0.07946408693205809\n",
      "Operator 205: 1.9770839016247155\n",
      "Operator 206: -0.04059089913841838\n",
      "Operator 207: 1.9899910762000999\n",
      "Operator 208: -0.014988294056854007\n",
      "Operator 209: 1.9975086927779893\n",
      "Operator 210: -1.4876826482868906\n",
      "Operator 211: 1.2078534048354417\n",
      "Operator 212: 1.5583539564093998\n",
      "Operator 213: -1.0393962250284412\n",
      "Operator 214: 1.7482769784313934\n",
      "Operator 215: -1.748276978431405\n",
      "Operator 216: 1.8712287362018314\n",
      "Operator 217: -1.8712287362018314\n",
      "Operator 218: 1.9263036032511365\n",
      "Operator 219: -1.9263036032511511\n",
      "Operator 220: 1.9573257380125995\n",
      "Operator 221: -1.9573257380125941\n",
      "Operator 222: 1.977083901624715\n",
      "Operator 223: -1.9770839016247093\n",
      "Operator 224: 1.9899910762000994\n",
      "Operator 225: -1.9899910762000967\n",
      "Operator 226: 1.9975086927779895\n",
      "Operator 227: -2.659492872228752\n",
      "Operator 228: 0.411392170070898\n",
      "Operator 229: -2.222093322891494\n",
      "Operator 230: -0.6191622564104498\n",
      "Operator 231: 0.9964639306835239\n",
      "Operator 232: -0.8782279846099512\n",
      "Operator 233: 1.530396637727342\n",
      "Operator 234: -0.45115103308264926\n",
      "Operator 235: 1.7358666562214344\n",
      "Operator 236: -0.25560055875646087\n",
      "Operator 237: 1.8449770118239586\n",
      "Operator 238: -0.14322728164346119\n",
      "Operator 239: 1.9127284400414983\n",
      "Operator 240: -0.07122631606470746\n",
      "Operator 241: 1.9573449335908428\n",
      "Operator 242: -0.025035122641124813\n",
      "Operator 243: 1.985036484310347\n",
      "Operator 245: -0.6811955348861936\n",
      "Operator 248: -1.139938278711791\n",
      "Operator 250: -1.635713060440457\n",
      "Operator 252: -1.8022773285263067\n",
      "Operator 254: -1.885201810934913\n",
      "Operator 256: -1.934898603430181\n",
      "Operator 258: -1.967189660566\n",
      "Operator 260: -1.9875122366301405\n",
      "Total gradient norm: 24.43278949680202\n",
      "Operators under consideration (1):\n",
      "[172]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.3367125113449956)]\n",
      "Operator(s) added to ansatz: [172]\n",
      "Gradients: [np.float64(3.3367125113449956)]\n",
      "Initial energy: -28.6862289418695\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172]...\n",
      "Starting point: [np.float64(0.6492424675970471), np.float64(0.7353549741212638), np.float64(0.32420928733360305), np.float64(0.6819248707550891), np.float64(0.41939977221299773), np.float64(0.5318295695712449), np.float64(-0.7604390738129783), np.float64(0.7096353841426098), np.float64(-0.6049976864692715), np.float64(-0.3551328768460698), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -29.452771\n",
      "         Iterations: 16\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 25\n",
      "\n",
      "Current energy: -29.452770945695725\n",
      "(change of -0.7665420038262241)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172]\n",
      "On iteration 11.\n",
      "\n",
      "*** ADAPT-VQE Iteration 12 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 2.165819143373688\n",
      "Operator 1: -0.32736437798854406\n",
      "Operator 3: 2.232032889916144\n",
      "Operator 4: -0.7713295903121753\n",
      "Operator 5: 2.3378273861090726\n",
      "Operator 6: -1.4385502289041026\n",
      "Operator 7: 2.1876257046964156\n",
      "Operator 8: -1.6900592896481705\n",
      "Operator 9: 2.109358987595955\n",
      "Operator 10: -1.8177015662804794\n",
      "Operator 11: 2.061415758941581\n",
      "Operator 12: -1.8946720633348824\n",
      "Operator 13: 2.0298739493871536\n",
      "Operator 14: -1.9451838948656754\n",
      "Operator 15: 2.009876044524728\n",
      "Operator 16: -1.977780423849307\n",
      "Operator 19: 3.386172399424887\n",
      "Operator 20: -0.6211236085496075\n",
      "Operator 21: 1.1117468072795589\n",
      "Operator 22: -0.9542726460742366\n",
      "Operator 24: -0.6253024837287385\n",
      "Operator 26: -0.44721853145689416\n",
      "Operator 28: -0.31684988336994824\n",
      "Operator 30: -0.20498646360687456\n",
      "Operator 32: -0.10080046191261915\n",
      "Operator 34: 0.34988509505381254\n",
      "Operator 35: -2.53384768128355\n",
      "Operator 36: -1.2897270495126358\n",
      "Operator 37: 0.30057362777902896\n",
      "Operator 38: -2.720745040978332\n",
      "Operator 39: 1.5371649000507075\n",
      "Operator 40: -2.3378273861090717\n",
      "Operator 41: 1.738953591729421\n",
      "Operator 42: -2.187625704696411\n",
      "Operator 43: 1.846592723849124\n",
      "Operator 44: -2.1093589875959537\n",
      "Operator 45: 1.913588023589214\n",
      "Operator 46: -2.0614157589415827\n",
      "Operator 47: 1.957755682443718\n",
      "Operator 48: -2.029873949387152\n",
      "Operator 49: 1.9851797045905117\n",
      "Operator 50: -2.0098760445247255\n",
      "Operator 51: 1.0269062507938949\n",
      "Operator 52: 2.53384768128355\n",
      "Operator 54: -1.0190249070057404\n",
      "Operator 55: 2.7207450409783327\n",
      "Operator 56: -1.5371649000507066\n",
      "Operator 57: 2.3378273861090726\n",
      "Operator 58: -1.7389535917294214\n",
      "Operator 59: 2.187625704696415\n",
      "Operator 60: -1.8465927238491253\n",
      "Operator 61: 2.1093589875959555\n",
      "Operator 62: -1.913588023589214\n",
      "Operator 63: 2.061415758941581\n",
      "Operator 64: -1.957755682443718\n",
      "Operator 65: 2.0298739493871536\n",
      "Operator 66: -1.9851797045905117\n",
      "Operator 67: 2.009876044524728\n",
      "Operator 68: -3.3304313887148185\n",
      "Operator 70: -1.1117468072795589\n",
      "Operator 71: 2.4597712990483798\n",
      "Operator 73: 1.6646650586430936\n",
      "Operator 75: 1.2364221644018363\n",
      "Operator 77: 0.9438052639103476\n",
      "Operator 79: 0.7092849299054922\n",
      "Operator 81: 0.4993022126608747\n",
      "Operator 83: 0.2981962688641807\n",
      "Operator 85: -1.0610839657361586\n",
      "Operator 88: 0.6118744018914343\n",
      "Operator 89: -0.7586617913393756\n",
      "Operator 90: -0.3653662607785775\n",
      "Operator 91: 0.9538886335747486\n",
      "Operator 93: 1.6414405654102617\n",
      "Operator 95: 1.8047067504789682\n",
      "Operator 97: 1.8864323370762488\n",
      "Operator 99: 1.9355489710729776\n",
      "Operator 101: 1.9675074461949453\n",
      "Operator 103: 1.9876319326248129\n",
      "Operator 104: -0.8704874123869151\n",
      "Operator 105: 1.1408017117149658\n",
      "Operator 106: -3.386172399424887\n",
      "Operator 109: 0.9542726460742372\n",
      "Operator 111: 0.625302483728739\n",
      "Operator 113: 0.44721853145689494\n",
      "Operator 115: 0.31684988336994835\n",
      "Operator 117: 0.2049864636068741\n",
      "Operator 119: 0.10080046191261938\n",
      "Operator 121: 3.330431388714814\n",
      "Operator 122: -1.2897270495126358\n",
      "Operator 124: -2.459771299048376\n",
      "Operator 126: -1.6646650586430949\n",
      "Operator 128: -1.2364221644018416\n",
      "Operator 130: -0.9438052639103414\n",
      "Operator 132: -0.7092849299054828\n",
      "Operator 134: -0.4993022126608718\n",
      "Operator 136: -0.2981962688641857\n",
      "Operator 139: -2.165819143373688\n",
      "Operator 140: -0.8446487642679602\n",
      "Operator 141: -1.111746807279559\n",
      "Operator 142: -2.232032889916144\n",
      "Operator 143: 0.7713295903121757\n",
      "Operator 144: -2.3378273861090717\n",
      "Operator 145: 1.4385502289041021\n",
      "Operator 146: -2.1876257046964116\n",
      "Operator 147: 1.690059289648171\n",
      "Operator 148: -2.1093589875959537\n",
      "Operator 149: 1.817701566280478\n",
      "Operator 150: -2.0614157589415827\n",
      "Operator 151: 1.8946720633348824\n",
      "Operator 152: -2.0298739493871523\n",
      "Operator 153: 1.9451838948656728\n",
      "Operator 154: -2.0098760445247255\n",
      "Operator 156: 0.29285109083950256\n",
      "Operator 157: -0.6409478869785226\n",
      "Operator 158: -0.7586617913393704\n",
      "Operator 159: 1.1627462037719338\n",
      "Operator 161: 1.6414405654102622\n",
      "Operator 163: 1.8047067504789682\n",
      "Operator 165: 1.8864323370762492\n",
      "Operator 167: 1.9355489710729779\n",
      "Operator 169: 1.9675074461949453\n",
      "Operator 171: 1.9876319326248124\n",
      "Operator 173: -1.5245396548339718\n",
      "Operator 174: 1.977780423849307\n",
      "Operator 175: 1.5245396548339718\n",
      "Operator 176: 0.6844035553577823\n",
      "Operator 177: -0.855784832053986\n",
      "Operator 178: 1.4548364709430004\n",
      "Operator 179: 1.326737675098732\n",
      "Operator 180: -1.7527899080508322\n",
      "Operator 181: 1.7527899080508405\n",
      "Operator 182: -1.8729461618541747\n",
      "Operator 183: 1.8729461618541692\n",
      "Operator 184: -1.9271314757839764\n",
      "Operator 185: 1.927131475783991\n",
      "Operator 186: -1.9577619490739155\n",
      "Operator 187: 1.957761949073911\n",
      "Operator 188: -1.977307784522615\n",
      "Operator 189: 1.977307784522607\n",
      "Operator 190: -1.990087189860521\n",
      "Operator 191: 1.9900871898605126\n",
      "Operator 192: -1.9975325128987331\n",
      "Operator 193: -0.8778329491770228\n",
      "Operator 194: 0.5473658612851939\n",
      "Operator 195: 1.347503783894087\n",
      "Operator 196: -0.524177088038975\n",
      "Operator 197: 1.4379461011443242\n",
      "Operator 198: -0.46002976421795405\n",
      "Operator 199: 1.8729461618541734\n",
      "Operator 200: -0.2412588392680352\n",
      "Operator 201: 1.9271314757839748\n",
      "Operator 202: -0.1381792232569839\n",
      "Operator 203: 1.9577619490739124\n",
      "Operator 204: -0.07865759239842365\n",
      "Operator 205: 1.9773077845226144\n",
      "Operator 206: -0.04019579669538641\n",
      "Operator 207: 1.9900871898605192\n",
      "Operator 208: -0.014844603779430005\n",
      "Operator 209: 1.9975325128987302\n",
      "Operator 210: -1.0700378359435847\n",
      "Operator 211: 1.1436500305652673\n",
      "Operator 212: 1.594980895162746\n",
      "Operator 213: -1.08842323794015\n",
      "Operator 214: 1.7527899080508296\n",
      "Operator 215: -1.752789908050842\n",
      "Operator 216: 1.8729461618541734\n",
      "Operator 217: -1.872946161854175\n",
      "Operator 218: 1.9271314757839748\n",
      "Operator 219: -1.92713147578399\n",
      "Operator 220: 1.9577619490739124\n",
      "Operator 221: -1.957761949073907\n",
      "Operator 222: 1.9773077845226146\n",
      "Operator 223: -1.9773077845226084\n",
      "Operator 224: 1.990087189860519\n",
      "Operator 225: -1.9900871898605157\n",
      "Operator 226: 1.9975325128987302\n",
      "Operator 228: -0.7684263278832533\n",
      "Operator 229: -2.4921370965643233\n",
      "Operator 230: -0.6211236085496075\n",
      "Operator 231: 1.0190249070057409\n",
      "Operator 232: -0.8627388567935467\n",
      "Operator 233: 1.537164900050707\n",
      "Operator 234: -0.4452506638988489\n",
      "Operator 235: 1.7389535917294205\n",
      "Operator 236: -0.2527630313711655\n",
      "Operator 237: 1.8465927238491253\n",
      "Operator 238: -0.1417703622533964\n",
      "Operator 239: 1.913588023589214\n",
      "Operator 240: -0.07053104587966597\n",
      "Operator 241: 1.957755682443719\n",
      "Operator 242: -0.024794590661850885\n",
      "Operator 243: 1.9851797045905117\n",
      "Operator 244: 0.6747921046416943\n",
      "Operator 245: -0.29285109083950334\n",
      "Operator 248: -1.1627462037719343\n",
      "Operator 250: -1.6414405654102602\n",
      "Operator 252: -1.8047067504789651\n",
      "Operator 254: -1.886432337076247\n",
      "Operator 256: -1.9355489710729794\n",
      "Operator 258: -1.9675074461949436\n",
      "Operator 260: -1.9876319326248093\n",
      "Total gradient norm: 23.702051923863557\n",
      "Operators under consideration (1):\n",
      "[19]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.386172399424887)]\n",
      "Operator(s) added to ansatz: [19]\n",
      "Gradients: [np.float64(3.386172399424887)]\n",
      "Initial energy: -29.452770945695725\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19]...\n",
      "Starting point: [np.float64(0.6500141175550417), np.float64(0.73559603083723), np.float64(0.3043643721616385), np.float64(0.6824569605089705), np.float64(0.2822650696728668), np.float64(0.5341623837253034), np.float64(-0.7605587056605337), np.float64(0.7100070877092517), np.float64(-0.6062178588396752), np.float64(-0.36265593007165065), np.float64(-0.4384047926070975), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -30.176069\n",
      "         Iterations: 20\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 69\n",
      "\n",
      "Current energy: -30.176069376129476\n",
      "(change of -0.7232984304337506)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19]\n",
      "On iteration 12.\n",
      "\n",
      "*** ADAPT-VQE Iteration 13 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -1.055047020299857\n",
      "Operator 1: 1.4714425790564003\n",
      "Operator 2: -1.1728612806754035\n",
      "Operator 3: 2.299630101235744\n",
      "Operator 4: -1.330117910269097\n",
      "Operator 5: 2.2200840820449335\n",
      "Operator 6: -1.6384537152757233\n",
      "Operator 7: 2.131417508309498\n",
      "Operator 8: -1.7841599452009405\n",
      "Operator 9: 2.0794256965132956\n",
      "Operator 10: -1.8679510164317183\n",
      "Operator 11: 2.045382261798143\n",
      "Operator 12: -1.9222470239849179\n",
      "Operator 13: 2.0222315828891437\n",
      "Operator 14: -1.9592159141215766\n",
      "Operator 15: 2.0073650513638377\n",
      "Operator 16: -1.9834294821449774\n",
      "Operator 18: 8.9341701687469e-08\n",
      "Operator 19: -1.0433070591468539e-07\n",
      "Operator 20: -0.6209169975197342\n",
      "Operator 21: 0.5585223804296585\n",
      "Operator 22: -0.6966997005172593\n",
      "Operator 24: -0.5030334761301916\n",
      "Operator 26: -0.3735700930227559\n",
      "Operator 27: -1.6581798647310775e-08\n",
      "Operator 28: -0.26921296796786603\n",
      "Operator 29: 1.136296437899251e-08\n",
      "Operator 30: -0.17561528210590205\n",
      "Operator 32: -0.08673389557003464\n",
      "Operator 34: 0.09441063130526689\n",
      "Operator 35: 1.1956483460431315\n",
      "Operator 36: -1.6363291990236357\n",
      "Operator 37: 1.1774673874142245\n",
      "Operator 38: -2.4024250941485663\n",
      "Operator 39: 1.694799934476387\n",
      "Operator 40: -2.2200840820449317\n",
      "Operator 41: 1.8157868627465956\n",
      "Operator 42: -2.131417508309495\n",
      "Operator 43: 1.8881435687933805\n",
      "Operator 44: -2.0794256965132947\n",
      "Operator 45: 1.936037885862007\n",
      "Operator 46: -2.045382261798145\n",
      "Operator 47: 1.9685483818029046\n",
      "Operator 48: -2.0222315828891424\n",
      "Operator 49: 1.9889489771721744\n",
      "Operator 50: -2.007365051363835\n",
      "Operator 51: 1.940976339695045\n",
      "Operator 52: -0.6698584935909383\n",
      "Operator 53: 1.578479691418753\n",
      "Operator 54: -1.451509997645422\n",
      "Operator 55: 2.4024250941485654\n",
      "Operator 56: -1.6947999344763849\n",
      "Operator 57: 2.2200840820449335\n",
      "Operator 58: -1.8157868627465956\n",
      "Operator 59: 2.1314175083094975\n",
      "Operator 60: -1.8881435687933799\n",
      "Operator 61: 2.0794256965132956\n",
      "Operator 62: -1.936037885862007\n",
      "Operator 63: 2.045382261798143\n",
      "Operator 64: -1.9685483818029046\n",
      "Operator 65: 2.0222315828891437\n",
      "Operator 66: -1.9889489771721744\n",
      "Operator 67: 2.0073650513638377\n",
      "Operator 68: -0.5492444114732733\n",
      "Operator 69: -1.439162121720049e-07\n",
      "Operator 70: -0.5585223804296573\n",
      "Operator 71: 1.8194426373396855\n",
      "Operator 73: 1.3389115462654173\n",
      "Operator 75: 1.033163170607966\n",
      "Operator 76: 1.6581798647310775e-08\n",
      "Operator 77: 0.8037029075387605\n",
      "Operator 78: -1.1362964319919876e-08\n",
      "Operator 79: 0.6094668748635393\n",
      "Operator 81: 0.4306489041748577\n",
      "Operator 83: 0.25749916736563516\n",
      "Operator 84: 1.4128769265653318e-08\n",
      "Operator 85: -0.37080645295363945\n",
      "Operator 86: 0.7310851895942948\n",
      "Operator 87: 1.4198044577244515\n",
      "Operator 88: 0.09889885469069092\n",
      "Operator 89: 1.3238910693243846\n",
      "Operator 90: -0.18620139734307983\n",
      "Operator 91: 1.501717299340526\n",
      "Operator 93: 1.7709006755395527\n",
      "Operator 95: 1.8642731714069036\n",
      "Operator 97: 1.9178302489359047\n",
      "Operator 99: 1.9524699038199191\n",
      "Operator 101: 1.9758446538549859\n",
      "Operator 103: 1.9907809091517195\n",
      "Operator 104: -0.35494038212536033\n",
      "Operator 105: 1.0807663601213706\n",
      "Operator 106: -0.7903410027639457\n",
      "Operator 107: 0.5989655817584978\n",
      "Operator 108: 2.842716365245186e-08\n",
      "Operator 109: 0.6966997005172589\n",
      "Operator 111: 0.5030334761301922\n",
      "Operator 113: 0.37357009302275646\n",
      "Operator 114: 1.658179613026892e-08\n",
      "Operator 115: 0.26921296796786565\n",
      "Operator 116: -1.136296437899251e-08\n",
      "Operator 117: 0.1756152821059015\n",
      "Operator 119: 0.08673389557003464\n",
      "Operator 121: 0.27051823209675463\n",
      "Operator 122: -1.7456054137064725\n",
      "Operator 123: -2.8427163407974504e-08\n",
      "Operator 124: -1.819442637339681\n",
      "Operator 126: -1.3389115462654195\n",
      "Operator 128: -1.033163170607972\n",
      "Operator 129: -1.6581797467129125e-08\n",
      "Operator 130: -0.8037029075387545\n",
      "Operator 131: 1.1362964319919876e-08\n",
      "Operator 132: -0.6094668748635299\n",
      "Operator 134: -0.430648904174855\n",
      "Operator 136: -0.2574991673656405\n",
      "Operator 137: -1.4128769265653318e-08\n",
      "Operator 138: 1.6848530451930696e-07\n",
      "Operator 139: 1.9106776003248118\n",
      "Operator 140: -1.5036826083652763\n",
      "Operator 141: 0.8125496185500833\n",
      "Operator 142: -2.299630101235744\n",
      "Operator 143: 1.330117910269097\n",
      "Operator 144: -2.220084082044932\n",
      "Operator 145: 1.6384537152757233\n",
      "Operator 146: -2.1314175083094944\n",
      "Operator 147: 1.784159945200941\n",
      "Operator 148: -2.079425696513295\n",
      "Operator 149: 1.8679510164317183\n",
      "Operator 150: -2.0453822617981445\n",
      "Operator 151: 1.9222470239849179\n",
      "Operator 152: -2.0222315828891424\n",
      "Operator 153: 1.9592159141215775\n",
      "Operator 154: -2.007365051363835\n",
      "Operator 155: 1.4832706600023533\n",
      "Operator 156: 0.01828871662357918\n",
      "Operator 157: 1.2179712933748472\n",
      "Operator 158: -0.272470449237202\n",
      "Operator 159: 1.5688450600442225\n",
      "Operator 161: 1.770900675539552\n",
      "Operator 163: 1.864273171406904\n",
      "Operator 165: 1.9178302489359051\n",
      "Operator 167: 1.9524699038199185\n",
      "Operator 169: 1.975844653854986\n",
      "Operator 171: 1.9907809091517192\n",
      "Operator 173: -1.1292937520515693\n",
      "Operator 174: 1.983429482144976\n",
      "Operator 175: 2.038166355869168\n",
      "Operator 176: -2.202359872500976\n",
      "Operator 177: 0.7099054896656986\n",
      "Operator 178: -0.7700198400530525\n",
      "Operator 179: 1.6956650968361904\n",
      "Operator 180: -1.8504185324937388\n",
      "Operator 181: 1.850418532493748\n",
      "Operator 182: -1.914054193083542\n",
      "Operator 183: 1.9140541930835364\n",
      "Operator 184: -1.9479836862963498\n",
      "Operator 185: 1.9479836862963635\n",
      "Operator 186: -1.9690413861547795\n",
      "Operator 187: 1.9690413861547755\n",
      "Operator 188: -1.983167969498925\n",
      "Operator 189: 1.983167969498917\n",
      "Operator 190: -1.9926145281120562\n",
      "Operator 191: 1.9926145281120469\n",
      "Operator 192: -1.9981595848726013\n",
      "Operator 193: -0.48810608922235155\n",
      "Operator 194: -0.7498212286476205\n",
      "Operator 195: 1.7577790313375954\n",
      "Operator 196: -0.3419876471742994\n",
      "Operator 197: 1.7712428027709919\n",
      "Operator 198: -0.28454956607243087\n",
      "Operator 199: 1.9140541930835409\n",
      "Operator 200: -0.16456768628198992\n",
      "Operator 201: 1.947983686296347\n",
      "Operator 202: -0.09901127552352448\n",
      "Operator 203: 1.9690413861547773\n",
      "Operator 204: -0.05776102330345877\n",
      "Operator 205: 1.983167969498926\n",
      "Operator 206: -0.02984357808221829\n",
      "Operator 207: 1.9926145281120538\n",
      "Operator 208: -0.011064551787755394\n",
      "Operator 209: 1.9981595848725995\n",
      "Operator 210: -0.5616314702201669\n",
      "Operator 211: -1.8167445906599098\n",
      "Operator 212: 1.8474332097070836\n",
      "Operator 213: -1.6231109589209867\n",
      "Operator 214: 1.8504185324937383\n",
      "Operator 215: -1.8504185324937505\n",
      "Operator 216: 1.9140541930835409\n",
      "Operator 217: -1.914054193083542\n",
      "Operator 218: 1.947983686296347\n",
      "Operator 219: -1.9479836862963635\n",
      "Operator 220: 1.9690413861547773\n",
      "Operator 221: -1.9690413861547724\n",
      "Operator 222: 1.9831679694989257\n",
      "Operator 223: -1.9831679694989188\n",
      "Operator 224: 1.9926145281120538\n",
      "Operator 225: -1.9926145281120502\n",
      "Operator 226: 1.9981595848725986\n",
      "Operator 227: 1.6229577696875914\n",
      "Operator 228: -0.5557426936845923\n",
      "Operator 229: 0.9941785200235467\n",
      "Operator 230: -0.6623826507401707\n",
      "Operator 231: 1.4515099976454215\n",
      "Operator 232: -0.5276356560003945\n",
      "Operator 233: 1.6947999344763849\n",
      "Operator 234: -0.30337469413697415\n",
      "Operator 235: 1.8157868627465952\n",
      "Operator 236: -0.18108083481862003\n",
      "Operator 237: 1.8881435687933787\n",
      "Operator 238: -0.10405144337001715\n",
      "Operator 239: 1.936037885862007\n",
      "Operator 240: -0.052328456720489754\n",
      "Operator 241: 1.9685483818029046\n",
      "Operator 242: -0.018470613058414992\n",
      "Operator 243: 1.9889489771721744\n",
      "Operator 244: 0.5197164832667833\n",
      "Operator 245: 0.46182048939766707\n",
      "Operator 246: -1.2462899816014752\n",
      "Operator 248: -1.5688450600442239\n",
      "Operator 250: -1.7709006755395507\n",
      "Operator 252: -1.8642731714068996\n",
      "Operator 254: -1.917830248935903\n",
      "Operator 256: -1.9524699038199214\n",
      "Operator 258: -1.9758446538549836\n",
      "Operator 260: -1.9907809091517161\n",
      "Total gradient norm: 22.979546869768843\n",
      "Operators under consideration (1):\n",
      "[38]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4024250941485663)]\n",
      "Operator(s) added to ansatz: [38]\n",
      "Gradients: [np.float64(-2.4024250941485663)]\n",
      "Initial energy: -30.176069376129476\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38]...\n",
      "Starting point: [np.float64(0.6711141253370706), np.float64(0.7424155453925091), np.float64(0.1467935243278197), np.float64(0.6973089829757804), np.float64(0.15640767479171142), np.float64(0.5907933560286689), np.float64(-0.7639464883034047), np.float64(0.7204834243112903), np.float64(-0.6382855223605929), np.float64(-0.5059421713198039), np.float64(-0.6072858313518218), np.float64(-0.49105811694496043), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -30.404506\n",
      "         Iterations: 20\n",
      "         Function evaluations: 40\n",
      "         Gradient evaluations: 39\n",
      "\n",
      "Current energy: -30.404506148825625\n",
      "(change of -0.22843677269614915)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38]\n",
      "On iteration 13.\n",
      "\n",
      "*** ADAPT-VQE Iteration 14 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.6516359977802069\n",
      "Operator 1: 1.2522272330577713\n",
      "Operator 2: -0.40525321365574907\n",
      "Operator 3: 1.8082018100278332\n",
      "Operator 4: -0.34344472563941425\n",
      "Operator 5: 2.2864833553562542\n",
      "Operator 6: -1.2070945778498343\n",
      "Operator 7: 2.24393351904467\n",
      "Operator 8: -1.594885946453957\n",
      "Operator 9: 2.13745165007893\n",
      "Operator 10: -1.7703194135715052\n",
      "Operator 11: 2.0759894845509494\n",
      "Operator 12: -1.8695615464799384\n",
      "Operator 13: 2.0367285560943995\n",
      "Operator 14: -1.9325930810540237\n",
      "Operator 15: 2.012119236705551\n",
      "Operator 16: -1.972734012324926\n",
      "Operator 20: -0.7613255773840113\n",
      "Operator 21: 0.7140646493505718\n",
      "Operator 24: -0.7452689841083349\n",
      "Operator 26: -0.5114771291338008\n",
      "Operator 28: -0.3562899478998056\n",
      "Operator 30: -0.22871346788321412\n",
      "Operator 32: -0.11202419587234957\n",
      "Operator 34: 0.1775912614992596\n",
      "Operator 35: 0.7464442502717639\n",
      "Operator 36: -1.12877570247525\n",
      "Operator 37: 0.7696661136926561\n",
      "Operator 39: 1.358884790671766\n",
      "Operator 40: -2.4717771793966348\n",
      "Operator 41: 1.6627818985537712\n",
      "Operator 42: -2.243933519044667\n",
      "Operator 43: 1.807849684385467\n",
      "Operator 44: -2.137451650078929\n",
      "Operator 45: 1.893243744627453\n",
      "Operator 46: -2.075989484550951\n",
      "Operator 47: 1.948083403393025\n",
      "Operator 48: -2.0367285560943977\n",
      "Operator 49: 1.9818117198317018\n",
      "Operator 50: -2.0121192367055483\n",
      "Operator 51: 1.8519213342370575\n",
      "Operator 52: 0.07088201101855968\n",
      "Operator 53: 1.216550511454214\n",
      "Operator 54: -0.574035068594088\n",
      "Operator 55: 2.010928148093594\n",
      "Operator 56: -1.0253616685711588\n",
      "Operator 57: 2.4717771793966365\n",
      "Operator 58: -1.6627818985537703\n",
      "Operator 59: 2.24393351904467\n",
      "Operator 60: -1.8078496843854692\n",
      "Operator 61: 2.13745165007893\n",
      "Operator 62: -1.8932437446274557\n",
      "Operator 63: 2.0759894845509494\n",
      "Operator 64: -1.948083403393025\n",
      "Operator 65: 2.0367285560943995\n",
      "Operator 66: -1.9818117198317018\n",
      "Operator 67: 2.0121192367055514\n",
      "Operator 68: -0.7192425321279001\n",
      "Operator 70: -1.1159828196714856\n",
      "Operator 71: 1.2246643885151982\n",
      "Operator 73: 1.9753060079397171\n",
      "Operator 75: 1.4120586115474196\n",
      "Operator 77: 1.0588982636175386\n",
      "Operator 79: 0.7892537271846846\n",
      "Operator 81: 0.5537198963602635\n",
      "Operator 83: 0.3303456948056763\n",
      "Operator 85: -0.4824570918294723\n",
      "Operator 86: 0.7508649934709829\n",
      "Operator 87: 1.181075731692203\n",
      "Operator 88: 0.17429067083095984\n",
      "Operator 89: 0.8546512883220524\n",
      "Operator 90: -0.002242606767331177\n",
      "Operator 91: 0.9787427570799621\n",
      "Operator 93: 1.485883104279487\n",
      "Operator 95: 1.7439403990523767\n",
      "Operator 97: 1.8567266960252675\n",
      "Operator 99: 1.920107000688036\n",
      "Operator 101: 1.9600146651454309\n",
      "Operator 103: 1.9848162495918564\n",
      "Operator 104: -0.4450429338529168\n",
      "Operator 105: 1.4434047864794568\n",
      "Operator 106: -0.9381318437766668\n",
      "Operator 107: 0.8134591059382085\n",
      "Operator 108: -0.49373600139730633\n",
      "Operator 109: 0.813456454306142\n",
      "Operator 110: -0.5726716610191818\n",
      "Operator 111: 0.7452689841083353\n",
      "Operator 113: 0.5114771291338014\n",
      "Operator 115: 0.3562899478998057\n",
      "Operator 117: 0.22871346788321367\n",
      "Operator 119: 0.1120241958723498\n",
      "Operator 121: 0.34147234194935966\n",
      "Operator 122: -1.853216900447325\n",
      "Operator 124: -0.9175494925211747\n",
      "Operator 125: 0.5726716610191811\n",
      "Operator 126: -1.9753060079397182\n",
      "Operator 128: -1.412058611547425\n",
      "Operator 130: -1.0588982636175324\n",
      "Operator 132: -0.7892537271846751\n",
      "Operator 134: -0.5537198963602611\n",
      "Operator 136: -0.3303456948056811\n",
      "Operator 139: 1.6598169529839244\n",
      "Operator 140: -1.1165853971174635\n",
      "Operator 141: 0.2571909710633013\n",
      "Operator 142: 0.11326814778320278\n",
      "Operator 143: 1.1173457688629167\n",
      "Operator 144: -2.2864833553562525\n",
      "Operator 145: 1.2070945778498352\n",
      "Operator 146: -2.243933519044668\n",
      "Operator 147: 1.594885946453957\n",
      "Operator 148: -2.137451650078928\n",
      "Operator 149: 1.7703194135715057\n",
      "Operator 150: -2.0759894845509512\n",
      "Operator 151: 1.8695615464799384\n",
      "Operator 152: -2.0367285560943977\n",
      "Operator 153: 1.9325930810540237\n",
      "Operator 154: -2.0121192367055483\n",
      "Operator 155: 1.2803671722398535\n",
      "Operator 156: 0.051391701282239396\n",
      "Operator 157: 0.8142557322315307\n",
      "Operator 158: 0.10894622302310344\n",
      "Operator 159: 1.0610243379035826\n",
      "Operator 161: 1.37449565205932\n",
      "Operator 163: 1.7439403990523767\n",
      "Operator 165: 1.8567266960252673\n",
      "Operator 167: 1.920107000688036\n",
      "Operator 169: 1.9600146651454309\n",
      "Operator 171: 1.9848162495918562\n",
      "Operator 173: -1.2880267264674958\n",
      "Operator 174: 1.972734012324926\n",
      "Operator 175: 2.037982200076711\n",
      "Operator 176: -2.0522949371753003\n",
      "Operator 177: -0.013741104649137992\n",
      "Operator 178: -0.11676441797189235\n",
      "Operator 179: -0.9205286089653562\n",
      "Operator 180: -2.105004514378254\n",
      "Operator 181: 1.5029529247192084\n",
      "Operator 182: -1.8290601514563358\n",
      "Operator 183: 1.8290601514563312\n",
      "Operator 184: -1.9069251469546553\n",
      "Operator 185: 1.906925146954669\n",
      "Operator 186: -1.9473514196301387\n",
      "Operator 187: 1.9473514196301343\n",
      "Operator 188: -1.9720190011238454\n",
      "Operator 189: 1.972019001123839\n",
      "Operator 190: -1.9878253343689372\n",
      "Operator 191: 1.9878253343689276\n",
      "Operator 192: -1.9969724857360067\n",
      "Operator 193: -0.6644788748260445\n",
      "Operator 194: -1.080559430034598\n",
      "Operator 195: 1.603962760544212\n",
      "Operator 196: -0.83268604943044\n",
      "Operator 197: -0.902926554080575\n",
      "Operator 198: -0.4654919369522259\n",
      "Operator 199: 1.6919468417744503\n",
      "Operator 200: -0.3215887851867394\n",
      "Operator 201: 1.906925146954654\n",
      "Operator 202: -0.1758278375886031\n",
      "Operator 203: 1.947351419630136\n",
      "Operator 204: -0.09787129409918799\n",
      "Operator 205: 1.9720190011238459\n",
      "Operator 206: -0.049521514457956245\n",
      "Operator 207: 1.9878253343689347\n",
      "Operator 208: -0.018224858873862687\n",
      "Operator 209: 1.9969724857360043\n",
      "Operator 210: -0.7905403366162993\n",
      "Operator 211: -1.7183131611556723\n",
      "Operator 212: 1.38742023452743\n",
      "Operator 213: -1.6746086161749874\n",
      "Operator 214: -0.8790824601106138\n",
      "Operator 215: -1.6247503977344946\n",
      "Operator 216: 1.8290601514563352\n",
      "Operator 217: -1.829060151456337\n",
      "Operator 218: 1.906925146954654\n",
      "Operator 219: -1.906925146954669\n",
      "Operator 220: 1.947351419630136\n",
      "Operator 221: -1.94735141963013\n",
      "Operator 222: 1.9720190011238459\n",
      "Operator 223: -1.9720190011238405\n",
      "Operator 224: 1.9878253343689347\n",
      "Operator 225: -1.9878253343689312\n",
      "Operator 226: 1.9969724857360047\n",
      "Operator 227: 1.261082676942504\n",
      "Operator 228: -0.7891384206929644\n",
      "Operator 229: 0.4254924773860932\n",
      "Operator 230: -0.9691627880341838\n",
      "Operator 231: 1.2857729217086526\n",
      "Operator 232: -0.3711652042586732\n",
      "Operator 233: 1.0253616685711604\n",
      "Operator 234: -0.5955772689024001\n",
      "Operator 235: 1.6627818985537703\n",
      "Operator 236: -0.3218614449462045\n",
      "Operator 237: 1.8078496843854692\n",
      "Operator 238: -0.176506826323559\n",
      "Operator 239: 1.8932437446274544\n",
      "Operator 240: -0.08695273185509689\n",
      "Operator 241: 1.948083403393025\n",
      "Operator 242: -0.03045571583050155\n",
      "Operator 243: 1.9818117198317018\n",
      "Operator 244: 0.692565014290089\n",
      "Operator 245: 0.730078740367264\n",
      "Operator 246: -0.9467781410855685\n",
      "Operator 247: 0.17131344363245457\n",
      "Operator 248: 0.9302014866129215\n",
      "Operator 249: 0.17683060200066433\n",
      "Operator 250: -1.3744956520593192\n",
      "Operator 252: -1.7439403990523734\n",
      "Operator 254: -1.8567266960252669\n",
      "Operator 256: -1.9201070006880387\n",
      "Operator 258: -1.9600146651454293\n",
      "Operator 260: -1.9848162495918533\n",
      "Total gradient norm: 21.772549149918657\n",
      "Operators under consideration (1):\n",
      "[40]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4717771793966348)]\n",
      "Operator(s) added to ansatz: [40]\n",
      "Gradients: [np.float64(-2.4717771793966348)]\n",
      "Initial energy: -30.404506148825625\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40]...\n",
      "Starting point: [np.float64(0.6322594526638966), np.float64(0.7302007051347348), np.float64(0.19820792684190167), np.float64(0.6704185944083793), np.float64(0.1737593386183784), np.float64(0.47410689439646275), np.float64(-0.7578832656477655), np.float64(0.7016627346909154), np.float64(-0.5771723506304482), np.float64(-0.3918886960168098), np.float64(-0.5706990885250273), np.float64(-0.42317898369788876), np.float64(0.1948327325826549), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -30.652337\n",
      "         Iterations: 20\n",
      "         Function evaluations: 35\n",
      "         Gradient evaluations: 35\n",
      "\n",
      "Current energy: -30.652337130848682\n",
      "(change of -0.2478309820230571)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40]\n",
      "On iteration 14.\n",
      "\n",
      "*** ADAPT-VQE Iteration 15 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.504511962374958\n",
      "Operator 1: 1.1719668807941404\n",
      "Operator 2: -0.10062885035676616\n",
      "Operator 3: 1.5879160960821372\n",
      "Operator 4: 0.4371805758669981\n",
      "Operator 5: 1.6855677556821291\n",
      "Operator 6: -0.21863365755102568\n",
      "Operator 7: 2.2829963791062635\n",
      "Operator 8: -1.1676404566010279\n",
      "Operator 9: 2.243804912375052\n",
      "Operator 10: -1.589146018715804\n",
      "Operator 11: 2.1274869520493933\n",
      "Operator 12: -1.7804905019363595\n",
      "Operator 13: 2.0602792176385787\n",
      "Operator 14: -1.8892972320553938\n",
      "Operator 15: 2.019762292684357\n",
      "Operator 16: -1.9555409437670201\n",
      "Operator 20: -0.8412214170361869\n",
      "Operator 21: 0.7019149156039679\n",
      "Operator 26: -0.7416604670515234\n",
      "Operator 28: -0.48047149457068583\n",
      "Operator 30: -0.299448391163216\n",
      "Operator 32: -0.14463664329948622\n",
      "Operator 34: 0.21849265583577704\n",
      "Operator 35: 0.5789759189259429\n",
      "Operator 36: -0.8864360481289015\n",
      "Operator 37: 0.20848951899054918\n",
      "Operator 38: 0.24424292415553467\n",
      "Operator 39: 1.2172349196823036\n",
      "Operator 41: 1.3316242260666553\n",
      "Operator 42: -2.491448533390238\n",
      "Operator 43: 1.6629276986314383\n",
      "Operator 44: -2.243804912375049\n",
      "Operator 45: 1.8217819393671117\n",
      "Operator 46: -2.127486952049396\n",
      "Operator 47: 1.9149059707579759\n",
      "Operator 48: -2.060279217638576\n",
      "Operator 49: 1.9703310819638273\n",
      "Operator 50: -2.019762292684354\n",
      "Operator 51: 1.8003974598565693\n",
      "Operator 52: 0.3572692470318658\n",
      "Operator 53: 1.0650444123643736\n",
      "Operator 54: -0.011912293339999866\n",
      "Operator 55: 1.6181122188823647\n",
      "Operator 56: -0.0231833175529324\n",
      "Operator 57: 1.9727860924523788\n",
      "Operator 58: -0.9649602746274633\n",
      "Operator 59: 2.4914485333902405\n",
      "Operator 60: -1.6629276986314374\n",
      "Operator 61: 2.243804912375052\n",
      "Operator 62: -1.8217819393671109\n",
      "Operator 63: 2.1274869520493933\n",
      "Operator 64: -1.9149059707579759\n",
      "Operator 65: 2.0602792176385787\n",
      "Operator 66: -1.9703310819638262\n",
      "Operator 67: 2.019762292684357\n",
      "Operator 68: -0.7863527759404603\n",
      "Operator 70: -1.3117405832998774\n",
      "Operator 71: 1.0495895584075985\n",
      "Operator 72: -0.5088118168815838\n",
      "Operator 73: 1.245271770166374\n",
      "Operator 75: 2.0191138325933435\n",
      "Operator 77: 1.4143749412166482\n",
      "Operator 79: 1.0236298165474156\n",
      "Operator 81: 0.7097692726345668\n",
      "Operator 83: 0.42190922155058863\n",
      "Operator 85: -0.5224628371214459\n",
      "Operator 86: 0.7419276460818007\n",
      "Operator 87: 1.0946031408556265\n",
      "Operator 88: 0.20847006716483532\n",
      "Operator 89: 0.6829476974452608\n",
      "Operator 90: 0.09451446663546056\n",
      "Operator 91: 0.6375979380619913\n",
      "Operator 92: 0.16000188244720526\n",
      "Operator 93: 0.9956378757948423\n",
      "Operator 95: 1.4596215692989023\n",
      "Operator 97: 1.7418966704304881\n",
      "Operator 99: 1.8650422863344231\n",
      "Operator 101: 1.9341608087894944\n",
      "Operator 103: 1.9752043761900038\n",
      "Operator 104: -0.4731019954729999\n",
      "Operator 105: 1.5692694190199377\n",
      "Operator 106: -0.9778121831575473\n",
      "Operator 107: 0.9772535338829618\n",
      "Operator 108: -0.6365877979625484\n",
      "Operator 109: 1.1136285178767953\n",
      "Operator 110: -1.1442875604718785\n",
      "Operator 111: 0.8078658382812913\n",
      "Operator 112: -0.6233156028870319\n",
      "Operator 113: 0.7416604670515241\n",
      "Operator 115: 0.4804714945706868\n",
      "Operator 117: 0.29944839116321575\n",
      "Operator 119: 0.14463664329948622\n",
      "Operator 121: 0.3647193397022601\n",
      "Operator 122: -1.8259623133907712\n",
      "Operator 124: -0.9722125633901463\n",
      "Operator 125: 0.7010580399310368\n",
      "Operator 126: -0.8629660725734208\n",
      "Operator 127: 0.6233156028870306\n",
      "Operator 128: -2.019113832593348\n",
      "Operator 130: -1.414374941216642\n",
      "Operator 132: -1.0236298165474063\n",
      "Operator 134: -0.7097692726345639\n",
      "Operator 136: -0.4219092215505936\n",
      "Operator 139: 1.572259526478879\n",
      "Operator 140: -0.9316917734967483\n",
      "Operator 141: 0.060418545130114215\n",
      "Operator 142: 0.16332588228952652\n",
      "Operator 143: 0.7956230918501471\n",
      "Operator 144: 0.27668970218216404\n",
      "Operator 145: 1.033367481937302\n",
      "Operator 146: -2.282996379106262\n",
      "Operator 147: 1.1676404566010283\n",
      "Operator 148: -2.24380491237505\n",
      "Operator 149: 1.5891460187158057\n",
      "Operator 150: -2.1274869520493955\n",
      "Operator 151: 1.7804905019363595\n",
      "Operator 152: -2.060279217638576\n",
      "Operator 153: 1.889297232055392\n",
      "Operator 154: -2.019762292684354\n",
      "Operator 155: 1.2088079694563727\n",
      "Operator 156: 0.07044804471694191\n",
      "Operator 157: 0.6610327180697939\n",
      "Operator 158: 0.19535885248060342\n",
      "Operator 159: 0.7684121550202807\n",
      "Operator 160: 0.20603070436001764\n",
      "Operator 161: 0.8873121863295029\n",
      "Operator 163: 1.3374993353927929\n",
      "Operator 165: 1.7418966704304886\n",
      "Operator 167: 1.8650422863344234\n",
      "Operator 169: 1.9341608087894944\n",
      "Operator 171: 1.9752043761900047\n",
      "Operator 173: -1.3304785293498462\n",
      "Operator 174: 1.9555409437670201\n",
      "Operator 175: 2.0309622680098\n",
      "Operator 176: -1.9948472712211105\n",
      "Operator 177: -0.30226427005034534\n",
      "Operator 178: 0.12524444270968318\n",
      "Operator 179: -1.1833601538159182\n",
      "Operator 180: -1.8598664413460129\n",
      "Operator 181: -1.1079353108636847\n",
      "Operator 182: -2.0803958274736996\n",
      "Operator 183: 1.4660614012963262\n",
      "Operator 184: -1.824615714198833\n",
      "Operator 185: 1.8246157141988477\n",
      "Operator 186: -1.9093299009488938\n",
      "Operator 187: 1.9093299009488902\n",
      "Operator 188: -1.9536092588374558\n",
      "Operator 189: 1.953609258837448\n",
      "Operator 190: -1.9800897237152935\n",
      "Operator 191: 1.980089723715284\n",
      "Operator 192: -1.995065529135645\n",
      "Operator 193: -0.7184658743899771\n",
      "Operator 194: -1.1900087709079932\n",
      "Operator 195: 1.5294534977487595\n",
      "Operator 196: -0.8871935859201174\n",
      "Operator 197: -1.1381764532986491\n",
      "Operator 198: -1.2182722789422211\n",
      "Operator 199: -1.0537928382757857\n",
      "Operator 200: -0.48091459667979847\n",
      "Operator 201: 1.6719554961498617\n",
      "Operator 202: -0.32592180918257246\n",
      "Operator 203: 1.9093299009488902\n",
      "Operator 204: -0.16742594251691312\n",
      "Operator 205: 1.9536092588374556\n",
      "Operator 206: -0.08185514719759321\n",
      "Operator 207: 1.9800897237152912\n",
      "Operator 208: -0.029765943617169416\n",
      "Operator 209: 1.9950655291356425\n",
      "Operator 210: -0.8690798645271418\n",
      "Operator 211: -1.6782094119427926\n",
      "Operator 212: 1.1621525880485253\n",
      "Operator 213: -1.422910071713773\n",
      "Operator 214: -1.2837642652201977\n",
      "Operator 215: -1.915928215211061\n",
      "Operator 216: -0.9340800203378093\n",
      "Operator 217: -1.5999221731353312\n",
      "Operator 218: 1.8246157141988335\n",
      "Operator 219: -1.8246157141988464\n",
      "Operator 220: 1.9093299009488898\n",
      "Operator 221: -1.909329900948886\n",
      "Operator 222: 1.9536092588374556\n",
      "Operator 223: -1.9536092588374494\n",
      "Operator 224: 1.9800897237152908\n",
      "Operator 225: -1.9800897237152872\n",
      "Operator 226: 1.995065529135643\n",
      "Operator 227: 1.1372970312433432\n",
      "Operator 228: -0.8570647596794871\n",
      "Operator 229: 0.2315906161007878\n",
      "Operator 230: -1.1255820001266112\n",
      "Operator 231: 0.77995579251148\n",
      "Operator 232: -0.421326744008628\n",
      "Operator 233: 0.6641282120453967\n",
      "Operator 234: -0.35338895194724207\n",
      "Operator 235: 0.9649602746274639\n",
      "Operator 236: -0.6010547230023072\n",
      "Operator 237: 1.6629276986314374\n",
      "Operator 238: -0.3028636037570533\n",
      "Operator 239: 1.8217819393671109\n",
      "Operator 240: -0.14407811122721403\n",
      "Operator 241: 1.9149059707579748\n",
      "Operator 242: -0.049827539991712855\n",
      "Operator 243: 1.9703310819638262\n",
      "Operator 244: 0.7431582383790045\n",
      "Operator 245: 0.8325276436118607\n",
      "Operator 246: -0.8468575725378599\n",
      "Operator 247: 0.09468141748930961\n",
      "Operator 248: 1.0879812106600721\n",
      "Operator 249: 0.9845804023686713\n",
      "Operator 250: 1.0608248931707809\n",
      "Operator 251: 0.19256647297711926\n",
      "Operator 252: -1.3374993353927904\n",
      "Operator 254: -1.7418966704304877\n",
      "Operator 256: -1.8650422863344254\n",
      "Operator 258: -1.934160808789493\n",
      "Operator 260: -1.975204376190001\n",
      "Total gradient norm: 20.759292383011775\n",
      "Operators under consideration (1):\n",
      "[59]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.4914485333902405)]\n",
      "Operator(s) added to ansatz: [59]\n",
      "Gradients: [np.float64(2.4914485333902405)]\n",
      "Initial energy: -30.652337130848682\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59]...\n",
      "Starting point: [np.float64(0.5744424360526741), np.float64(0.714787613212915), np.float64(0.21909306886326013), np.float64(0.634266107811851), np.float64(0.1804630236575237), np.float64(0.37328445876282695), np.float64(-0.7502680435427933), np.float64(0.6774963555500185), np.float64(-0.4636151825424554), np.float64(-0.3438776880582546), np.float64(-0.5590730164297278), np.float64(-0.40073107897404453), np.float64(0.23540659576440323), np.float64(0.20598604321001643), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -30.899540\n",
      "         Iterations: 22\n",
      "         Function evaluations: 34\n",
      "         Gradient evaluations: 34\n",
      "\n",
      "Current energy: -30.899539621090824\n",
      "(change of -0.2472024902421417)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59]\n",
      "On iteration 15.\n",
      "\n",
      "*** ADAPT-VQE Iteration 16 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.4553137853436618\n",
      "Operator 1: 1.1453923883773542\n",
      "Operator 2: 0.013805025785825925\n",
      "Operator 3: 1.471888549831876\n",
      "Operator 4: 0.6982555671002386\n",
      "Operator 5: 1.4710899961465365\n",
      "Operator 6: 0.14416488981851489\n",
      "Operator 7: -0.17172617278339575\n",
      "Operator 8: -1.0069813930303806\n",
      "Operator 9: 2.2809651472536006\n",
      "Operator 10: -1.1726542203209405\n",
      "Operator 11: 2.226613153383693\n",
      "Operator 12: -1.6076313871948025\n",
      "Operator 13: 2.102910125118784\n",
      "Operator 14: -1.8107803305998595\n",
      "Operator 15: 2.0333505756482264\n",
      "Operator 16: -1.9249785837916882\n",
      "Operator 20: -0.8575278940484272\n",
      "Operator 21: 0.6929248414693128\n",
      "Operator 25: 0.5237821765384716\n",
      "Operator 26: -0.8025192940389334\n",
      "Operator 27: 0.6179630552034949\n",
      "Operator 28: -0.6981882238225012\n",
      "Operator 30: -0.40747567048723643\n",
      "Operator 32: -0.19161836848376967\n",
      "Operator 34: 0.23393940601216867\n",
      "Operator 35: 0.5252656941207382\n",
      "Operator 36: -0.791137731036124\n",
      "Operator 37: 0.0020302947209884436\n",
      "Operator 38: 0.3398621047413976\n",
      "Operator 39: 0.8155992407884763\n",
      "Operator 40: 0.14561755260721412\n",
      "Operator 41: 0.4763003497985393\n",
      "Operator 42: -1.9914598809162447\n",
      "Operator 43: 0.9826517751395047\n",
      "Operator 44: -2.4831406618040344\n",
      "Operator 45: 1.6857092371616162\n",
      "Operator 46: -2.226613153383694\n",
      "Operator 47: 1.8550374437245996\n",
      "Operator 48: -2.102910125118782\n",
      "Operator 49: 1.9498994295409626\n",
      "Operator 50: -2.033350575648224\n",
      "Operator 51: 1.780358651511645\n",
      "Operator 52: 0.45184452097445393\n",
      "Operator 53: 1.0027160290886743\n",
      "Operator 54: 0.2058400183133941\n",
      "Operator 55: 1.4309732610055064\n",
      "Operator 56: 0.5525313914678394\n",
      "Operator 57: 1.592604921609273\n",
      "Operator 58: -0.6077322319011332\n",
      "Operator 60: -1.3408497917921727\n",
      "Operator 61: 2.4831406618040357\n",
      "Operator 62: -1.6857092371616194\n",
      "Operator 63: 2.2266131533836933\n",
      "Operator 64: -1.8550374437245996\n",
      "Operator 65: 2.1029101251187834\n",
      "Operator 66: -1.9498994295409626\n",
      "Operator 67: 2.0333505756482264\n",
      "Operator 68: -0.8100913474162921\n",
      "Operator 70: -1.384127233123777\n",
      "Operator 71: 0.9441021851685784\n",
      "Operator 72: -0.6763359017091057\n",
      "Operator 73: 1.091686503804734\n",
      "Operator 75: 0.8898450335129694\n",
      "Operator 76: -0.6179630552034949\n",
      "Operator 77: 2.0048793152949917\n",
      "Operator 79: 1.3683036651328369\n",
      "Operator 81: 0.9283477778920781\n",
      "Operator 83: 0.5482460466417801\n",
      "Operator 85: -0.5357149489729326\n",
      "Operator 86: 0.7373924074685856\n",
      "Operator 87: 1.0658930078676723\n",
      "Operator 88: 0.22086434310606895\n",
      "Operator 89: 0.624762151875863\n",
      "Operator 90: 0.14566181084810753\n",
      "Operator 91: 0.52310549428082\n",
      "Operator 92: 0.2629969623943917\n",
      "Operator 93: 0.7330089091818506\n",
      "Operator 94: 0.2489430945522122\n",
      "Operator 95: -0.9767828685022251\n",
      "Operator 96: -0.18893914751621227\n",
      "Operator 97: 1.3457901941807855\n",
      "Operator 99: 1.756573714594787\n",
      "Operator 101: 1.8869025935670185\n",
      "Operator 103: 1.958045156739402\n",
      "Operator 104: -0.48167441587367565\n",
      "Operator 105: 1.608527258425322\n",
      "Operator 106: -0.985213783816292\n",
      "Operator 107: 1.0317011651869112\n",
      "Operator 108: -0.6874829801899955\n",
      "Operator 109: 1.3084733013495267\n",
      "Operator 110: -1.2188646660729934\n",
      "Operator 111: 1.094743987887362\n",
      "Operator 112: -0.7578042562425673\n",
      "Operator 115: 0.6981882238225019\n",
      "Operator 117: 0.4074756704872362\n",
      "Operator 119: 0.19161836848376956\n",
      "Operator 121: 0.3720977776220189\n",
      "Operator 122: -1.809032593729979\n",
      "Operator 124: -0.9781238357963777\n",
      "Operator 125: 0.7402750093876344\n",
      "Operator 126: -0.8952317088190131\n",
      "Operator 127: 1.1595120528437155\n",
      "Operator 128: -1.2514652496198146\n",
      "Operator 130: -2.0048793152949873\n",
      "Operator 132: -1.3683036651328289\n",
      "Operator 134: -0.9283477778920748\n",
      "Operator 136: -0.5482460466417853\n",
      "Operator 139: 1.5438786718512132\n",
      "Operator 140: -0.8661080697382655\n",
      "Operator 141: -0.0035325890295322586\n",
      "Operator 142: 0.1853500908848868\n",
      "Operator 143: 0.6788546830713384\n",
      "Operator 144: 0.35273604643259443\n",
      "Operator 145: 0.2761587316601435\n",
      "Operator 146: -1.6856261370035073\n",
      "Operator 147: 0.20502870607290535\n",
      "Operator 148: -2.280965147253599\n",
      "Operator 149: 1.1726542203209362\n",
      "Operator 150: -2.226613153383694\n",
      "Operator 151: 1.607631387194803\n",
      "Operator 152: -2.1029101251187825\n",
      "Operator 153: 1.8107803305998622\n",
      "Operator 154: -2.0333505756482237\n",
      "Operator 155: 1.1854788203453048\n",
      "Operator 156: 0.0777807725141276\n",
      "Operator 157: 0.6107412495824083\n",
      "Operator 158: 0.23001332546060968\n",
      "Operator 159: 0.6575926729886974\n",
      "Operator 160: 0.28151516710435565\n",
      "Operator 161: 0.5892996763960994\n",
      "Operator 162: 0.05442628678397379\n",
      "Operator 163: -0.9564845207690174\n",
      "Operator 164: -0.6326938178210175\n",
      "Operator 165: 1.4650755876086659\n",
      "Operator 167: 1.7565737145947873\n",
      "Operator 169: 1.8869025935670187\n",
      "Operator 171: 1.9580451567394022\n",
      "Operator 173: -1.3430461742445163\n",
      "Operator 174: 1.9249785837916882\n",
      "Operator 175: 2.0278364227274532\n",
      "Operator 176: -1.9755551326727472\n",
      "Operator 177: -0.3986560968037898\n",
      "Operator 178: 0.20370591145313033\n",
      "Operator 179: -1.2741525694705162\n",
      "Operator 180: -1.7412219854069684\n",
      "Operator 181: -1.352211195037751\n",
      "Operator 182: -1.5361317455121535\n",
      "Operator 183: 1.5280954816372228\n",
      "Operator 184: 0.9372782281625185\n",
      "Operator 185: 1.6008105386908285\n",
      "Operator 186: -1.830417219525382\n",
      "Operator 187: 1.830417219525379\n",
      "Operator 188: -1.9193151111748152\n",
      "Operator 189: 1.9193151111748064\n",
      "Operator 190: -1.9662249128149485\n",
      "Operator 191: 1.9662249128149394\n",
      "Operator 192: -1.9916797350880842\n",
      "Operator 193: -0.7349195266790902\n",
      "Operator 194: -1.2241318843135813\n",
      "Operator 195: 1.5026076000591777\n",
      "Operator 196: -0.890588657027894\n",
      "Operator 197: -1.1971952102259251\n",
      "Operator 198: -1.3347550883041188\n",
      "Operator 199: -1.2717533244055335\n",
      "Operator 200: 0.26289353171510554\n",
      "Operator 201: 1.832546388754822\n",
      "Operator 202: -0.4391224320868422\n",
      "Operator 203: 1.6813859749841746\n",
      "Operator 204: -0.3085183244035632\n",
      "Operator 205: 1.919315111174814\n",
      "Operator 206: -0.14154258278730922\n",
      "Operator 207: 1.9662249128149465\n",
      "Operator 208: -0.0503756680224281\n",
      "Operator 209: 1.9916797350880824\n",
      "Operator 210: -0.8947235309567778\n",
      "Operator 211: -1.6641181749338394\n",
      "Operator 212: 1.067989991122295\n",
      "Operator 213: -1.3150264953511366\n",
      "Operator 214: -1.4053743053086256\n",
      "Operator 215: -1.7669550261723397\n",
      "Operator 216: -1.2048280231369293\n",
      "Operator 217: 0.9820678634838524\n",
      "Operator 218: 2.071297472022231\n",
      "Operator 219: -1.4704737038365163\n",
      "Operator 220: 1.8304172195253772\n",
      "Operator 221: -1.830417219525375\n",
      "Operator 222: 1.919315111174814\n",
      "Operator 223: -1.9193151111748077\n",
      "Operator 224: 1.9662249128149465\n",
      "Operator 225: -1.9662249128149432\n",
      "Operator 226: 1.991679735088082\n",
      "Operator 227: 1.097279810538606\n",
      "Operator 228: -0.8754839640003553\n",
      "Operator 229: 0.17102650380856602\n",
      "Operator 230: -1.1557649881374847\n",
      "Operator 231: 0.6085143740825689\n",
      "Operator 232: -0.4415088483268009\n",
      "Operator 233: 0.15178567353232716\n",
      "Operator 234: -0.42426198553931926\n",
      "Operator 235: 0.00411268643672821\n",
      "Operator 236: -0.5043159635116901\n",
      "Operator 237: 1.3408497917921731\n",
      "Operator 238: -0.5637147945969838\n",
      "Operator 239: 1.6857092371616194\n",
      "Operator 240: -0.2504029281120775\n",
      "Operator 241: 1.855037443724605\n",
      "Operator 242: -0.08459157833726466\n",
      "Operator 243: 1.9498994295409626\n",
      "Operator 244: 0.7583163460848171\n",
      "Operator 245: 0.8665166387971797\n",
      "Operator 246: -0.8153687579124734\n",
      "Operator 247: 0.06077108926404688\n",
      "Operator 248: 1.108926945778507\n",
      "Operator 249: 1.0862211522871759\n",
      "Operator 250: 1.140725127624532\n",
      "Operator 251: -0.019275391270767498\n",
      "Operator 252: -0.87354862688299\n",
      "Operator 254: -1.4650755876086652\n",
      "Operator 256: -1.756573714594789\n",
      "Operator 258: -1.8869025935670167\n",
      "Operator 260: -1.958045156739399\n",
      "Total gradient norm: 19.702196588848718\n",
      "Operators under consideration (1):\n",
      "[61]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.4831406618040357)]\n",
      "Operator(s) added to ansatz: [61]\n",
      "Gradients: [np.float64(2.4831406618040357)]\n",
      "Initial energy: -30.899539621090824\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61]...\n",
      "Starting point: [np.float64(0.46398548569522685), np.float64(0.6933783548404598), np.float64(0.22651564227716442), np.float64(0.5780126420187339), np.float64(0.18274879284632245), np.float64(0.3324301799366447), np.float64(-0.7397745943211648), np.float64(0.6428908775010443), np.float64(-0.3680856703417468), np.float64(-0.3273559626402279), np.float64(-0.5553873651979927), np.float64(-0.3935388759914302), np.float64(0.25246880185182113), np.float64(0.2424371320814954), np.float64(-0.20316097119333265), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -31.150701\n",
      "         Iterations: 25\n",
      "         Function evaluations: 105\n",
      "         Gradient evaluations: 93\n",
      "\n",
      "Current energy: -31.150700877612543\n",
      "(change of -0.25116125652171917)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61]\n",
      "On iteration 16.\n",
      "\n",
      "*** ADAPT-VQE Iteration 17 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.43696700924956644\n",
      "Operator 1: 1.1355521123336914\n",
      "Operator 2: 0.05873946071966685\n",
      "Operator 3: 1.422288759886198\n",
      "Operator 4: 0.8026273209698246\n",
      "Operator 5: 1.350306168066335\n",
      "Operator 6: 0.28560819311395086\n",
      "Operator 7: -0.2304780764415516\n",
      "Operator 8: -0.7225194649386538\n",
      "Operator 9: -0.2956015002075902\n",
      "Operator 10: -1.0059251970009404\n",
      "Operator 11: 2.2579348870249953\n",
      "Operator 12: -1.1797849055187313\n",
      "Operator 13: 2.1943649379128893\n",
      "Operator 14: -1.6417370167770526\n",
      "Operator 15: 2.0614724774649376\n",
      "Operator 16: -1.8617459697841099\n",
      "Operator 17: -1.473882005785961e-08\n",
      "Operator 18: 7.377932219088358e-08\n",
      "Operator 19: -1.78873334020445e-08\n",
      "Operator 20: -0.8611605594365106\n",
      "Operator 21: 0.6856854403952222\n",
      "Operator 22: 1.7129354804140848e-08\n",
      "Operator 25: 0.6603301405442255\n",
      "Operator 26: -1.0935022843040205\n",
      "Operator 27: 1.179721578785661\n",
      "Operator 28: -0.7681293778370825\n",
      "Operator 29: 0.6349590603185541\n",
      "Operator 30: -0.6142780734211567\n",
      "Operator 32: -0.2709883742459165\n",
      "Operator 34: 0.2399705309118197\n",
      "Operator 35: 0.5058287346574744\n",
      "Operator 36: -0.7530136028499907\n",
      "Operator 37: -0.0730197480651203\n",
      "Operator 38: 0.38883604845052344\n",
      "Operator 39: 0.6514133641354904\n",
      "Operator 40: 0.2175904820334435\n",
      "Operator 41: -0.056788929597882065\n",
      "Operator 42: -1.5788518371486662\n",
      "Operator 43: -0.014043942293358435\n",
      "Operator 44: -1.9672310196790417\n",
      "Operator 45: 0.9934149129761718\n",
      "Operator 46: -2.4680621787999795\n",
      "Operator 47: 1.7271793872928984\n",
      "Operator 48: -2.194364937912887\n",
      "Operator 49: 1.907521937672942\n",
      "Operator 50: -2.0614724774649353\n",
      "Operator 51: 1.7724824923024296\n",
      "Operator 52: 0.4866098299958781\n",
      "Operator 53: 0.9768180830896191\n",
      "Operator 54: 0.2886061941835173\n",
      "Operator 55: 1.3413501320471497\n",
      "Operator 56: 0.7870647017798506\n",
      "Operator 57: 1.3941915738786879\n",
      "Operator 58: -0.08836845597142716\n",
      "Operator 59: -0.2548581066783588\n",
      "Operator 60: -1.2035529422094706\n",
      "Operator 62: -1.3568638895870282\n",
      "Operator 63: 2.46806217879998\n",
      "Operator 64: -1.7271793872928984\n",
      "Operator 65: 2.1943649379128893\n",
      "Operator 66: -1.9075219376729409\n",
      "Operator 67: 2.0614724774649376\n",
      "Operator 68: -0.8191707829438954\n",
      "Operator 69: -2.9767303462761947e-08\n",
      "Operator 70: -1.412283791331382\n",
      "Operator 71: 0.8984173946811561\n",
      "Operator 72: -0.7498451063220384\n",
      "Operator 73: 0.9930800289618456\n",
      "Operator 75: 0.9346351902553585\n",
      "Operator 76: -0.7385053070338019\n",
      "Operator 77: 0.845667382331482\n",
      "Operator 78: -0.6349590603185535\n",
      "Operator 79: 1.979663159554851\n",
      "Operator 81: 1.278706110119047\n",
      "Operator 83: 0.7447673783447558\n",
      "Operator 85: -0.5406321582701382\n",
      "Operator 86: 0.7355230826878291\n",
      "Operator 87: 1.0552255068249958\n",
      "Operator 88: 0.22562172958347898\n",
      "Operator 89: 0.6029516155306801\n",
      "Operator 90: 0.16723998733168793\n",
      "Operator 91: 0.479465552101461\n",
      "Operator 92: 0.3155261828206314\n",
      "Operator 93: 0.6234449541781045\n",
      "Operator 94: 0.3608567049283838\n",
      "Operator 95: -1.1069394047924808\n",
      "Operator 96: -0.9890159587604275\n",
      "Operator 97: -1.0725565250601217\n",
      "Operator 98: -0.18759126683446004\n",
      "Operator 99: 1.3483780954170743\n",
      "Operator 101: 1.7832969928437763\n",
      "Operator 103: 1.9222357627249855\n",
      "Operator 104: -0.48474374784781393\n",
      "Operator 105: 1.6225718662228439\n",
      "Operator 106: -0.9866372067608078\n",
      "Operator 107: 1.0504959690892086\n",
      "Operator 108: -0.7037392625810079\n",
      "Operator 109: 1.3726720612711552\n",
      "Operator 110: -1.2393106380132326\n",
      "Operator 111: 1.2900593702895229\n",
      "Operator 112: -0.7431782351023781\n",
      "Operator 117: 0.6142780734211568\n",
      "Operator 119: 0.2709883742459168\n",
      "Operator 121: 0.3747898904480506\n",
      "Operator 122: -1.8018726200302664\n",
      "Operator 124: -0.9784538002863176\n",
      "Operator 125: 0.7531542102012585\n",
      "Operator 126: -0.8948869058304596\n",
      "Operator 127: 1.3444677679814614\n",
      "Operator 128: -1.0550195820085166\n",
      "Operator 129: 0.5103692396151346\n",
      "Operator 130: -1.258810428889399\n",
      "Operator 132: -1.9796631595548444\n",
      "Operator 134: -1.2787061101190442\n",
      "Operator 136: -0.7447673783447605\n",
      "Operator 138: 9.214967013007821e-08\n",
      "Operator 139: 1.5334542191304936\n",
      "Operator 140: -0.8415092835926259\n",
      "Operator 141: -0.027052358642719907\n",
      "Operator 142: 0.1946091628636886\n",
      "Operator 143: 0.6359502043166272\n",
      "Operator 144: 0.3890172456227586\n",
      "Operator 145: -0.01982862535688861\n",
      "Operator 146: -1.4479219391460751\n",
      "Operator 147: -0.5402853953468798\n",
      "Operator 148: -1.6592702841436144\n",
      "Operator 149: 0.18365711294332615\n",
      "Operator 150: -2.2579348870249945\n",
      "Operator 151: 1.1797849055187313\n",
      "Operator 152: -2.194364937912887\n",
      "Operator 153: 1.641737016777054\n",
      "Operator 154: -2.0614724774649353\n",
      "Operator 155: 1.1768874704405858\n",
      "Operator 156: 0.08063521231177666\n",
      "Operator 157: 0.5922999648566786\n",
      "Operator 158: 0.2433123923267287\n",
      "Operator 159: 0.6158595833287985\n",
      "Operator 160: 0.3177107272476039\n",
      "Operator 161: 0.47822652719883346\n",
      "Operator 162: 0.1294105862755119\n",
      "Operator 163: -1.0990589693777122\n",
      "Operator 164: -1.0892512066034328\n",
      "Operator 165: -0.9460989684758618\n",
      "Operator 166: -0.6464103742812144\n",
      "Operator 167: 1.4738604727463918\n",
      "Operator 169: 1.783296992843776\n",
      "Operator 171: 1.922235762724985\n",
      "Operator 172: -1.6438132516958793e-08\n",
      "Operator 173: -1.3475238618714622\n",
      "Operator 174: 1.8617459697841099\n",
      "Operator 175: 2.0265767912002355\n",
      "Operator 176: -1.9683787236877852\n",
      "Operator 177: -0.43416764675846864\n",
      "Operator 178: 0.23235168086462596\n",
      "Operator 179: -1.3075405618036016\n",
      "Operator 180: -1.6908031909836074\n",
      "Operator 181: -1.4466627940357144\n",
      "Operator 182: -1.2858517853229814\n",
      "Operator 183: 1.288181599896944\n",
      "Operator 184: 1.327103466666808\n",
      "Operator 185: 1.8966634621505483\n",
      "Operator 186: 0.9425587096825838\n",
      "Operator 187: 1.6009451738511589\n",
      "Operator 188: -1.84123790972928\n",
      "Operator 189: 1.8412379097292706\n",
      "Operator 190: -1.9370630850263533\n",
      "Operator 191: 1.9370630850263435\n",
      "Operator 192: -1.9846909247138842\n",
      "Operator 193: -0.7408195025027224\n",
      "Operator 194: -1.2364467521109148\n",
      "Operator 195: 1.492469126800371\n",
      "Operator 196: -0.8886881127274442\n",
      "Operator 197: -1.2118426078232472\n",
      "Operator 198: -1.3663338805916414\n",
      "Operator 199: -1.3218169777598425\n",
      "Operator 200: 0.5258207676390657\n",
      "Operator 201: 1.3582228730498564\n",
      "Operator 202: 0.354367295083417\n",
      "Operator 203: 1.8335758171830931\n",
      "Operator 204: -0.42504613820615855\n",
      "Operator 205: 1.684477541693103\n",
      "Operator 206: -0.2746713533892974\n",
      "Operator 207: 1.9370630850263506\n",
      "Operator 208: -0.0934038075763784\n",
      "Operator 209: 1.9846909247138824\n",
      "Operator 210: -0.904206965906697\n",
      "Operator 211: -1.6587626566474567\n",
      "Operator 212: 1.0293749202593667\n",
      "Operator 213: -1.2720908324411218\n",
      "Operator 214: -1.4508157836837163\n",
      "Operator 215: -1.6950553480284725\n",
      "Operator 216: -1.3021238241702666\n",
      "Operator 217: 1.2254911006161229\n",
      "Operator 218: 1.8304033370517878\n",
      "Operator 219: 1.1256704777712552\n",
      "Operator 220: 2.0752126518778757\n",
      "Operator 221: -1.4646429864301143\n",
      "Operator 222: 1.8412379097292775\n",
      "Operator 223: -1.8412379097292715\n",
      "Operator 224: 1.9370630850263506\n",
      "Operator 225: -1.9370630850263466\n",
      "Operator 226: 1.9846909247138818\n",
      "Operator 227: 1.0825675938284638\n",
      "Operator 228: -0.8815956952944728\n",
      "Operator 229: 0.1493508772727002\n",
      "Operator 230: -1.1608525334439221\n",
      "Operator 231: 0.5456181645185784\n",
      "Operator 232: -0.4279948347498826\n",
      "Operator 233: -0.02945238522758863\n",
      "Operator 234: -0.4573288789621551\n",
      "Operator 235: -0.533150208017628\n",
      "Operator 236: -0.5104866903362928\n",
      "Operator 237: 0.4784779242062863\n",
      "Operator 238: -0.4915179060746011\n",
      "Operator 239: 1.3568638895870295\n",
      "Operator 240: -0.49272003036222706\n",
      "Operator 241: 1.7271793872928984\n",
      "Operator 242: -0.15791105842634257\n",
      "Operator 243: 1.9075219376729409\n",
      "Operator 244: 0.7637204467157536\n",
      "Operator 245: 0.8790791980940817\n",
      "Operator 246: -0.8039418739447901\n",
      "Operator 247: 0.046914943441641\n",
      "Operator 248: 1.1094635862295608\n",
      "Operator 249: 1.1207672699789795\n",
      "Operator 250: 1.1278034210068975\n",
      "Operator 251: -0.11429270233661082\n",
      "Operator 252: -0.569521683877805\n",
      "Operator 253: -0.16846967205290794\n",
      "Operator 254: -0.979893159218705\n",
      "Operator 256: -1.473860472746394\n",
      "Operator 258: -1.7832969928437747\n",
      "Operator 260: -1.922235762724982\n",
      "Total gradient norm: 18.704282974602087\n",
      "Operators under consideration (1):\n",
      "[63]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.46806217879998)]\n",
      "Operator(s) added to ansatz: [63]\n",
      "Gradients: [np.float64(2.46806217879998)]\n",
      "Initial energy: -31.150700877612543\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63]...\n",
      "Starting point: [np.float64(0.3664528638706231), np.float64(0.6596307180769003), np.float64(0.2293555450089267), np.float64(0.464041638491861), np.float64(0.1836063157907074), np.float64(0.31677303766651815), np.float64(-0.7234937089948766), np.float64(0.5848313598173223), np.float64(-0.3257777528904131), np.float64(-0.3212113132212991), np.float64(-0.5540412753561752), np.float64(-0.3909053697149832), np.float64(0.2596578201571101), np.float64(0.25952469052053956), np.float64(-0.24369258611269992), np.float64(-0.20781586952102363), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -31.399342\n",
      "         Iterations: 24\n",
      "         Function evaluations: 41\n",
      "         Gradient evaluations: 41\n",
      "\n",
      "Current energy: -31.399342419939295\n",
      "(change of -0.24864154232675162)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63]\n",
      "On iteration 17.\n",
      "\n",
      "*** ADAPT-VQE Iteration 18 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.4301878946642339\n",
      "Operator 1: 1.1319287614135645\n",
      "Operator 2: 0.07570114502206411\n",
      "Operator 3: 1.4031568567671906\n",
      "Operator 4: 0.8422402894119766\n",
      "Operator 5: 1.3002269020128479\n",
      "Operator 6: 0.3381611767052495\n",
      "Operator 7: -0.258878651183093\n",
      "Operator 8: -0.6106022503357285\n",
      "Operator 9: -0.3861138104882045\n",
      "Operator 10: -0.7206648765578745\n",
      "Operator 11: -0.30912799396513624\n",
      "Operator 12: -1.0106687972321444\n",
      "Operator 13: 2.217592550369443\n",
      "Operator 14: -1.2160805052213208\n",
      "Operator 15: 2.1261486881889415\n",
      "Operator 16: -1.716414084426912\n",
      "Operator 20: -0.8620780523725464\n",
      "Operator 21: 0.6821563865300804\n",
      "Operator 25: 0.7107809972888857\n",
      "Operator 26: -1.2824488059792591\n",
      "Operator 27: 1.2596016279073887\n",
      "Operator 28: -1.052884932997041\n",
      "Operator 29: 1.1938549429440823\n",
      "Operator 30: -0.705343858904968\n",
      "Operator 31: 0.6343895389710944\n",
      "Operator 32: -0.42688784661909507\n",
      "Operator 34: 0.24223924375072298\n",
      "Operator 35: 0.4987512737046139\n",
      "Operator 36: -0.7385088754719884\n",
      "Operator 37: -0.10004386816133415\n",
      "Operator 38: 0.4098442732859003\n",
      "Operator 39: 0.5921800747173868\n",
      "Operator 40: 0.2551592482041021\n",
      "Operator 41: -0.2795381946876748\n",
      "Operator 42: -1.3628268879940624\n",
      "Operator 43: -0.614606806082502\n",
      "Operator 44: -1.5394054127312198\n",
      "Operator 45: -0.006213607841204463\n",
      "Operator 46: -1.9703145165949096\n",
      "Operator 47: 1.060795994176054\n",
      "Operator 48: -2.4228491775537053\n",
      "Operator 49: 1.8094814839508373\n",
      "Operator 50: -2.1261486881889393\n",
      "Operator 51: 1.7695138573572295\n",
      "Operator 52: 0.499359272287273\n",
      "Operator 53: 0.9667849416190868\n",
      "Operator 54: 0.31913785030795894\n",
      "Operator 55: 1.3044611248900457\n",
      "Operator 56: 0.8733346982044525\n",
      "Operator 57: 1.3004712888847039\n",
      "Operator 58: 0.1177012506219667\n",
      "Operator 59: -0.36963351883381845\n",
      "Operator 60: -0.7975314569305536\n",
      "Operator 61: -0.25962832329875696\n",
      "Operator 62: -1.2206842348398932\n",
      "Operator 64: -1.4071038816800805\n",
      "Operator 65: 2.422849177553707\n",
      "Operator 66: -1.8094814839508384\n",
      "Operator 67: 2.1261486881889415\n",
      "Operator 68: -0.8225614885179424\n",
      "Operator 70: -1.4228641059263343\n",
      "Operator 71: 0.8808070394443579\n",
      "Operator 72: -0.7788058856954372\n",
      "Operator 73: 0.9520742290435794\n",
      "Operator 75: 0.9384620810694564\n",
      "Operator 76: -0.7774738965092554\n",
      "Operator 77: 0.8754953148155473\n",
      "Operator 78: -0.7616078614517192\n",
      "Operator 79: 0.8340357736585918\n",
      "Operator 80: -0.6343895389710944\n",
      "Operator 81: 1.8971619067077123\n",
      "Operator 83: 1.0683558231277557\n",
      "Operator 85: -0.5424448886961944\n",
      "Operator 86: 0.7348091686218887\n",
      "Operator 87: 1.0512901638857468\n",
      "Operator 88: 0.2273989368537378\n",
      "Operator 89: 0.5948746628269469\n",
      "Operator 90: 0.175505971523601\n",
      "Operator 91: 0.4632369776775326\n",
      "Operator 92: 0.33715138754855173\n",
      "Operator 93: 0.5825201380366642\n",
      "Operator 94: 0.41333429294011814\n",
      "Operator 95: -1.1191969717769426\n",
      "Operator 96: -1.0995951858466237\n",
      "Operator 97: -1.1803823156528521\n",
      "Operator 98: -0.9905175337014751\n",
      "Operator 99: -1.0718827633690373\n",
      "Operator 100: -0.17316165854573307\n",
      "Operator 101: 1.3793088886396012\n",
      "Operator 103: 1.8382393966718724\n",
      "Operator 104: -0.4858585981180591\n",
      "Operator 105: 1.627661313584678\n",
      "Operator 106: -0.9869283248597405\n",
      "Operator 107: 1.0570887506914015\n",
      "Operator 108: -0.7089903502654029\n",
      "Operator 109: 1.3933244790334944\n",
      "Operator 110: -1.2391514754810249\n",
      "Operator 111: 1.35343119344135\n",
      "Operator 112: -0.7316018780879128\n",
      "Operator 119: 0.42688784661909596\n",
      "Operator 121: 0.37577579841106457\n",
      "Operator 122: -1.7991270806266373\n",
      "Operator 124: -0.9783063664535141\n",
      "Operator 125: 0.7575407352533052\n",
      "Operator 126: -0.8927850419749919\n",
      "Operator 127: 1.4191490849986093\n",
      "Operator 128: -0.936916541339553\n",
      "Operator 129: 0.6954961769966608\n",
      "Operator 130: -1.0609745424316785\n",
      "Operator 131: 0.5028342678838675\n",
      "Operator 132: -1.2708968481767204\n",
      "Operator 134: -1.8971619067077095\n",
      "Operator 136: -1.0683558231277601\n",
      "Operator 139: 1.529627669434507\n",
      "Operator 140: -0.8324324237999448\n",
      "Operator 141: -0.03569185703175068\n",
      "Operator 142: 0.19820346209227177\n",
      "Operator 143: 0.6203907300275842\n",
      "Operator 144: 0.4040747991662282\n",
      "Operator 145: -0.14381051357119315\n",
      "Operator 146: -1.3162991729681797\n",
      "Operator 147: -0.8117122204802267\n",
      "Operator 148: -1.4000801916411048\n",
      "Operator 149: -0.5605395679118891\n",
      "Operator 150: -1.647482866108385\n",
      "Operator 151: 0.18741078644756531\n",
      "Operator 152: -2.2175925503694414\n",
      "Operator 153: 1.2160805052213208\n",
      "Operator 154: -2.1261486881889393\n",
      "Operator 155: 1.173730336656173\n",
      "Operator 156: 0.08170573633222158\n",
      "Operator 157: 0.5855441893796427\n",
      "Operator 158: 0.2482410988875433\n",
      "Operator 159: 0.6005565584731807\n",
      "Operator 160: 0.33261296653706796\n",
      "Operator 161: 0.4362677217282841\n",
      "Operator 162: 0.17121441199062418\n",
      "Operator 163: -1.1101131788785468\n",
      "Operator 164: -1.136689835220928\n",
      "Operator 165: -1.1322661397285463\n",
      "Operator 166: -1.1042157031792665\n",
      "Operator 167: -0.9372575394906377\n",
      "Operator 168: -0.6501117818262865\n",
      "Operator 169: 1.5069753935979966\n",
      "Operator 171: 1.8382393966718724\n",
      "Operator 173: -1.3491492560252154\n",
      "Operator 174: 1.716414084426912\n",
      "Operator 175: 2.0260989205960915\n",
      "Operator 176: -1.9657317724165124\n",
      "Operator 177: -0.4471937046237911\n",
      "Operator 178: 0.24282942167226926\n",
      "Operator 179: -1.319741085185961\n",
      "Operator 180: -1.6712609437104764\n",
      "Operator 181: -1.4816326478748034\n",
      "Operator 182: -1.1734212233411676\n",
      "Operator 183: 1.1746075537222302\n",
      "Operator 184: 1.4551851255895656\n",
      "Operator 185: 1.7442984275122848\n",
      "Operator 186: 1.341054847721022\n",
      "Operator 187: 1.8954740630390363\n",
      "Operator 188: 0.9301313863069995\n",
      "Operator 189: 1.6139354503545584\n",
      "Operator 190: -1.8674543560796808\n",
      "Operator 191: 1.8674543560796704\n",
      "Operator 192: -1.9687114608047405\n",
      "Operator 193: -0.7429647795625542\n",
      "Operator 194: -1.2409343500832835\n",
      "Operator 195: 1.4887177616632457\n",
      "Operator 196: -0.8874453259730274\n",
      "Operator 197: -1.2158359766622135\n",
      "Operator 198: -1.3753539467472993\n",
      "Operator 199: -1.331491481987257\n",
      "Operator 200: 0.6533747672280634\n",
      "Operator 201: 1.1550317738108982\n",
      "Operator 202: 0.6544101006079726\n",
      "Operator 203: 1.354493171517481\n",
      "Operator 204: 0.34980899803787513\n",
      "Operator 205: 1.8279656648835043\n",
      "Operator 206: -0.3934642104544499\n",
      "Operator 207: 1.7092491379833152\n",
      "Operator 208: -0.19432450424900904\n",
      "Operator 209: 1.9687114608047391\n",
      "Operator 210: -0.907700074514266\n",
      "Operator 211: -1.6567691463600704\n",
      "Operator 212: 1.0145402811354227\n",
      "Operator 213: -1.2559246173543444\n",
      "Operator 214: -1.467805753252264\n",
      "Operator 215: -1.6666552250068292\n",
      "Operator 216: -1.3356996199900475\n",
      "Operator 217: 1.3166026419908277\n",
      "Operator 218: 1.704269860262432\n",
      "Operator 219: 1.3865923138038716\n",
      "Operator 220: 1.8314756044782268\n",
      "Operator 221: 1.1241315155470748\n",
      "Operator 222: 2.0831949200602287\n",
      "Operator 223: -1.4772076052613001\n",
      "Operator 224: 1.8674543560796777\n",
      "Operator 225: -1.8674543560796741\n",
      "Operator 226: 1.9687114608047391\n",
      "Operator 227: 1.0771628982527748\n",
      "Operator 228: -0.8837350049143984\n",
      "Operator 229: 0.14149425334017085\n",
      "Operator 230: -1.1616066525095774\n",
      "Operator 231: 0.5227638288677368\n",
      "Operator 232: -0.41794621099037876\n",
      "Operator 233: -0.09037027671008702\n",
      "Operator 234: -0.45064383183872975\n",
      "Operator 235: -0.715988686510935\n",
      "Operator 236: -0.47499000215939247\n",
      "Operator 237: -0.04073364112630283\n",
      "Operator 238: -0.5051297457645734\n",
      "Operator 239: 0.4994799222135798\n",
      "Operator 240: -0.4549625349724964\n",
      "Operator 241: 1.4071038816800805\n",
      "Operator 242: -0.3342656936904108\n",
      "Operator 243: 1.8094814839508384\n",
      "Operator 244: 0.7656812972675759\n",
      "Operator 245: 0.8836999744582024\n",
      "Operator 246: -0.7997678040890148\n",
      "Operator 247: 0.04161656216619043\n",
      "Operator 248: 1.1084889020263369\n",
      "Operator 249: 1.1328355878167478\n",
      "Operator 250: 1.1131276912726868\n",
      "Operator 251: -0.16717305290645113\n",
      "Operator 252: -0.4583571918588387\n",
      "Operator 253: -0.2850409790392612\n",
      "Operator 254: -0.6479364391361537\n",
      "Operator 255: -0.16978860639543136\n",
      "Operator 256: -0.9869683418096411\n",
      "Operator 258: -1.5069753935979948\n",
      "Operator 260: -1.8382393966718695\n",
      "Total gradient norm: 17.673228071599496\n",
      "Operators under consideration (1):\n",
      "[48]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4228491775537053)]\n",
      "Operator(s) added to ansatz: [48]\n",
      "Gradients: [np.float64(-2.4228491775537053)]\n",
      "Initial energy: -31.399342419939295\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48]...\n",
      "Starting point: [np.float64(0.32408979607173855), np.float64(0.6023434510870859), np.float64(0.23041593967991308), np.float64(0.3658470649915838), np.float64(0.18392380676010575), np.float64(0.31101504173721684), np.float64(-0.6968396201709074), np.float64(0.4694998446295947), np.float64(-0.3096294125074456), np.float64(-0.31895058106969953), np.float64(-0.5535480360938403), np.float64(-0.38993968530150114), np.float64(0.2624584048140637), np.float64(0.26660272515953076), np.float64(-0.2623732024676162), np.float64(-0.25010504750799334), np.float64(-0.20729326005441795), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -31.630040\n",
      "         Iterations: 26\n",
      "         Function evaluations: 40\n",
      "         Gradient evaluations: 40\n",
      "\n",
      "Current energy: -31.63004030088893\n",
      "(change of -0.23069788094963428)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48]\n",
      "On iteration 18.\n",
      "\n",
      "*** ADAPT-VQE Iteration 19 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.4278843888242772\n",
      "Operator 1: 1.1306993238184346\n",
      "Operator 2: 0.08151260392111542\n",
      "Operator 3: 1.396565204695096\n",
      "Operator 4: 0.8558362150354402\n",
      "Operator 5: 1.282707858482632\n",
      "Operator 6: 0.35603720558172314\n",
      "Operator 7: -0.26978017473412197\n",
      "Operator 8: -0.5734717481586284\n",
      "Operator 9: -0.4244898377745543\n",
      "Operator 10: -0.6181498492131848\n",
      "Operator 11: -0.3899685076405471\n",
      "Operator 12: -0.30790689602519306\n",
      "Operator 13: 1.716185056131311\n",
      "Operator 14: -0.2946751451040368\n",
      "Operator 15: 2.12030048663326\n",
      "Operator 16: -1.3418284484815857\n",
      "Operator 20: -0.8623309805407571\n",
      "Operator 21: 0.6808259252597789\n",
      "Operator 25: 0.7247963927790103\n",
      "Operator 26: -1.3369672061533637\n",
      "Operator 27: 1.281275904905135\n",
      "Operator 28: -1.2274218668704666\n",
      "Operator 29: 1.2642934853719434\n",
      "Operator 30: -1.0085118955439532\n",
      "Operator 31: 0.765812222620692\n",
      "Operator 34: 0.24301533144919302\n",
      "Operator 35: 0.4963607974029439\n",
      "Operator 36: -0.7335241283897209\n",
      "Operator 37: -0.10910621347497437\n",
      "Operator 38: 0.41743057955342133\n",
      "Operator 39: 0.5725693976050048\n",
      "Operator 40: 0.27012672335427435\n",
      "Operator 41: -0.3560269923814934\n",
      "Operator 42: -1.2706024810207914\n",
      "Operator 43: -0.8330329664834043\n",
      "Operator 44: -1.3462057181760483\n",
      "Operator 45: -0.5625576778181232\n",
      "Operator 46: -1.6128363061690332\n",
      "Operator 47: 0.7417886970928227\n",
      "Operator 49: 1.5506016467217283\n",
      "Operator 50: -2.2931171398523547\n",
      "Operator 51: 1.7684977504949975\n",
      "Operator 52: 0.5036778067096588\n",
      "Operator 53: 0.9633114393614\n",
      "Operator 54: 0.3294862593015387\n",
      "Operator 55: 1.2913801372531433\n",
      "Operator 56: 0.9022904043999884\n",
      "Operator 57: 1.2650086301067254\n",
      "Operator 58: 0.18533341432442718\n",
      "Operator 59: -0.4216021726542848\n",
      "Operator 60: -0.6479605823445598\n",
      "Operator 61: -0.35686018560989075\n",
      "Operator 62: -0.8363324423536428\n",
      "Operator 63: -0.13533410588172184\n",
      "Operator 64: -0.6180394819231638\n",
      "Operator 65: 2.0155815128003987\n",
      "Operator 66: -1.2774167656169189\n",
      "Operator 67: 2.2931171398523555\n",
      "Operator 68: -0.8237183599716649\n",
      "Operator 70: -1.4264827042255197\n",
      "Operator 71: 0.8747474038093583\n",
      "Operator 72: -0.7888866820605248\n",
      "Operator 73: 0.93785557705203\n",
      "Operator 75: 0.9380001415492547\n",
      "Operator 76: -0.7886890391678276\n",
      "Operator 77: 0.8732478186303444\n",
      "Operator 78: -0.7994563744145337\n",
      "Operator 79: 0.8643503141269684\n",
      "Operator 80: -1.13030978215233\n",
      "Operator 81: 1.288339930448248\n",
      "Operator 83: 1.634397992508198\n",
      "Operator 85: -0.5430602744885173\n",
      "Operator 86: 0.7345637704905129\n",
      "Operator 87: 1.049953790807712\n",
      "Operator 88: 0.22800525269995922\n",
      "Operator 89: 0.5921274782365029\n",
      "Operator 90: 0.17834550813524847\n",
      "Operator 91: 0.45771023864630433\n",
      "Operator 92: 0.3447692193485696\n",
      "Operator 93: 0.5687098340944122\n",
      "Operator 94: 0.43316004266895525\n",
      "Operator 95: -1.116282571957886\n",
      "Operator 96: -1.1311761993362837\n",
      "Operator 97: -1.1809627942394882\n",
      "Operator 98: -1.0889648692437306\n",
      "Operator 99: -1.1496368411129851\n",
      "Operator 100: 0.0034718726772705716\n",
      "Operator 101: 0.9343598598007115\n",
      "Operator 103: 1.6084556006212347\n",
      "Operator 104: -0.4862349364954276\n",
      "Operator 105: 1.6293771240931847\n",
      "Operator 106: -0.986994690493414\n",
      "Operator 107: 1.0592745912383295\n",
      "Operator 108: -0.7106510112039046\n",
      "Operator 109: 1.3997972414258597\n",
      "Operator 110: -1.2374273675729817\n",
      "Operator 111: 1.3720053267090144\n",
      "Operator 112: -0.72375498110297\n",
      "Operator 118: -0.477338869666454\n",
      "Operator 119: 0.5357183956832994\n",
      "Operator 120: -0.5881615322755259\n",
      "Operator 121: 0.3761096725867501\n",
      "Operator 122: -1.7981830412206126\n",
      "Operator 124: -0.9782226124683462\n",
      "Operator 125: 0.7589770402984484\n",
      "Operator 126: -0.8918161696096483\n",
      "Operator 127: 1.445382673769077\n",
      "Operator 128: -0.8914641339599172\n",
      "Operator 129: 0.7673172861462475\n",
      "Operator 130: -0.9537007328682654\n",
      "Operator 131: 0.6630419522974675\n",
      "Operator 132: -1.124022148956584\n",
      "Operator 134: -0.8582117105278833\n",
      "Operator 135: 0.5881615322755259\n",
      "Operator 136: -1.6343979925082013\n",
      "Operator 139: 1.528330786845842\n",
      "Operator 140: -0.829351929258351\n",
      "Operator 141: -0.03862087319406949\n",
      "Operator 142: 0.19944819279492407\n",
      "Operator 143: 0.6151567497113017\n",
      "Operator 144: 0.4094406470649373\n",
      "Operator 145: -0.18829900264428617\n",
      "Operator 146: -1.2657764296904503\n",
      "Operator 147: -0.9089341475235844\n",
      "Operator 148: -1.2717036421890917\n",
      "Operator 149: -0.8021354952780684\n",
      "Operator 150: -1.4331579451927308\n",
      "Operator 151: -0.15989947099637017\n",
      "Operator 152: 0.16577625285837747\n",
      "Operator 153: 1.0802091564373768\n",
      "Operator 154: -2.1203004866332593\n",
      "Operator 155: 1.1726598626293043\n",
      "Operator 156: 0.08207138265233485\n",
      "Operator 157: 0.5832567959485231\n",
      "Operator 158: 0.24991478620706462\n",
      "Operator 159: 0.5953851441318643\n",
      "Operator 160: 0.3378960713781042\n",
      "Operator 161: 0.4218867705371462\n",
      "Operator 162: 0.18752056491645003\n",
      "Operator 163: -1.1083662509688297\n",
      "Operator 164: -1.1440143225125545\n",
      "Operator 165: -1.1581251889688797\n",
      "Operator 166: -1.1427173834860231\n",
      "Operator 167: -1.073912955210465\n",
      "Operator 168: 0.2109162340957879\n",
      "Operator 169: 1.056357182579604\n",
      "Operator 171: 1.4872372341801863\n",
      "Operator 173: -1.3496979106610827\n",
      "Operator 174: 1.3418284484815857\n",
      "Operator 175: 2.025935028309317\n",
      "Operator 176: -1.9648331063030318\n",
      "Operator 177: -0.45160568455781946\n",
      "Operator 178: 0.24637504640597974\n",
      "Operator 179: -1.3238652174475332\n",
      "Operator 180: -1.6645065580898049\n",
      "Operator 181: -1.4934978677658148\n",
      "Operator 182: -1.131842502818067\n",
      "Operator 183: 1.1332664129801453\n",
      "Operator 184: 1.498244763034275\n",
      "Operator 185: 1.6758336722643397\n",
      "Operator 186: 1.4579343221840595\n",
      "Operator 187: 1.752510042993173\n",
      "Operator 188: 1.1963481206918396\n",
      "Operator 189: -0.913433928542474\n",
      "Operator 190: -2.120891360255934\n",
      "Operator 191: 1.5427270206911303\n",
      "Operator 192: -1.9280627281862555\n",
      "Operator 193: -0.7436893471293633\n",
      "Operator 194: -1.2424511075372355\n",
      "Operator 195: 1.4874433201778081\n",
      "Operator 196: -0.8869495374419392\n",
      "Operator 197: -1.216991344053232\n",
      "Operator 198: -1.3780186427166448\n",
      "Operator 199: -1.3332901554297962\n",
      "Operator 200: 0.6996924756500442\n",
      "Operator 201: 1.0768091214064184\n",
      "Operator 202: 0.7839768145576577\n",
      "Operator 203: 1.1729998873178376\n",
      "Operator 204: 0.6092053622934099\n",
      "Operator 205: 1.6305960264209025\n",
      "Operator 206: -0.7528059219948842\n",
      "Operator 207: -0.8915146615642062\n",
      "Operator 208: -0.3231904452600462\n",
      "Operator 209: 1.78275774481193\n",
      "Operator 210: -0.9088856952067537\n",
      "Operator 211: -1.6560899300787713\n",
      "Operator 212: 1.0094235201637858\n",
      "Operator 213: -1.2504012035937933\n",
      "Operator 214: -1.4736260159603\n",
      "Operator 215: -1.6568534520038485\n",
      "Operator 216: -1.3467264779053432\n",
      "Operator 217: 1.3469340672398942\n",
      "Operator 218: 1.6555972856101429\n",
      "Operator 219: 1.4765837459697329\n",
      "Operator 220: 1.7169658573010826\n",
      "Operator 221: 1.3605610758516362\n",
      "Operator 222: 1.5757815732161191\n",
      "Operator 223: -1.5684676349724582\n",
      "Operator 224: -0.8515645521006479\n",
      "Operator 225: -1.6684681230618854\n",
      "Operator 226: 1.9280627281862548\n",
      "Operator 227: 1.075330460804236\n",
      "Operator 228: -0.8844463143884644\n",
      "Operator 229: 0.13884502388863224\n",
      "Operator 230: -1.1617048199781015\n",
      "Operator 231: 0.5150608001010313\n",
      "Operator 232: -0.41374491193255114\n",
      "Operator 233: -0.10977198483584351\n",
      "Operator 234: -0.44408068511199483\n",
      "Operator 235: -0.7688886229066584\n",
      "Operator 236: -0.43628777692298515\n",
      "Operator 237: -0.2121908828969677\n",
      "Operator 238: -0.48640177638562565\n",
      "Operator 239: 0.01960435138468605\n",
      "Operator 240: -0.5187017268088042\n",
      "Operator 241: 1.316055089027384\n",
      "Operator 242: -0.22810280695710394\n",
      "Operator 243: 1.2774167656169189\n",
      "Operator 244: 0.766343081419308\n",
      "Operator 245: 0.885267154653383\n",
      "Operator 246: -0.7983556934297877\n",
      "Operator 247: 0.03979375518255129\n",
      "Operator 248: 1.1080058709547755\n",
      "Operator 249: 1.1368389396318657\n",
      "Operator 250: 1.1066334529680877\n",
      "Operator 251: -0.18728456186050596\n",
      "Operator 252: -0.4203655676964345\n",
      "Operator 253: -0.33837575101807915\n",
      "Operator 254: -0.5369829451499046\n",
      "Operator 255: -0.2751839321513588\n",
      "Operator 256: -0.73667002021667\n",
      "Operator 257: -0.2306481784435278\n",
      "Operator 258: 0.9206003995102423\n",
      "Operator 259: 0.12308711150081633\n",
      "Operator 260: -1.487237234180184\n",
      "Total gradient norm: 16.40478357704279\n",
      "Operators under consideration (1):\n",
      "[50]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.2931171398523547)]\n",
      "Operator(s) added to ansatz: [50]\n",
      "Gradients: [np.float64(-2.2931171398523547)]\n",
      "Initial energy: -31.63004030088893\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50]...\n",
      "Starting point: [np.float64(0.30947511482846973), np.float64(0.49337113452353315), np.float64(0.23077769588149188), np.float64(0.32687035677115667), np.float64(0.1840317648885188), np.float64(0.30906962208368866), np.float64(-0.6508872863135746), np.float64(0.37711911951526067), np.float64(-0.30415169862716823), np.float64(-0.31818413345161334), np.float64(-0.5533809641574184), np.float64(-0.38961251258061724), np.float64(0.26343016081839377), np.float64(0.2691249426391657), np.float64(-0.26950850558131423), np.float64(-0.2674766497569879), np.float64(-0.24267545738672952), np.float64(0.19535775213750523), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -31.829014\n",
      "         Iterations: 28\n",
      "         Function evaluations: 40\n",
      "         Gradient evaluations: 40\n",
      "\n",
      "Current energy: -31.829013735329106\n",
      "(change of -0.1989734344401768)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50]\n",
      "On iteration 19.\n",
      "\n",
      "*** ADAPT-VQE Iteration 20 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.4271038298482975\n",
      "Operator 1: 1.1302829361341806\n",
      "Operator 2: 0.08348768733737169\n",
      "Operator 3: 1.394321632779858\n",
      "Operator 4: 0.8604599581807545\n",
      "Operator 5: 1.276729458748427\n",
      "Operator 6: 0.3620975848463007\n",
      "Operator 7: -0.2736508302564758\n",
      "Operator 8: -0.5611745507471663\n",
      "Operator 9: -0.4388957953898259\n",
      "Operator 10: -0.5843717353208109\n",
      "Operator 11: -0.423522515928868\n",
      "Operator 12: -0.06899462708286347\n",
      "Operator 13: 1.5518973594196728\n",
      "Operator 14: 0.28198096559011643\n",
      "Operator 15: 1.7896906811339552\n",
      "Operator 16: -0.5813312815458787\n",
      "Operator 20: -0.8624094754764458\n",
      "Operator 21: 0.6803581642372186\n",
      "Operator 25: 0.7288387510182276\n",
      "Operator 26: -1.352580639636727\n",
      "Operator 27: 1.2832852299365505\n",
      "Operator 28: -1.2783762962200116\n",
      "Operator 29: 1.2859838438690288\n",
      "Operator 30: -1.1847773523109058\n",
      "Operator 31: 0.7617196625003455\n",
      "Operator 34: 0.2432789209033759\n",
      "Operator 35: 0.4955525151096414\n",
      "Operator 36: -0.7318282144385637\n",
      "Operator 37: -0.1121611013729808\n",
      "Operator 38: 0.42005912856709826\n",
      "Operator 39: 0.5660077030345687\n",
      "Operator 40: 0.2755192784139488\n",
      "Operator 41: -0.3817995036628546\n",
      "Operator 42: -1.2362872238672424\n",
      "Operator 43: -0.9056362081868568\n",
      "Operator 44: -1.2663263694567926\n",
      "Operator 45: -0.764246117310664\n",
      "Operator 46: -1.4567830094150378\n",
      "Operator 47: 0.30766439417465374\n",
      "Operator 48: 0.18457229310420514\n",
      "Operator 49: 1.6269291723681825\n",
      "Operator 51: 1.7681525738265003\n",
      "Operator 52: 0.5051395018060454\n",
      "Operator 53: 0.9621265394451006\n",
      "Operator 54: 0.33298871228954496\n",
      "Operator 55: 1.2868788819242163\n",
      "Operator 56: 0.9120398369297901\n",
      "Operator 57: 1.2524883649876655\n",
      "Operator 58: 0.2075943085779205\n",
      "Operator 59: -0.4416852146209642\n",
      "Operator 60: -0.5992912786583906\n",
      "Operator 61: -0.399826886462566\n",
      "Operator 62: -0.6953681499681575\n",
      "Operator 63: -0.1887532251974851\n",
      "Operator 64: -0.18695009826550307\n",
      "Operator 65: 1.7346963210604545\n",
      "Operator 66: -0.5917670779981241\n",
      "Operator 67: 2.0336831683762444\n",
      "Operator 68: -0.8241109393196207\n",
      "Operator 70: -1.427711764888106\n",
      "Operator 71: 0.8726861720691708\n",
      "Operator 72: -0.7923320968801044\n",
      "Operator 73: 0.9330289160186983\n",
      "Operator 75: 0.9376348749343477\n",
      "Operator 76: -0.7921414069013616\n",
      "Operator 77: 0.8708877015609803\n",
      "Operator 78: -0.8106371656320309\n",
      "Operator 79: 0.8644671051390438\n",
      "Operator 80: -1.2821186758395935\n",
      "Operator 81: 1.1670816223869611\n",
      "Operator 82: -0.35223148751088357\n",
      "Operator 83: 1.3060304804176635\n",
      "Operator 85: -0.5432687301955785\n",
      "Operator 86: 0.7344802968629947\n",
      "Operator 87: 1.0495010503217015\n",
      "Operator 88: 0.2282109904017134\n",
      "Operator 89: 0.5911962117741437\n",
      "Operator 90: 0.1793109241508397\n",
      "Operator 91: 0.4558358501908966\n",
      "Operator 92: 0.34738087219007124\n",
      "Operator 93: 0.5640525174232418\n",
      "Operator 94: 0.4401568626900793\n",
      "Operator 95: -1.11437233092752\n",
      "Operator 96: -1.1410240440456816\n",
      "Operator 97: -1.175436368406097\n",
      "Operator 98: -1.1182608555780127\n",
      "Operator 99: -1.1433816389960112\n",
      "Operator 100: 0.07017394686848477\n",
      "Operator 101: 0.6814840807030005\n",
      "Operator 102: 0.08781169774187195\n",
      "Operator 103: 1.2500652574003752\n",
      "Operator 104: -0.48636216602047677\n",
      "Operator 105: 1.6299569093455397\n",
      "Operator 106: -0.9870131950622905\n",
      "Operator 107: 1.060008314242776\n",
      "Operator 108: -0.7111975352960584\n",
      "Operator 109: 1.401916155271028\n",
      "Operator 110: -1.2365934103828917\n",
      "Operator 111: 1.3777988622929456\n",
      "Operator 112: -0.7203400481462012\n",
      "Operator 118: -0.5938920988846345\n",
      "Operator 119: 0.8131074681681594\n",
      "Operator 120: -0.9984958151500563\n",
      "Operator 121: 0.37622267023797923\n",
      "Operator 122: -1.7978619328097145\n",
      "Operator 124: -0.978190321931544\n",
      "Operator 125: 0.7594570749063121\n",
      "Operator 126: -0.8914578761804817\n",
      "Operator 127: 1.454377588113294\n",
      "Operator 128: -0.8756104865718823\n",
      "Operator 129: 0.7928761399244502\n",
      "Operator 130: -0.9131288745990445\n",
      "Operator 131: 0.7245000157813642\n",
      "Operator 132: -1.0413525408341666\n",
      "Operator 134: -0.91145866795527\n",
      "Operator 135: 0.6938267037919122\n",
      "Operator 136: -0.745270075632596\n",
      "Operator 137: 0.502666931407429\n",
      "Operator 139: 1.5278917315564107\n",
      "Operator 140: -0.828308643984042\n",
      "Operator 141: -0.03961261034758898\n",
      "Operator 142: 0.1998728222269012\n",
      "Operator 143: 0.6133903824630283\n",
      "Operator 144: 0.4112909201490196\n",
      "Operator 145: -0.2036899714326608\n",
      "Operator 146: -1.248074328408396\n",
      "Operator 147: -0.9424962246724995\n",
      "Operator 148: -1.2233762207849803\n",
      "Operator 149: -0.8876671287010007\n",
      "Operator 150: -1.3281906939912766\n",
      "Operator 151: -0.2800915541718634\n",
      "Operator 152: 0.21189524022998343\n",
      "Operator 153: 0.8417894682393254\n",
      "Operator 154: 0.23216770438879003\n",
      "Operator 155: 1.1722974005407987\n",
      "Operator 156: 0.0821954987188458\n",
      "Operator 157: 0.5824826932162899\n",
      "Operator 158: 0.25048162437695065\n",
      "Operator 159: 0.5936369187150699\n",
      "Operator 160: 0.33971373808306843\n",
      "Operator 161: 0.41699640915603836\n",
      "Operator 162: 0.1932954619116983\n",
      "Operator 163: -1.107204107090797\n",
      "Operator 164: -1.145511495533684\n",
      "Operator 165: -1.1628894034255934\n",
      "Operator 166: -1.1488230711115226\n",
      "Operator 167: -1.0997218919065173\n",
      "Operator 168: 0.31576525511626125\n",
      "Operator 169: 0.8349394394146621\n",
      "Operator 170: 0.16015475616714095\n",
      "Operator 171: 1.1237333009326549\n",
      "Operator 173: -1.3498834055530236\n",
      "Operator 174: 1.3248940895705719\n",
      "Operator 175: 2.025879320635095\n",
      "Operator 176: -1.9645286827275101\n",
      "Operator 177: -0.45309894237851844\n",
      "Operator 178: 0.24757473531543486\n",
      "Operator 179: -1.3252599723682503\n",
      "Operator 180: -1.6622045715418419\n",
      "Operator 181: -1.4975153522364804\n",
      "Operator 182: -1.1172938286456553\n",
      "Operator 183: 1.1190067148352911\n",
      "Operator 184: 1.5129896769271285\n",
      "Operator 185: 1.6513214560944782\n",
      "Operator 186: 1.4969923617419618\n",
      "Operator 187: 1.6913104409475788\n",
      "Operator 188: 1.282892316911373\n",
      "Operator 189: -1.1228698052005828\n",
      "Operator 190: -1.9472073381700654\n",
      "Operator 191: -0.8467935718088982\n",
      "Operator 192: -2.239545192193834\n",
      "Operator 193: -0.7439343537031826\n",
      "Operator 194: -1.2429641208877031\n",
      "Operator 195: 1.4870115475890198\n",
      "Operator 196: -0.8867726592364704\n",
      "Operator 197: -1.2173580306238758\n",
      "Operator 198: -1.3788711560596214\n",
      "Operator 199: -1.3337023215262267\n",
      "Operator 200: 0.7155922717548538\n",
      "Operator 201: 1.0490310608864424\n",
      "Operator 202: 0.8302894045484086\n",
      "Operator 203: 1.10431284233474\n",
      "Operator 204: 0.7203698546886216\n",
      "Operator 205: 1.5470917675779237\n",
      "Operator 206: -0.7939252945758282\n",
      "Operator 207: -1.0884192581171814\n",
      "Operator 208: -1.0292571598860132\n",
      "Operator 209: -0.7624166524260108\n",
      "Operator 210: -0.909287296087762\n",
      "Operator 211: -1.6558595616798941\n",
      "Operator 212: 1.0076804669676158\n",
      "Operator 213: -1.2485265416302844\n",
      "Operator 214: -1.4756055873026304\n",
      "Operator 215: -1.6535210229743293\n",
      "Operator 216: -1.3504157033216977\n",
      "Operator 217: 1.3570821435200602\n",
      "Operator 218: 1.6383912964294747\n",
      "Operator 219: 1.5069172734625655\n",
      "Operator 220: 1.673766484512255\n",
      "Operator 221: 1.4417990984366273\n",
      "Operator 222: 1.3769736824593655\n",
      "Operator 223: -1.3816100953027939\n",
      "Operator 224: -1.1882421120181816\n",
      "Operator 225: -2.0305224789507355\n",
      "Operator 226: -0.6144309031031628\n",
      "Operator 227: 1.0747100021071314\n",
      "Operator 228: -0.8846854952223988\n",
      "Operator 229: 0.13794974726005363\n",
      "Operator 230: -1.1617186518628262\n",
      "Operator 231: 0.5124585090223435\n",
      "Operator 232: -0.4122200402025713\n",
      "Operator 233: -0.11615865074228943\n",
      "Operator 234: -0.44121588870458\n",
      "Operator 235: -0.7849958132095257\n",
      "Operator 236: -0.41864920080249723\n",
      "Operator 237: -0.2661596725074933\n",
      "Operator 238: -0.4588939201095653\n",
      "Operator 239: -0.14080852056987916\n",
      "Operator 240: -0.5337644656650404\n",
      "Operator 241: 0.9226230055637986\n",
      "Operator 242: -0.3027124533749242\n",
      "Operator 243: 1.1671494539614402\n",
      "Operator 244: 0.7665668020616079\n",
      "Operator 245: 0.8857978518140752\n",
      "Operator 246: -0.7978779208393172\n",
      "Operator 247: 0.039173484845049435\n",
      "Operator 248: 1.1078243560321241\n",
      "Operator 249: 1.138184414994682\n",
      "Operator 250: 1.10424070039897\n",
      "Operator 251: -0.19429584863539473\n",
      "Operator 252: -0.40748830901066796\n",
      "Operator 253: -0.3581451517327447\n",
      "Operator 254: -0.4990905398451293\n",
      "Operator 255: -0.32211854547416874\n",
      "Operator 256: -0.6440043024973765\n",
      "Operator 257: -0.3178942463186485\n",
      "Operator 258: 1.0639687697541667\n",
      "Operator 259: 0.865649982047944\n",
      "Operator 260: 0.8498464600149019\n",
      "Total gradient norm: 15.53882514387425\n",
      "Operators under consideration (1):\n",
      "[192]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.239545192193834)]\n",
      "Operator(s) added to ansatz: [192]\n",
      "Gradients: [np.float64(-2.239545192193834)]\n",
      "Initial energy: -31.829013735329106\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192]...\n",
      "Starting point: [np.float64(0.30458181843494003), np.float64(0.4142208562356563), np.float64(0.2309004513317344), np.float64(0.31354447615065767), np.float64(0.18406835544031175), np.float64(0.3084121973094982), np.float64(-0.5655306852282191), np.float64(0.3409240191296947), np.float64(-0.3023029096552093), np.float64(-0.31792464796939535), np.float64(-0.553324412977402), np.float64(-0.3895017615695343), np.float64(0.26376193420857047), np.float64(0.26999482458210977), np.float64(-0.2720437205737253), np.float64(-0.273968510085623), np.float64(-0.2570676087623611), np.float64(0.2267266032622375), np.float64(0.17786011180019562), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -32.008305\n",
      "         Iterations: 31\n",
      "         Function evaluations: 149\n",
      "         Gradient evaluations: 137\n",
      "\n",
      "Current energy: -32.00830481895166\n",
      "(change of -0.17929108362255164)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192]\n",
      "On iteration 20.\n",
      "\n",
      "*** ADAPT-VQE Iteration 21 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.42729913383967244\n",
      "Operator 1: 1.1303871147121551\n",
      "Operator 2: 0.08299320547573495\n",
      "Operator 3: 1.3948835013045664\n",
      "Operator 4: 0.8593022305194336\n",
      "Operator 5: 1.2782273988719635\n",
      "Operator 6: 0.3605810194775855\n",
      "Operator 7: -0.2726742389150101\n",
      "Operator 8: -0.5642392705939616\n",
      "Operator 9: -0.43523550523811766\n",
      "Operator 10: -0.5928076082228201\n",
      "Operator 11: -0.41502356400616786\n",
      "Operator 12: -0.12189830698100199\n",
      "Operator 13: 1.6050046452453826\n",
      "Operator 14: 0.15658734599489343\n",
      "Operator 15: -0.3933442746630689\n",
      "Operator 16: -1.2013664956676693\n",
      "Operator 19: 1.124198516569419e-08\n",
      "Operator 20: -0.8623901795667226\n",
      "Operator 21: 0.6804760149246314\n",
      "Operator 25: 0.7278594044816274\n",
      "Operator 26: -1.3487819152980411\n",
      "Operator 27: 1.2829300037946\n",
      "Operator 28: -1.265523657906603\n",
      "Operator 29: 1.2768634553185494\n",
      "Operator 30: -1.1257245484168923\n",
      "Operator 31: 0.7038548295491946\n",
      "Operator 32: -0.16753923565824272\n",
      "Operator 33: 0.004537281342144832\n",
      "Operator 34: 0.24321294096929358\n",
      "Operator 35: 0.49575466780376776\n",
      "Operator 36: -0.7322529024580369\n",
      "Operator 37: -0.11139745447857462\n",
      "Operator 38: 0.41939866382546975\n",
      "Operator 39: 0.5676456637662107\n",
      "Operator 40: 0.2741552123634458\n",
      "Operator 41: -0.3753575030509937\n",
      "Operator 42: -1.245002115835852\n",
      "Operator 43: -0.8875161154509562\n",
      "Operator 44: -1.2867287633437807\n",
      "Operator 45: -0.7125535947133974\n",
      "Operator 46: -1.4903070731203982\n",
      "Operator 47: 0.45531140354584365\n",
      "Operator 48: 0.28872631164502055\n",
      "Operator 49: 1.4377411215253217\n",
      "Operator 50: 0.3956500639650172\n",
      "Operator 51: 1.7682389843085784\n",
      "Operator 52: 0.504773843887326\n",
      "Operator 53: 0.9624234055913197\n",
      "Operator 54: 0.33211251454732993\n",
      "Operator 55: 1.2880084531498983\n",
      "Operator 56: 0.9096032678465199\n",
      "Operator 57: 1.255644302834083\n",
      "Operator 58: 0.20205307332341654\n",
      "Operator 59: -0.43656013216324685\n",
      "Operator 60: -0.6114178839951999\n",
      "Operator 61: -0.38889907053325107\n",
      "Operator 62: -0.7321026504580985\n",
      "Operator 63: -0.18005638833758159\n",
      "Operator 64: -0.3138431195587564\n",
      "Operator 65: 1.6156717083572938\n",
      "Operator 66: -0.8666739790284609\n",
      "Operator 67: -0.2842835305682284\n",
      "Operator 68: -0.8240126926051202\n",
      "Operator 70: -1.4274040912738777\n",
      "Operator 71: 0.8732023177000208\n",
      "Operator 72: -0.7914686152274681\n",
      "Operator 73: 0.9342370782318429\n",
      "Operator 75: 0.9377361428029497\n",
      "Operator 76: -0.7912955351984412\n",
      "Operator 77: 0.8715507986921394\n",
      "Operator 78: -0.8079355596073043\n",
      "Operator 79: 0.864890866430618\n",
      "Operator 80: -1.2492408185738475\n",
      "Operator 81: 1.2144887581521864\n",
      "Operator 82: -0.27428124306178114\n",
      "Operator 83: 0.011520746849797758\n",
      "Operator 85: -0.5432165706561711\n",
      "Operator 86: 0.7345011933220881\n",
      "Operator 87: 1.0496143278007428\n",
      "Operator 88: 0.228159497891345\n",
      "Operator 89: 0.5914292497590776\n",
      "Operator 90: 0.17906920088923908\n",
      "Operator 91: 0.45630493606340083\n",
      "Operator 92: 0.346725936951213\n",
      "Operator 93: 0.5652168167133264\n",
      "Operator 94: 0.43839344136665337\n",
      "Operator 95: -1.1148940481192522\n",
      "Operator 96: -1.138618979442354\n",
      "Operator 97: -1.1771144625136072\n",
      "Operator 98: -1.1113906355808962\n",
      "Operator 99: -1.1456312912999398\n",
      "Operator 100: 0.04586499070027872\n",
      "Operator 101: 0.7274427442818694\n",
      "Operator 102: 0.21213198963688476\n",
      "Operator 103: -0.6332993658631759\n",
      "Operator 104: -0.4863303421541981\n",
      "Operator 105: 1.6298119096519594\n",
      "Operator 106: -0.9870087669444523\n",
      "Operator 107: 1.0598250483465916\n",
      "Operator 108: -0.7110615574168312\n",
      "Operator 109: 1.4013894516568\n",
      "Operator 110: -1.23681366366032\n",
      "Operator 111: 1.3763716006579834\n",
      "Operator 112: -0.7212263027292172\n",
      "Operator 114: -1.0240636856272466e-08\n",
      "Operator 118: -0.5282905515169612\n",
      "Operator 119: 0.7858205040153341\n",
      "Operator 120: -0.9073388041484614\n",
      "Operator 121: 0.37619441914290097\n",
      "Operator 122: -1.7979423413770799\n",
      "Operator 124: -0.9781985890869112\n",
      "Operator 125: 0.7593372844827474\n",
      "Operator 126: -0.89154893938728\n",
      "Operator 127: 1.4521229666167292\n",
      "Operator 128: -0.8795975257379298\n",
      "Operator 129: 0.7864428614851505\n",
      "Operator 130: -0.9234781834479919\n",
      "Operator 131: 0.7090478782506476\n",
      "Operator 132: -1.0648492215792502\n",
      "Operator 134: -0.9011019513172153\n",
      "Operator 135: 0.6467955014132158\n",
      "Operator 136: -0.5300641728271573\n",
      "Operator 137: -0.169705421291695\n",
      "Operator 139: 1.5280015625990604\n",
      "Operator 140: -0.8285696764893609\n",
      "Operator 141: -0.03936450037357762\n",
      "Operator 142: 0.19976642918857215\n",
      "Operator 143: 0.6138320220989709\n",
      "Operator 144: 0.41082643353650083\n",
      "Operator 145: -0.19982511214345144\n",
      "Operator 146: -1.2525305151110855\n",
      "Operator 147: -0.9340854577836564\n",
      "Operator 148: -1.2356960247707907\n",
      "Operator 149: -0.8663104132276933\n",
      "Operator 150: -1.3569014052551314\n",
      "Operator 151: -0.25024788219777444\n",
      "Operator 152: 0.20300399498648153\n",
      "Operator 153: 0.8705222758887632\n",
      "Operator 154: 0.6020533353913606\n",
      "Operator 155: 1.1723880791273444\n",
      "Operator 156: 0.08216443236214835\n",
      "Operator 157: 0.5826763397034926\n",
      "Operator 158: 0.2503398018879896\n",
      "Operator 159: 0.5940741690913509\n",
      "Operator 160: 0.3392576184078526\n",
      "Operator 161: 0.41822065708514056\n",
      "Operator 162: 0.19183858146262756\n",
      "Operator 163: -1.107525000721\n",
      "Operator 164: -1.1452040630979348\n",
      "Operator 165: -1.1619627088456361\n",
      "Operator 166: -1.14798197763983\n",
      "Operator 167: -1.0948691035873808\n",
      "Operator 168: 0.28245135125399645\n",
      "Operator 169: 0.8547687095988175\n",
      "Operator 170: 0.15906109850666686\n",
      "Operator 171: -0.6612367170748948\n",
      "Operator 173: -1.3498370115784777\n",
      "Operator 174: 1.1694913180790467\n",
      "Operator 175: 2.025893266040445\n",
      "Operator 176: -1.9646048456235174\n",
      "Operator 177: -0.4527253793021513\n",
      "Operator 178: 0.24727463270764927\n",
      "Operator 179: -1.3249110970862876\n",
      "Operator 180: -1.6627812111323395\n",
      "Operator 181: -1.4965102484404902\n",
      "Operator 182: -1.12095502301945\n",
      "Operator 183: 1.1225876562340968\n",
      "Operator 184: 1.5093013852376054\n",
      "Operator 185: 1.6575427751854614\n",
      "Operator 186: 1.4873931608344293\n",
      "Operator 187: 1.7077322484550002\n",
      "Operator 188: 1.2614281140575965\n",
      "Operator 189: -1.0674519034406116\n",
      "Operator 190: -1.901812122424203\n",
      "Operator 191: -0.6573527744392864\n",
      "Operator 193: -0.743873079336718\n",
      "Operator 194: -1.2428357928669427\n",
      "Operator 195: 1.4871195797054297\n",
      "Operator 196: -0.8868173390710438\n",
      "Operator 197: -1.217267454712216\n",
      "Operator 198: -1.3786602498285976\n",
      "Operator 199: -1.333608618523593\n",
      "Operator 200: 0.7116048364965913\n",
      "Operator 201: 1.0560286530808267\n",
      "Operator 202: 0.8185896077549772\n",
      "Operator 203: 1.1216567422545778\n",
      "Operator 204: 0.6908670256622164\n",
      "Operator 205: 1.5695104534591802\n",
      "Operator 206: -0.7803911358938124\n",
      "Operator 207: -1.0296175761248094\n",
      "Operator 208: -1.0456356055828695\n",
      "Operator 209: -0.2116947707281691\n",
      "Operator 210: -0.9091868203130347\n",
      "Operator 211: -1.6559172057800455\n",
      "Operator 212: 1.0081170572860534\n",
      "Operator 213: -1.2489957703453252\n",
      "Operator 214: -1.4751099097169929\n",
      "Operator 215: -1.6543554404066374\n",
      "Operator 216: -1.3494947981148824\n",
      "Operator 217: 1.3545491446034448\n",
      "Operator 218: 1.6427300031723875\n",
      "Operator 219: 1.499344130805401\n",
      "Operator 220: 1.6847839828824813\n",
      "Operator 221: 1.4215559779052382\n",
      "Operator 222: 1.420832666965905\n",
      "Operator 223: -1.4442746527809593\n",
      "Operator 224: -1.1386019678626937\n",
      "Operator 225: -0.19880096119479845\n",
      "Operator 226: -0.0037796155213041045\n",
      "Operator 227: 1.0748652304498232\n",
      "Operator 228: -0.8846257358399661\n",
      "Operator 229: 0.13817363663322388\n",
      "Operator 230: -1.1617161153161195\n",
      "Operator 231: 0.5131092757877276\n",
      "Operator 232: -0.41260639896725154\n",
      "Operator 233: -0.11456957689181893\n",
      "Operator 234: -0.44196239596853476\n",
      "Operator 235: -0.7810498033496135\n",
      "Operator 236: -0.4232592376108233\n",
      "Operator 237: -0.2528533051882226\n",
      "Operator 238: -0.4665239786282591\n",
      "Operator 239: -0.1001430320879299\n",
      "Operator 240: -0.5225251644945221\n",
      "Operator 241: 0.9682554738239594\n",
      "Operator 242: -0.161169109601819\n",
      "Operator 243: 1.0866794283074532\n",
      "Operator 244: 0.766510853696119\n",
      "Operator 245: 0.8856650731736921\n",
      "Operator 246: -0.7979974303659793\n",
      "Operator 247: 0.03932881397410636\n",
      "Operator 248: 1.1078706202781536\n",
      "Operator 249: 1.1378483142442393\n",
      "Operator 250: 1.1048484548756485\n",
      "Operator 251: -0.19253223842031403\n",
      "Operator 252: -0.410706612375535\n",
      "Operator 253: -0.35311744394107725\n",
      "Operator 254: -0.5085226985409489\n",
      "Operator 255: -0.3097672523393112\n",
      "Operator 256: -0.6679303770273723\n",
      "Operator 257: -0.29976609492034595\n",
      "Operator 258: 1.0189123677457745\n",
      "Operator 259: 0.905812190240215\n",
      "Operator 260: 1.0648303041702665\n",
      "Total gradient norm: 14.849694586651307\n",
      "Operators under consideration (1):\n",
      "[175]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.025893266040445)]\n",
      "Operator(s) added to ansatz: [175]\n",
      "Gradients: [np.float64(2.025893266040445)]\n",
      "Initial energy: -32.00830481895166\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175]...\n",
      "Starting point: [np.float64(0.3058039681453567), np.float64(0.44169330196891776), np.float64(0.23086972666787253), np.float64(0.3168995717463356), np.float64(0.18405919988805866), np.float64(0.3085766159263636), np.float64(-0.6268950269371341), np.float64(0.3505474090720137), np.float64(-0.30276518154986753), np.float64(-0.3179895661370908), np.float64(-0.5533385602830239), np.float64(-0.38952946696282387), np.float64(0.26367879811606015), np.float64(0.26977644803500966), np.float64(-0.271404219633383), np.float64(-0.27232272060871876), np.float64(-0.2534681294733361), np.float64(0.22258978592400233), np.float64(0.19538511403958694), np.float64(0.15907313348927665), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -32.151516\n",
      "         Iterations: 28\n",
      "         Function evaluations: 79\n",
      "         Gradient evaluations: 68\n",
      "\n",
      "Current energy: -32.151515879304746\n",
      "(change of -0.14321106035308873)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175]\n",
      "On iteration 21.\n",
      "\n",
      "*** ADAPT-VQE Iteration 22 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.9581564924244371\n",
      "Operator 1: 1.0037619140253289\n",
      "Operator 2: 0.12548207564937602\n",
      "Operator 3: 1.3708903688832677\n",
      "Operator 4: 0.879259781981577\n",
      "Operator 5: 1.2692326303921186\n",
      "Operator 6: 0.36749563975954197\n",
      "Operator 7: -0.2741138996693483\n",
      "Operator 8: -0.5624909916919544\n",
      "Operator 9: -0.43597113805164345\n",
      "Operator 10: -0.5921567949695564\n",
      "Operator 11: -0.4153079727877984\n",
      "Operator 12: -0.12153958939953706\n",
      "Operator 13: 1.6048545041142797\n",
      "Operator 14: 0.15679515186905513\n",
      "Operator 15: -0.3933287914941507\n",
      "Operator 16: -1.2012877445812613\n",
      "Operator 17: 0.0627161209345421\n",
      "Operator 19: 0.08962557093588003\n",
      "Operator 20: -0.856679425503666\n",
      "Operator 21: 0.6960159066664666\n",
      "Operator 22: 3.492401725393637e-08\n",
      "Operator 23: 8.744378844067564e-08\n",
      "Operator 24: 2.5482310970674954e-08\n",
      "Operator 25: 0.7283764977836216\n",
      "Operator 26: -1.347932222738521\n",
      "Operator 27: 1.2836817433700416\n",
      "Operator 28: -1.265193973455402\n",
      "Operator 29: 1.2771908157153256\n",
      "Operator 30: -1.1256594623290566\n",
      "Operator 31: 0.7039987052502661\n",
      "Operator 32: -0.16754577203188245\n",
      "Operator 33: 0.0045397020643694885\n",
      "Operator 34: 0.2338557115726403\n",
      "Operator 35: 0.37245008361310705\n",
      "Operator 36: -0.7155114171345462\n",
      "Operator 37: -0.13921437382313587\n",
      "Operator 38: 0.4231719261251825\n",
      "Operator 39: 0.5643415027459632\n",
      "Operator 40: 0.2751998102303647\n",
      "Operator 41: -0.37698084701306644\n",
      "Operator 42: -1.2433480106652905\n",
      "Operator 43: -0.8887625776292506\n",
      "Operator 44: -1.2860607939739541\n",
      "Operator 45: -0.7130944540166271\n",
      "Operator 46: -1.4900772644760836\n",
      "Operator 47: 0.45502562658337464\n",
      "Operator 48: 0.28874670987173323\n",
      "Operator 49: 1.4376790848974728\n",
      "Operator 50: 0.39562329319149\n",
      "Operator 51: -0.14977174979907387\n",
      "Operator 52: 0.3369457708747386\n",
      "Operator 53: 0.9467765822138754\n",
      "Operator 54: 0.3443013804949471\n",
      "Operator 55: 1.2760236935211628\n",
      "Operator 56: 0.9185814138626613\n",
      "Operator 57: 1.2508866238241092\n",
      "Operator 58: 0.20615085575258313\n",
      "Operator 59: -0.43709396105935316\n",
      "Operator 60: -0.6109362974912704\n",
      "Operator 61: -0.3890945848807155\n",
      "Operator 62: -0.7318741044556498\n",
      "Operator 63: -0.18010039460868313\n",
      "Operator 64: -0.31368712983340385\n",
      "Operator 65: 1.61561010042986\n",
      "Operator 66: -0.8665556178512843\n",
      "Operator 67: -0.28425052888778696\n",
      "Operator 68: -0.889045344635033\n",
      "Operator 69: 7.393165027242101e-08\n",
      "Operator 70: -1.442734470389619\n",
      "Operator 71: 0.8726515713948755\n",
      "Operator 72: -0.7924178019108907\n",
      "Operator 73: 0.9341418618126871\n",
      "Operator 74: 8.020870103552425e-08\n",
      "Operator 75: 0.9364369569265057\n",
      "Operator 76: -0.7922109964178702\n",
      "Operator 77: 0.8709923227966564\n",
      "Operator 78: -0.8083053853293507\n",
      "Operator 79: 0.8646870472240268\n",
      "Operator 80: -1.2494045788698287\n",
      "Operator 81: 1.2145021588316505\n",
      "Operator 82: -0.2742951910014899\n",
      "Operator 83: 0.011526884929985382\n",
      "Operator 84: -2.2672045218996573e-07\n",
      "Operator 85: -0.08297352135825661\n",
      "Operator 86: 0.2227341653111863\n",
      "Operator 87: -0.490765984824575\n",
      "Operator 88: 0.2852732612770842\n",
      "Operator 89: 0.5192143753222951\n",
      "Operator 90: 0.18917788466187838\n",
      "Operator 91: 0.44624194133268663\n",
      "Operator 92: 0.3504337078861045\n",
      "Operator 93: 0.5618499741236433\n",
      "Operator 94: 0.44000582843526403\n",
      "Operator 95: -1.1149778032375863\n",
      "Operator 96: -1.1386539453749125\n",
      "Operator 97: -1.1771805343808006\n",
      "Operator 98: -1.1114297004295475\n",
      "Operator 99: -1.1456614543701598\n",
      "Operator 100: 0.0459137108916878\n",
      "Operator 101: 0.7273217292212185\n",
      "Operator 102: 0.21216381771402304\n",
      "Operator 103: -0.6332937357186244\n",
      "Operator 104: -0.0738763564126656\n",
      "Operator 105: 1.109371486523297e-08\n",
      "Operator 106: -0.7915612842086626\n",
      "Operator 107: 1.057411754610126\n",
      "Operator 108: -0.7149048833026185\n",
      "Operator 109: 1.3949652767717227\n",
      "Operator 110: -1.242250193487361\n",
      "Operator 111: 1.373674905196975\n",
      "Operator 112: -0.7237245054678705\n",
      "Operator 113: 3.830622810665927e-08\n",
      "Operator 114: -1.2369186258223215e-07\n",
      "Operator 115: 3.0950628663939904e-08\n",
      "Operator 116: -5.3043204043690045e-08\n",
      "Operator 117: -2.0356535600471882e-08\n",
      "Operator 118: -0.5283339309278129\n",
      "Operator 119: 0.785838875654617\n",
      "Operator 120: -0.9074141947593397\n",
      "Operator 121: 0.09303813622359852\n",
      "Operator 122: -1.8079165565986273\n",
      "Operator 123: -6.992285955967774e-08\n",
      "Operator 124: -0.9685681843220941\n",
      "Operator 125: 0.76615890877306\n",
      "Operator 126: -0.8872969600408078\n",
      "Operator 127: 1.4545148877657657\n",
      "Operator 128: -0.8794840029577489\n",
      "Operator 129: 0.786582581516317\n",
      "Operator 130: -0.9234316809421693\n",
      "Operator 131: 0.7091117386209722\n",
      "Operator 132: -1.0648448753128992\n",
      "Operator 133: 7.875957869218908e-08\n",
      "Operator 134: -0.9010548888278362\n",
      "Operator 135: 0.6468606530304322\n",
      "Operator 136: -0.5300674371904286\n",
      "Operator 137: -0.16970328996396944\n",
      "Operator 139: 1.50485697690014\n",
      "Operator 140: -0.7067510925597755\n",
      "Operator 141: -0.09394194177835372\n",
      "Operator 142: 0.20982734344112444\n",
      "Operator 143: 0.6003050030065995\n",
      "Operator 144: 0.41601556801727285\n",
      "Operator 145: -0.20584513379317562\n",
      "Operator 146: -1.2491762449169133\n",
      "Operator 147: -0.9366929598971437\n",
      "Operator 148: -1.2344363401345217\n",
      "Operator 149: -0.8673071004672668\n",
      "Operator 150: -1.356423779412963\n",
      "Operator 151: -0.2506512013067223\n",
      "Operator 152: 0.20306879452729332\n",
      "Operator 153: 0.8703689383909876\n",
      "Operator 154: 0.6020533504188279\n",
      "Operator 155: -0.4752625694871725\n",
      "Operator 156: 0.045646735900937235\n",
      "Operator 157: 0.6498747889762364\n",
      "Operator 158: 0.265260944252204\n",
      "Operator 159: 0.5846536729866072\n",
      "Operator 160: 0.344541136167952\n",
      "Operator 161: 0.41478271739987216\n",
      "Operator 162: 0.19374209525923947\n",
      "Operator 163: -1.1068614272199293\n",
      "Operator 164: -1.1455529891464242\n",
      "Operator 165: -1.1618648410029786\n",
      "Operator 166: -1.1481315453804253\n",
      "Operator 167: -1.0948739430009389\n",
      "Operator 168: 0.2825475487970124\n",
      "Operator 169: 0.8546636204131719\n",
      "Operator 170: 0.15908897632018282\n",
      "Operator 171: -0.66123158106805\n",
      "Operator 172: 0.07043900988838281\n",
      "Operator 173: -0.255491712300402\n",
      "Operator 174: 1.16941106131258\n",
      "Operator 175: 1.3714084096864947e-08\n",
      "Operator 176: -0.17248768751565643\n",
      "Operator 177: -0.4682032033331997\n",
      "Operator 178: 0.2862752360886651\n",
      "Operator 179: -1.3326987184846517\n",
      "Operator 180: -1.6562117975203512\n",
      "Operator 181: -1.5004303911565446\n",
      "Operator 182: -1.1171199197865846\n",
      "Operator 183: 1.1186987100531356\n",
      "Operator 184: 1.5103819441663455\n",
      "Operator 185: 1.6569089470753247\n",
      "Operator 186: 1.4878183879897164\n",
      "Operator 187: 1.707480067660191\n",
      "Operator 188: 1.2615960894389233\n",
      "Operator 189: -1.0675428421614934\n",
      "Operator 190: -1.9017479553535646\n",
      "Operator 191: -0.6574087279034397\n",
      "Operator 192: 2.8755926528845066e-08\n",
      "Operator 193: 0.19378080144847712\n",
      "Operator 194: -1.1970684165332126\n",
      "Operator 195: 1.4075167526877213\n",
      "Operator 196: -0.8706455054636377\n",
      "Operator 197: -1.2220502003122071\n",
      "Operator 198: -1.376291616994667\n",
      "Operator 199: -1.3355759303139063\n",
      "Operator 200: 0.7140219631218899\n",
      "Operator 201: 1.0541826059664154\n",
      "Operator 202: 0.8197275439549232\n",
      "Operator 203: 1.120955308642936\n",
      "Operator 204: 0.6912754400128728\n",
      "Operator 205: 1.5692247537170276\n",
      "Operator 206: -0.7802822835223459\n",
      "Operator 207: -1.0296974459769395\n",
      "Operator 208: -1.0456407091008635\n",
      "Operator 209: -0.21171787800683894\n",
      "Operator 210: -0.1340400899597367\n",
      "Operator 211: -1.5104630876301988\n",
      "Operator 212: 0.9897711509068615\n",
      "Operator 213: -1.221976738356653\n",
      "Operator 214: -1.4832937148046175\n",
      "Operator 215: -1.6497842491527395\n",
      "Operator 216: -1.352216247426886\n",
      "Operator 217: 1.3555383718713647\n",
      "Operator 218: 1.6418198490749045\n",
      "Operator 219: 1.4998972574928238\n",
      "Operator 220: 1.684436442506846\n",
      "Operator 221: 1.421789248254124\n",
      "Operator 222: 1.4206247600838924\n",
      "Operator 223: -1.4440629290322438\n",
      "Operator 224: -1.138695444499115\n",
      "Operator 225: -0.19881147888403883\n",
      "Operator 226: -0.00378168026368364\n",
      "Operator 227: 1.0500056964466786\n",
      "Operator 228: -0.0447918293930817\n",
      "Operator 229: 0.3278880500529441\n",
      "Operator 230: -1.162012833626811\n",
      "Operator 231: 0.5046755112054291\n",
      "Operator 232: -0.40149697745358676\n",
      "Operator 233: -0.12298395132026144\n",
      "Operator 234: -0.4378720511116233\n",
      "Operator 235: -0.7837193705018313\n",
      "Operator 236: -0.42285276262190974\n",
      "Operator 237: -0.2533036846600221\n",
      "Operator 238: -0.4663922840452365\n",
      "Operator 239: -0.10036739884247503\n",
      "Operator 240: -0.5225118333635795\n",
      "Operator 241: 0.9681334737458567\n",
      "Operator 242: -0.16114918552667418\n",
      "Operator 243: 1.0865767032084497\n",
      "Operator 244: 0.4612806466748288\n",
      "Operator 245: 0.3368725429056452\n",
      "Operator 246: -0.7902324866621598\n",
      "Operator 247: 0.024702782322561782\n",
      "Operator 248: 1.1089970239057503\n",
      "Operator 249: 1.1382832955299693\n",
      "Operator 250: 1.1045295513847775\n",
      "Operator 251: -0.1940945775192993\n",
      "Operator 252: -0.40941780533356953\n",
      "Operator 253: -0.35362865155506906\n",
      "Operator 254: -0.5080879056965243\n",
      "Operator 255: -0.3099551535482963\n",
      "Operator 256: -0.6677198644820885\n",
      "Operator 257: -0.29984618789438977\n",
      "Operator 258: 1.0189657646180013\n",
      "Operator 259: 0.9058221848115865\n",
      "Operator 260: 1.0648530055154435\n",
      "Total gradient norm: 14.057300774483512\n",
      "Operators under consideration (1):\n",
      "[190]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.9017479553535646)]\n",
      "Operator(s) added to ansatz: [190]\n",
      "Gradients: [np.float64(-1.9017479553535646)]\n",
      "Initial energy: -32.151515879304746\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190]...\n",
      "Starting point: [np.float64(0.30562685350876395), np.float64(0.4416749673130132), np.float64(0.23632981545804277), np.float64(0.3168280299634277), np.float64(0.14572098458020266), np.float64(0.30725476078173997), np.float64(-0.6268877552819637), np.float64(0.35051359436629503), np.float64(-0.30227011071924637), np.float64(-0.3142343832347969), np.float64(-0.5429863625591983), np.float64(-0.37928195403336096), np.float64(0.26538551142009303), np.float64(0.2704490662292934), np.float64(-0.2716395935497494), np.float64(-0.2724176160922016), np.float64(-0.25350448878136034), np.float64(0.2226033033045357), np.float64(0.195388582776248), np.float64(0.1590728703798881), np.float64(-0.1417937317194401), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -32.280299\n",
      "         Iterations: 32\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 72\n",
      "\n",
      "Current energy: -32.28029860333202\n",
      "(change of -0.12878272402727475)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190]\n",
      "On iteration 22.\n",
      "\n",
      "*** ADAPT-VQE Iteration 23 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.9586017678467182\n",
      "Operator 1: 1.0039969916084694\n",
      "Operator 2: 0.12436471370839418\n",
      "Operator 3: 1.3722022022329643\n",
      "Operator 4: 0.8765984107940773\n",
      "Operator 5: 1.2727386227916975\n",
      "Operator 6: 0.3639804908295231\n",
      "Operator 7: -0.2718653015915858\n",
      "Operator 8: -0.5697558068211951\n",
      "Operator 9: -0.42798196027567775\n",
      "Operator 10: -0.6132588867171508\n",
      "Operator 11: -0.40163332795345236\n",
      "Operator 12: -0.2657009524908186\n",
      "Operator 13: 0.0429787001070658\n",
      "Operator 14: -0.5524680319891854\n",
      "Operator 15: -0.39719238329484524\n",
      "Operator 16: -1.3484130816686983\n",
      "Operator 17: 0.06272726197890069\n",
      "Operator 19: 0.08963730920902419\n",
      "Operator 20: -0.8566329336442379\n",
      "Operator 21: 0.6963056747880297\n",
      "Operator 25: 0.7258405640176848\n",
      "Operator 26: -1.3375131023510463\n",
      "Operator 27: 1.2781294140003503\n",
      "Operator 28: -1.2190141881012186\n",
      "Operator 29: 1.2011417834741582\n",
      "Operator 30: -1.0559572619276785\n",
      "Operator 31: 0.6860351419186419\n",
      "Operator 32: -0.10642182213686224\n",
      "Operator 33: 0.06998979166224295\n",
      "Operator 34: 0.23371779678230803\n",
      "Operator 35: 0.37290311709279184\n",
      "Operator 36: -0.7164937468991636\n",
      "Operator 37: -0.13746410096486064\n",
      "Operator 38: 0.4216323136660819\n",
      "Operator 39: 0.568161332871387\n",
      "Operator 40: 0.2720796532975173\n",
      "Operator 41: -0.36184291807521973\n",
      "Operator 42: -1.2626988294258508\n",
      "Operator 43: -0.8444695536215181\n",
      "Operator 44: -1.3239299850366075\n",
      "Operator 45: -0.5729088851973075\n",
      "Operator 46: -1.447132373372979\n",
      "Operator 47: 0.5415885789829084\n",
      "Operator 48: 0.4235646721826616\n",
      "Operator 49: 1.4635192518211855\n",
      "Operator 50: 0.4049927688045671\n",
      "Operator 51: -0.14967570635867283\n",
      "Operator 52: 0.33619246775048367\n",
      "Operator 53: 0.9474458541000501\n",
      "Operator 54: 0.3422822889717825\n",
      "Operator 55: 1.278656371474904\n",
      "Operator 56: 0.9129092250677975\n",
      "Operator 57: 1.258156755509297\n",
      "Operator 58: 0.19296446911639065\n",
      "Operator 59: -0.42611623670202686\n",
      "Operator 60: -0.6418181641461411\n",
      "Operator 61: -0.3738332974983148\n",
      "Operator 62: -0.8446745674174423\n",
      "Operator 63: -0.27635348865358933\n",
      "Operator 64: -0.603682514922158\n",
      "Operator 65: 0.0034493376182298573\n",
      "Operator 66: -1.3245943714247217\n",
      "Operator 67: -0.09361193586260891\n",
      "Operator 68: -0.8888368216220359\n",
      "Operator 70: -1.442035717131019\n",
      "Operator 71: 0.8738600688289582\n",
      "Operator 72: -0.7904130712002069\n",
      "Operator 73: 0.9369754384059779\n",
      "Operator 75: 0.9366477415552643\n",
      "Operator 76: -0.79018266707873\n",
      "Operator 77: 0.8722556927065852\n",
      "Operator 78: -0.8015860578389042\n",
      "Operator 79: 0.8630476612105225\n",
      "Operator 80: -1.1472630640371495\n",
      "Operator 81: 0.17986633284133596\n",
      "Operator 82: -0.2181558207399341\n",
      "Operator 83: 0.2183215330012802\n",
      "Operator 85: -0.08297213541812547\n",
      "Operator 86: 0.22277454325580381\n",
      "Operator 87: -0.4907066643409315\n",
      "Operator 88: 0.2851687749948413\n",
      "Operator 89: 0.5197058499384664\n",
      "Operator 90: 0.18860651185545077\n",
      "Operator 91: 0.4473096092114316\n",
      "Operator 92: 0.34890108823955646\n",
      "Operator 93: 0.5645578206853038\n",
      "Operator 94: 0.4359471783315598\n",
      "Operator 95: -1.1160747734281107\n",
      "Operator 96: -1.1331822575414614\n",
      "Operator 97: -1.1805854542396803\n",
      "Operator 98: -1.0990130427039393\n",
      "Operator 99: -1.1409281276143428\n",
      "Operator 100: -0.2496717672125371\n",
      "Operator 101: -0.5057982181936184\n",
      "Operator 102: 0.2527834835460307\n",
      "Operator 103: -0.7274727904696133\n",
      "Operator 104: -0.07388036168688714\n",
      "Operator 106: -0.7915425865395367\n",
      "Operator 107: 1.056965329933005\n",
      "Operator 108: -0.714593134083814\n",
      "Operator 109: 1.3937416649589243\n",
      "Operator 110: -1.2427340897091748\n",
      "Operator 111: 1.3702176305656293\n",
      "Operator 112: -0.725522470703905\n",
      "Operator 117: 0.11117723772088846\n",
      "Operator 118: -0.4545148910165179\n",
      "Operator 119: 0.20347589897569096\n",
      "Operator 120: -0.14327690115043154\n",
      "Operator 121: 0.09303794617602848\n",
      "Operator 122: -1.808099151929444\n",
      "Operator 124: -0.9685860075795796\n",
      "Operator 125: 0.7658882471310019\n",
      "Operator 126: -0.8875067888588494\n",
      "Operator 127: 1.449301621664662\n",
      "Operator 128: -0.888799151690526\n",
      "Operator 129: 0.7720942166300143\n",
      "Operator 130: -0.9477456976568792\n",
      "Operator 131: 0.6794247307306568\n",
      "Operator 132: -1.1194606533826756\n",
      "Operator 133: -0.004204279932320969\n",
      "Operator 134: -0.7968527429368943\n",
      "Operator 135: -0.1453706243134238\n",
      "Operator 136: -0.5875616595636723\n",
      "Operator 137: -0.06898366107144938\n",
      "Operator 139: 1.505092833579126\n",
      "Operator 140: -0.7073486172530208\n",
      "Operator 141: -0.09340856600314648\n",
      "Operator 142: 0.20957546159681525\n",
      "Operator 143: 0.6013068516105824\n",
      "Operator 144: 0.4149301263011085\n",
      "Operator 145: -0.1969231464927305\n",
      "Operator 146: -1.2595528286764988\n",
      "Operator 147: -0.9174305446800785\n",
      "Operator 148: -1.262985027350937\n",
      "Operator 149: -0.8218232202963575\n",
      "Operator 150: -1.4205040277329093\n",
      "Operator 151: -0.18435070645135862\n",
      "Operator 152: 0.38970960024799944\n",
      "Operator 153: 0.740216196043283\n",
      "Operator 154: 0.6241150109752531\n",
      "Operator 155: -0.4751953146518424\n",
      "Operator 156: 0.04541896527411057\n",
      "Operator 157: 0.6503051078387024\n",
      "Operator 158: 0.26492777226128905\n",
      "Operator 159: 0.5856544395719059\n",
      "Operator 160: 0.3434743980482314\n",
      "Operator 161: 0.4176102468535278\n",
      "Operator 162: 0.1903549764719921\n",
      "Operator 163: -1.107655984972737\n",
      "Operator 164: -1.145151991212594\n",
      "Operator 165: -1.160838105814904\n",
      "Operator 166: -1.1511457753603098\n",
      "Operator 167: -1.1006921818394801\n",
      "Operator 168: 0.1659038680103084\n",
      "Operator 169: -0.5411657915047481\n",
      "Operator 170: 0.15725493189023854\n",
      "Operator 171: -0.4040267050402734\n",
      "Operator 172: 0.07044652674250679\n",
      "Operator 173: -0.25551028455334335\n",
      "Operator 174: 1.4190548733981156\n",
      "Operator 176: -0.1725710642475068\n",
      "Operator 177: -0.4673834851928311\n",
      "Operator 178: 0.28562362160615457\n",
      "Operator 179: -1.3318986596250577\n",
      "Operator 180: -1.657549067278538\n",
      "Operator 181: -1.4980944238256262\n",
      "Operator 182: -1.125569472769416\n",
      "Operator 183: 1.127077378779932\n",
      "Operator 184: 1.5020449209638522\n",
      "Operator 185: 1.6720801395848752\n",
      "Operator 186: 1.4685731259355301\n",
      "Operator 187: 1.7547494553772873\n",
      "Operator 188: 1.2503924450956414\n",
      "Operator 189: -0.8528440101219513\n",
      "Operator 191: -0.526628353777297\n",
      "Operator 192: -0.26786581735875026\n",
      "Operator 193: 0.1938402091978379\n",
      "Operator 194: -1.1968263571578992\n",
      "Operator 195: 1.4077550404041193\n",
      "Operator 196: -0.8707649233826882\n",
      "Operator 197: -1.221856946772168\n",
      "Operator 198: -1.3758066661297021\n",
      "Operator 199: -1.33535028246901\n",
      "Operator 200: 0.7046824122161913\n",
      "Operator 201: 1.0700613250894886\n",
      "Operator 202: 0.7921175280891709\n",
      "Operator 203: 1.1565257270181195\n",
      "Operator 204: 0.6204539829775444\n",
      "Operator 205: 1.5903559560559994\n",
      "Operator 206: -0.7970061518726008\n",
      "Operator 207: -0.14547026489474685\n",
      "Operator 208: -0.7965231053700048\n",
      "Operator 209: -0.2382704005642169\n",
      "Operator 210: -0.13382077726016692\n",
      "Operator 211: -1.5106102263831929\n",
      "Operator 212: 0.9907861268117693\n",
      "Operator 213: -1.2230607290484692\n",
      "Operator 214: -1.4821523045987421\n",
      "Operator 215: -1.6517278468242484\n",
      "Operator 216: -1.3500705826909316\n",
      "Operator 217: 1.3495984103571133\n",
      "Operator 218: 1.6518464007643303\n",
      "Operator 219: 1.4822349521375666\n",
      "Operator 220: 1.7094935297954108\n",
      "Operator 221: 1.3756591829389762\n",
      "Operator 222: 1.5044866509323882\n",
      "Operator 223: -0.30078273099830444\n",
      "Operator 224: -0.31115227045690974\n",
      "Operator 225: -0.04273304586875187\n",
      "Operator 226: -0.06532992561723971\n",
      "Operator 227: 1.050326622001674\n",
      "Operator 228: -0.044901847238330655\n",
      "Operator 229: 0.3283444851428323\n",
      "Operator 230: -1.1620184678124168\n",
      "Operator 231: 0.5061663737841647\n",
      "Operator 232: -0.4024076036996874\n",
      "Operator 233: -0.1192815825216473\n",
      "Operator 234: -0.43949521565497246\n",
      "Operator 235: -0.7739888492347198\n",
      "Operator 236: -0.4322765593066298\n",
      "Operator 237: -0.2196609407872544\n",
      "Operator 238: -0.47062136346495836\n",
      "Operator 239: 0.008007425230575614\n",
      "Operator 240: -0.35077750825089615\n",
      "Operator 241: 0.9410846477373804\n",
      "Operator 242: -0.13859985906865294\n",
      "Operator 243: 1.5987593610888995\n",
      "Operator 244: 0.4612265497412597\n",
      "Operator 245: 0.33683096829365755\n",
      "Operator 246: -0.7904831825572618\n",
      "Operator 247: 0.02505874303707077\n",
      "Operator 248: 1.1091191360470476\n",
      "Operator 249: 1.1375094780189992\n",
      "Operator 250: 1.1059380514296548\n",
      "Operator 251: -0.18996160778061008\n",
      "Operator 252: -0.41685217719668577\n",
      "Operator 253: -0.34202782558753597\n",
      "Operator 254: -0.5291242511749665\n",
      "Operator 255: -0.2823316423147632\n",
      "Operator 256: -0.7051434953136138\n",
      "Operator 257: -0.28613547790630667\n",
      "Operator 258: 1.1314287447593776\n",
      "Operator 259: 0.13797734704985198\n",
      "Operator 260: 0.9863520650140492\n",
      "Total gradient norm: 13.504918191039962\n",
      "Operators under consideration (1):\n",
      "[122]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.808099151929444)]\n",
      "Operator(s) added to ansatz: [122]\n",
      "Gradients: [np.float64(-1.808099151929444)]\n",
      "Initial energy: -32.28029860333202\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122]...\n",
      "Starting point: [np.float64(0.30853319425927733), np.float64(0.523184401500302), np.float64(0.23626045514218585), np.float64(0.32525503331039957), np.float64(0.1457117319105309), np.float64(0.3076356999929739), np.float64(-0.6400197449317122), np.float64(0.37881764331223106), np.float64(-0.30335049129750224), np.float64(-0.31438155374979065), np.float64(-0.5430121048086137), np.float64(-0.3793393966036965), np.float64(0.26519240990558585), np.float64(0.2699419181033171), np.float64(-0.27017819892471057), np.float64(-0.2688716033621012), np.float64(-0.2484745579263215), np.float64(0.22422957360666956), np.float64(0.1858915150618539), np.float64(0.1446835448672151), np.float64(-0.14178691322642875), np.float64(0.13501051823474425), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -32.431281\n",
      "         Iterations: 31\n",
      "         Function evaluations: 136\n",
      "         Gradient evaluations: 123\n",
      "\n",
      "Current energy: -32.43128124249228\n",
      "(change of -0.15098263916026156)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122]\n",
      "On iteration 23.\n",
      "\n",
      "*** ADAPT-VQE Iteration 24 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -1.354449622169385\n",
      "Operator 1: -0.005380613329815008\n",
      "Operator 2: 0.12789882443392053\n",
      "Operator 3: 1.1635432583900402\n",
      "Operator 4: 0.92239841348187\n",
      "Operator 5: 1.230747246665353\n",
      "Operator 6: 0.3875738831643738\n",
      "Operator 7: -0.27756694290323863\n",
      "Operator 8: -0.5635339052466427\n",
      "Operator 9: -0.4306565223131741\n",
      "Operator 10: -0.6108227782051538\n",
      "Operator 11: -0.40266063582621836\n",
      "Operator 12: -0.26430478125685747\n",
      "Operator 13: 0.04288124377940111\n",
      "Operator 14: -0.5517780938063466\n",
      "Operator 15: -0.3971108630397555\n",
      "Operator 16: -1.3480668712434902\n",
      "Operator 17: 0.1630639163178627\n",
      "Operator 18: -0.02319250496140992\n",
      "Operator 19: 0.21992323607052283\n",
      "Operator 20: -0.27245248831205554\n",
      "Operator 21: 0.15364427467866243\n",
      "Operator 22: -2.4715563360836536e-07\n",
      "Operator 23: 9.361972093260903e-08\n",
      "Operator 24: -1.7963887771602553e-07\n",
      "Operator 25: 0.7277840011262239\n",
      "Operator 26: -1.3346337495642582\n",
      "Operator 27: 1.28091645532404\n",
      "Operator 28: -1.2179634108170003\n",
      "Operator 29: 1.2023510539721727\n",
      "Operator 30: -1.0558572472392374\n",
      "Operator 31: 0.6866007217448452\n",
      "Operator 32: -0.10649318833374391\n",
      "Operator 33: 0.07001868411367967\n",
      "Operator 34: 0.31435867951948826\n",
      "Operator 35: 0.3481482357807305\n",
      "Operator 36: 0.04879190112340626\n",
      "Operator 37: 0.39860204234121177\n",
      "Operator 38: 0.44105770621056595\n",
      "Operator 39: 0.5575999348121212\n",
      "Operator 40: 0.27610350810827605\n",
      "Operator 41: -0.36778574201318975\n",
      "Operator 42: -1.256844132012842\n",
      "Operator 43: -0.8491226013597253\n",
      "Operator 44: -1.3215194557516672\n",
      "Operator 45: -0.5750344695170133\n",
      "Operator 46: -1.446326432393457\n",
      "Operator 47: 0.5405425020724623\n",
      "Operator 48: 0.4234530433339721\n",
      "Operator 49: 1.463259417211858\n",
      "Operator 50: 0.40489837033582116\n",
      "Operator 51: -0.3180395283330416\n",
      "Operator 52: -0.36134709031042295\n",
      "Operator 53: -0.015320651884838707\n",
      "Operator 54: 0.5014355622307768\n",
      "Operator 55: 1.2559330455902258\n",
      "Operator 56: 0.9494191346506052\n",
      "Operator 57: 1.241343962461949\n",
      "Operator 58: 0.20842808959283232\n",
      "Operator 59: -0.4280476601866032\n",
      "Operator 60: -0.6399736254312958\n",
      "Operator 61: -0.3745434107082197\n",
      "Operator 62: -0.8437029946552318\n",
      "Operator 63: -0.27653290298315447\n",
      "Operator 64: -0.6029726728059517\n",
      "Operator 65: 0.003629227144014434\n",
      "Operator 66: -1.3242638592772815\n",
      "Operator 67: -0.09347919180019139\n",
      "Operator 68: -0.19079687110653296\n",
      "Operator 69: 1.922707448182199e-08\n",
      "Operator 70: -0.9130910250268032\n",
      "Operator 71: 0.8701453865218381\n",
      "Operator 72: -0.7935492058123564\n",
      "Operator 73: 0.9365492104009192\n",
      "Operator 74: -1.268010724470579e-07\n",
      "Operator 75: 0.9321193486103837\n",
      "Operator 76: -0.7935236515057195\n",
      "Operator 77: 0.8702652805110725\n",
      "Operator 78: -0.8029478976621192\n",
      "Operator 79: 0.862340847253154\n",
      "Operator 80: -1.1478895817242174\n",
      "Operator 81: 0.17991981525939416\n",
      "Operator 82: -0.21820894480787428\n",
      "Operator 83: 0.21839642517342214\n",
      "Operator 84: 4.8198145696787265e-08\n",
      "Operator 85: -0.08310160902933005\n",
      "Operator 86: 0.25506514297156124\n",
      "Operator 87: -0.48030316161727776\n",
      "Operator 88: 0.0016861755985157695\n",
      "Operator 89: 0.40736587498116955\n",
      "Operator 90: 0.2915666390163496\n",
      "Operator 91: 0.45874162250208433\n",
      "Operator 92: 0.36624432122233397\n",
      "Operator 93: 0.5533814866375312\n",
      "Operator 94: 0.44137645874822007\n",
      "Operator 95: -1.1164507586515102\n",
      "Operator 96: -1.133373309755357\n",
      "Operator 97: -1.1808990591235442\n",
      "Operator 98: -1.0991817651425009\n",
      "Operator 99: -1.1411549811229438\n",
      "Operator 100: -0.24930377705436008\n",
      "Operator 101: -0.5058569226022209\n",
      "Operator 102: 0.25288987989152395\n",
      "Operator 103: -0.7275102142052912\n",
      "Operator 104: -0.1626237103341475\n",
      "Operator 105: 0.023198928263160536\n",
      "Operator 106: -0.19623269675842786\n",
      "Operator 107: 0.2322681830823624\n",
      "Operator 108: -0.8390286743978408\n",
      "Operator 109: 1.3905729325747922\n",
      "Operator 110: -1.266115290486207\n",
      "Operator 111: 1.3608924829275144\n",
      "Operator 112: -0.7351187823062627\n",
      "Operator 113: 2.3104925548297288e-07\n",
      "Operator 114: -1.3912895862568276e-07\n",
      "Operator 115: 3.046104134850254e-07\n",
      "Operator 116: -7.86639651516964e-08\n",
      "Operator 117: 0.11120442500060594\n",
      "Operator 118: -0.4546703958713529\n",
      "Operator 119: 0.2035817597125783\n",
      "Operator 120: -0.14342328349027\n",
      "Operator 121: 0.21773241511855684\n",
      "Operator 122: 4.609779102326347e-08\n",
      "Operator 123: 0.16004497426087433\n",
      "Operator 124: -0.9654627429239235\n",
      "Operator 125: 0.7962142413110572\n",
      "Operator 126: -0.8728413144451157\n",
      "Operator 127: 1.4583071058952872\n",
      "Operator 128: -0.8883770445225859\n",
      "Operator 129: 0.7726363593101917\n",
      "Operator 130: -0.9475688663610682\n",
      "Operator 131: 0.6797024301219777\n",
      "Operator 132: -1.1194665984058778\n",
      "Operator 133: -0.004197340949782341\n",
      "Operator 134: -0.7967747229276219\n",
      "Operator 135: -0.14529907414651874\n",
      "Operator 136: -0.5876420833310368\n",
      "Operator 137: -0.06896381718055822\n",
      "Operator 138: 5.225093001262501e-08\n",
      "Operator 139: 1.334089600523975\n",
      "Operator 140: -0.03958378053819989\n",
      "Operator 141: 0.546426304035644\n",
      "Operator 142: 0.44903261649944215\n",
      "Operator 143: 0.5858821858348824\n",
      "Operator 144: 0.443910144170251\n",
      "Operator 145: -0.21589484637660655\n",
      "Operator 146: -1.2467375238303253\n",
      "Operator 147: -0.9268057304251632\n",
      "Operator 148: -1.2584209749184316\n",
      "Operator 149: -0.8255451317101351\n",
      "Operator 150: -1.418802708313966\n",
      "Operator 151: -0.1859218156086613\n",
      "Operator 152: 0.389764645187523\n",
      "Operator 153: 0.7396249256858948\n",
      "Operator 154: 0.6240991696278945\n",
      "Operator 155: -0.5673410362997956\n",
      "Operator 156: -0.21090752658989775\n",
      "Operator 157: 0.6161889606625632\n",
      "Operator 158: 0.450908207208474\n",
      "Operator 159: 0.5338497155407255\n",
      "Operator 160: 0.36201379206857476\n",
      "Operator 161: 0.4043337995834259\n",
      "Operator 162: 0.19688341746990395\n",
      "Operator 163: -1.1051782289433028\n",
      "Operator 164: -1.146459238574733\n",
      "Operator 165: -1.1605461565244823\n",
      "Operator 166: -1.1517349796815801\n",
      "Operator 167: -1.1007761761309272\n",
      "Operator 168: 0.1662331145900997\n",
      "Operator 169: -0.5410743623155602\n",
      "Operator 170: 0.15735000276238595\n",
      "Operator 171: -0.40401491875900275\n",
      "Operator 172: 0.08366524645388076\n",
      "Operator 173: -0.25364196389459104\n",
      "Operator 174: 1.4187088335206899\n",
      "Operator 175: 7.407543478841054e-08\n",
      "Operator 176: -0.003480689919629998\n",
      "Operator 177: 0.2979391528974552\n",
      "Operator 178: -0.45982065536392175\n",
      "Operator 179: -1.4528403658184952\n",
      "Operator 180: -1.6448970093315012\n",
      "Operator 181: -1.5157325567112667\n",
      "Operator 182: -1.112349730220088\n",
      "Operator 183: 1.1123538669261483\n",
      "Operator 184: 1.5059716435519448\n",
      "Operator 185: 1.669766991011394\n",
      "Operator 186: 1.4701657389547296\n",
      "Operator 187: 1.7537952787778943\n",
      "Operator 188: 1.2510758495646108\n",
      "Operator 189: -0.853221971028507\n",
      "Operator 190: -4.7687150003111745e-08\n",
      "Operator 191: -0.5268219292271279\n",
      "Operator 192: -0.2678445441837882\n",
      "Operator 193: 0.13896920041482483\n",
      "Operator 194: -0.19931070291963404\n",
      "Operator 195: 0.4250197041457543\n",
      "Operator 196: -1.1475531077040193\n",
      "Operator 197: -1.281924766853638\n",
      "Operator 198: -1.3687116939022193\n",
      "Operator 199: -1.342717026764389\n",
      "Operator 200: 0.7126409408927552\n",
      "Operator 201: 1.0630149816811059\n",
      "Operator 202: 0.7961788058291731\n",
      "Operator 203: 1.153898898915511\n",
      "Operator 204: 0.621923502504448\n",
      "Operator 205: 1.5892953906457945\n",
      "Operator 206: -0.7966253242173162\n",
      "Operator 207: -0.14560599711658342\n",
      "Operator 208: -0.7965721954490412\n",
      "Operator 209: -0.2383534613892199\n",
      "Operator 210: 0.01592245634935017\n",
      "Operator 211: -0.23481607713772432\n",
      "Operator 212: -0.003026127835088493\n",
      "Operator 213: -1.4888135166529055\n",
      "Operator 214: -1.512129846274755\n",
      "Operator 215: -1.6348851767448416\n",
      "Operator 216: -1.3595968651013384\n",
      "Operator 217: 1.3531658695964324\n",
      "Operator 218: 1.648588087081218\n",
      "Operator 219: 1.4842985392333314\n",
      "Operator 220: 1.7081967104054732\n",
      "Operator 221: 1.3765970296261083\n",
      "Operator 222: 1.5037006085497213\n",
      "Operator 223: -0.3004486894845337\n",
      "Operator 224: -0.311265480138639\n",
      "Operator 225: -0.04272470289025646\n",
      "Operator 226: -0.06536901655283693\n",
      "Operator 227: 1.039866693482526\n",
      "Operator 228: 0.0829463302562602\n",
      "Operator 229: 0.3315273385661476\n",
      "Operator 230: 0.3040898808830625\n",
      "Operator 231: 0.3522531599626776\n",
      "Operator 232: -0.3841156198482283\n",
      "Operator 233: -0.15428287533781349\n",
      "Operator 234: -0.4252580629852144\n",
      "Operator 235: -0.7840253282294942\n",
      "Operator 236: -0.430843796649464\n",
      "Operator 237: -0.22141200667116848\n",
      "Operator 238: -0.47019370255673093\n",
      "Operator 239: 0.007080466506527501\n",
      "Operator 240: -0.3507341214665055\n",
      "Operator 241: 0.9406251715355013\n",
      "Operator 242: -0.13859430941717804\n",
      "Operator 243: 1.5985100079855883\n",
      "Operator 244: 0.4814789954598613\n",
      "Operator 245: -0.01666020141799116\n",
      "Operator 246: -0.6247510787380383\n",
      "Operator 247: 0.5868959950009185\n",
      "Operator 248: 1.1591180835617874\n",
      "Operator 249: 1.14499057640097\n",
      "Operator 250: 1.106022659050733\n",
      "Operator 251: -0.195586780195395\n",
      "Operator 252: -0.4120478871444501\n",
      "Operator 253: -0.3438676950353766\n",
      "Operator 254: -0.5274808722010031\n",
      "Operator 255: -0.28299556632413486\n",
      "Operator 256: -0.7043219136029122\n",
      "Operator 257: -0.2864376453717455\n",
      "Operator 258: 1.131581646040504\n",
      "Operator 259: 0.13805897139389472\n",
      "Operator 260: 0.9864733332626981\n",
      "Total gradient norm: 12.909112996155775\n",
      "Operators under consideration (1):\n",
      "[187]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(1.7537952787778943)]\n",
      "Operator(s) added to ansatz: [187]\n",
      "Gradients: [np.float64(1.7537952787778943)]\n",
      "Initial energy: -32.43128124249228\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187]...\n",
      "Starting point: [np.float64(0.30788655236837864), np.float64(0.5231203552161262), np.float64(0.16004773188997645), np.float64(0.3249800785531316), np.float64(0.14653039411218563), np.float64(0.30354427279292184), np.float64(-0.6399842491587986), np.float64(0.37867794827763746), np.float64(-0.30159940588055245), np.float64(-0.3098845650222946), np.float64(-0.539757629946348), np.float64(-0.3767483505595357), np.float64(0.2746020452508302), np.float64(0.2726381474136036), np.float64(-0.27104045568731694), np.float64(-0.26921816385755665), np.float64(-0.2486115516078821), np.float64(0.22427099862358568), np.float64(0.18590392300425768), np.float64(0.14468178281760327), np.float64(-0.1467062076892384), np.float64(0.13500818829092512), np.float64(0.16747241075072558), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -32.543296\n",
      "         Iterations: 31\n",
      "         Function evaluations: 146\n",
      "         Gradient evaluations: 134\n",
      "\n",
      "Current energy: -32.543296119256595\n",
      "(change of -0.11201487676431299)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187]\n",
      "On iteration 24.\n",
      "\n",
      "*** ADAPT-VQE Iteration 25 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -1.355271958627534\n",
      "Operator 1: -0.0029325253141582377\n",
      "Operator 2: 0.12105784034373093\n",
      "Operator 3: 1.1729689033381128\n",
      "Operator 4: 0.9045788427372784\n",
      "Operator 5: 1.255683916122362\n",
      "Operator 6: 0.36326647242159266\n",
      "Operator 7: -0.2624408848383143\n",
      "Operator 8: -0.6159256395159871\n",
      "Operator 9: -0.3833024171880348\n",
      "Operator 10: -0.7223855598997382\n",
      "Operator 11: -0.5125907221347109\n",
      "Operator 12: -0.32983663235150246\n",
      "Operator 13: -0.054765435579500324\n",
      "Operator 14: -0.6770145254182807\n",
      "Operator 15: -0.41327068378187853\n",
      "Operator 16: -1.4062547463592843\n",
      "Operator 17: 0.1628658789514267\n",
      "Operator 18: -0.023241553574176434\n",
      "Operator 19: 0.2205661686423946\n",
      "Operator 20: -0.27262195927855637\n",
      "Operator 21: 0.15442726176566235\n",
      "Operator 22: 2.810693268071131e-08\n",
      "Operator 23: -2.4149203053451288e-08\n",
      "Operator 24: 1.5398695096473635e-08\n",
      "Operator 25: 0.7059902102945581\n",
      "Operator 26: -1.2419997707975243\n",
      "Operator 27: 1.1682312632479002\n",
      "Operator 28: -1.302165464411477\n",
      "Operator 29: 0.46206065197928037\n",
      "Operator 30: -0.30503919280994407\n",
      "Operator 31: 0.6494664282606675\n",
      "Operator 32: -0.09210044946057652\n",
      "Operator 33: 0.06709522556130088\n",
      "Operator 34: 0.31344137794673593\n",
      "Operator 35: 0.3508195441569757\n",
      "Operator 36: 0.04372541379465601\n",
      "Operator 37: 0.40792477342950934\n",
      "Operator 38: 0.4301423100690741\n",
      "Operator 39: 0.5844277500617326\n",
      "Operator 40: 0.2556209751529901\n",
      "Operator 41: -0.2606107752612304\n",
      "Operator 42: -1.3750152533516586\n",
      "Operator 43: -0.5255041870382358\n",
      "Operator 44: -1.3853505545565756\n",
      "Operator 45: 0.1878776655458805\n",
      "Operator 46: -0.14724732180060224\n",
      "Operator 47: 0.6546074459301167\n",
      "Operator 48: 0.45557932461647993\n",
      "Operator 49: 1.5029179601425149\n",
      "Operator 50: 0.4196040535782292\n",
      "Operator 51: -0.31707982539256313\n",
      "Operator 52: -0.3638341119835704\n",
      "Operator 53: -0.010480855946626557\n",
      "Operator 54: 0.4880783270006049\n",
      "Operator 55: 1.2742950020688824\n",
      "Operator 56: 0.9098230335319539\n",
      "Operator 57: 1.2901904747409725\n",
      "Operator 58: 0.11201274389600158\n",
      "Operator 59: -0.3662552647883899\n",
      "Operator 60: -0.8764257469321968\n",
      "Operator 61: -0.3924027257572653\n",
      "Operator 62: -0.7515410086233393\n",
      "Operator 63: -0.4711619366286741\n",
      "Operator 64: -0.6758594428756091\n",
      "Operator 65: -0.04557629679537625\n",
      "Operator 66: -1.3759419000325375\n",
      "Operator 67: -0.10771769742379278\n",
      "Operator 68: -0.19156506897961192\n",
      "Operator 69: -1.2574238505512774e-08\n",
      "Operator 70: -0.9084504181669373\n",
      "Operator 71: 0.878693842016979\n",
      "Operator 72: -0.7797490573225836\n",
      "Operator 73: 0.9565750335876058\n",
      "Operator 74: 1.2300426468499552e-08\n",
      "Operator 75: 0.9326874380167984\n",
      "Operator 76: -0.7777250925712413\n",
      "Operator 77: 0.8708794726696163\n",
      "Operator 78: -0.7047648506997741\n",
      "Operator 79: 0.0428328921140187\n",
      "Operator 80: -1.0882574005617207\n",
      "Operator 81: 0.164947278110261\n",
      "Operator 82: -0.207990277495671\n",
      "Operator 83: 0.2127785484583522\n",
      "Operator 85: -0.08309797496228279\n",
      "Operator 86: 0.2551418041333551\n",
      "Operator 87: -0.48008166596452234\n",
      "Operator 88: 0.0017335698956780325\n",
      "Operator 89: 0.41031469609508897\n",
      "Operator 90: 0.287341013515241\n",
      "Operator 91: 0.4661691023262063\n",
      "Operator 92: 0.35525666745644935\n",
      "Operator 93: 0.5722190010425326\n",
      "Operator 94: 0.414172157415159\n",
      "Operator 95: -1.1199133107148518\n",
      "Operator 96: -1.0940201023551388\n",
      "Operator 97: -1.151010677484776\n",
      "Operator 98: -0.5867712227154104\n",
      "Operator 99: -1.2146855935961651\n",
      "Operator 100: -0.06078212980092374\n",
      "Operator 101: -0.5267529730037439\n",
      "Operator 102: 0.2334679661721421\n",
      "Operator 103: -0.7235642295152471\n",
      "Operator 104: -0.16243083700334798\n",
      "Operator 105: 0.02324788608489328\n",
      "Operator 106: -0.1970922521209718\n",
      "Operator 107: 0.23301014797043268\n",
      "Operator 108: -0.8379422052723192\n",
      "Operator 109: 1.3817333280375987\n",
      "Operator 110: -1.2688235806706194\n",
      "Operator 111: 1.334343299711624\n",
      "Operator 112: -0.7433898139846509\n",
      "Operator 113: -1.1676719894425876e-08\n",
      "Operator 114: -0.026145776365582095\n",
      "Operator 115: 0.0654126290817699\n",
      "Operator 117: 0.008616465782371466\n",
      "Operator 118: -0.4457358715460714\n",
      "Operator 119: 0.18130282582304724\n",
      "Operator 120: -0.11531827857723398\n",
      "Operator 121: 0.2182111702335513\n",
      "Operator 123: 0.16052755291962767\n",
      "Operator 124: -0.9654178446522635\n",
      "Operator 125: 0.794433702786504\n",
      "Operator 126: -0.8742914209350406\n",
      "Operator 127: 1.42261226988364\n",
      "Operator 128: -0.9519226912507529\n",
      "Operator 129: 0.6798682528752193\n",
      "Operator 130: -1.1302017849725154\n",
      "Operator 131: -0.25288294712290665\n",
      "Operator 132: -1.0789941360788877\n",
      "Operator 133: 0.009034379945322302\n",
      "Operator 134: -0.7985695935417141\n",
      "Operator 135: -0.16120886230849196\n",
      "Operator 136: -0.5743865620618696\n",
      "Operator 137: -0.06843755225001757\n",
      "Operator 138: 5.4544651733148727e-08\n",
      "Operator 139: 1.3351401108315812\n",
      "Operator 140: -0.041550556547484074\n",
      "Operator 141: 0.5483747307387167\n",
      "Operator 142: 0.44632429273249785\n",
      "Operator 143: 0.5924031545848844\n",
      "Operator 144: 0.43604727754005373\n",
      "Operator 145: -0.15530323649168093\n",
      "Operator 146: -1.3173256798894224\n",
      "Operator 147: -0.7972826671286917\n",
      "Operator 148: -1.4573746433198749\n",
      "Operator 149: 0.0019124516741869054\n",
      "Operator 150: -0.2083551579162145\n",
      "Operator 151: 0.07273286401851635\n",
      "Operator 152: 0.49313924827330413\n",
      "Operator 153: 0.8466105927808851\n",
      "Operator 154: 0.6345321371557294\n",
      "Operator 155: -0.5668299439822431\n",
      "Operator 156: -0.21141159461746772\n",
      "Operator 157: 0.6182259184106725\n",
      "Operator 158: 0.44781808986689164\n",
      "Operator 159: 0.5402387285104417\n",
      "Operator 160: 0.35445075926847835\n",
      "Operator 161: 0.4235770943560019\n",
      "Operator 162: 0.17385592349899276\n",
      "Operator 163: -1.1090873891550757\n",
      "Operator 164: -1.1420556628946006\n",
      "Operator 165: -1.1310859961539506\n",
      "Operator 166: -0.2656644499892999\n",
      "Operator 167: -1.1997117777680166\n",
      "Operator 168: 0.1507344766863976\n",
      "Operator 169: -0.5670948076934167\n",
      "Operator 170: 0.14510827856325975\n",
      "Operator 171: -0.4000810093705305\n",
      "Operator 172: 0.08365458181946911\n",
      "Operator 173: -0.25373598257472596\n",
      "Operator 174: 1.4804752085537682\n",
      "Operator 175: 3.636944299789565e-08\n",
      "Operator 176: -0.0041890013084458335\n",
      "Operator 177: 0.29997776131877996\n",
      "Operator 178: -0.46189292580858066\n",
      "Operator 179: -1.44702734811428\n",
      "Operator 180: -1.6541857659017678\n",
      "Operator 181: -1.4994455246744112\n",
      "Operator 182: -1.1695061733291738\n",
      "Operator 183: 1.170501242168082\n",
      "Operator 184: 1.4497240113650918\n",
      "Operator 185: 1.7747690491431705\n",
      "Operator 186: 1.304654762650352\n",
      "Operator 188: 1.1329022713695083\n",
      "Operator 189: -0.8367180104284901\n",
      "Operator 191: -0.4998079385481582\n",
      "Operator 192: -0.28138892867082754\n",
      "Operator 193: 0.13919978462900387\n",
      "Operator 194: -0.1987080986828942\n",
      "Operator 195: 0.42597358326732515\n",
      "Operator 196: -1.1466017073176205\n",
      "Operator 197: -1.2812363830613274\n",
      "Operator 198: -1.3653965852051644\n",
      "Operator 199: -1.3408503598955233\n",
      "Operator 200: 0.6476469604900832\n",
      "Operator 201: 1.1660640637018669\n",
      "Operator 202: 0.5989588430455208\n",
      "Operator 203: 1.6515672521803832\n",
      "Operator 204: -0.6474303111617113\n",
      "Operator 205: 0.700018526597686\n",
      "Operator 206: -0.749488133276484\n",
      "Operator 207: -0.1974974463692558\n",
      "Operator 208: -0.7819565196160009\n",
      "Operator 209: -0.23408598381122347\n",
      "Operator 210: 0.01648886527028078\n",
      "Operator 211: -0.23756017342039737\n",
      "Operator 212: 0.0026335987886753347\n",
      "Operator 213: -1.4940323202019479\n",
      "Operator 214: -1.5042006123485783\n",
      "Operator 215: -1.6485489847316883\n",
      "Operator 216: -1.3444624989055531\n",
      "Operator 217: 1.3108885713547018\n",
      "Operator 218: 1.7155197568320906\n",
      "Operator 219: 1.3605156286336704\n",
      "Operator 220: 1.7499101616261958\n",
      "Operator 221: 0.4580512310808068\n",
      "Operator 222: 0.5198603865425946\n",
      "Operator 223: -0.2848470701835962\n",
      "Operator 224: -0.2932607882403656\n",
      "Operator 225: -0.04007875450926779\n",
      "Operator 226: -0.060876389749222604\n",
      "Operator 227: 1.041196917307344\n",
      "Operator 228: 0.08214896896512913\n",
      "Operator 229: 0.33423154533668453\n",
      "Operator 230: 0.3000115684226608\n",
      "Operator 231: 0.3614576608609754\n",
      "Operator 232: -0.3904749783007204\n",
      "Operator 233: -0.12822831333272416\n",
      "Operator 234: -0.43400736771691933\n",
      "Operator 235: -0.70645208948637\n",
      "Operator 236: -0.4710500653056239\n",
      "Operator 237: 0.04961344359314878\n",
      "Operator 238: -0.47051494328998544\n",
      "Operator 239: 0.7088848884398538\n",
      "Operator 240: -0.31449245978866025\n",
      "Operator 241: 0.9828796422974614\n",
      "Operator 242: -0.13537207936124337\n",
      "Operator 243: 1.639330231861714\n",
      "Operator 244: 0.48124598652374484\n",
      "Operator 245: -0.016541881677823944\n",
      "Operator 246: -0.6262645613602359\n",
      "Operator 247: 0.5869024005675872\n",
      "Operator 248: 1.1604288319069482\n",
      "Operator 249: 1.1397355120038215\n",
      "Operator 250: 1.115555181241605\n",
      "Operator 251: -0.1669634437862008\n",
      "Operator 252: -0.46327694840285616\n",
      "Operator 253: -0.2705256135806585\n",
      "Operator 254: -0.6921642091604135\n",
      "Operator 255: -0.2911703385058323\n",
      "Operator 256: 0.6275695245252066\n",
      "Operator 257: -0.22451073602217195\n",
      "Operator 258: 1.1318203515702738\n",
      "Operator 259: 0.12604157225684526\n",
      "Operator 260: 0.9682837440344874\n",
      "Total gradient norm: 12.273943318426378\n",
      "Operators under consideration (1):\n",
      "[185]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(1.7747690491431705)]\n",
      "Operator(s) added to ansatz: [185]\n",
      "Gradients: [np.float64(1.7747690491431705)]\n",
      "Initial energy: -32.543296119256595\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185]...\n",
      "Starting point: [np.float64(0.3287607071033684), np.float64(0.5357627502813742), np.float64(0.15989701026611597), np.float64(0.41320983726402116), np.float64(0.14648682682796693), np.float64(0.30617723430802), np.float64(-0.6460690734452872), np.float64(0.4049089373965464), np.float64(-0.3091987583020766), np.float64(-0.3107894054867478), np.float64(-0.539874348657789), np.float64(-0.3769913454271981), np.float64(0.27323649067282946), np.float64(0.2691281433776216), np.float64(-0.2614056766911288), np.float64(-0.24868225096161206), np.float64(-0.2515991086029626), np.float64(0.22199232148028794), np.float64(0.18404106629539152), np.float64(0.1446418742451886), np.float64(-0.14666051322476367), np.float64(0.13878457864124308), np.float64(0.1672420688390862), np.float64(-0.12777853613008616), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -32.657499\n",
      "         Iterations: 33\n",
      "         Function evaluations: 53\n",
      "         Gradient evaluations: 53\n",
      "\n",
      "Current energy: -32.657499103679896\n",
      "(change of -0.11420298442330079)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185]\n",
      "On iteration 25.\n",
      "\n",
      "*** ADAPT-VQE Iteration 26 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -1.3574949922362411\n",
      "Operator 1: 0.003687165663301698\n",
      "Operator 2: 0.10278902579686572\n",
      "Operator 3: 1.198110279672893\n",
      "Operator 4: 0.8570030794868742\n",
      "Operator 5: 1.3215926685098616\n",
      "Operator 6: 0.29749498345059355\n",
      "Operator 7: -0.2301143476765675\n",
      "Operator 8: -0.7266198603287836\n",
      "Operator 9: -0.5066540805450896\n",
      "Operator 10: -0.7034241718577632\n",
      "Operator 11: -0.5959391789536177\n",
      "Operator 12: -0.4471647976747748\n",
      "Operator 13: -0.0769042448267519\n",
      "Operator 14: -0.7418923402768285\n",
      "Operator 15: -0.4218264510685428\n",
      "Operator 16: -1.4383482756575017\n",
      "Operator 17: 0.1623338988535818\n",
      "Operator 18: -0.02337543376331496\n",
      "Operator 19: 0.22229836293823424\n",
      "Operator 20: -0.2730069202911864\n",
      "Operator 21: 0.15641654777492184\n",
      "Operator 25: 0.6093320527377415\n",
      "Operator 26: -1.3206705531556135\n",
      "Operator 27: 0.4512713371927642\n",
      "Operator 28: -0.339770907657883\n",
      "Operator 29: 0.41463254510378494\n",
      "Operator 30: -0.251868902930113\n",
      "Operator 31: 0.6148014898692093\n",
      "Operator 32: -0.08512315773337972\n",
      "Operator 33: 0.06490394866274762\n",
      "Operator 34: 0.3109858524557904\n",
      "Operator 35: 0.3580892210901483\n",
      "Operator 36: 0.03029514863208254\n",
      "Operator 37: 0.43378901901424305\n",
      "Operator 38: 0.40307416987709016\n",
      "Operator 39: 0.6609360868313876\n",
      "Operator 40: 0.21520329646904807\n",
      "Operator 41: 0.03455439037662341\n",
      "Operator 42: -1.421596113689132\n",
      "Operator 43: 0.230277486957536\n",
      "Operator 44: -0.08880121945537951\n",
      "Operator 45: 0.2903291283498577\n",
      "Operator 46: -0.06004081734235185\n",
      "Operator 47: 0.7284798592010999\n",
      "Operator 48: 0.4697669302538329\n",
      "Operator 49: 1.5257407943943608\n",
      "Operator 50: 0.4280245086824988\n",
      "Operator 51: -0.3145140284337964\n",
      "Operator 52: -0.3706237780353255\n",
      "Operator 53: 0.0023612160628604033\n",
      "Operator 54: 0.4516393710524139\n",
      "Operator 55: 1.3211622912709176\n",
      "Operator 56: 0.7995925276513058\n",
      "Operator 57: 1.398878771852118\n",
      "Operator 58: -0.18362596256679709\n",
      "Operator 59: -0.3886198627374694\n",
      "Operator 60: -0.7657102548219817\n",
      "Operator 61: -0.5917582850277856\n",
      "Operator 62: -0.7749129418934587\n",
      "Operator 63: -0.5023095659827188\n",
      "Operator 64: -0.7352609866571254\n",
      "Operator 65: -0.0689301936561707\n",
      "Operator 66: -1.4050949258086298\n",
      "Operator 67: -0.11800627821594278\n",
      "Operator 68: -0.19363533872556032\n",
      "Operator 70: -0.8960643817274281\n",
      "Operator 71: 0.9015918028058278\n",
      "Operator 72: -0.7435827255835358\n",
      "Operator 73: 1.0106367969771675\n",
      "Operator 75: 0.9253645211934898\n",
      "Operator 76: -0.6831284759847995\n",
      "Operator 77: 0.055064419511395\n",
      "Operator 78: -0.6685210557301746\n",
      "Operator 79: 0.028838402747628528\n",
      "Operator 80: -1.0431959033157734\n",
      "Operator 81: 0.1580609518358465\n",
      "Operator 82: -0.20251293990848662\n",
      "Operator 83: 0.20743006700784228\n",
      "Operator 85: -0.08308822580663673\n",
      "Operator 86: 0.2553496708312982\n",
      "Operator 87: -0.4794796130583766\n",
      "Operator 88: 0.001861243432133872\n",
      "Operator 89: 0.41821875383774065\n",
      "Operator 90: 0.2760208407449276\n",
      "Operator 91: 0.48618956627379195\n",
      "Operator 92: 0.32673442865314434\n",
      "Operator 93: 0.6242803218641593\n",
      "Operator 94: 0.3539989376164255\n",
      "Operator 95: -1.0757430537189303\n",
      "Operator 96: -0.6009183592693133\n",
      "Operator 97: -1.2776998594986086\n",
      "Operator 98: -0.2555997853556353\n",
      "Operator 99: -1.2251916472325173\n",
      "Operator 100: -0.06447344599333134\n",
      "Operator 101: -0.5311239606655591\n",
      "Operator 102: 0.2233550529091182\n",
      "Operator 103: -0.7206786338105018\n",
      "Operator 104: -0.1619122929268163\n",
      "Operator 105: 0.023381529376155022\n",
      "Operator 106: -0.19939218016182195\n",
      "Operator 107: 0.2348991370719191\n",
      "Operator 108: -0.8341981309228004\n",
      "Operator 109: 1.3544616933586058\n",
      "Operator 110: -1.2645619199925504\n",
      "Operator 111: 1.2368473870973213\n",
      "Operator 112: -0.715828901246192\n",
      "Operator 113: 0.0683006423357007\n",
      "Operator 114: -0.026222289564998683\n",
      "Operator 115: -0.06869889188625616\n",
      "Operator 116: -0.026126513659703494\n",
      "Operator 117: -0.010416578230055762\n",
      "Operator 118: -0.4274501048764805\n",
      "Operator 119: 0.17025449239475327\n",
      "Operator 120: -0.10160048301309565\n",
      "Operator 121: 0.21952782236734852\n",
      "Operator 123: 0.16182038534922433\n",
      "Operator 124: -0.9651358171205613\n",
      "Operator 125: 0.7893295715494513\n",
      "Operator 126: -0.876942737999174\n",
      "Operator 127: 1.3341473948049418\n",
      "Operator 128: -1.1310211278610218\n",
      "Operator 129: -0.2487459851973167\n",
      "Operator 130: -1.0847688934481243\n",
      "Operator 131: -0.2535801747289621\n",
      "Operator 132: -1.0530159496096123\n",
      "Operator 133: 0.0022429582033651474\n",
      "Operator 134: -0.799304854704342\n",
      "Operator 135: -0.16780500247292363\n",
      "Operator 136: -0.5657990301753582\n",
      "Operator 137: -0.06897684161102191\n",
      "Operator 139: 1.3379569679984498\n",
      "Operator 140: -0.046913755842002226\n",
      "Operator 141: 0.5536440746805265\n",
      "Operator 142: 0.43916777224229986\n",
      "Operator 143: 0.6103562861718101\n",
      "Operator 144: 0.4161743706398906\n",
      "Operator 145: -0.008815455693186557\n",
      "Operator 146: -1.5019592077295278\n",
      "Operator 147: 0.029152446769727218\n",
      "Operator 148: -0.20949054351987223\n",
      "Operator 149: 0.22179331461933163\n",
      "Operator 150: -0.03800455438676628\n",
      "Operator 151: 0.2082294072513145\n",
      "Operator 152: 0.5134559146047715\n",
      "Operator 153: 0.9026158519860088\n",
      "Operator 154: 0.638138085132224\n",
      "Operator 155: -0.5654564893916345\n",
      "Operator 156: -0.21279334038870784\n",
      "Operator 157: 0.6236906144186217\n",
      "Operator 158: 0.4395370853391476\n",
      "Operator 159: 0.5577207046665671\n",
      "Operator 160: 0.33514005589999785\n",
      "Operator 161: 0.4742064203966839\n",
      "Operator 162: 0.12186419439486815\n",
      "Operator 163: -1.1032752718358014\n",
      "Operator 164: -0.2644525072765715\n",
      "Operator 165: -1.2775861755363473\n",
      "Operator 166: -0.24737391167340608\n",
      "Operator 167: -1.1921739548871462\n",
      "Operator 168: 0.1320867384626617\n",
      "Operator 169: -0.57744643378923\n",
      "Operator 170: 0.1377034968396704\n",
      "Operator 171: -0.39949620805581043\n",
      "Operator 172: 0.08362656003192151\n",
      "Operator 173: -0.25398897679825455\n",
      "Operator 174: 1.513550536649575\n",
      "Operator 176: -0.006084510474425896\n",
      "Operator 177: 0.30555745097509324\n",
      "Operator 178: -0.4674585085977821\n",
      "Operator 179: -1.4312272868594937\n",
      "Operator 180: -1.6788111221058386\n",
      "Operator 181: -1.4551862343831603\n",
      "Operator 182: -1.3016327579519191\n",
      "Operator 183: 1.3215255724181563\n",
      "Operator 184: 1.2889891805823468\n",
      "Operator 186: 1.1947087364674966\n",
      "Operator 187: -0.0743712434888855\n",
      "Operator 188: 1.065166593662091\n",
      "Operator 189: -0.809876715013456\n",
      "Operator 191: -0.48313044553820617\n",
      "Operator 192: -0.28603077635190033\n",
      "Operator 193: 0.1398207936113495\n",
      "Operator 194: -0.1970507595434257\n",
      "Operator 195: 0.42860746979089714\n",
      "Operator 196: -1.1437367681645043\n",
      "Operator 197: -1.2784023170239782\n",
      "Operator 198: -1.3542782349016331\n",
      "Operator 199: -1.3276689423191472\n",
      "Operator 200: 0.4676426688633317\n",
      "Operator 201: 1.649815104762322\n",
      "Operator 202: -0.6737177853620531\n",
      "Operator 203: 0.7457501897468959\n",
      "Operator 204: -0.6203817392480693\n",
      "Operator 205: 0.5660224507200108\n",
      "Operator 206: -0.7588930990435889\n",
      "Operator 207: -0.2021233131370328\n",
      "Operator 208: -0.7751118751648087\n",
      "Operator 209: -0.22898549522404865\n",
      "Operator 210: 0.018015219157672763\n",
      "Operator 211: -0.24498128872264768\n",
      "Operator 212: 0.01766821179148231\n",
      "Operator 213: -1.5081181029621535\n",
      "Operator 214: -1.483078819341145\n",
      "Operator 215: -1.6852956173935294\n",
      "Operator 216: -1.3012163398833856\n",
      "Operator 217: 1.1914264737944187\n",
      "Operator 218: 1.753430366468895\n",
      "Operator 219: 0.45237335609608154\n",
      "Operator 220: 0.6952434259225062\n",
      "Operator 221: 0.4465112033400922\n",
      "Operator 222: 0.4619640878272674\n",
      "Operator 223: -0.2901533264856644\n",
      "Operator 224: -0.28329801180962966\n",
      "Operator 225: -0.039514369234243674\n",
      "Operator 226: -0.05779484978475269\n",
      "Operator 227: 1.0447880695153016\n",
      "Operator 228: 0.0800260584930791\n",
      "Operator 229: 0.3415711134245033\n",
      "Operator 230: 0.2892707757694226\n",
      "Operator 231: 0.38689169938885043\n",
      "Operator 232: -0.4033935063482741\n",
      "Operator 233: -0.04979962378421067\n",
      "Operator 234: -0.4289848929621055\n",
      "Operator 235: -0.38268482561891287\n",
      "Operator 236: -0.4670605393063158\n",
      "Operator 237: 0.7008072451324405\n",
      "Operator 238: -0.4259850836485117\n",
      "Operator 239: 0.7462407103831128\n",
      "Operator 240: -0.2987125194441306\n",
      "Operator 241: 1.0218754226822144\n",
      "Operator 242: -0.1332408052789798\n",
      "Operator 243: 1.661615757132557\n",
      "Operator 244: 0.48061395283233876\n",
      "Operator 245: -0.01623758677097977\n",
      "Operator 246: -0.6303624234181373\n",
      "Operator 247: 0.5867737953705864\n",
      "Operator 248: 1.163317216721738\n",
      "Operator 249: 1.1250509964381616\n",
      "Operator 250: 1.1330610861005606\n",
      "Operator 251: -0.09048925445991948\n",
      "Operator 252: -0.6100516334601026\n",
      "Operator 253: -0.28797157309433286\n",
      "Operator 254: 0.6428848666592789\n",
      "Operator 255: -0.24599532188046774\n",
      "Operator 256: 0.6727233147796607\n",
      "Operator 257: -0.1906705620627683\n",
      "Operator 258: 1.1225854430844417\n",
      "Operator 259: 0.11914727175294278\n",
      "Operator 260: 0.9571907740476915\n",
      "Total gradient norm: 11.533864708854578\n",
      "Operators under consideration (1):\n",
      "[218]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(1.753430366468895)]\n",
      "Operator(s) added to ansatz: [218]\n",
      "Gradients: [np.float64(1.753430366468895)]\n",
      "Initial energy: -32.657499103679896\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185, 218]...\n",
      "Starting point: [np.float64(0.41667796177246735), np.float64(0.5423753288942645), np.float64(0.15949187816398347), np.float64(0.4382024499687154), np.float64(0.14636969603562913), np.float64(0.31340159506817733), np.float64(-0.6495323458835562), np.float64(0.41806211803944926), np.float64(-0.33018134144991423), np.float64(-0.31324743502859065), np.float64(-0.5401896980746977), np.float64(-0.3776483059245883), np.float64(0.26964270416377434), np.float64(0.2602756214734356), np.float64(-0.24189094892272084), np.float64(-0.25292186672625006), np.float64(-0.24841950851093622), np.float64(0.21941177815220883), np.float64(0.18296497781166743), np.float64(0.14471347458745434), np.float64(-0.14653785317629478), np.float64(0.13990082276611857), np.float64(0.16662962436952775), np.float64(-0.13724599530671416), np.float64(-0.1289027222624634), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -32.767802\n",
      "         Iterations: 36\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 51\n",
      "\n",
      "Current energy: -32.767802085251404\n",
      "(change of -0.11030298157150753)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185, 218]\n",
      "On iteration 26.\n",
      "\n",
      "*** ADAPT-VQE Iteration 27 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -1.3589558508864101\n",
      "Operator 1: 0.00807256603087126\n",
      "Operator 2: 0.0912450283725022\n",
      "Operator 3: 1.2146894040208276\n",
      "Operator 4: 0.8294844078540702\n",
      "Operator 5: 1.366733248476284\n",
      "Operator 6: 0.26307644363419025\n",
      "Operator 7: -0.38020064142609733\n",
      "Operator 8: -0.6241610468270339\n",
      "Operator 9: -0.5843978973268841\n",
      "Operator 10: -0.9268021062813543\n",
      "Operator 11: -0.585991507482962\n",
      "Operator 12: -0.5763344859602934\n",
      "Operator 13: -0.09110077614545273\n",
      "Operator 14: -0.8212210051363864\n",
      "Operator 15: -0.4327257047778804\n",
      "Operator 16: -1.478371381900244\n",
      "Operator 17: 0.16198743827707024\n",
      "Operator 18: -0.023471450656901153\n",
      "Operator 19: 0.2234317771130128\n",
      "Operator 20: -0.2730654564553562\n",
      "Operator 21: 0.15720709563534513\n",
      "Operator 24: -0.09576287187437592\n",
      "Operator 25: 0.5771175577715746\n",
      "Operator 26: -0.37871113321847316\n",
      "Operator 27: -0.15022255446108118\n",
      "Operator 28: -0.39178275776318294\n",
      "Operator 29: 0.3163205443558404\n",
      "Operator 30: -0.20071353397800837\n",
      "Operator 31: 0.5662114704235508\n",
      "Operator 32: -0.07698658564509667\n",
      "Operator 33: 0.06191582409530305\n",
      "Operator 34: 0.30939876878118916\n",
      "Operator 35: 0.3630140851257677\n",
      "Operator 36: 0.02202779097192874\n",
      "Operator 37: 0.4532695146386476\n",
      "Operator 38: 0.3945789302299516\n",
      "Operator 39: 0.7387570197551414\n",
      "Operator 40: 0.29850912706832644\n",
      "Operator 41: 0.2504561616359757\n",
      "Operator 42: -0.0739187334510511\n",
      "Operator 43: 0.87930501212047\n",
      "Operator 44: -0.19804897180936737\n",
      "Operator 45: 0.46874978809447376\n",
      "Operator 46: 0.015235060564965971\n",
      "Operator 47: 0.8283110148178681\n",
      "Operator 48: 0.4860155611813226\n",
      "Operator 49: 1.554644570800341\n",
      "Operator 50: 0.43876268406498337\n",
      "Operator 51: -0.31286273165616296\n",
      "Operator 52: -0.3752629783808674\n",
      "Operator 53: 0.010312934295309934\n",
      "Operator 54: 0.4261833875795179\n",
      "Operator 55: 1.3431038149980994\n",
      "Operator 56: 0.7063716274505569\n",
      "Operator 57: 1.3538320368826804\n",
      "Operator 58: -0.2376737156881024\n",
      "Operator 59: -0.5165999811876139\n",
      "Operator 60: -0.8707669314953719\n",
      "Operator 61: -0.5722534631319727\n",
      "Operator 62: -0.8793710693339005\n",
      "Operator 63: -0.5239333940833912\n",
      "Operator 64: -0.8116787844858817\n",
      "Operator 65: -0.0974700293928419\n",
      "Operator 66: -1.4413147443553371\n",
      "Operator 67: -0.13220096348040594\n",
      "Operator 68: -0.1950059827823249\n",
      "Operator 70: -0.8882994588175381\n",
      "Operator 71: 0.9170348550695178\n",
      "Operator 72: -0.7253264603085581\n",
      "Operator 73: 1.0518522202785054\n",
      "Operator 74: -0.006441720572651537\n",
      "Operator 75: 0.8553049165770119\n",
      "Operator 76: 0.21030565362094034\n",
      "Operator 77: 0.2098126911182865\n",
      "Operator 78: -0.5776901334060106\n",
      "Operator 79: 0.019794988799133578\n",
      "Operator 80: -0.9827919299591121\n",
      "Operator 81: 0.15056233144007264\n",
      "Operator 82: -0.1956457645056665\n",
      "Operator 83: 0.1996558929859058\n",
      "Operator 85: -0.08308170830995214\n",
      "Operator 86: 0.2554885992591184\n",
      "Operator 87: -0.47907915294763426\n",
      "Operator 88: 0.0019417330295275655\n",
      "Operator 89: 0.4232451215235854\n",
      "Operator 90: 0.26842965479989367\n",
      "Operator 91: 0.49853905970178347\n",
      "Operator 92: 0.30847566465270454\n",
      "Operator 93: 0.6470934441033885\n",
      "Operator 94: 0.34779008848361037\n",
      "Operator 95: -1.182431011428147\n",
      "Operator 96: 0.20896481447493448\n",
      "Operator 97: -1.2127774388586163\n",
      "Operator 98: -0.2866102030763299\n",
      "Operator 99: -1.2115511811691655\n",
      "Operator 100: -0.0732200881318852\n",
      "Operator 101: -0.530791467908243\n",
      "Operator 102: 0.21091279057712772\n",
      "Operator 103: -0.7168826367422991\n",
      "Operator 104: -0.16157368485942658\n",
      "Operator 105: 0.02347745815833473\n",
      "Operator 106: -0.20085773885228475\n",
      "Operator 107: 0.23589208983327853\n",
      "Operator 108: -0.8290826149313613\n",
      "Operator 109: 1.3206003605808467\n",
      "Operator 110: -1.2056330384808223\n",
      "Operator 111: 1.1902012566741185\n",
      "Operator 112: -0.7512153326749935\n",
      "Operator 113: -0.013973770728137392\n",
      "Operator 114: -0.026072319481539326\n",
      "Operator 115: -0.07399695003357953\n",
      "Operator 116: -0.012685259007862463\n",
      "Operator 117: -0.02683507778308223\n",
      "Operator 118: -0.4065764062127729\n",
      "Operator 119: 0.15686484219357086\n",
      "Operator 120: -0.08621629409279019\n",
      "Operator 121: 0.22046103124705446\n",
      "Operator 123: 0.1626701376562574\n",
      "Operator 124: -0.9647798496320836\n",
      "Operator 125: 0.7856104136705612\n",
      "Operator 126: -0.8765656852128312\n",
      "Operator 127: 1.2667872731345884\n",
      "Operator 128: -0.21084125746256394\n",
      "Operator 129: -0.24900175825673238\n",
      "Operator 130: -1.0391847315939793\n",
      "Operator 131: -0.27798174935822273\n",
      "Operator 132: -1.027791838996477\n",
      "Operator 133: -0.002479070548534232\n",
      "Operator 134: -0.7981287093951914\n",
      "Operator 135: -0.17398914725830927\n",
      "Operator 136: -0.5539654749453271\n",
      "Operator 137: -0.0698752366863502\n",
      "Operator 139: 1.3397633213512663\n",
      "Operator 140: -0.05056351023360649\n",
      "Operator 141: 0.5571602419425903\n",
      "Operator 142: 0.43483083632399266\n",
      "Operator 143: 0.6235599414336391\n",
      "Operator 144: 0.4085133101773645\n",
      "Operator 145: 0.08793895554127108\n",
      "Operator 146: -0.17796962865813015\n",
      "Operator 147: 0.6525453287455918\n",
      "Operator 148: -0.09347671345931524\n",
      "Operator 149: 0.4968466503740838\n",
      "Operator 150: 0.005092569769472488\n",
      "Operator 151: 0.36799927901614493\n",
      "Operator 152: 0.5259774413293574\n",
      "Operator 153: 0.9714947753383449\n",
      "Operator 154: 0.6420491469270402\n",
      "Operator 155: -0.5645653316080693\n",
      "Operator 156: -0.21375358809929884\n",
      "Operator 157: 0.6272206501774145\n",
      "Operator 158: 0.43414443350327636\n",
      "Operator 159: 0.5701208819885069\n",
      "Operator 160: 0.32615551160968653\n",
      "Operator 161: 0.5076576794104692\n",
      "Operator 162: 0.200463032492408\n",
      "Operator 163: -1.168608672238252\n",
      "Operator 164: 0.25363551310996124\n",
      "Operator 165: -1.212737894364932\n",
      "Operator 166: -0.24096174955403737\n",
      "Operator 167: -1.1873833931876971\n",
      "Operator 168: 0.10502051357411696\n",
      "Operator 169: -0.5891090562611314\n",
      "Operator 170: 0.12841954473917822\n",
      "Operator 171: -0.3997141219485352\n",
      "Operator 172: 0.0836093335589839\n",
      "Operator 173: -0.2541542924591793\n",
      "Operator 174: 1.5543369112575416\n",
      "Operator 176: -0.007299292109406983\n",
      "Operator 177: 0.3093997872022965\n",
      "Operator 178: -0.47108404136267223\n",
      "Operator 179: -1.4206083104056364\n",
      "Operator 180: -1.6946511160814333\n",
      "Operator 181: -1.4265819229907728\n",
      "Operator 182: -1.3567473174000115\n",
      "Operator 183: 0.3750314354379317\n",
      "Operator 184: 0.4004006124034637\n",
      "Operator 186: 1.053693694827019\n",
      "Operator 187: -0.06841905878285248\n",
      "Operator 188: 0.9872936071177665\n",
      "Operator 189: -0.7713807193172717\n",
      "Operator 191: -0.4616315313167723\n",
      "Operator 192: -0.29038132682237716\n",
      "Operator 193: 0.14021908234662686\n",
      "Operator 194: -0.19589046701081786\n",
      "Operator 195: 0.4304455137355737\n",
      "Operator 196: -1.14140186354255\n",
      "Operator 197: -1.27465835079173\n",
      "Operator 198: -1.3429166839679463\n",
      "Operator 199: -1.29636949938023\n",
      "Operator 200: 0.30954504251178316\n",
      "Operator 201: 0.17304890556967678\n",
      "Operator 202: -0.694384393440753\n",
      "Operator 203: 0.6169484881111003\n",
      "Operator 204: -0.6943208877363491\n",
      "Operator 205: 0.5177145640221545\n",
      "Operator 206: -0.7784334436717866\n",
      "Operator 207: -0.19945750180896038\n",
      "Operator 208: -0.7667866742956571\n",
      "Operator 209: -0.22168601097912255\n",
      "Operator 210: 0.019015094746656084\n",
      "Operator 211: -0.249906062727497\n",
      "Operator 212: 0.026981263043438442\n",
      "Operator 213: -1.5180367544628546\n",
      "Operator 214: -1.4721226769297455\n",
      "Operator 215: -1.7184223276280408\n",
      "Operator 216: -1.3031334326480324\n",
      "Operator 217: 1.043929044782601\n",
      "Operator 219: 0.4160355347742202\n",
      "Operator 220: 0.7573614019249613\n",
      "Operator 221: 0.38231763268464025\n",
      "Operator 222: 0.41213426979720225\n",
      "Operator 223: -0.30553227448095766\n",
      "Operator 224: -0.27132071834385985\n",
      "Operator 225: -0.03902904736153559\n",
      "Operator 226: -0.05372453241935382\n",
      "Operator 227: 1.0471459989881513\n",
      "Operator 228: 0.07867077447199668\n",
      "Operator 229: 0.34644243932462215\n",
      "Operator 230: 0.28255972566933385\n",
      "Operator 231: 0.404587721035886\n",
      "Operator 232: -0.3980505639691345\n",
      "Operator 233: 0.029989807198217353\n",
      "Operator 234: -0.30864440139163307\n",
      "Operator 235: -0.16640990308796433\n",
      "Operator 236: 0.1179274698804966\n",
      "Operator 237: 0.7940113616061095\n",
      "Operator 238: -0.40251956572744446\n",
      "Operator 239: 0.8349544653181692\n",
      "Operator 240: -0.28548225630132584\n",
      "Operator 241: 1.0711269522214093\n",
      "Operator 242: -0.1296845189241701\n",
      "Operator 243: 1.6888106414890462\n",
      "Operator 244: 0.4801963346701316\n",
      "Operator 245: -0.01606568150165129\n",
      "Operator 246: -0.633081809258111\n",
      "Operator 247: 0.5865439760768106\n",
      "Operator 248: 1.1646201117602055\n",
      "Operator 249: 1.118584167388582\n",
      "Operator 250: 1.1339053213036525\n",
      "Operator 251: 0.13653174227308087\n",
      "Operator 252: 0.48518338199847433\n",
      "Operator 253: -0.19318157664592508\n",
      "Operator 254: 0.601921292392732\n",
      "Operator 255: -0.18943185971592374\n",
      "Operator 256: 0.686858391637978\n",
      "Operator 257: -0.15605329398651016\n",
      "Operator 258: 1.1067613221850596\n",
      "Operator 259: 0.11057060136223362\n",
      "Operator 260: 0.9428980535349584\n",
      "Total gradient norm: 10.844726126797235\n",
      "Operators under consideration (1):\n",
      "[215]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.7184223276280408)]\n",
      "Operator(s) added to ansatz: [215]\n",
      "Gradients: [np.float64(-1.7184223276280408)]\n",
      "Initial energy: -32.767802085251404\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185, 218, 215]...\n",
      "Starting point: [np.float64(0.4907063437851321), np.float64(0.5505807313169137), np.float64(0.15922794643762067), np.float64(0.46209488929318365), np.float64(0.146293254827263), np.float64(0.3187523213400177), np.float64(-0.6539684634857377), np.float64(0.4340201729591267), np.float64(-0.3504051302119787), np.float64(-0.3149165116170382), np.float64(-0.5403974429244671), np.float64(-0.3780820220715483), np.float64(0.2675298419251605), np.float64(0.2574799527242606), np.float64(-0.24390197482059672), np.float64(-0.23599757543728972), np.float64(-0.23987917666387373), np.float64(0.21572039990622374), np.float64(0.18162036883016514), np.float64(0.14485774751481534), np.float64(-0.14645817887709586), np.float64(0.1407974572942703), np.float64(0.16624537729832697), np.float64(-0.1422943637471628), np.float64(-0.1231964126742191), np.float64(-0.1255844620794393), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -32.877388\n",
      "         Iterations: 33\n",
      "         Function evaluations: 127\n",
      "         Gradient evaluations: 114\n",
      "\n",
      "Current energy: -32.877388055889995\n",
      "(change of -0.10958597063859088)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185, 218, 215]\n",
      "On iteration 27.\n",
      "\n",
      "*** ADAPT-VQE Iteration 28 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -1.3741223012256367\n",
      "Operator 1: 0.05342835105270696\n",
      "Operator 2: -0.019743248922044328\n",
      "Operator 3: 1.3928099725474914\n",
      "Operator 4: 0.008482457440460722\n",
      "Operator 5: 0.20062363832956226\n",
      "Operator 6: 0.04232210147319003\n",
      "Operator 7: -0.4774697752966367\n",
      "Operator 8: -0.6994697194571566\n",
      "Operator 9: -0.5904876460571372\n",
      "Operator 10: -0.9659819943824286\n",
      "Operator 11: -0.58867650716956\n",
      "Operator 12: -0.6039846344790655\n",
      "Operator 13: -0.09519888043952446\n",
      "Operator 14: -0.8384667330106685\n",
      "Operator 15: -0.43516508713724456\n",
      "Operator 16: -1.487086168265158\n",
      "Operator 17: 0.15851276299671632\n",
      "Operator 18: -0.024469525925310084\n",
      "Operator 19: 0.23488910527703452\n",
      "Operator 20: -0.2709541894206027\n",
      "Operator 21: 0.1867373386091655\n",
      "Operator 22: -0.05770623386707159\n",
      "Operator 23: -1.5125668847614266e-08\n",
      "Operator 24: 0.012199639884705729\n",
      "Operator 25: 0.5776301403171846\n",
      "Operator 26: -0.3580558899328356\n",
      "Operator 27: -0.16884566886306346\n",
      "Operator 28: -0.37282442838635244\n",
      "Operator 29: 0.29878609092771125\n",
      "Operator 30: -0.1897119017221856\n",
      "Operator 31: 0.556325972486966\n",
      "Operator 32: -0.07522800988670822\n",
      "Operator 33: 0.06127959361019464\n",
      "Operator 34: 0.29377643098668405\n",
      "Operator 35: 0.41524626493753747\n",
      "Operator 36: -0.05514059723461723\n",
      "Operator 37: 0.6681713447025315\n",
      "Operator 38: 0.4122892037117162\n",
      "Operator 39: 0.6384315982699693\n",
      "Operator 40: 0.4623390400775853\n",
      "Operator 41: 0.29555144670531563\n",
      "Operator 42: -0.05198034683111409\n",
      "Operator 43: 0.919179352196547\n",
      "Operator 44: -0.1781793345455639\n",
      "Operator 45: 0.5030140639533762\n",
      "Operator 46: 0.03257579904941851\n",
      "Operator 47: 0.8491342988624488\n",
      "Operator 48: 0.4896842156456964\n",
      "Operator 49: 1.5608914974636274\n",
      "Operator 50: 0.44109656223490057\n",
      "Operator 51: -0.2967015359430254\n",
      "Operator 52: -0.42506139909167573\n",
      "Operator 53: 0.08494380414402902\n",
      "Operator 54: 0.16080855960352752\n",
      "Operator 55: 1.3856560600571297\n",
      "Operator 56: -0.05425798377853682\n",
      "Operator 57: 0.11138130237778113\n",
      "Operator 58: -0.32786545014285023\n",
      "Operator 59: -0.5352561962089397\n",
      "Operator 60: -0.9006506743234375\n",
      "Operator 61: -0.5764509152280846\n",
      "Operator 62: -0.8988564790463373\n",
      "Operator 63: -0.5294292662297568\n",
      "Operator 64: -0.8281495700139934\n",
      "Operator 65: -0.10399497278960912\n",
      "Operator 66: -1.4491217527850564\n",
      "Operator 67: -0.13525001627928757\n",
      "Operator 68: -0.20891143996247755\n",
      "Operator 69: -3.00353466001714e-07\n",
      "Operator 70: -0.814564045933399\n",
      "Operator 71: 1.0988873908318801\n",
      "Operator 72: 0.23290773988344549\n",
      "Operator 73: 1.014107284964209\n",
      "Operator 74: -0.02225969586029903\n",
      "Operator 75: 0.8743144415868194\n",
      "Operator 76: 0.22522613769926014\n",
      "Operator 77: 0.20782406074114812\n",
      "Operator 78: -0.5613846063456409\n",
      "Operator 79: 0.01757829514935326\n",
      "Operator 80: -0.9701000372068094\n",
      "Operator 81: 0.14887173020205585\n",
      "Operator 82: -0.1941154533146605\n",
      "Operator 83: 0.19799142609658832\n",
      "Operator 84: 2.6030375011032447e-07\n",
      "Operator 85: -0.08301177548166434\n",
      "Operator 86: 0.2569399942172234\n",
      "Operator 87: -0.47481938298416065\n",
      "Operator 88: 0.002765126117563342\n",
      "Operator 89: 0.47264326503387144\n",
      "Operator 90: 0.1888324368879235\n",
      "Operator 91: 0.6493997900818598\n",
      "Operator 92: 0.3220568623512021\n",
      "Operator 93: -0.6063527669981905\n",
      "Operator 94: 0.28818359773375535\n",
      "Operator 95: -1.1878221077027216\n",
      "Operator 96: 0.2066721793109987\n",
      "Operator 97: -1.20559795847631\n",
      "Operator 98: -0.2842409503791303\n",
      "Operator 99: -1.2088816274253402\n",
      "Operator 100: -0.07481129884134809\n",
      "Operator 101: -0.5309883323028098\n",
      "Operator 102: 0.20819895037974495\n",
      "Operator 103: -0.7160786666661059\n",
      "Operator 104: -0.15816514298740242\n",
      "Operator 105: 0.024474815385232253\n",
      "Operator 106: -0.21518542915700137\n",
      "Operator 107: 0.24201153386295415\n",
      "Operator 108: -0.7483313047049875\n",
      "Operator 109: 1.411633674736952\n",
      "Operator 110: -0.46701418538516726\n",
      "Operator 111: 0.34458675135796346\n",
      "Operator 112: -0.7191167952653406\n",
      "Operator 113: -0.029225128344051016\n",
      "Operator 114: -0.026332741073070376\n",
      "Operator 115: -0.0792874561902562\n",
      "Operator 116: -0.011530150417850646\n",
      "Operator 117: -0.030464065049786528\n",
      "Operator 118: -0.4019808418368791\n",
      "Operator 119: 0.15392080303941413\n",
      "Operator 120: -0.08294164599245502\n",
      "Operator 121: 0.23068551203466914\n",
      "Operator 122: -3.5009713515680827e-07\n",
      "Operator 123: 0.17107231282171356\n",
      "Operator 124: -0.9552007016398187\n",
      "Operator 125: 0.6944345963350445\n",
      "Operator 126: -0.044442735331433655\n",
      "Operator 127: 1.2147754060403155\n",
      "Operator 128: -0.20242815022662003\n",
      "Operator 129: -0.2519042655239139\n",
      "Operator 130: -1.0273398428979037\n",
      "Operator 131: -0.28139244247172984\n",
      "Operator 132: -1.0213522262109236\n",
      "Operator 133: -0.0035817805024664917\n",
      "Operator 134: -0.7974112610301496\n",
      "Operator 135: -0.1752294869403972\n",
      "Operator 136: -0.5512514183951365\n",
      "Operator 137: -0.07000590897226644\n",
      "Operator 139: 1.3578360863450845\n",
      "Operator 140: -0.08964439229062034\n",
      "Operator 141: 0.5934146306008683\n",
      "Operator 142: 0.3953703325679879\n",
      "Operator 143: 0.7184681987952821\n",
      "Operator 144: 0.49099822089313283\n",
      "Operator 145: 0.138536316381346\n",
      "Operator 146: -0.0974238945275252\n",
      "Operator 147: 0.7337414801862914\n",
      "Operator 148: -0.07016049904506286\n",
      "Operator 149: 0.5501683739003748\n",
      "Operator 150: 0.020712823997293333\n",
      "Operator 151: 0.4016517237593008\n",
      "Operator 152: 0.5293551738204345\n",
      "Operator 153: 0.9865105632232485\n",
      "Operator 154: 0.6429869728222048\n",
      "Operator 155: -0.555588518475832\n",
      "Operator 156: -0.22419791336688977\n",
      "Operator 157: 0.6623793665990696\n",
      "Operator 158: 0.3812828769283849\n",
      "Operator 159: 0.656157724496057\n",
      "Operator 160: 0.22565468183549303\n",
      "Operator 161: -0.627560553824824\n",
      "Operator 162: 0.09755432891515516\n",
      "Operator 163: -1.158889900146882\n",
      "Operator 164: 0.24426004804245907\n",
      "Operator 165: -1.2061731245154301\n",
      "Operator 166: -0.2389114471670027\n",
      "Operator 167: -1.1853297620868237\n",
      "Operator 168: 0.09957859308648215\n",
      "Operator 169: -0.591644228496425\n",
      "Operator 170: 0.1264706873546277\n",
      "Operator 171: -0.3997158949508375\n",
      "Operator 172: 0.08344951667702316\n",
      "Operator 173: -0.2558273234985311\n",
      "Operator 174: 1.5632505092222893\n",
      "Operator 175: 3.698328894182818e-08\n",
      "Operator 176: -0.019299420744579583\n",
      "Operator 177: 0.3510577166952198\n",
      "Operator 178: -0.5074357097416686\n",
      "Operator 179: -1.3095978690221641\n",
      "Operator 180: -1.7236595986167516\n",
      "Operator 181: -0.47134620034894736\n",
      "Operator 182: -0.4369261115084899\n",
      "Operator 183: 0.3707461454314519\n",
      "Operator 184: 0.3865218350028059\n",
      "Operator 185: 1.0362406802169443e-07\n",
      "Operator 186: 1.0254290327642912\n",
      "Operator 187: -0.070274712943076\n",
      "Operator 188: 0.9704634345871564\n",
      "Operator 189: -0.7630802877281588\n",
      "Operator 190: 2.3523994308050078e-07\n",
      "Operator 191: -0.45698054199826554\n",
      "Operator 192: -0.2914029654067538\n",
      "Operator 193: 0.14431027328979018\n",
      "Operator 194: -0.18313766169325374\n",
      "Operator 195: 0.451112739294357\n",
      "Operator 196: -1.1091267769876465\n",
      "Operator 197: -1.20645705302932\n",
      "Operator 198: -0.29085932560394717\n",
      "Operator 199: -1.229008202934391\n",
      "Operator 200: 0.2599202760087854\n",
      "Operator 201: 0.13227090664251767\n",
      "Operator 202: -0.7058850958493829\n",
      "Operator 203: 0.5940676403747458\n",
      "Operator 204: -0.7036919407405821\n",
      "Operator 205: 0.5031259886298021\n",
      "Operator 206: -0.7815137879981496\n",
      "Operator 207: -0.19928859737760019\n",
      "Operator 208: -0.7648589683463611\n",
      "Operator 209: -0.2201896867144475\n",
      "Operator 210: 0.029209773835636964\n",
      "Operator 211: -0.30081039943395205\n",
      "Operator 212: 0.11446720421133029\n",
      "Operator 213: -1.6177511005146727\n",
      "Operator 214: -1.3197006783245366\n",
      "Operator 215: 4.4178193383986345e-08\n",
      "Operator 216: -1.1947792322781514\n",
      "Operator 217: 1.0425121605042356\n",
      "Operator 218: -1.1284819661979426e-07\n",
      "Operator 219: 0.40520839748220944\n",
      "Operator 220: 0.741668929391436\n",
      "Operator 221: 0.37189762335882237\n",
      "Operator 222: 0.40068422886918714\n",
      "Operator 223: -0.30785991565978843\n",
      "Operator 224: -0.268758443712537\n",
      "Operator 225: -0.038859823087975975\n",
      "Operator 226: -0.052859089785675106\n",
      "Operator 227: 1.0714308617694117\n",
      "Operator 228: 0.0657270874878668\n",
      "Operator 229: 0.3974587690487119\n",
      "Operator 230: 0.22292033684841506\n",
      "Operator 231: 0.5929482811984157\n",
      "Operator 232: -0.37215211924874303\n",
      "Operator 233: 0.033680060359995545\n",
      "Operator 234: 0.16986948148194597\n",
      "Operator 235: -0.07606951646202116\n",
      "Operator 236: 0.11844846754373156\n",
      "Operator 237: 0.8196337805408408\n",
      "Operator 238: -0.39492858894280086\n",
      "Operator 239: 0.8520298389407548\n",
      "Operator 240: -0.2819099624748726\n",
      "Operator 241: 1.0817416663988495\n",
      "Operator 242: -0.12873025637950386\n",
      "Operator 243: 1.6946654998094903\n",
      "Operator 244: 0.47579286358611117\n",
      "Operator 245: -0.014747538436483255\n",
      "Operator 246: -0.6613319746100562\n",
      "Operator 247: 0.5803080135864418\n",
      "Operator 248: 1.1330026081771019\n",
      "Operator 249: 0.5871760140212599\n",
      "Operator 250: 1.204988315631733\n",
      "Operator 251: -0.036756625328630846\n",
      "Operator 252: 0.5021992315708097\n",
      "Operator 253: -0.18173747780604962\n",
      "Operator 254: 0.6053156360553318\n",
      "Operator 255: -0.17818821846325494\n",
      "Operator 256: 0.6910637673147367\n",
      "Operator 257: -0.14856251830207268\n",
      "Operator 258: 1.1032773880318356\n",
      "Operator 259: 0.10874102551583069\n",
      "Operator 260: 0.9397689696682783\n",
      "Total gradient norm: 10.061897899045185\n",
      "Operators under consideration (1):\n",
      "[180]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.7236595986167516)]\n",
      "Operator(s) added to ansatz: [180]\n",
      "Gradients: [np.float64(-1.7236595986167516)]\n",
      "Initial energy: -32.877388055889995\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185, 218, 215, 180]...\n",
      "Starting point: [np.float64(0.4987154188483362), np.float64(0.5524085300058075), np.float64(0.15657737570028812), np.float64(0.4672295865171474), np.float64(0.1455232254673597), np.float64(0.40610500085121803), np.float64(-0.654953015527848), np.float64(0.43749832500906133), np.float64(-0.37190710354223), np.float64(-0.3323811208874086), np.float64(-0.5425451160209679), np.float64(-0.3825760540447641), np.float64(0.24901269933426584), np.float64(0.2601363647604585), np.float64(-0.24238592716267984), np.float64(-0.23353802528447345), np.float64(-0.23832318363632227), np.float64(0.21495851388721035), np.float64(0.1813314099764002), np.float64(0.14488676894747143), np.float64(-0.14566103111004974), np.float64(0.14101746378438196), np.float64(0.1625821663560485), np.float64(-0.14349527007188304), np.float64(-0.1246821454367673), np.float64(-0.12856224357839993), np.float64(0.1275056214027298), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -32.982790\n",
      "         Iterations: 34\n",
      "         Function evaluations: 75\n",
      "         Gradient evaluations: 65\n",
      "\n",
      "Current energy: -32.982789861114455\n",
      "(change of -0.10540180522446008)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185, 218, 215, 180]\n",
      "On iteration 28.\n",
      "\n",
      "*** ADAPT-VQE Iteration 29 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -1.3781162207113444\n",
      "Operator 1: 0.09058930591395305\n",
      "Operator 2: -0.08076506264070757\n",
      "Operator 3: 0.16753440463245012\n",
      "Operator 4: -0.5977311187921879\n",
      "Operator 5: 0.1073694750846838\n",
      "Operator 6: -0.22530362067506166\n",
      "Operator 7: -0.46386447140699194\n",
      "Operator 8: -0.7850667089855162\n",
      "Operator 9: -0.5865264044884212\n",
      "Operator 10: -1.0124439852017186\n",
      "Operator 11: -0.5919311098693254\n",
      "Operator 12: -0.6392189304045162\n",
      "Operator 13: -0.10064701917298524\n",
      "Operator 14: -0.8606824649075905\n",
      "Operator 15: -0.4383456158688711\n",
      "Operator 16: -1.4983325250192363\n",
      "Operator 17: 0.156962480993008\n",
      "Operator 18: -0.026293384738001618\n",
      "Operator 19: 0.23488762348692535\n",
      "Operator 20: -0.31287229186483456\n",
      "Operator 21: 0.2456130691354544\n",
      "Operator 22: 0.029568267074969696\n",
      "Operator 23: -5.2024512012496834e-08\n",
      "Operator 24: 0.023800901808041765\n",
      "Operator 25: 0.5453757040709974\n",
      "Operator 26: -0.34042998487919746\n",
      "Operator 27: -0.1910517916327314\n",
      "Operator 28: -0.34449493238069967\n",
      "Operator 29: 0.27667742856054806\n",
      "Operator 30: -0.17584660862237045\n",
      "Operator 31: 0.5437500547837836\n",
      "Operator 32: -0.07297458965158826\n",
      "Operator 33: 0.06045895006512376\n",
      "Operator 34: 0.28879555786951416\n",
      "Operator 35: 0.46528494427917316\n",
      "Operator 36: -0.025517325965438733\n",
      "Operator 37: 0.6380114307768856\n",
      "Operator 38: 0.5279455242249046\n",
      "Operator 39: 0.731801533815026\n",
      "Operator 40: 0.44959129171917633\n",
      "Operator 41: 0.4098657355217599\n",
      "Operator 42: -0.039273127711177254\n",
      "Operator 43: 0.9724384443877303\n",
      "Operator 44: -0.14639764876255912\n",
      "Operator 45: 0.5468425484497085\n",
      "Operator 46: 0.05473741287967927\n",
      "Operator 47: 0.8757927844214562\n",
      "Operator 48: 0.4944461989899347\n",
      "Operator 49: 1.568942260755403\n",
      "Operator 50: 0.4441113424759715\n",
      "Operator 51: -0.29111434159172583\n",
      "Operator 52: -0.4726368125752696\n",
      "Operator 53: 0.050676953808446855\n",
      "Operator 54: -0.03304964405324575\n",
      "Operator 55: 0.10105365228070788\n",
      "Operator 56: -0.7127634434245198\n",
      "Operator 57: 0.2385296166990478\n",
      "Operator 58: -0.48351984690531435\n",
      "Operator 59: -0.5441524749449184\n",
      "Operator 60: -0.9404862089018751\n",
      "Operator 61: -0.5824167892420026\n",
      "Operator 62: -0.9231986547347687\n",
      "Operator 63: -0.5365367350771478\n",
      "Operator 64: -0.8493612384581607\n",
      "Operator 65: -0.11252804928897696\n",
      "Operator 66: -1.4591620501557196\n",
      "Operator 67: -0.13919486818322296\n",
      "Operator 68: -0.2233569529787448\n",
      "Operator 69: -2.522590947167417e-07\n",
      "Operator 70: -0.7666554584231339\n",
      "Operator 71: 0.24084987765068666\n",
      "Operator 72: 0.23464127964031514\n",
      "Operator 73: 0.9842126856233462\n",
      "Operator 74: -0.007126405678867962\n",
      "Operator 75: 0.9008203690460577\n",
      "Operator 76: 0.23525740729202702\n",
      "Operator 77: 0.20039028384851587\n",
      "Operator 78: -0.5407393604978155\n",
      "Operator 79: 0.014844916826983462\n",
      "Operator 80: -0.9538326949840451\n",
      "Operator 81: 0.1466870056837348\n",
      "Operator 82: -0.1921243877087877\n",
      "Operator 83: 0.19583321871169243\n",
      "Operator 84: 2.969592617918515e-07\n",
      "Operator 85: -0.0830742371763135\n",
      "Operator 86: 0.2577911776632899\n",
      "Operator 87: -0.47239923043377524\n",
      "Operator 88: 0.005255560039375453\n",
      "Operator 89: 0.4966998095113206\n",
      "Operator 90: 0.11616092877003244\n",
      "Operator 91: -0.44192995602149626\n",
      "Operator 92: 0.23138506180985952\n",
      "Operator 93: -0.5659524747271825\n",
      "Operator 94: 0.22453616214721756\n",
      "Operator 95: -1.1673106609297357\n",
      "Operator 96: 0.20346293569114346\n",
      "Operator 97: -1.193435120920943\n",
      "Operator 98: -0.27935333909088955\n",
      "Operator 99: -1.204938819168622\n",
      "Operator 100: -0.07680542626974807\n",
      "Operator 101: -0.5312410078604508\n",
      "Operator 102: 0.20469802680887292\n",
      "Operator 103: -0.7150487673677608\n",
      "Operator 104: -0.1566883205079734\n",
      "Operator 105: 0.026297896130879225\n",
      "Operator 106: -0.21980262161295588\n",
      "Operator 107: 0.28211180667974156\n",
      "Operator 108: -0.7346728169212844\n",
      "Operator 109: 0.4358846025406467\n",
      "Operator 110: 0.1332074427712117\n",
      "Operator 111: 0.4016429942826646\n",
      "Operator 112: -0.6377089337842532\n",
      "Operator 113: -0.04242672744731426\n",
      "Operator 114: -0.026669124183522727\n",
      "Operator 115: -0.0863855557531441\n",
      "Operator 116: -0.010650625303209468\n",
      "Operator 117: -0.03504101946800419\n",
      "Operator 118: -0.39608964955262155\n",
      "Operator 119: 0.15012008098357352\n",
      "Operator 120: -0.07877869337864213\n",
      "Operator 121: 0.24058797707176724\n",
      "Operator 122: -2.8848517429622804e-07\n",
      "Operator 123: 0.18021318794489258\n",
      "Operator 124: -0.8945369493977495\n",
      "Operator 125: -0.1943163199747542\n",
      "Operator 126: -0.20856089076004028\n",
      "Operator 127: 1.120142719659705\n",
      "Operator 128: -0.1955571206121705\n",
      "Operator 129: -0.2547527473515073\n",
      "Operator 130: -1.0123501199434517\n",
      "Operator 131: -0.2847484843014984\n",
      "Operator 132: -1.0128361132085466\n",
      "Operator 133: -0.0049360047769122116\n",
      "Operator 134: -0.7962557145099938\n",
      "Operator 135: -0.17674766537330902\n",
      "Operator 136: -0.5476695084101498\n",
      "Operator 137: -0.07015172687394058\n",
      "Operator 138: -1.3792065534199334e-07\n",
      "Operator 139: 1.3652432324185877\n",
      "Operator 140: -0.11862685405663213\n",
      "Operator 141: 0.590031060463399\n",
      "Operator 142: 0.536300635131591\n",
      "Operator 143: 0.5900980888251256\n",
      "Operator 144: 0.5693661491754656\n",
      "Operator 145: 0.3900304960608673\n",
      "Operator 146: -0.12114748478926363\n",
      "Operator 147: 0.8287440435075154\n",
      "Operator 148: -0.04827636629352788\n",
      "Operator 149: 0.6160591350773691\n",
      "Operator 150: 0.04078255938251307\n",
      "Operator 151: 0.4444712272076456\n",
      "Operator 152: 0.5337559805478246\n",
      "Operator 153: 1.0058773926183762\n",
      "Operator 154: 0.644221635339037\n",
      "Operator 155: -0.5513775336797632\n",
      "Operator 156: -0.23341701506588852\n",
      "Operator 157: 0.6560476551300524\n",
      "Operator 158: 0.34431793212345385\n",
      "Operator 159: -0.5509649747103869\n",
      "Operator 160: 0.252700354818572\n",
      "Operator 161: -0.466322741145486\n",
      "Operator 162: 0.02791200597084319\n",
      "Operator 163: -1.158131828122053\n",
      "Operator 164: 0.23393796473131495\n",
      "Operator 165: -1.1994886948427326\n",
      "Operator 166: -0.23614371569423856\n",
      "Operator 167: -1.182402053260819\n",
      "Operator 168: 0.09266673076287231\n",
      "Operator 169: -0.5948941675240641\n",
      "Operator 170: 0.12398356585968213\n",
      "Operator 171: -0.3997191022992314\n",
      "Operator 172: 0.08341809088468277\n",
      "Operator 173: -0.25691529419129505\n",
      "Operator 174: 1.5747574439605085\n",
      "Operator 175: 2.1001092462697035e-07\n",
      "Operator 176: -0.024188625236953205\n",
      "Operator 177: 0.3845548660009964\n",
      "Operator 178: -0.47812593150585664\n",
      "Operator 179: -1.1884548033905915\n",
      "Operator 180: 4.5884017723573526e-08\n",
      "Operator 181: -0.4439130789160662\n",
      "Operator 182: -0.5343259553492494\n",
      "Operator 183: 0.4264008654014199\n",
      "Operator 184: 0.3668698541683669\n",
      "Operator 185: 3.7085353765831785e-07\n",
      "Operator 186: 0.9901345597252874\n",
      "Operator 187: -0.07297351705836637\n",
      "Operator 188: 0.9489379607295928\n",
      "Operator 189: -0.7523257562583542\n",
      "Operator 190: -2.2713160743479885e-08\n",
      "Operator 191: -0.4509781438450021\n",
      "Operator 192: -0.29272294214722705\n",
      "Operator 193: 0.1462513161340139\n",
      "Operator 194: -0.17506278463936645\n",
      "Operator 195: 0.45517937178004925\n",
      "Operator 196: -1.1260990654188836\n",
      "Operator 197: -0.2875443813225608\n",
      "Operator 198: -0.16107361129142328\n",
      "Operator 199: -1.0847956828878114\n",
      "Operator 200: 0.16115057567895233\n",
      "Operator 201: 0.1497521189719314\n",
      "Operator 202: -0.7281242733094238\n",
      "Operator 203: 0.5708230547442512\n",
      "Operator 204: -0.714831178857754\n",
      "Operator 205: 0.4844351499012082\n",
      "Operator 206: -0.7851535043577911\n",
      "Operator 207: -0.19909351473046627\n",
      "Operator 208: -0.762329071733068\n",
      "Operator 209: -0.2182790672332353\n",
      "Operator 210: 0.032030898831534996\n",
      "Operator 211: -0.3459323974264202\n",
      "Operator 212: 0.14021177561278345\n",
      "Operator 213: -0.6612543821835412\n",
      "Operator 214: -0.4507067470003749\n",
      "Operator 215: -7.004737253433545e-08\n",
      "Operator 216: -1.0695933486215052\n",
      "Operator 217: 0.9815998593693089\n",
      "Operator 218: -2.2633198168842193e-07\n",
      "Operator 219: 0.37974227098463625\n",
      "Operator 220: 0.7154962950083433\n",
      "Operator 221: 0.358402214011141\n",
      "Operator 222: 0.38601019515189156\n",
      "Operator 223: -0.31062893301536554\n",
      "Operator 224: -0.26548045027387546\n",
      "Operator 225: -0.03861815932667802\n",
      "Operator 226: -0.05174611996904307\n",
      "Operator 227: 1.0840388134713577\n",
      "Operator 228: 0.06304868309455926\n",
      "Operator 229: 0.4306866028364912\n",
      "Operator 230: 0.2665816910797298\n",
      "Operator 231: 0.5596742750337547\n",
      "Operator 232: -0.3589853050082126\n",
      "Operator 233: 0.7640245792497726\n",
      "Operator 234: 0.05665591904538434\n",
      "Operator 235: 0.057392270291304476\n",
      "Operator 236: 0.11351966286582722\n",
      "Operator 237: 0.853456395356022\n",
      "Operator 238: -0.38547073746069266\n",
      "Operator 239: 0.8733298054974594\n",
      "Operator 240: -0.2771676354725347\n",
      "Operator 241: 1.0953904972961248\n",
      "Operator 242: -0.12741151535832718\n",
      "Operator 243: 1.7021830947927428\n",
      "Operator 244: 0.47318273546851924\n",
      "Operator 245: -0.01461383514055866\n",
      "Operator 246: -0.6643410959322362\n",
      "Operator 247: 0.5907328822980747\n",
      "Operator 248: 1.2155311543975713\n",
      "Operator 249: -0.23319818813572402\n",
      "Operator 250: 1.1828295715403396\n",
      "Operator 251: 0.01888105623552369\n",
      "Operator 252: 0.4978319806480326\n",
      "Operator 253: -0.16913635159974086\n",
      "Operator 254: 0.6115678337979376\n",
      "Operator 255: -0.16448250880732118\n",
      "Operator 256: 0.6964475848015824\n",
      "Operator 257: -0.13906393524626615\n",
      "Operator 258: 1.098695702980501\n",
      "Operator 259: 0.10639595101020276\n",
      "Operator 260: 0.9357165837598254\n",
      "Total gradient norm: 9.296911685679168\n",
      "Operators under consideration (1):\n",
      "[243]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(1.7021830947927428)]\n",
      "Operator(s) added to ansatz: [243]\n",
      "Gradients: [np.float64(1.7021830947927428)]\n",
      "Initial energy: -32.982789861114455\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185, 218, 215, 180, 243]...\n",
      "Starting point: [np.float64(0.5072122842931602), np.float64(0.5547843949157273), np.float64(0.15686167067758564), np.float64(0.4737313547654113), np.float64(0.14519107107728804), np.float64(0.47797319194589377), np.float64(-0.6562338891071787), np.float64(0.44198343202634804), np.float64(-0.39446896716254964), np.float64(-0.3491816374409979), np.float64(-0.5437453212357622), np.float64(-0.38521229225725295), np.float64(0.25148901549419833), np.float64(0.24335701364250015), np.float64(-0.23525258736041973), np.float64(-0.23016621234254545), np.float64(-0.23634734892537537), np.float64(0.21398373104062177), np.float64(0.1809600104158107), np.float64(0.14492439774799376), np.float64(-0.14529977557989965), np.float64(0.14130225380995), np.float64(0.16161454597621924), np.float64(-0.1449903055859341), np.float64(-0.12677635917695004), np.float64(-0.12894024455265404), np.float64(0.12146691143238451), np.float64(0.12214289284229439), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -33.076881\n",
      "         Iterations: 34\n",
      "         Function evaluations: 155\n",
      "         Gradient evaluations: 142\n",
      "\n",
      "Current energy: -33.07688137337122\n",
      "(change of -0.09409151225676737)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185, 218, 215, 180, 243]\n",
      "On iteration 29.\n",
      "\n",
      "*** ADAPT-VQE Iteration 30 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -1.3789237877365759\n",
      "Operator 1: 0.09308247624953067\n",
      "Operator 2: -0.0863430839732825\n",
      "Operator 3: 0.16330932316943894\n",
      "Operator 4: -0.6075678576135912\n",
      "Operator 5: 0.10599562011074178\n",
      "Operator 6: -0.24670270783662077\n",
      "Operator 7: -0.4687689228410921\n",
      "Operator 8: -0.8150364406662938\n",
      "Operator 9: -0.5960948803029331\n",
      "Operator 10: -1.0724680161843152\n",
      "Operator 11: -0.6186799804216455\n",
      "Operator 12: -0.8607148102800595\n",
      "Operator 13: -0.2814677754512478\n",
      "Operator 14: -1.0301507743246596\n",
      "Operator 15: -0.053903993411397\n",
      "Operator 16: -0.14777701335906832\n",
      "Operator 17: 0.15678620271854005\n",
      "Operator 18: -0.02634450720633802\n",
      "Operator 19: 0.23541371061181277\n",
      "Operator 20: -0.3129108679676857\n",
      "Operator 21: 0.24478598491458423\n",
      "Operator 22: 0.028300396894855855\n",
      "Operator 23: 2.7611221401529285e-07\n",
      "Operator 24: 0.021359458729198002\n",
      "Operator 25: 0.5275279713257441\n",
      "Operator 26: -0.31301218957499055\n",
      "Operator 27: -0.2153357120946452\n",
      "Operator 28: -0.30834809579255407\n",
      "Operator 29: 0.25022294984925864\n",
      "Operator 30: -0.13295145220959761\n",
      "Operator 31: 0.5508726775809929\n",
      "Operator 32: -0.16170335560848614\n",
      "Operator 33: 0.08117131955569784\n",
      "Operator 34: 0.28803436259805204\n",
      "Operator 35: 0.4682190981185981\n",
      "Operator 36: -0.028789302863204573\n",
      "Operator 37: 0.6468720912662648\n",
      "Operator 38: 0.526089925895839\n",
      "Operator 39: 0.7507153315223087\n",
      "Operator 40: 0.45137336772189973\n",
      "Operator 41: 0.4685013511003124\n",
      "Operator 42: -0.021229035414868216\n",
      "Operator 43: 1.0501732029610413\n",
      "Operator 44: -0.141167615699412\n",
      "Operator 45: 0.7166813946589717\n",
      "Operator 46: 0.07668175359299731\n",
      "Operator 47: 1.0773088140974416\n",
      "Operator 48: 0.3242513860619095\n",
      "Operator 49: 0.16777369922805146\n",
      "Operator 50: 0.041939985908702994\n",
      "Operator 51: -0.29032739672149127\n",
      "Operator 52: -0.47546528224078743\n",
      "Operator 53: 0.05377150624793289\n",
      "Operator 54: -0.046066967894179967\n",
      "Operator 55: 0.09860184169709789\n",
      "Operator 56: -0.7344063386180459\n",
      "Operator 57: 0.24054485478913357\n",
      "Operator 58: -0.5344108728259471\n",
      "Operator 59: -0.54181812451368\n",
      "Operator 60: -1.013683093422947\n",
      "Operator 61: -0.5805642909064433\n",
      "Operator 62: -1.0566156707398897\n",
      "Operator 63: -0.5678339940217046\n",
      "Operator 64: -1.1958169175368223\n",
      "Operator 65: -0.2786854777539136\n",
      "Operator 66: 0.14892034404915655\n",
      "Operator 67: 0.2383913694203344\n",
      "Operator 68: -0.22410914871981485\n",
      "Operator 69: 1.06445039614253e-06\n",
      "Operator 70: -0.7628731169536906\n",
      "Operator 71: 0.23998752750307312\n",
      "Operator 72: 0.23739235829494792\n",
      "Operator 73: 0.9915309793737958\n",
      "Operator 74: -0.005673761658371507\n",
      "Operator 75: 0.888723679190031\n",
      "Operator 76: 0.23679838646276397\n",
      "Operator 77: 0.19117643382513627\n",
      "Operator 78: -0.5252372871244412\n",
      "Operator 79: 0.010901324933278132\n",
      "Operator 80: -0.8033060206320316\n",
      "Operator 81: 0.22526777423035213\n",
      "Operator 82: -0.13891696660976685\n",
      "Operator 83: 0.3322080855921873\n",
      "Operator 84: -0.021524875889966245\n",
      "Operator 85: -0.08307130588085254\n",
      "Operator 86: 0.2578692486709199\n",
      "Operator 87: -0.4721588679975159\n",
      "Operator 88: 0.0053126074087390405\n",
      "Operator 89: 0.49922296635033214\n",
      "Operator 90: 0.11253923687988654\n",
      "Operator 91: -0.44346582143033925\n",
      "Operator 92: 0.2257493151478168\n",
      "Operator 93: -0.5692743727044511\n",
      "Operator 94: 0.21480709110501883\n",
      "Operator 95: -1.1605940098725047\n",
      "Operator 96: 0.19441884372416524\n",
      "Operator 97: -1.1704380910978782\n",
      "Operator 98: -0.2837860717148176\n",
      "Operator 99: -1.1906977086894517\n",
      "Operator 100: -0.19026270485026625\n",
      "Operator 101: -0.6366111997236641\n",
      "Operator 102: 0.1735801736100134\n",
      "Operator 103: -0.2274633631585829\n",
      "Operator 104: -0.1565151592533356\n",
      "Operator 105: 0.026348860561762763\n",
      "Operator 106: -0.22047950026686405\n",
      "Operator 107: 0.2824535370302756\n",
      "Operator 108: -0.7315499027397344\n",
      "Operator 109: 0.42850380751151307\n",
      "Operator 110: 0.13892266928188213\n",
      "Operator 111: 0.3920047154962226\n",
      "Operator 112: -0.6300586797767147\n",
      "Operator 113: -0.037951696410922414\n",
      "Operator 114: -0.019520073185184623\n",
      "Operator 115: -0.07743999198850895\n",
      "Operator 116: -0.009126788600366495\n",
      "Operator 117: -0.020520533969905563\n",
      "Operator 118: -0.2712538979592539\n",
      "Operator 119: 0.43579687295129943\n",
      "Operator 120: -0.05662537270777379\n",
      "Operator 121: 0.24115786546716228\n",
      "Operator 122: -2.5687735908871967e-07\n",
      "Operator 123: 0.18033354178020644\n",
      "Operator 124: -0.8924737356214055\n",
      "Operator 125: -0.19501934939598808\n",
      "Operator 126: -0.2071649022929338\n",
      "Operator 127: 1.1001829585982357\n",
      "Operator 128: -0.19060910629137817\n",
      "Operator 129: -0.26256934723893827\n",
      "Operator 130: -1.0209563426672728\n",
      "Operator 131: -0.2966335112588939\n",
      "Operator 132: -1.0298710866796004\n",
      "Operator 133: 0.03910672561305803\n",
      "Operator 134: -0.7091219618058604\n",
      "Operator 135: -0.07931923334143239\n",
      "Operator 136: -0.4544337620225917\n",
      "Operator 137: 0.014172705400710844\n",
      "Operator 138: -2.7959701554003402e-08\n",
      "Operator 139: 1.3661919967773786\n",
      "Operator 140: -0.12081012124846871\n",
      "Operator 141: 0.5919303602808952\n",
      "Operator 142: 0.5363036862409974\n",
      "Operator 143: 0.595828937638542\n",
      "Operator 144: 0.5711769196376204\n",
      "Operator 145: 0.42170496916474864\n",
      "Operator 146: -0.0978461205966516\n",
      "Operator 147: 0.8695608294365736\n",
      "Operator 148: -0.028199101957043733\n",
      "Operator 149: 0.7013458981103441\n",
      "Operator 150: 0.08263861193029734\n",
      "Operator 151: 0.5699045219478663\n",
      "Operator 152: 0.39594041884749076\n",
      "Operator 153: 1.1134888827566307\n",
      "Operator 154: 0.16298091220434865\n",
      "Operator 155: -0.5509096310790786\n",
      "Operator 156: -0.23400420761326018\n",
      "Operator 157: 0.6576925323213851\n",
      "Operator 158: 0.34164603983214403\n",
      "Operator 159: -0.551893407339277\n",
      "Operator 160: 0.24919692184885964\n",
      "Operator 161: -0.46620329722129433\n",
      "Operator 162: 0.023243417489362813\n",
      "Operator 163: -1.150747244057792\n",
      "Operator 164: 0.2303983233146994\n",
      "Operator 165: -1.1765098074430522\n",
      "Operator 166: -0.2176545596463394\n",
      "Operator 167: -1.147770305474135\n",
      "Operator 168: -0.08246415373827838\n",
      "Operator 169: -0.7474138495768237\n",
      "Operator 170: 0.16709988541690718\n",
      "Operator 171: 0.08849872076229603\n",
      "Operator 172: 0.08341104394571985\n",
      "Operator 173: -0.25700369555853875\n",
      "Operator 174: 0.262275019751043\n",
      "Operator 175: -5.125956520357633e-08\n",
      "Operator 176: -0.024799487917920183\n",
      "Operator 177: 0.38690090548842343\n",
      "Operator 178: -0.47970133409543697\n",
      "Operator 179: -1.1819258021309487\n",
      "Operator 180: 1.4700342140538223e-08\n",
      "Operator 181: -0.43932828173973787\n",
      "Operator 182: -0.5450622622578264\n",
      "Operator 183: 0.41401134971618464\n",
      "Operator 184: 0.3482203781122094\n",
      "Operator 185: -1.2454353437703018e-07\n",
      "Operator 186: 0.936959693835765\n",
      "Operator 187: -0.0744756077173477\n",
      "Operator 188: 0.871758295160395\n",
      "Operator 189: -0.3446093610800778\n",
      "Operator 190: 0.09096373209869253\n",
      "Operator 191: -0.33865147599471684\n",
      "Operator 192: -0.30512395872136966\n",
      "Operator 193: 0.14648037677198333\n",
      "Operator 194: -0.1743637799494995\n",
      "Operator 195: 0.4563229976496204\n",
      "Operator 196: -1.124219952913401\n",
      "Operator 197: -0.2862068820621752\n",
      "Operator 198: -0.16224636765074205\n",
      "Operator 199: -1.0761001488212316\n",
      "Operator 200: 0.133608695652658\n",
      "Operator 201: 0.14194818823753969\n",
      "Operator 202: -0.7566723979431892\n",
      "Operator 203: 0.5513506011587443\n",
      "Operator 204: -0.7678812687821506\n",
      "Operator 205: 0.4231075949379905\n",
      "Operator 206: -0.651907325558186\n",
      "Operator 207: -0.2776142234545881\n",
      "Operator 208: -0.5310627828599778\n",
      "Operator 209: -0.1874492020404867\n",
      "Operator 210: 0.03255488208610962\n",
      "Operator 211: -0.34872378748767674\n",
      "Operator 212: 0.14442074157394857\n",
      "Operator 213: -0.6571963503149432\n",
      "Operator 214: -0.44524893118400954\n",
      "Operator 215: -6.153192115089986e-07\n",
      "Operator 216: -1.0582193825558277\n",
      "Operator 217: 0.9517819860362631\n",
      "Operator 218: -6.022674540741168e-08\n",
      "Operator 219: 0.36185601994193456\n",
      "Operator 220: 0.7103513306314992\n",
      "Operator 221: 0.33460332941129156\n",
      "Operator 222: 0.4274043288967275\n",
      "Operator 223: -0.07539533101829907\n",
      "Operator 224: -0.22714236253877998\n",
      "Operator 225: 0.030064846417418734\n",
      "Operator 226: -0.09219002480992078\n",
      "Operator 227: 1.085344102824501\n",
      "Operator 228: 0.062459307087769075\n",
      "Operator 229: 0.4333827207792621\n",
      "Operator 230: 0.2644736690021485\n",
      "Operator 231: 0.5670401715813593\n",
      "Operator 232: -0.3571199990132571\n",
      "Operator 233: 0.7823006313650429\n",
      "Operator 234: 0.054750553756645406\n",
      "Operator 235: 0.11053657982708938\n",
      "Operator 236: 0.10791300093126377\n",
      "Operator 237: 0.9195537946830348\n",
      "Operator 238: -0.3626829950363174\n",
      "Operator 239: 0.9982652056305739\n",
      "Operator 240: -0.22977694142722546\n",
      "Operator 241: 1.2288757356986175\n",
      "Operator 242: -0.1397532412364581\n",
      "Operator 243: 4.3276704608132126e-07\n",
      "Operator 244: 0.4729347291361212\n",
      "Operator 245: -0.014566629852978867\n",
      "Operator 246: -0.665756023582678\n",
      "Operator 247: 0.5902564944737341\n",
      "Operator 248: 1.2151168486582595\n",
      "Operator 249: -0.23106297401905684\n",
      "Operator 250: 1.1817046056273537\n",
      "Operator 251: 0.03318475245730311\n",
      "Operator 252: 0.503673542674544\n",
      "Operator 253: -0.15273772744829203\n",
      "Operator 254: 0.6217827626296746\n",
      "Operator 255: -0.12989979367293952\n",
      "Operator 256: 0.7222900717247287\n",
      "Operator 257: -0.09094165864780211\n",
      "Operator 258: 1.1037758351394402\n",
      "Operator 259: -0.03633085031590212\n",
      "Operator 260: 0.2781096802018149\n",
      "Total gradient norm: 8.633808289119948\n",
      "Operators under consideration (1):\n",
      "[0]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.3789237877365759)]\n",
      "Operator(s) added to ansatz: [0]\n",
      "Gradients: [np.float64(-1.3789237877365759)]\n",
      "Initial energy: -33.07688137337122\n",
      "Optimizing energy with indices [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185, 218, 215, 180, 243, 0]...\n",
      "Starting point: [np.float64(0.5148648390977673), np.float64(0.620187380715955), np.float64(0.1567367896134956), np.float64(0.4887825146935752), np.float64(0.1451515921481595), np.float64(0.4797061958266729), np.float64(-0.6803514021435736), np.float64(0.47570633400806206), np.float64(-0.39972903248482605), np.float64(-0.35012109522493295), np.float64(-0.5438617186596857), np.float64(-0.38545670156088674), np.float64(0.25072996640006373), np.float64(0.24193515006801503), np.float64(-0.23230235291093015), np.float64(-0.22530347816958798), np.float64(-0.22799134924127132), np.float64(0.18808221424998206), np.float64(0.18102161912401304), np.float64(0.12206316923630879), np.float64(-0.14525903806502136), np.float64(0.1557807960763019), np.float64(0.16143943888204518), np.float64(-0.14686520925024615), np.float64(-0.12778287779243133), np.float64(-0.13054927369717947), np.float64(0.12164626478077033), np.float64(0.12255473919539563), np.float64(-0.10912944029131337), np.float64(0.0)]\n",
      "         Current function value: -33.164041\n",
      "         Iterations: 36\n",
      "         Function evaluations: 109\n",
      "         Gradient evaluations: 95\n",
      "\n",
      "Current energy: -33.16404066852931\n",
      "(change of -0.08715929515808796)\n",
      "Current ansatz: [237, 243, 230, 239, 173, 233, 137, 118, 127, 123, 172, 19, 38, 40, 59, 61, 63, 48, 50, 192, 175, 190, 122, 187, 185, 218, 215, 180, 243, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    }
   ],
   "source": [
    "# Now go to the larger size.\n",
    "new_l = 5 * l\n",
    "print(f\"new_l = {new_l}\")\n",
    "j_xy = 1\n",
    "j_z = 1\n",
    "h = XXZHamiltonian(\n",
    "    j_xy, j_z, new_l,\n",
    "    store_ref_vector=False,\n",
    "    diag_mode=\"quimb\", max_mpo_bond=max_mpo_bond, max_mps_bond=dmrg_mps_bond\n",
    ")\n",
    "dmrg_energy = h.ground_energy\n",
    "exact_energy = h.ground_energy\n",
    "print(f\"Got DMRG energy {dmrg_energy:4.5e}\")\n",
    "\n",
    "h_of = h.operator\n",
    "h_cirq = of.transforms.qubit_operator_to_pauli_sum(h_of)\n",
    "h_qiskit = cirq_pauli_sum_to_qiskit_pauli_op(h_cirq)\n",
    "\n",
    "tiled_pool = TiledPauliPool(n=new_l, source_ops=source_ops)\n",
    "num_ops = len(tiled_pool.operators)\n",
    "print(f\"Tiled pool has {num_ops} operators.\")\n",
    "\n",
    "tn_adapt = TensorNetAdapt(\n",
    "    pool=tiled_pool,\n",
    "    custom_hamiltonian=h,\n",
    "    verbose=True,\n",
    "    threshold=10**-5,\n",
    "    max_adapt_iter=30,\n",
    "    max_opt_iter=10000,\n",
    "    sel_criterion=\"gradient\",\n",
    "    recycle_hessian=False,\n",
    "    rand_degenerate=True,\n",
    "    max_mpo_bond=max_mpo_bond,\n",
    "    max_mps_bond=adapt_mps_bond\n",
    ")\n",
    "tn_adapt.initialize()\n",
    "nq = tn_adapt.n\n",
    "\n",
    "circuits = []\n",
    "adapt_energies = []\n",
    "for i in range(30):\n",
    "    print(f\"On iteration {i}.\")\n",
    "    tn_adapt.run_iteration()\n",
    "    data = tn_adapt.data\n",
    "    circuit = data.get_circuit(\n",
    "        tiled_pool, indices=tn_adapt.indices, coefficients=tn_adapt.coefficients,\n",
    "        include_ref=True\n",
    "    )\n",
    "    circuit.measure_all()\n",
    "    circuits.append(circuit)\n",
    "    adapt_energies.append(tn_adapt.energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cc70396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "16\n",
      "23\n",
      "30\n",
      "35\n",
      "42\n",
      "47\n",
      "54\n",
      "59\n",
      "64\n",
      "69\n",
      "76\n",
      "83\n",
      "90\n",
      "97\n",
      "104\n",
      "111\n",
      "118\n",
      "125\n",
      "132\n",
      "139\n",
      "146\n",
      "151\n",
      "158\n",
      "165\n",
      "172\n",
      "179\n",
      "186\n",
      "193\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for circuit in circuits:\n",
    "    print(circuit.depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "572ff26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Energy error')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adapt_errors = abs(np.array(adapt_energies) - exact_energy)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(adapt_errors)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68f30093",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_errors = np.abs(np.array(adapt_energies) - exact_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020ff13",
   "metadata": {},
   "source": [
    "## Get circuit expectation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c6c2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_model = NoiseModel.from_backend(backend)\n",
    "simulator_energies = []\n",
    "for circuit in circuits:\n",
    "    sim = AerSimulator(method=\"matrix_product_state\", noise_model=noise_model, matrix_product_state_max_bond_dimension=adapt_mps_bond)\n",
    "    estimator = BackendEstimator(backend=sim)\n",
    "    # The circuit needs to be transpiled to the AerSimulator target\n",
    "    pass_manager = generate_preset_pass_manager(3, sim)\n",
    "    isa_circuit = pass_manager.run(circuit)\n",
    "    isa_circuit = RemoveFinalMeasurements()(isa_circuit)\n",
    "    pub = (isa_circuit, h_qiskit)\n",
    "    job = estimator.run([pub])\n",
    "    result = job.result()\n",
    "    pub_result = result[0]\n",
    "    exact_value = float(pub_result.data.evs)\n",
    "    simulator_energies.append(exact_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1c3064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simualtor_errors = np.abs(np.array(simulator_energies) - exact_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a265c33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Energy error')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(adapt_errors, label=\"ADAPT\")\n",
    "ax.plot(simualtor_errors, label=\"Simulator\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965f4a6",
   "metadata": {},
   "source": [
    "## Carry out SQD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0a71f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# spin_a_layout = list(range(0, 12))\n",
    "# spin_b_layout = [12, 13, 14, 15, 19, 35, 34, 33, 32, 31, 30, 29]\n",
    "# initial_layout = spin_a_layout + spin_b_layout\n",
    "initial_layout = range(nq)\n",
    "\n",
    "# sim = AerSimulator.from_backend(computer, method=\"matrix_product_state\")\n",
    "sim = AerSimulator(method=\"matrix_product_state\", noise_model=noise_model, matrix_product_state_max_bond_dimension=4 * adapt_mps_bond)\n",
    "\n",
    "pass_manager = generate_preset_pass_manager(\n",
    "    optimization_level=3, backend=sim, initial_layout=initial_layout[:nq]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9b18ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shots = 100_000\n",
    "sampler = Sampler(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbb1145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On circuit 0/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'measure': 20, 'rz': 11, 'x': 10, 'sx': 10, 'cz': 4, 'barrier': 2})\n",
      "On circuit 1/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 22, 'sx': 20, 'measure': 20, 'x': 11, 'cz': 8, 'barrier': 3})\n",
      "On circuit 2/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 33, 'sx': 30, 'measure': 20, 'x': 12, 'cz': 12, 'barrier': 4})\n",
      "On circuit 3/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 44, 'sx': 40, 'measure': 20, 'cz': 16, 'x': 13, 'barrier': 5})\n",
      "On circuit 4/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 53, 'sx': 48, 'measure': 20, 'cz': 18, 'x': 14, 'barrier': 6})\n",
      "On circuit 5/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 62, 'sx': 58, 'cz': 22, 'measure': 20, 'x': 15, 'barrier': 7})\n",
      "On circuit 6/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 69, 'sx': 66, 'cz': 24, 'measure': 20, 'x': 16, 'barrier': 8})\n",
      "On circuit 7/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 87, 'sx': 80, 'cz': 30, 'measure': 20, 'x': 17, 'barrier': 9})\n",
      "On circuit 8/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 96, 'sx': 88, 'cz': 32, 'measure': 20, 'x': 18, 'barrier': 10})\n",
      "On circuit 9/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 101, 'sx': 96, 'cz': 34, 'measure': 20, 'x': 19, 'barrier': 11})\n",
      "On circuit 10/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 111, 'sx': 104, 'cz': 36, 'x': 20, 'measure': 20, 'barrier': 12})\n",
      "On circuit 11/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 122, 'sx': 112, 'cz': 42, 'x': 23, 'measure': 20, 'barrier': 13})\n",
      "On circuit 12/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 129, 'sx': 116, 'cz': 46, 'x': 26, 'measure': 20, 'barrier': 14})\n",
      "On circuit 13/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 136, 'sx': 120, 'cz': 50, 'x': 29, 'measure': 20, 'barrier': 15})\n",
      "On circuit 14/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 145, 'sx': 130, 'cz': 54, 'x': 26, 'measure': 20, 'barrier': 16})\n",
      "On circuit 15/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 162, 'sx': 140, 'cz': 58, 'x': 29, 'measure': 20, 'barrier': 17})\n",
      "On circuit 16/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 167, 'sx': 150, 'cz': 62, 'x': 28, 'measure': 20, 'barrier': 18})\n",
      "On circuit 17/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 176, 'sx': 154, 'cz': 66, 'x': 31, 'measure': 20, 'barrier': 19})\n",
      "On circuit 18/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 184, 'sx': 158, 'cz': 70, 'x': 30, 'barrier': 20, 'measure': 20})\n",
      "On circuit 19/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 195, 'sx': 168, 'cz': 74, 'x': 33, 'barrier': 21, 'measure': 20})\n",
      "On circuit 20/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 203, 'sx': 174, 'cz': 78, 'x': 35, 'barrier': 22, 'measure': 20})\n",
      "On circuit 21/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 218, 'sx': 188, 'cz': 82, 'x': 38, 'barrier': 23, 'measure': 20})\n",
      "On circuit 22/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 225, 'sx': 200, 'cz': 84, 'x': 37, 'barrier': 24, 'measure': 20})\n",
      "On circuit 23/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 241, 'sx': 212, 'cz': 88, 'x': 38, 'barrier': 25, 'measure': 20})\n",
      "On circuit 24/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 250, 'sx': 222, 'cz': 92, 'x': 41, 'barrier': 26, 'measure': 20})\n",
      "On circuit 25/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 262, 'sx': 232, 'cz': 96, 'x': 42, 'barrier': 27, 'measure': 20})\n",
      "On circuit 26/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 271, 'sx': 240, 'cz': 100, 'x': 43, 'barrier': 28, 'measure': 20})\n",
      "On circuit 27/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 282, 'sx': 250, 'cz': 104, 'x': 42, 'barrier': 29, 'measure': 20})\n",
      "On circuit 28/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 290, 'sx': 258, 'cz': 108, 'x': 47, 'barrier': 30, 'measure': 20})\n",
      "On circuit 29/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 303, 'sx': 272, 'cz': 112, 'x': 45, 'barrier': 31, 'measure': 20})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bit_arrays = []\n",
    "counts_list = []\n",
    "for i, circuit in enumerate(circuits):\n",
    "    print(f\"On circuit {i}/{len(circuits)}\")\n",
    "    pass_manager.pre_init = ffsim.qiskit.PRE_INIT\n",
    "    to_run = pass_manager.run(circuit)\n",
    "    print(f\"Gate counts (w/ pre-init passes): {to_run.count_ops()}\")\n",
    "    # job = sim.run(to_run)\n",
    "    # counts = job.result().data()['counts']\n",
    "    # bit_array = BitArray.from_counts(counts, num_bits=circuit.num_qubits)\n",
    "    # counts1 = bit_array.get_counts()\n",
    "    job = sampler.run((circuit,), shots=num_shots)\n",
    "    data = job.result()[0].data\n",
    "    bit_array = data['meas']\n",
    "    counts1 = bit_array.get_counts()\n",
    "    counts_list.append(counts1)\n",
    "    bit_arrays.append(deepcopy(bit_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77f6310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = []\n",
    "errors = []\n",
    "\n",
    "for bit_array in bit_arrays[1:]:\n",
    "    bit_matrix = bit_array.to_bool_array()\n",
    "    eigvals, eigvecs = solve_qubit(bit_matrix, h_qiskit, k=1)\n",
    "    min_energy = np.min(eigvals)\n",
    "    err = abs(min_energy - exact_energy)\n",
    "    energies.append(min_energy)\n",
    "    errors.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8500129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Energy error')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(errors)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01421e02",
   "metadata": {},
   "source": [
    "## Concatenate mulitple rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2e3f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_energies = []\n",
    "stacked_errors = []\n",
    "\n",
    "for i in range(2, len(counts_list) + 1):\n",
    "    all_counts = collections.Counter()\n",
    "    tuple_of_counts = tuple(counts_list[:i])\n",
    "    assert len(tuple_of_counts) == i\n",
    "    for counts in tuple_of_counts:\n",
    "        for bitstring, count in counts.items():\n",
    "            all_counts[bitstring] += count\n",
    "\n",
    "    bit_array = qiskit.primitives.BitArray.from_counts(all_counts, num_bits=circuits[0].num_qubits)\n",
    "    bit_matrix = bit_array.to_bool_array()\n",
    "    eigvals, eigvecs = solve_qubit(bit_matrix, h_qiskit, k=1)\n",
    "    min_energy = np.min(eigvals)\n",
    "    err = abs(min_energy - exact_energy)\n",
    "    stacked_energies.append(min_energy)\n",
    "    stacked_errors.append(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6263d499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Energy error')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(stacked_errors)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb9a1bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1656365d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adapt_rel_errors = adapt_errors / abs(exact_energy)\n",
    "rel_errors = np.array(errors) / abs(exact_energy)\n",
    "stacked_rel_errors = np.array(stacked_errors) / abs(exact_energy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(adapt_rel_errors, '.', label=\"ADAPT\")\n",
    "ax.plot(rel_errors, '.', label=\"SQD\")\n",
    "ax.plot(stacked_rel_errors, '.', label=\"iSQD\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd058369",
   "metadata": {},
   "source": [
    "## How many did we keep?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e16e09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_kept = []\n",
    "total_shots = []\n",
    "for bit_array in bit_arrays:\n",
    "    bit_matrix = bit_array.to_bool_array()\n",
    "    original_size = bit_matrix.shape[0]\n",
    "    bit_matrix = sort_and_remove_duplicates(bit_matrix)\n",
    "    new_size = bit_matrix.shape[0]\n",
    "    num_kept.append(new_size)\n",
    "    total_shots.append(original_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11b61c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratio_kept = np.array(num_kept) / np.array(total_shots)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Number of basis states', color=color)\n",
    "ax1.plot(num_kept, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second Axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Fraction of shots kept', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(ratio_kept, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f225920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qasm_strs = []\n",
    "for circuit in circuits:\n",
    "    # print(circuit.num_qubits)\n",
    "    # isa_circuit = pass_manager.run(circuit)\n",
    "    # print(isa_circuit.num_qubits)\n",
    "    isa_circuit = circuit\n",
    "    qasm_str = dumps(isa_circuit)\n",
    "    qasm_strs.append(qasm_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4a60674",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"data/xxz_output.hdf5\", \"w\")\n",
    "f.create_dataset(\"qasm_strs\", data=qasm_strs)\n",
    "f.create_dataset(\"exact_energy\", data=exact_energy)\n",
    "f.create_dataset(\"adapt_errors\", data=np.array(adapt_errors))\n",
    "f.create_dataset(\"sqd_errors\", data=np.array(errors))\n",
    "f.create_dataset(\"isqd_errors\", data=np.array(stacked_errors))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc0a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapt",
   "language": "python",
   "name": "adapt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
