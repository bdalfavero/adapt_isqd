{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cd88d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from copy import deepcopy\n",
    "\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcParams.update({\"font.family\": \"serif\"})\n",
    "\n",
    "import pyscf\n",
    "import pyscf.cc\n",
    "import pyscf.mcscf\n",
    "\n",
    "# To get molecular geometries.\n",
    "import openfermion as of\n",
    "from openfermion import MolecularData\n",
    "from openfermionpyscf import run_pyscf\n",
    "\n",
    "import qiskit\n",
    "from qiskit import QuantumCircuit, QuantumRegister\n",
    "from qiskit.primitives import BitArray\n",
    "from qiskit_aer import AerSimulator  # For MPS Simulator.\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "from qiskit_ibm_runtime import SamplerV2 as Sampler\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit.primitives import BackendEstimatorV2 as BackendEstimator\n",
    "from qiskit.transpiler.passes import RemoveFinalMeasurements\n",
    "from qiskit.qasm2 import dumps\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "\n",
    "import ffsim\n",
    "\n",
    "# To run on hardware.\n",
    "import qiskit_ibm_runtime\n",
    "from qiskit_ibm_runtime import SamplerV2 as Sampler\n",
    "\n",
    "from functools import partial, reduce\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from qiskit_addon_sqd.fermion import SCIResult, diagonalize_fermionic_hamiltonian, solve_sci_batch\n",
    "from qiskit_addon_sqd.qubit import solve_qubit, sort_and_remove_duplicates, project_operator_to_subspace\n",
    "\n",
    "from adaptvqe.pools import DVG_CEO, FullPauliPool, TiledPauliPool\n",
    "from adaptvqe.convert import cirq_pauli_sum_to_qiskit_pauli_op\n",
    "from adaptvqe.hamiltonians import XXZHamiltonian\n",
    "from adaptvqe.algorithms.adapt_vqe import LinAlgAdapt, TensorNetAdapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "268707c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qiskit_runtime_service.__init__:WARNING:2026-02-05 10:45:36,686: Instance was not set at service instantiation. Free and trial plan instances will be prioritized. Based on the following filters: (tags: None, region: us-east, eu-de), and available plans: (open), the available account instances are: open-instance. If you need a specific instance set it explicitly either by using a saved account with a saved default instance or passing it in directly to QiskitRuntimeService().\n",
      "qiskit_runtime_service.backends:WARNING:2026-02-05 10:45:36,690: Using instance: open-instance, plan: open\n"
     ]
    }
   ],
   "source": [
    "ibm_computer: str = \"ibm_fez\"\n",
    "\n",
    "service = QiskitRuntimeService(name=\"dalfaver@msu.edu\")\n",
    "backend = service.backend(ibm_computer)\n",
    "sampler = Sampler(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09186101",
   "metadata": {},
   "source": [
    "## Build a tiled pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aca34c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got DMRG energy -6.46410e+00\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 74]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002066)\n",
      "Current ansatz: [244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000004)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [244, 74, 228]...\n",
      "Starting point: [np.float64(0.7853981703433218), np.float64(-0.7853981783720295), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.91752620004858\n",
      "Operator(s) added to ansatz: [108]\n",
      "Gradients: [np.float64(2.4850710477670868)]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 74, 228, 108]...\n",
      "Starting point: [np.float64(0.7853981659552435), np.float64(-0.7853981611613353), np.float64(0.12248927943047701), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819716\n",
      "(change of -0.20417052920206835)\n",
      "Current ansatz: [244, 74, 228, 108]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531887\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.089492926734878)]\n",
      "Initial energy: -6.327276154819716\n",
      "Optimizing energy with indices [244, 74, 228, 108, 210]...\n",
      "Starting point: [np.float64(0.7853981759756399), np.float64(-0.7853981514072985), np.float64(0.16357019740838008), np.float64(-0.16356963668287852), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614747027\n",
      "(change of -0.13682545992731132)\n",
      "Current ansatz: [244, 74, 228, 108, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0003134262119402355\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531887 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002093)\n",
      "Current ansatz: [241, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132733\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [241, 79, 228]...\n",
      "Starting point: [np.float64(-0.785398171825775), np.float64(0.7853981815917083), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.123105625617642\n",
      "(change of -0.1231056256176366)\n",
      "Current ansatz: [241, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199441697\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071047428846)]\n",
      "Initial energy: -6.123105625617642\n",
      "Optimizing energy with indices [241, 79, 228, 210]...\n",
      "Starting point: [np.float64(-0.785398162647287), np.float64(0.7853981641254796), np.float64(0.1224892793433147), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819982\n",
      "(change of -0.20417052920234013)\n",
      "Current ansatz: [241, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.24096404138082\n",
      "Operator(s) added to ansatz: [57]\n",
      "Gradients: [np.float64(2.0894916438682456)]\n",
      "Initial energy: -6.327276154819982\n",
      "Optimizing energy with indices [241, 79, 228, 210, 57]...\n",
      "Starting point: [np.float64(-0.7853982024976439), np.float64(0.7853981311150512), np.float64(0.1635702864850446), np.float64(0.16356997194303877), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614608976\n",
      "(change of -0.13682545978899352)\n",
      "Current ansatz: [241, 79, 228, 210, 57]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0003254105179039936\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.24096404138082 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000004\n",
      "(change of -1.7639320225002084)\n",
      "Current ansatz: [241, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132728\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000027)]\n",
      "Initial energy: -6.000000000000004\n",
      "Optimizing energy with indices [241, 74, 228]...\n",
      "Starting point: [np.float64(-0.7853981634264042), np.float64(-0.7853981633494633), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617643\n",
      "(change of -0.12310562561763838)\n",
      "Current ansatz: [241, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327163\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.4850710484797034)]\n",
      "Initial energy: -6.123105625617643\n",
      "Optimizing energy with indices [241, 74, 228, 210]...\n",
      "Starting point: [np.float64(-0.7853981639976342), np.float64(-0.7853981625399249), np.float64(0.12248927961411428), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819971\n",
      "(change of -0.2041705292023286)\n",
      "Current ansatz: [241, 74, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964057733311\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.089491629507777)]\n",
      "Initial energy: -6.327276154819971\n",
      "Optimizing energy with indices [241, 74, 228, 210, 198]...\n",
      "Starting point: [np.float64(-0.785398162447052), np.float64(-0.7853981711958521), np.float64(0.16357028748210503), np.float64(0.16356997569593643), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.464101615072614\n",
      "(change of -0.1368254602526422)\n",
      "Current ansatz: [241, 74, 228, 210, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013515787565729383\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964057733311 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.000000000000001)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199442337\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071047429203)]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 210]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819987\n",
      "(change of -0.20417052920234813)\n",
      "Current ansatz: [244, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964041846258\n",
      "Operator(s) added to ansatz: [108]\n",
      "Gradients: [np.float64(2.0894916434588646)]\n",
      "Initial energy: -6.327276154819987\n",
      "Optimizing energy with indices [244, 79, 228, 210, 108]...\n",
      "Starting point: [np.float64(0.7853981591889313), np.float64(0.7853981652005415), np.float64(0.16357028651334282), np.float64(0.1635699720499918), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072751\n",
      "(change of -0.13682546025276388)\n",
      "Current ansatz: [244, 79, 228, 210, 108]\n",
      "Performing final convergence check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 0.0001350560817700983\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964041846258 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 74]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002066)\n",
      "Current ansatz: [244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 9.79795897113273\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000004)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [244, 74, 225]...\n",
      "Starting point: [np.float64(0.7853981703433218), np.float64(-0.7853981783720295), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 74, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526200048677\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.485071047767142)]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 74, 225, 198]...\n",
      "Starting point: [np.float64(0.7853981633976963), np.float64(-0.7853981633977503), np.float64(-0.12248927943049101), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819957\n",
      "(change of -0.20417052920230994)\n",
      "Current ansatz: [244, 74, 225, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.2409640413812895\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.0894916438671864)]\n",
      "Initial energy: -6.327276154819957\n",
      "Optimizing energy with indices [244, 74, 225, 198, 135]...\n",
      "Starting point: [np.float64(0.7853981633827103), np.float64(-0.7853981633905597), np.float64(-0.1635702864850013), np.float64(-0.16356997194328274), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016150727975\n",
      "(change of -0.13682546025284026)\n",
      "Current ansatz: [244, 74, 225, 198, 135]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0001350387836355389\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.2409640413812895 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [31]\n",
      "Gradients: [np.float64(4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 31]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000006\n",
      "(change of -1.7639320225002075)\n",
      "Current ansatz: [244, 31]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000027)]\n",
      "Initial energy: -6.000000000000006\n",
      "Optimizing energy with indices [244, 31, 225]...\n",
      "Starting point: [np.float64(0.7853981634264086), np.float64(-0.7853981633494667), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.1231056256176455\n",
      "(change of -0.12310562561763927)\n",
      "Current ansatz: [244, 31, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327167\n",
      "Operator(s) added to ansatz: [120]\n",
      "Gradients: [np.float64(-2.4850710484797043)]\n",
      "Initial energy: -6.1231056256176455\n",
      "Optimizing energy with indices [244, 31, 225, 120]...\n",
      "Starting point: [np.float64(0.7853981639978266), np.float64(-0.7853981625399236), np.float64(-0.1224892796141142), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819701\n",
      "(change of -0.20417052920205592)\n",
      "Current ansatz: [244, 31, 225, 120]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531883\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.0894929267350113)]\n",
      "Initial energy: -6.327276154819701\n",
      "Optimizing energy with indices [244, 31, 225, 120, 147]...\n",
      "Starting point: [np.float64(0.7853981625487558), np.float64(-0.7853981630058687), np.float64(-0.1635701974084142), np.float64(0.16356963668285474), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615135295\n",
      "(change of -0.13682546031559362)\n",
      "Current ansatz: [244, 31, 225, 120, 147]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 2.6208924815045996e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531883 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.0000000000000058)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 198]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617649\n",
      "(change of -0.12310562561764016)\n",
      "Current ansatz: [244, 79, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199634004\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.485071047536024)]\n",
      "Initial energy: -6.123105625617649\n",
      "Optimizing energy with indices [244, 79, 198, 228]...\n",
      "Starting point: [np.float64(0.7853981603119451), np.float64(0.7853981603795771), np.float64(-0.12248927937093335), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819696\n",
      "(change of -0.20417052920204704)\n",
      "Current ansatz: [244, 79, 198, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531684\n",
      "Operator(s) added to ansatz: [216]\n",
      "Gradients: [np.float64(2.0894929267352373)]\n",
      "Initial energy: -6.327276154819696\n",
      "Optimizing energy with indices [244, 79, 198, 228, 216]...\n",
      "Starting point: [np.float64(0.7853981197421888), np.float64(0.7853981481872133), np.float64(-0.1635701974083944), np.float64(0.1635696366827917), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614707953\n",
      "(change of -0.13682545988825723)\n",
      "Current ansatz: [244, 79, 198, 228, 216]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00032795699741329547\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531684 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [225]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [225, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -5.999999999998188\n",
      "(change of -1.7639320224983894)\n",
      "Current ansatz: [225, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971140572\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-1.9999999999944214)]\n",
      "Initial energy: -5.999999999998188\n",
      "Optimizing energy with indices [225, 79, 228]...\n",
      "Starting point: [np.float64(0.7853985607314237), np.float64(0.7853989420959421), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625610647\n",
      "(change of -0.12310562561245852)\n",
      "Current ansatz: [225, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917522148955765\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.4850687898689596)]\n",
      "Initial energy: -6.123105625610647\n",
      "Optimizing energy with indices [225, 79, 228, 198]...\n",
      "Starting point: [np.float64(0.7853983869831845), np.float64(0.7853991695302365), np.float64(0.12248869758311001), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154816359\n",
      "(change of -0.20417052920571255)\n",
      "Current ansatz: [225, 79, 228, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.2409625671446225\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.089492948563802)]\n",
      "Initial energy: -6.327276154816359\n",
      "Optimizing energy with indices [225, 79, 228, 198, 210]...\n",
      "Starting point: [np.float64(0.7853984388284393), np.float64(0.785399159170205), np.float64(0.1635701984908049), np.float64(-0.16356963170294428), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615132083\n",
      "(change of -0.13682546031572418)\n",
      "Current ansatz: [225, 79, 228, 198, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 3.185075527210695e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.2409625671446225 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000004\n",
      "(change of -1.7639320225002084)\n",
      "Current ansatz: [241, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132728\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000027)]\n",
      "Initial energy: -6.000000000000004\n",
      "Optimizing energy with indices [241, 74, 228]...\n",
      "Starting point: [np.float64(-0.7853981634264042), np.float64(-0.7853981633494633), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617643\n",
      "(change of -0.12310562561763838)\n",
      "Current ansatz: [241, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327163\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.4850710484797034)]\n",
      "Initial energy: -6.123105625617643\n",
      "Optimizing energy with indices [241, 74, 228, 210]...\n",
      "Starting point: [np.float64(-0.7853981639976342), np.float64(-0.7853981625399249), np.float64(0.12248927961411428), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819971\n",
      "(change of -0.2041705292023286)\n",
      "Current ansatz: [241, 74, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964057733311\n",
      "Operator(s) added to ansatz: [108]\n",
      "Gradients: [np.float64(2.0894916295077763)]\n",
      "Initial energy: -6.327276154819971\n",
      "Optimizing energy with indices [241, 74, 228, 210, 108]...\n",
      "Starting point: [np.float64(-0.785398162447052), np.float64(-0.7853981711958521), np.float64(0.16357028748210503), np.float64(0.16356997569593643), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615067952\n",
      "(change of -0.13682546024798015)\n",
      "Current ansatz: [241, 74, 228, 210, 108]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013840064821418684\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964057733311 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.000000000000001)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199442337\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071047429203)]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 210]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819987\n",
      "(change of -0.20417052920234813)\n",
      "Current ansatz: [244, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964041846258\n",
      "Operator(s) added to ansatz: [57]\n",
      "Gradients: [np.float64(2.0894916434588646)]\n",
      "Initial energy: -6.327276154819987\n",
      "Optimizing energy with indices [244, 79, 228, 210, 57]...\n",
      "Starting point: [np.float64(0.7853981591889313), np.float64(0.7853981652005415), np.float64(0.16357028651334282), np.float64(0.1635699720499918), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072774\n",
      "(change of -0.13682546025278697)\n",
      "Current ansatz: [244, 79, 228, 210, 57]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.000135056081442826\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964041846258 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002093)\n",
      "Current ansatz: [241, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132733\n",
      "Operator(s) added to ansatz: [216]\n",
      "Gradients: [np.float64(2.0000000000000036)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [241, 79, 216]...\n",
      "Starting point: [np.float64(-0.785398171825775), np.float64(0.7853981815917083), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617644\n",
      "(change of -0.12310562561763838)\n",
      "Current ansatz: [241, 79, 216]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526200767302\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.485071048167666)]\n",
      "Initial energy: -6.123105625617644\n",
      "Optimizing energy with indices [241, 79, 216, 225]...\n",
      "Starting point: [np.float64(-0.7853981624814353), np.float64(0.7853981626766198), np.float64(-0.12248927953370452), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819948\n",
      "(change of -0.2041705292023046)\n",
      "Current ansatz: [241, 79, 216, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964115398415\n",
      "Operator(s) added to ansatz: [54]\n",
      "Gradients: [np.float64(-2.089491578871177)]\n",
      "Initial energy: -6.327276154819948\n",
      "Optimizing energy with indices [241, 79, 216, 225, 54]...\n",
      "Starting point: [np.float64(-0.7853982205487021), np.float64(0.7853982043140048), np.float64(-0.16357029099862372), np.float64(-0.1635699889292778), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614739763\n",
      "(change of -0.1368254599198151)\n",
      "Current ansatz: [241, 79, 216, 225, 54]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0003351091692272735\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964115398415 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.000000000000001)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199442337\n",
      "Operator(s) added to ansatz: [57]\n",
      "Gradients: [np.float64(2.485071047429203)]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 57]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819719\n",
      "(change of -0.2041705292020799)\n",
      "Current ansatz: [244, 79, 228, 57]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531794\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.089492926734892)]\n",
      "Initial energy: -6.327276154819719\n",
      "Optimizing energy with indices [244, 79, 228, 57, 210]...\n",
      "Starting point: [np.float64(0.7853981655442799), np.float64(0.7853981644065913), np.float64(0.16357019740836665), np.float64(-0.16356963668287158), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615121422\n",
      "(change of -0.1368254603017025)\n",
      "Current ansatz: [244, 79, 228, 57, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 5.68620773404476e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531794 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [225]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [225, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -5.999999999998188\n",
      "(change of -1.7639320224983894)\n",
      "Current ansatz: [225, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971140572\n",
      "Operator(s) added to ansatz: [120]\n",
      "Gradients: [np.float64(-1.9999999999969473)]\n",
      "Initial energy: -5.999999999998188\n",
      "Optimizing energy with indices [225, 79, 120]...\n",
      "Starting point: [np.float64(0.7853985607314237), np.float64(0.7853989420959421), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.1231056253012826\n",
      "(change of -0.12310562530309443)\n",
      "Current ansatz: [225, 79, 120]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526204648539\n",
      "Operator(s) added to ansatz: [156]\n",
      "Gradients: [np.float64(-2.485071048889239)]\n",
      "Initial energy: -6.1231056253012826\n",
      "Optimizing energy with indices [225, 79, 120, 156]...\n",
      "Starting point: [np.float64(0.7854035417148227), np.float64(0.7854075559311637), np.float64(0.12248927979678016), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154483843\n",
      "(change of -0.2041705291825604)\n",
      "Current ansatz: [225, 79, 120, 156]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.24095257780531\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0895005268730102)]\n",
      "Initial energy: -6.327276154483843\n",
      "Optimizing energy with indices [225, 79, 120, 156, 228]...\n",
      "Starting point: [np.float64(0.7853942888658061), np.float64(0.7853897046603734), np.float64(0.16356756471343573), np.float64(0.16356936264078176), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614718532\n",
      "(change of -0.13682546023468944)\n",
      "Current ansatz: [225, 79, 120, 156, 228]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0002944057752895776\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.24095257780531 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [228]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499795\n",
      "(change of -1.2360679774997907)\n",
      "Current ansatz: [228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696158\n",
      "Operator(s) added to ansatz: [26]\n",
      "Gradients: [np.float64(-4.000000000000003)]\n",
      "Initial energy: -4.236067977499795\n",
      "Optimizing energy with indices [228, 26]...\n",
      "Starting point: [np.float64(-0.5535743588970451), np.float64(0.0)]\n",
      "\n",
      "Current energy: -5.999999999929516\n",
      "(change of -1.7639320224297208)\n",
      "Current ansatz: [228, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971647986\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000193667)]\n",
      "Initial energy: -5.999999999929516\n",
      "Optimizing energy with indices [228, 26, 228]...\n",
      "Starting point: [np.float64(-0.7853947065773501), np.float64(0.785399377726245), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.1231056255624825\n",
      "(change of -0.12310562563296656)\n",
      "Current ansatz: [228, 26, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526201775818\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.4850710484682823)]\n",
      "Initial energy: -6.1231056255624825\n",
      "Optimizing energy with indices [228, 26, 228, 210]...\n",
      "Starting point: [np.float64(-0.7853947065772612), np.float64(0.7853985308794263), np.float64(0.12248927961669973), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154765017\n",
      "(change of -0.20417052920253465)\n",
      "Current ansatz: [228, 26, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964042069122\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.0894916438633278)]\n",
      "Initial energy: -6.327276154765017\n",
      "Optimizing energy with indices [228, 26, 228, 210, 198]...\n",
      "Starting point: [np.float64(-0.7853947065771328), np.float64(0.7853982468601286), np.float64(0.16357028648716873), np.float64(0.16356997194353046), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016150180075\n",
      "(change of -0.13682546025299036)\n",
      "Current ansatz: [228, 26, 228, 210, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00016418668716674994\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964042069122 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002093)\n",
      "Current ansatz: [241, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132733\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [241, 79, 228]...\n",
      "Starting point: [np.float64(-0.785398171825775), np.float64(0.7853981815917083), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617642\n",
      "(change of -0.1231056256176366)\n",
      "Current ansatz: [241, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526199441697\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.4850710474288453)]\n",
      "Initial energy: -6.123105625617642\n",
      "Optimizing energy with indices [241, 79, 228, 198]...\n",
      "Starting point: [np.float64(-0.785398162647287), np.float64(0.7853981641254796), np.float64(0.1224892793433147), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819708\n",
      "(change of -0.2041705292020657)\n",
      "Current ansatz: [241, 79, 228, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531757\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.089492926734934)]\n",
      "Initial energy: -6.327276154819708\n",
      "Optimizing energy with indices [241, 79, 228, 198, 210]...\n",
      "Starting point: [np.float64(-0.7853981618473267), np.float64(0.7853981651745618), np.float64(0.16357019740836948), np.float64(-0.16356963668286137), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615134318\n",
      "(change of -0.1368254603146104)\n",
      "Current ansatz: [241, 79, 228, 198, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 2.9260899740755612e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531757 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002093)\n",
      "Current ansatz: [241, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132733\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(1.9999999999999996)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [241, 79, 225]...\n",
      "Starting point: [np.float64(-0.785398171825775), np.float64(0.7853981815917083), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [241, 79, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.91752619944251\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.4850710474292965)]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [241, 79, 225, 198]...\n",
      "Starting point: [np.float64(-0.7853981627578538), np.float64(0.78539816425353), np.float64(-0.12248927934343061), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819986\n",
      "(change of -0.20417052920233836)\n",
      "Current ansatz: [241, 79, 225, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964058377264\n",
      "Operator(s) added to ansatz: [120]\n",
      "Gradients: [np.float64(-2.089491628942171)]\n",
      "Initial energy: -6.327276154819986\n",
      "Optimizing energy with indices [241, 79, 225, 198, 120]...\n",
      "Starting point: [np.float64(-0.7853981662933148), np.float64(0.7853981545803549), np.float64(-0.16357028752134434), np.float64(-0.16356997584374114), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072514\n",
      "(change of -0.1368254602525285)\n",
      "Current ansatz: [241, 79, 225, 198, 120]\n",
      "Performing final convergence check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 0.00013521654536773468\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964058377264 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.000000000000001)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526199442337\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.4850710474292024)]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 147]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819699\n",
      "(change of -0.20417052920205947)\n",
      "Current ansatz: [244, 79, 228, 147]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531783\n",
      "Operator(s) added to ansatz: [120]\n",
      "Gradients: [np.float64(-2.089492926734876)]\n",
      "Initial energy: -6.327276154819699\n",
      "Optimizing energy with indices [244, 79, 228, 147, 120]...\n",
      "Starting point: [np.float64(0.7853981646904773), np.float64(0.7853981643651435), np.float64(0.16357019740836662), np.float64(-0.1635696366828739), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016151315025\n",
      "(change of -0.13682546031180376)\n",
      "Current ansatz: [244, 79, 228, 147, 120]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 3.6719900116555346e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531783 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [26]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 26]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000014\n",
      "(change of -1.7639320225002155)\n",
      "Current ansatz: [244, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132747\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000018)]\n",
      "Initial energy: -6.000000000000014\n",
      "Optimizing energy with indices [244, 26, 228]...\n",
      "Starting point: [np.float64(0.7853981718257763), np.float64(0.7853981815917102), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561763305)\n",
      "Current ansatz: [244, 26, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526199440323\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071047428078)]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 26, 228, 210]...\n",
      "Starting point: [np.float64(0.7853981611549227), np.float64(0.7853981650265573), np.float64(0.1224892793431165), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.32727615481998\n",
      "(change of -0.20417052920233303)\n",
      "Current ansatz: [244, 26, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964040371926\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.0894916447538887)]\n",
      "Initial energy: -6.32727615481998\n",
      "Optimizing energy with indices [244, 26, 228, 210, 198]...\n",
      "Starting point: [np.float64(0.785398156811469), np.float64(0.785398154431449), np.float64(0.16357028642350993), np.float64(0.16356997171157828), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.46410161505858\n",
      "(change of -0.1368254602386001)\n",
      "Current ansatz: [244, 26, 228, 210, 198]\n",
      "Performing final convergence check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 0.0001435936303541698\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964040371926 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000004\n",
      "(change of -1.7639320225002084)\n",
      "Current ansatz: [241, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132728\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000027)]\n",
      "Initial energy: -6.000000000000004\n",
      "Optimizing energy with indices [241, 74, 225]...\n",
      "Starting point: [np.float64(-0.7853981634264042), np.float64(-0.7853981633494633), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617646\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [241, 74, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327169\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.4850710484797047)]\n",
      "Initial energy: -6.123105625617646\n",
      "Optimizing energy with indices [241, 74, 225, 210]...\n",
      "Starting point: [np.float64(-0.785398163997711), np.float64(-0.7853981625399766), np.float64(-0.1224892796141143), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.3272761548197085\n",
      "(change of -0.20417052920206213)\n",
      "Current ansatz: [241, 74, 225, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531922\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.0894929267349487)]\n",
      "Initial energy: -6.3272761548197085\n",
      "Optimizing energy with indices [241, 74, 225, 210, 147]...\n",
      "Starting point: [np.float64(-0.7853981657335386), np.float64(-0.7853981641901568), np.float64(-0.16357019740840956), np.float64(0.16356963668286917), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615122723\n",
      "(change of -0.13682546030301435)\n",
      "Current ansatz: [241, 74, 225, 210, 147]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 5.3335584305691664e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531922 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [26]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 26]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000014\n",
      "(change of -1.7639320225002155)\n",
      "Current ansatz: [244, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132747\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000027)]\n",
      "Initial energy: -6.000000000000014\n",
      "Optimizing energy with indices [244, 26, 225]...\n",
      "Starting point: [np.float64(0.7853981718257763), np.float64(0.7853981815917102), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617631\n",
      "(change of -0.12310562561761706)\n",
      "Current ansatz: [244, 26, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199440658\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.48507104742827)]\n",
      "Initial energy: -6.123105625617631\n",
      "Optimizing energy with indices [244, 26, 225, 147]...\n",
      "Starting point: [np.float64(0.7853981632980831), np.float64(0.78539816328158), np.float64(-0.12248927934316764), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.3272761548199945\n",
      "(change of -0.20417052920236323)\n",
      "Current ansatz: [244, 26, 225, 147]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964041893821\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.089491643417097)]\n",
      "Initial energy: -6.3272761548199945\n",
      "Optimizing energy with indices [244, 26, 225, 147, 210]...\n",
      "Starting point: [np.float64(0.7853981619384316), np.float64(0.785398165460987), np.float64(-0.16357028651624184), np.float64(-0.16356997206090712), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072618\n",
      "(change of -0.13682546025262354)\n",
      "Current ansatz: [244, 26, 225, 147, 210]\n",
      "Performing final convergence check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 0.0001351540793384578\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964041893821 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.0000000000000058)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 198]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617649\n",
      "(change of -0.12310562561764016)\n",
      "Current ansatz: [244, 79, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199634004\n",
      "Operator(s) added to ansatz: [141]\n",
      "Gradients: [np.float64(2.4850710475360245)]\n",
      "Initial energy: -6.123105625617649\n",
      "Optimizing energy with indices [244, 79, 198, 141]...\n",
      "Starting point: [np.float64(0.7853981603119451), np.float64(0.7853981603795771), np.float64(-0.12248927937093335), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154820003\n",
      "(change of -0.20417052920235434)\n",
      "Current ansatz: [244, 79, 198, 141]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964021189124\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.089491661599488)]\n",
      "Initial energy: -6.327276154820003\n",
      "Optimizing energy with indices [244, 79, 198, 141, 228]...\n",
      "Starting point: [np.float64(0.7853981648955715), np.float64(0.7853981822410845), np.float64(-0.1635702852538474), np.float64(-0.16356996730921505), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.464101615061342\n",
      "(change of -0.13682546024133835)\n",
      "Current ansatz: [244, 79, 198, 141, 228]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00014200521572705377\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964021189124 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 74]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002066)\n",
      "Current ansatz: [244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000004)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [244, 74, 225]...\n",
      "Starting point: [np.float64(0.7853981703433218), np.float64(-0.7853981783720295), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 74, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526200048677\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.4850710477671423)]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 74, 225, 210]...\n",
      "Starting point: [np.float64(0.7853981633976963), np.float64(-0.7853981633977503), np.float64(-0.12248927943049101), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.3272761548197005\n",
      "(change of -0.20417052920205325)\n",
      "Current ansatz: [244, 74, 225, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.24096258053184\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.0894929267348776)]\n",
      "Initial energy: -6.3272761548197005\n",
      "Optimizing energy with indices [244, 74, 225, 210, 198]...\n",
      "Starting point: [np.float64(0.7853981634001291), np.float64(-0.785398163399394), np.float64(-0.16357019740837944), np.float64(0.16356963668287733), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615135405\n",
      "(change of -0.13682546031570464)\n",
      "Current ansatz: [244, 74, 225, 210, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 2.5887660228229897e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.24096258053184 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [31]\n",
      "Gradients: [np.float64(4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 31]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000006\n",
      "(change of -1.7639320225002075)\n",
      "Current ansatz: [244, 31]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000027)]\n",
      "Initial energy: -6.000000000000006\n",
      "Optimizing energy with indices [244, 31, 225]...\n",
      "Starting point: [np.float64(0.7853981634264086), np.float64(-0.7853981633494667), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.1231056256176455\n",
      "(change of -0.12310562561763927)\n",
      "Current ansatz: [244, 31, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327167\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.4850710484797025)]\n",
      "Initial energy: -6.1231056256176455\n",
      "Optimizing energy with indices [244, 31, 225, 198]...\n",
      "Starting point: [np.float64(0.7853981639978266), np.float64(-0.7853981625399236), np.float64(-0.1224892796141142), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.3272761548199705\n",
      "(change of -0.20417052920232504)\n",
      "Current ansatz: [244, 31, 225, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964041381052\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.08949164386806)]\n",
      "Initial energy: -6.3272761548199705\n",
      "Optimizing energy with indices [244, 31, 225, 198, 210]...\n",
      "Starting point: [np.float64(0.7853981333456251), np.float64(-0.7853981977509684), np.float64(-0.1635702864850734), np.float64(-0.16356997194309295), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.464101614672586\n",
      "(change of -0.13682545985261552)\n",
      "Current ansatz: [244, 31, 225, 198, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00029671020679084166\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964041381052 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [26]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 26]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000014\n",
      "(change of -1.7639320225002155)\n",
      "Current ansatz: [244, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132747\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000027)]\n",
      "Initial energy: -6.000000000000014\n",
      "Optimizing energy with indices [244, 26, 225]...\n",
      "Starting point: [np.float64(0.7853981718257763), np.float64(0.7853981815917102), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617631\n",
      "(change of -0.12310562561761706)\n",
      "Current ansatz: [244, 26, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199440658\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.4850710474282707)]\n",
      "Initial energy: -6.123105625617631\n",
      "Optimizing energy with indices [244, 26, 225, 210]...\n",
      "Starting point: [np.float64(0.7853981632980831), np.float64(0.78539816328158), np.float64(-0.12248927934316764), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819707\n",
      "(change of -0.20417052920207546)\n",
      "Current ansatz: [244, 26, 225, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531786\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.089492926734879)]\n",
      "Initial energy: -6.327276154819707\n",
      "Optimizing energy with indices [244, 26, 225, 210, 198]...\n",
      "Starting point: [np.float64(0.7853981624018849), np.float64(0.78539816264672), np.float64(-0.16357019740836645), np.float64(0.16356963668287344), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.46410161513528\n",
      "(change of -0.1368254603155732)\n",
      "Current ansatz: [244, 26, 225, 210, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 2.6097435088026108e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531786 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [225]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [225, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -5.999999999998188\n",
      "(change of -1.7639320224983894)\n",
      "Current ansatz: [225, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971140572\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-1.9999999999944214)]\n",
      "Initial energy: -5.999999999998188\n",
      "Optimizing energy with indices [225, 79, 228]...\n",
      "Starting point: [np.float64(0.7853985607314237), np.float64(0.7853989420959421), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625610647\n",
      "(change of -0.12310562561245852)\n",
      "Current ansatz: [225, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917522148955765\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.4850687898689605)]\n",
      "Initial energy: -6.123105625610647\n",
      "Optimizing energy with indices [225, 79, 228, 210]...\n",
      "Starting point: [np.float64(0.7853983869831845), np.float64(0.7853991695302365), np.float64(0.12248869758311001), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154816644\n",
      "(change of -0.20417052920599765)\n",
      "Current ansatz: [225, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964056416012\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.0894916407310458)]\n",
      "Initial energy: -6.327276154816644\n",
      "Optimizing energy with indices [225, 79, 228, 210, 147]...\n",
      "Starting point: [np.float64(0.7853984379184568), np.float64(0.7853991591701261), np.float64(0.16357028929940762), np.float64(0.16356997348722394), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.46410161506949\n",
      "(change of -0.1368254602528456)\n",
      "Current ansatz: [225, 79, 228, 210, 147]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013629210882409932\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964056416012 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.000000000000001)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526199442337\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.4850710474292024)]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 147]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819699\n",
      "(change of -0.20417052920205947)\n",
      "Current ansatz: [244, 79, 228, 147]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531783\n",
      "Operator(s) added to ansatz: [135]\n",
      "Gradients: [np.float64(-2.089492926734874)]\n",
      "Initial energy: -6.327276154819699\n",
      "Optimizing energy with indices [244, 79, 228, 147, 135]...\n",
      "Starting point: [np.float64(0.7853981646904773), np.float64(0.7853981643651435), np.float64(0.16357019740836662), np.float64(-0.1635696366828739), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016151326465\n",
      "(change of -0.13682546031294773)\n",
      "Current ansatz: [244, 79, 228, 147, 135]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 3.3720329358920564e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531783 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [26]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 26]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000011\n",
      "(change of -1.7639320225002146)\n",
      "Current ansatz: [241, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113274\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0000000000000018)]\n",
      "Initial energy: -6.000000000000011\n",
      "Optimizing energy with indices [241, 26, 228]...\n",
      "Starting point: [np.float64(-0.7853981718257758), np.float64(0.7853981815917098), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.123105625617638\n",
      "(change of -0.12310562561762772)\n",
      "Current ansatz: [241, 26, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199441738\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.4850710474288693)]\n",
      "Initial energy: -6.123105625617638\n",
      "Optimizing energy with indices [241, 26, 228, 210]...\n",
      "Starting point: [np.float64(-0.7853981634447681), np.float64(0.7853981634524064), np.float64(0.12248927934332132), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819988\n",
      "(change of -0.2041705292023499)\n",
      "Current ansatz: [241, 26, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.24096404138126\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.089491643867201)]\n",
      "Initial energy: -6.327276154819988\n",
      "Optimizing energy with indices [241, 26, 228, 210, 198]...\n",
      "Starting point: [np.float64(-0.7853981604483139), np.float64(0.7853981623217249), np.float64(0.16357028648498867), np.float64(0.16356997194327816), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615071929\n",
      "(change of -0.13682546025194053)\n",
      "Current ansatz: [241, 26, 228, 210, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013555110317705658\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.24096404138126 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [74]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000004\n",
      "(change of -1.7639320225002084)\n",
      "Current ansatz: [241, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132728\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000027)]\n",
      "Initial energy: -6.000000000000004\n",
      "Optimizing energy with indices [241, 74, 225]...\n",
      "Starting point: [np.float64(-0.7853981634264042), np.float64(-0.7853981633494633), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617646\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [241, 74, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327169\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.485071048479704)]\n",
      "Initial energy: -6.123105625617646\n",
      "Optimizing energy with indices [241, 74, 225, 147]...\n",
      "Starting point: [np.float64(-0.785398163997711), np.float64(-0.7853981625399766), np.float64(-0.1224892796141143), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819985\n",
      "(change of -0.20417052920233836)\n",
      "Current ansatz: [241, 74, 225, 147]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964043282357\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.0894916421979004)]\n",
      "Initial energy: -6.327276154819985\n",
      "Optimizing energy with indices [241, 74, 225, 147, 210]...\n",
      "Starting point: [np.float64(-0.7853981486608416), np.float64(-0.7853981453038452), np.float64(-0.1635702866009366), np.float64(-0.16356997237953827), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016150129005\n",
      "(change of -0.13682546019291575)\n",
      "Current ansatz: [241, 74, 225, 147, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00016817881000671787\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964043282357 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002093)\n",
      "Current ansatz: [241, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132733\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(-2.0)]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [241, 79, 228]...\n",
      "Starting point: [np.float64(-0.785398171825775), np.float64(0.7853981815917083), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617642\n",
      "(change of -0.1231056256176366)\n",
      "Current ansatz: [241, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526199441697\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071047428846)]\n",
      "Initial energy: -6.123105625617642\n",
      "Optimizing energy with indices [241, 79, 228, 210]...\n",
      "Starting point: [np.float64(-0.785398162647287), np.float64(0.7853981641254796), np.float64(0.1224892793433147), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819982\n",
      "(change of -0.20417052920234013)\n",
      "Current ansatz: [241, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.24096404138082\n",
      "Operator(s) added to ansatz: [147]\n",
      "Gradients: [np.float64(2.0894916438682527)]\n",
      "Initial energy: -6.327276154819982\n",
      "Optimizing energy with indices [241, 79, 228, 210, 147]...\n",
      "Starting point: [np.float64(-0.7853982024976439), np.float64(0.7853981311150512), np.float64(0.1635702864850446), np.float64(0.16356997194303877), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614554787\n",
      "(change of -0.13682545973480487)\n",
      "Current ansatz: [241, 79, 228, 210, 147]\n",
      "Performing final convergence check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 0.00033002084338061577\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.24096404138082 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operator(s) added to ansatz: [244]\n",
      "Gradients: [np.float64(-4.000000000000005)]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operator(s) added to ansatz: [79]\n",
      "Gradients: [np.float64(-4.000000000000007)]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operator(s) added to ansatz: [225]\n",
      "Gradients: [np.float64(2.0000000000000018)]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 225]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.123105625617651\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 79, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199444833\n",
      "Operator(s) added to ansatz: [210]\n",
      "Gradients: [np.float64(-2.485071047430588)]\n",
      "Initial energy: -6.123105625617651\n",
      "Optimizing energy with indices [244, 79, 225, 210]...\n",
      "Starting point: [np.float64(0.7853981583089785), np.float64(0.785398168718093), np.float64(-0.12248927934376257), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819709\n",
      "(change of -0.20417052920205858)\n",
      "Current ansatz: [244, 79, 225, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580530028\n",
      "Operator(s) added to ansatz: [198]\n",
      "Gradients: [np.float64(2.089492926737891)]\n",
      "Initial energy: -6.327276154819709\n",
      "Optimizing energy with indices [244, 79, 225, 210, 198]...\n",
      "Starting point: [np.float64(0.7853981700346647), np.float64(0.7853981900506334), np.float64(-0.1635701974085294), np.float64(0.16356963668219085), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614835283\n",
      "(change of -0.13682546001557316)\n",
      "Current ansatz: [244, 79, 225, 210, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00027271975089248316\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580530028 > 1e-05)\n",
      "Pool will be tiled from 19 ops\n"
     ]
    }
   ],
   "source": [
    "max_mpo_bond = 300\n",
    "dmrg_mps_bond = 30\n",
    "adapt_mps_bond = 30\n",
    "l = 4\n",
    "\n",
    "j_xy = 1\n",
    "j_z = 1\n",
    "h = XXZHamiltonian(j_xy, j_z, l, diag_mode=\"quimb\", max_mpo_bond=max_mpo_bond, max_mps_bond=dmrg_mps_bond)\n",
    "dmrg_energy = h.ground_energy\n",
    "print(f\"Got DMRG energy {dmrg_energy:4.5e}\")\n",
    "pool = FullPauliPool(n=l, max_mpo_bond=max_mpo_bond)\n",
    "\n",
    "# Run 200 iterations of ADAPT-VQE for small problem instance, selecting randomly among degenerate gradients.\n",
    "# Form a list of all unique operators ever selected for this small instance.\n",
    "ixs = []\n",
    "for _ in range(30):\n",
    "    my_adapt = TensorNetAdapt(\n",
    "        pool=pool,\n",
    "        custom_hamiltonian=h,\n",
    "        verbose=False,\n",
    "        threshold=10**-5,\n",
    "        max_adapt_iter=5,\n",
    "        max_opt_iter=10000,\n",
    "        sel_criterion=\"gradient\",\n",
    "        recycle_hessian=False,\n",
    "        rand_degenerate=True,\n",
    "        max_mpo_bond=100,\n",
    "        max_mps_bond = 20\n",
    "    )\n",
    "    my_adapt.run()\n",
    "    data = my_adapt.data\n",
    "    for i in data.result.ansatz.indices:\n",
    "        if i not in ixs:\n",
    "            ixs.append(i)\n",
    "\n",
    "print(f\"Pool will be tiled from {len(ixs)} ops\")\n",
    "source_ops = [pool.operators[index].operator for index in ixs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f9939",
   "metadata": {},
   "source": [
    "## Run ADAPT at larger size to get a sequence of circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8a9715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neel_circuit(nq, start_zero=True):\n",
    "    circuit = QuantumCircuit(nq)\n",
    "    for i in range(nq):\n",
    "        if (i % 2 == 0 and start_zero) or (i % 2 != 0 and not start_zero):\n",
    "            circuit.x(i)\n",
    "        else:\n",
    "            circuit.id(i)\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fb433a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_l = 20\n",
      "No pre-computed energy for given parameters.\n",
      "Solving by DMRG with quimb.\n",
      "Got DMRG energy -3.47299e+01-5.15143e-14j\n",
      "Tiled pool has 261 operators.\n",
      "\n",
      "tensor-net-adapt prepared with the following settings:\n",
      "> Pool: tiled_pauli_pool\n",
      "> Custom Hamiltonian: XXZ_1_1\n",
      "> Orbital Optimization: False\n",
      "> Selection method: gradient\n",
      "> Convergence criterion: total_g_norm\n",
      "> Recycling Hessian: False\n",
      "> Tetris: False (progressive optimization: False)\n",
      "> Convergence threshold (gradient norm):  1e-05\n",
      "> Maximum number of iterations:  30\n",
      "> Candidates per iteration:  1\n",
      "> Swap-based circuits for LNN connectivity:  False\n",
      "> Qiskit-transpiler-based circuits for LNN connectivity:  False\n",
      "\n",
      "Initial energy: -19.00000000000003\n",
      "On iteration 0.\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -3.9999999999999996\n",
      "Operator 1: 4.000000000000045\n",
      "Operator 2: -4.000000000000009\n",
      "Operator 3: 3.99999999999999\n",
      "Operator 4: -4.000000000000025\n",
      "Operator 5: 4.000000000000014\n",
      "Operator 6: -4.00000000000002\n",
      "Operator 7: 4.0000000000000115\n",
      "Operator 8: -4.000000000000016\n",
      "Operator 9: 4.000000000000035\n",
      "Operator 10: -4.000000000000042\n",
      "Operator 11: 4.00000000000003\n",
      "Operator 12: -4.0000000000000515\n",
      "Operator 13: 4.00000000000003\n",
      "Operator 14: -4.000000000000028\n",
      "Operator 15: 4.000000000000019\n",
      "Operator 16: -4.000000000000017\n",
      "Operator 17: 4.000000000000009\n",
      "Operator 18: -4.000000000000006\n",
      "Operator 19: 3.9999999999999996\n",
      "Operator 20: -4.000000000000045\n",
      "Operator 21: 4.000000000000009\n",
      "Operator 22: -3.99999999999999\n",
      "Operator 23: 4.000000000000025\n",
      "Operator 24: -4.000000000000014\n",
      "Operator 25: 4.00000000000002\n",
      "Operator 26: -4.0000000000000115\n",
      "Operator 27: 4.000000000000016\n",
      "Operator 28: -4.000000000000035\n",
      "Operator 29: 4.000000000000042\n",
      "Operator 30: -4.00000000000003\n",
      "Operator 31: 4.0000000000000515\n",
      "Operator 32: -4.00000000000003\n",
      "Operator 33: 4.000000000000028\n",
      "Operator 34: 3.9999999999999996\n",
      "Operator 35: 4.000000000000045\n",
      "Operator 36: 4.000000000000009\n",
      "Operator 37: 3.99999999999999\n",
      "Operator 38: 4.000000000000025\n",
      "Operator 39: 4.000000000000014\n",
      "Operator 40: 4.00000000000002\n",
      "Operator 41: 4.0000000000000115\n",
      "Operator 42: 4.000000000000016\n",
      "Operator 43: 4.000000000000035\n",
      "Operator 44: 4.000000000000042\n",
      "Operator 45: 4.00000000000003\n",
      "Operator 46: 4.0000000000000515\n",
      "Operator 47: 4.00000000000003\n",
      "Operator 48: 4.000000000000028\n",
      "Operator 49: 4.000000000000019\n",
      "Operator 50: 4.000000000000017\n",
      "Operator 68: -4.000000000000006\n",
      "Operator 69: -3.9999999999999996\n",
      "Operator 70: -4.000000000000045\n",
      "Operator 71: -4.000000000000009\n",
      "Operator 72: -3.99999999999999\n",
      "Operator 73: -4.000000000000025\n",
      "Operator 74: -4.000000000000014\n",
      "Operator 75: -4.00000000000002\n",
      "Operator 76: -4.0000000000000115\n",
      "Operator 77: -4.000000000000016\n",
      "Operator 78: -4.000000000000035\n",
      "Operator 79: -4.000000000000042\n",
      "Operator 80: -4.00000000000003\n",
      "Operator 81: -4.0000000000000515\n",
      "Operator 82: -4.00000000000003\n",
      "Operator 83: -4.000000000000028\n",
      "Operator 84: -4.000000000000019\n",
      "Operator 85: 3.9999999999999996\n",
      "Operator 86: -4.000000000000045\n",
      "Operator 87: 4.000000000000009\n",
      "Operator 88: -3.99999999999999\n",
      "Operator 89: 4.000000000000025\n",
      "Operator 90: -4.000000000000014\n",
      "Operator 91: 4.00000000000002\n",
      "Operator 92: -4.0000000000000115\n",
      "Operator 93: 4.000000000000016\n",
      "Operator 94: -4.000000000000035\n",
      "Operator 95: 4.000000000000042\n",
      "Operator 96: -4.00000000000003\n",
      "Operator 97: 4.0000000000000515\n",
      "Operator 98: -4.00000000000003\n",
      "Operator 99: 4.000000000000028\n",
      "Operator 100: -4.000000000000019\n",
      "Operator 101: 4.000000000000017\n",
      "Operator 102: -4.000000000000009\n",
      "Operator 103: 4.000000000000006\n",
      "Operator 121: 4.000000000000006\n",
      "Operator 122: 3.9999999999999996\n",
      "Operator 123: 4.000000000000045\n",
      "Operator 124: 4.000000000000009\n",
      "Operator 125: 3.99999999999999\n",
      "Operator 126: 4.000000000000025\n",
      "Operator 127: 4.000000000000014\n",
      "Operator 128: 4.00000000000002\n",
      "Operator 129: 4.0000000000000115\n",
      "Operator 130: 4.000000000000016\n",
      "Operator 131: 4.000000000000035\n",
      "Operator 132: 4.000000000000042\n",
      "Operator 133: 4.00000000000003\n",
      "Operator 134: 4.0000000000000515\n",
      "Operator 135: 4.00000000000003\n",
      "Operator 136: 4.000000000000028\n",
      "Operator 137: 4.000000000000019\n",
      "Operator 138: -3.9999999999999996\n",
      "Operator 139: -4.000000000000045\n",
      "Operator 140: -4.000000000000009\n",
      "Operator 141: -3.99999999999999\n",
      "Operator 142: -4.000000000000025\n",
      "Operator 143: -4.000000000000014\n",
      "Operator 144: -4.00000000000002\n",
      "Operator 145: -4.0000000000000115\n",
      "Operator 146: -4.000000000000016\n",
      "Operator 147: -4.000000000000035\n",
      "Operator 148: -4.000000000000042\n",
      "Operator 149: -4.00000000000003\n",
      "Operator 150: -4.0000000000000515\n",
      "Operator 151: -4.00000000000003\n",
      "Operator 152: -4.000000000000028\n",
      "Operator 153: -4.000000000000019\n",
      "Operator 154: -4.000000000000017\n",
      "Operator 155: -4.000000000000006\n",
      "Operator 156: 4.000000000000009\n",
      "Operator 157: -4.000000000000006\n",
      "Operator 175: 4.000000000000006\n",
      "Operator 227: -4.000000000000009\n",
      "Operator 228: 4.000000000000006\n",
      "Operator 229: -3.9999999999999996\n",
      "Operator 230: 4.000000000000045\n",
      "Operator 231: -4.000000000000009\n",
      "Operator 232: 3.99999999999999\n",
      "Operator 233: -4.000000000000025\n",
      "Operator 234: 4.000000000000014\n",
      "Operator 235: -4.00000000000002\n",
      "Operator 236: 4.0000000000000115\n",
      "Operator 237: -4.000000000000016\n",
      "Operator 238: 4.000000000000035\n",
      "Operator 239: -4.000000000000042\n",
      "Operator 240: 4.00000000000003\n",
      "Operator 241: -4.0000000000000515\n",
      "Operator 242: 4.00000000000003\n",
      "Operator 243: -4.000000000000028\n",
      "Total gradient norm: 47.6655011512522\n",
      "Operators under consideration (1):\n",
      "[241]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.0000000000000515)]\n",
      "Operator(s) added to ansatz: [241]\n",
      "Gradients: [np.float64(-4.0000000000000515)]\n",
      "Initial energy: -19.00000000000003\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -19.828427\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "Current energy: -19.828427124746273\n",
      "(change of -0.8284271247462449)\n",
      "Current ansatz: [241]\n",
      "On iteration 1.\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -4.000000000000012\n",
      "Operator 1: 4.000000000000058\n",
      "Operator 2: -4.000000000000022\n",
      "Operator 3: 4.000000000000002\n",
      "Operator 4: -4.0000000000000355\n",
      "Operator 5: 4.000000000000023\n",
      "Operator 6: -4.000000000000029\n",
      "Operator 7: 4.000000000000021\n",
      "Operator 8: -4.000000000000025\n",
      "Operator 9: 4.000000000000044\n",
      "Operator 10: -4.0000000000000515\n",
      "Operator 11: 3.4142135623691967\n",
      "Operator 13: 3.4142135623691936\n",
      "Operator 14: -4.000000000000038\n",
      "Operator 15: 4.0000000000000275\n",
      "Operator 16: -4.000000000000023\n",
      "Operator 17: 4.000000000000021\n",
      "Operator 18: -4.000000000000018\n",
      "Operator 19: 4.000000000000012\n",
      "Operator 20: -4.000000000000058\n",
      "Operator 21: 4.000000000000022\n",
      "Operator 22: -4.000000000000002\n",
      "Operator 23: 4.0000000000000355\n",
      "Operator 24: -4.000000000000023\n",
      "Operator 25: 4.000000000000029\n",
      "Operator 26: -4.000000000000021\n",
      "Operator 27: 4.000000000000025\n",
      "Operator 28: -2.828427124738353\n",
      "Operator 29: 4.0000000000000515\n",
      "Operator 30: -3.4142135623691927\n",
      "Operator 32: -3.4142135623691936\n",
      "Operator 33: 4.000000000000038\n",
      "Operator 34: 4.000000000000012\n",
      "Operator 35: 4.000000000000058\n",
      "Operator 36: 4.000000000000022\n",
      "Operator 37: 4.000000000000002\n",
      "Operator 38: 4.0000000000000355\n",
      "Operator 39: 4.000000000000023\n",
      "Operator 40: 4.000000000000029\n",
      "Operator 41: 4.000000000000021\n",
      "Operator 42: 4.000000000000025\n",
      "Operator 43: 4.000000000000044\n",
      "Operator 44: 4.0000000000000515\n",
      "Operator 45: 3.4142135623691967\n",
      "Operator 47: 3.4142135623691914\n",
      "Operator 48: 2.8284271247383486\n",
      "Operator 49: 4.0000000000000275\n",
      "Operator 50: 4.000000000000023\n",
      "Operator 68: -4.000000000000018\n",
      "Operator 69: -4.000000000000012\n",
      "Operator 70: -4.000000000000058\n",
      "Operator 71: -4.000000000000022\n",
      "Operator 72: -4.000000000000002\n",
      "Operator 73: -4.0000000000000355\n",
      "Operator 74: -4.000000000000023\n",
      "Operator 75: -4.000000000000029\n",
      "Operator 76: -4.000000000000021\n",
      "Operator 77: -4.000000000000025\n",
      "Operator 78: -4.000000000000044\n",
      "Operator 79: -2.8284271247383583\n",
      "Operator 80: -3.4142135623691927\n",
      "Operator 82: -3.4142135623691936\n",
      "Operator 83: -4.000000000000038\n",
      "Operator 84: -4.0000000000000275\n",
      "Operator 85: 4.000000000000012\n",
      "Operator 86: -4.000000000000058\n",
      "Operator 87: 4.000000000000022\n",
      "Operator 88: -4.000000000000002\n",
      "Operator 89: 4.0000000000000355\n",
      "Operator 90: -4.000000000000023\n",
      "Operator 91: 4.000000000000029\n",
      "Operator 92: -4.000000000000021\n",
      "Operator 93: 4.000000000000025\n",
      "Operator 94: -4.000000000000044\n",
      "Operator 95: 4.0000000000000515\n",
      "Operator 96: -3.4142135623691927\n",
      "Operator 98: -3.4142135623691914\n",
      "Operator 99: 4.000000000000038\n",
      "Operator 100: -4.0000000000000275\n",
      "Operator 101: 4.000000000000023\n",
      "Operator 102: -4.000000000000021\n",
      "Operator 103: 4.000000000000018\n",
      "Operator 121: 4.000000000000018\n",
      "Operator 122: 4.000000000000012\n",
      "Operator 123: 4.000000000000058\n",
      "Operator 124: 4.000000000000022\n",
      "Operator 125: 4.000000000000002\n",
      "Operator 126: 4.0000000000000355\n",
      "Operator 127: 4.000000000000023\n",
      "Operator 128: 4.000000000000029\n",
      "Operator 129: 4.000000000000021\n",
      "Operator 130: 4.000000000000025\n",
      "Operator 131: 4.000000000000044\n",
      "Operator 132: 2.8284271247383583\n",
      "Operator 133: 3.4142135623691967\n",
      "Operator 135: 3.4142135623691914\n",
      "Operator 136: 4.000000000000038\n",
      "Operator 137: 4.0000000000000275\n",
      "Operator 138: -4.000000000000012\n",
      "Operator 139: -4.000000000000058\n",
      "Operator 140: -4.000000000000022\n",
      "Operator 141: -4.000000000000002\n",
      "Operator 142: -4.0000000000000355\n",
      "Operator 143: -4.000000000000023\n",
      "Operator 144: -4.000000000000029\n",
      "Operator 145: -4.000000000000021\n",
      "Operator 146: -4.000000000000025\n",
      "Operator 147: -4.000000000000044\n",
      "Operator 148: -4.0000000000000515\n",
      "Operator 149: -3.4142135623691927\n",
      "Operator 151: -3.4142135623691936\n",
      "Operator 152: -2.8284271247383486\n",
      "Operator 153: -4.0000000000000275\n",
      "Operator 154: -4.000000000000023\n",
      "Operator 155: -4.000000000000018\n",
      "Operator 156: 4.000000000000021\n",
      "Operator 157: -4.000000000000018\n",
      "Operator 175: 4.000000000000018\n",
      "Operator 188: 1.41421356237704\n",
      "Operator 189: -1.414213562377042\n",
      "Operator 206: 1.41421356237704\n",
      "Operator 207: -1.414213562377042\n",
      "Operator 222: -1.4142135623770455\n",
      "Operator 223: 1.4142135623770424\n",
      "Operator 227: -4.000000000000021\n",
      "Operator 228: 4.000000000000018\n",
      "Operator 229: -4.000000000000012\n",
      "Operator 230: 4.000000000000058\n",
      "Operator 231: -4.000000000000022\n",
      "Operator 232: 4.000000000000002\n",
      "Operator 233: -4.0000000000000355\n",
      "Operator 234: 4.000000000000023\n",
      "Operator 235: -4.000000000000029\n",
      "Operator 236: 4.000000000000021\n",
      "Operator 237: -4.000000000000025\n",
      "Operator 238: 2.828427124738353\n",
      "Operator 239: -4.0000000000000515\n",
      "Operator 240: 3.4142135623691967\n",
      "Operator 242: 3.4142135623691914\n",
      "Operator 243: -4.000000000000038\n",
      "Operator 256: 1.41421356237704\n",
      "Operator 257: -1.414213562377042\n",
      "Total gradient norm: 45.194133114723\n",
      "Operators under consideration (1):\n",
      "[243]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000038)]\n",
      "Operator(s) added to ansatz: [243]\n",
      "Gradients: [np.float64(-4.000000000000038)]\n",
      "Initial energy: -19.828427124746273\n",
      "Optimizing energy with indices [241, 243]...\n",
      "Starting point: [np.float64(0.39269908170011525), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -20.763298\n",
      "         Iterations: 6\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "\n",
      "Current energy: -20.763297828554666\n",
      "(change of -0.934870703808393)\n",
      "Current ansatz: [241, 243]\n",
      "On iteration 2.\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -4.00000000000001\n",
      "Operator 1: 4.000000000000055\n",
      "Operator 2: -4.000000000000021\n",
      "Operator 3: 4.000000000000001\n",
      "Operator 4: -4.0000000000000355\n",
      "Operator 5: 4.000000000000023\n",
      "Operator 6: -4.0000000000000275\n",
      "Operator 7: 4.000000000000019\n",
      "Operator 8: -4.000000000000022\n",
      "Operator 9: 4.000000000000043\n",
      "Operator 10: -4.00000000000005\n",
      "Operator 11: 3.264585445627358\n",
      "Operator 13: 2.529170891255627\n",
      "Operator 15: 3.2645854456282977\n",
      "Operator 16: -4.0000000000000195\n",
      "Operator 17: 4.0000000000000195\n",
      "Operator 18: -4.000000000000017\n",
      "Operator 19: 4.00000000000001\n",
      "Operator 20: -4.000000000000055\n",
      "Operator 21: 4.000000000000021\n",
      "Operator 22: -4.000000000000001\n",
      "Operator 23: 4.0000000000000355\n",
      "Operator 24: -4.000000000000023\n",
      "Operator 25: 4.0000000000000275\n",
      "Operator 26: -4.000000000000019\n",
      "Operator 27: 4.000000000000022\n",
      "Operator 28: -2.529170891254677\n",
      "Operator 29: 4.00000000000005\n",
      "Operator 30: -2.06417362027513\n",
      "Operator 32: -2.7995881746468565\n",
      "Operator 34: 4.00000000000001\n",
      "Operator 35: 4.000000000000055\n",
      "Operator 36: 4.000000000000021\n",
      "Operator 37: 4.000000000000001\n",
      "Operator 38: 4.0000000000000355\n",
      "Operator 39: 4.000000000000023\n",
      "Operator 40: 4.0000000000000275\n",
      "Operator 41: 4.000000000000019\n",
      "Operator 42: 4.000000000000022\n",
      "Operator 43: 4.000000000000043\n",
      "Operator 44: 4.00000000000005\n",
      "Operator 45: 3.264585445627358\n",
      "Operator 47: 2.799588174646858\n",
      "Operator 48: -0.9299945419594451\n",
      "Operator 49: 3.2645854456282994\n",
      "Operator 50: 2.529170891256571\n",
      "Operator 65: 1.200411825353176\n",
      "Operator 68: -4.000000000000017\n",
      "Operator 69: -4.00000000000001\n",
      "Operator 70: -4.000000000000055\n",
      "Operator 71: -4.000000000000021\n",
      "Operator 72: -4.000000000000001\n",
      "Operator 73: -4.0000000000000355\n",
      "Operator 74: -4.000000000000023\n",
      "Operator 75: -4.0000000000000275\n",
      "Operator 76: -4.000000000000019\n",
      "Operator 77: -4.000000000000022\n",
      "Operator 78: -4.000000000000043\n",
      "Operator 79: -2.5291708912546813\n",
      "Operator 80: -3.264585445627354\n",
      "Operator 81: 0.929994541961453\n",
      "Operator 82: -2.7995881746468565\n",
      "Operator 84: -3.2645854456282977\n",
      "Operator 85: 4.00000000000001\n",
      "Operator 86: -4.000000000000055\n",
      "Operator 87: 4.000000000000021\n",
      "Operator 88: -4.000000000000001\n",
      "Operator 89: 4.0000000000000355\n",
      "Operator 90: -4.000000000000023\n",
      "Operator 91: 4.0000000000000275\n",
      "Operator 92: -4.000000000000019\n",
      "Operator 93: 4.000000000000022\n",
      "Operator 94: -4.000000000000043\n",
      "Operator 95: 4.00000000000005\n",
      "Operator 96: -3.264585445627354\n",
      "Operator 98: -2.529170891255626\n",
      "Operator 100: -3.2645854456282994\n",
      "Operator 101: 4.0000000000000195\n",
      "Operator 102: -4.0000000000000195\n",
      "Operator 103: 4.000000000000017\n",
      "Operator 118: 1.2004118253531757\n",
      "Operator 121: 4.000000000000017\n",
      "Operator 122: 4.00000000000001\n",
      "Operator 123: 4.000000000000055\n",
      "Operator 124: 4.000000000000021\n",
      "Operator 125: 4.000000000000001\n",
      "Operator 126: 4.0000000000000355\n",
      "Operator 127: 4.000000000000023\n",
      "Operator 128: 4.0000000000000275\n",
      "Operator 129: 4.000000000000019\n",
      "Operator 130: 4.000000000000022\n",
      "Operator 131: 4.000000000000043\n",
      "Operator 132: 2.5291708912546813\n",
      "Operator 133: 3.264585445627358\n",
      "Operator 134: -0.929994541961453\n",
      "Operator 135: 2.7995881746468574\n",
      "Operator 137: 3.2645854456282994\n",
      "Operator 138: -4.00000000000001\n",
      "Operator 139: -4.000000000000055\n",
      "Operator 140: -4.000000000000021\n",
      "Operator 141: -4.000000000000001\n",
      "Operator 142: -4.0000000000000355\n",
      "Operator 143: -4.000000000000023\n",
      "Operator 144: -4.0000000000000275\n",
      "Operator 145: -4.000000000000019\n",
      "Operator 146: -4.000000000000022\n",
      "Operator 147: -4.000000000000043\n",
      "Operator 148: -4.00000000000005\n",
      "Operator 149: -3.264585445627354\n",
      "Operator 151: -2.799588174646857\n",
      "Operator 152: 0.9299945419594451\n",
      "Operator 153: -3.2645854456282977\n",
      "Operator 154: -2.529170891256571\n",
      "Operator 155: -4.000000000000017\n",
      "Operator 156: 4.0000000000000195\n",
      "Operator 157: -4.000000000000017\n",
      "Operator 172: -1.200411825353175\n",
      "Operator 175: 4.000000000000017\n",
      "Operator 188: 1.5494591478020883\n",
      "Operator 189: -1.54945914780209\n",
      "Operator 190: 1.5494591478013098\n",
      "Operator 191: -1.5494591478013104\n",
      "Operator 206: 0.9797117434530583\n",
      "Operator 207: -1.5494591478020898\n",
      "Operator 208: 0.9797117434518283\n",
      "Operator 209: -1.5494591478013104\n",
      "Operator 222: -1.5494591478020947\n",
      "Operator 223: 0.9797117434530611\n",
      "Operator 224: -1.5494591478013118\n",
      "Operator 225: 0.9797117434518241\n",
      "Operator 227: -4.0000000000000195\n",
      "Operator 228: 4.000000000000017\n",
      "Operator 229: -4.00000000000001\n",
      "Operator 230: 4.000000000000055\n",
      "Operator 231: -4.000000000000021\n",
      "Operator 232: 4.000000000000001\n",
      "Operator 233: -4.0000000000000355\n",
      "Operator 234: 4.000000000000023\n",
      "Operator 235: -4.0000000000000275\n",
      "Operator 236: 4.000000000000019\n",
      "Operator 237: -4.000000000000022\n",
      "Operator 238: 2.529170891254677\n",
      "Operator 239: -4.00000000000005\n",
      "Operator 240: 2.064173620275133\n",
      "Operator 242: 2.7995881746468574\n",
      "Operator 256: 1.5494591478020883\n",
      "Operator 257: -0.9797117434530602\n",
      "Operator 258: 1.54945914780131\n",
      "Operator 259: -0.9797117434518281\n",
      "Total gradient norm: 42.897102723451475\n",
      "Operators under consideration (1):\n",
      "[239]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.00000000000005)]\n",
      "Operator(s) added to ansatz: [239]\n",
      "Gradients: [np.float64(-4.00000000000005)]\n",
      "Initial energy: -20.763297828554666\n",
      "Optimizing energy with indices [241, 243, 239]...\n",
      "Starting point: [np.float64(0.44314364578043697), np.float64(0.4431436457801288), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -21.732445\n",
      "         Iterations: 7\n",
      "         Function evaluations: 52\n",
      "         Gradient evaluations: 42\n",
      "\n",
      "Current energy: -21.732444564744416\n",
      "(change of -0.9691467361897494)\n",
      "Current ansatz: [241, 243, 239]\n",
      "On iteration 3.\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -4.0000000000000115\n",
      "Operator 1: 4.000000000000058\n",
      "Operator 2: -4.00000000000002\n",
      "Operator 3: 4.000000000000001\n",
      "Operator 4: -4.000000000000035\n",
      "Operator 5: 4.000000000000021\n",
      "Operator 6: -4.000000000000028\n",
      "Operator 7: 4.000000000000018\n",
      "Operator 8: -4.000000000000022\n",
      "Operator 9: 3.2087802173415625\n",
      "Operator 11: 2.2432916638530482\n",
      "Operator 13: 2.2432916579340274\n",
      "Operator 14: 1.4624371047489149e-08\n",
      "Operator 15: 3.2087802114225283\n",
      "Operator 16: -4.000000000000013\n",
      "Operator 17: 4.0000000000000195\n",
      "Operator 18: -4.000000000000019\n",
      "Operator 19: 4.0000000000000115\n",
      "Operator 20: -4.000000000000058\n",
      "Operator 21: 4.00000000000002\n",
      "Operator 22: -4.000000000000001\n",
      "Operator 23: 4.000000000000035\n",
      "Operator 24: -4.000000000000021\n",
      "Operator 25: 4.000000000000028\n",
      "Operator 26: -2.4175604346830717\n",
      "Operator 27: 4.000000000000022\n",
      "Operator 28: -1.659759932089743\n",
      "Operator 30: -1.5866742097169593\n",
      "Operator 32: -2.625248482516607\n",
      "Operator 33: -1.4624371047489149e-08\n",
      "Operator 34: 4.0000000000000115\n",
      "Operator 35: 4.000000000000058\n",
      "Operator 36: 4.00000000000002\n",
      "Operator 37: 4.000000000000001\n",
      "Operator 38: 4.000000000000035\n",
      "Operator 39: 4.000000000000021\n",
      "Operator 40: 4.000000000000028\n",
      "Operator 41: 4.000000000000018\n",
      "Operator 42: 4.000000000000022\n",
      "Operator 43: 3.2087802173415625\n",
      "Operator 45: 2.6252484855782554\n",
      "Operator 46: -1.0864133001466045\n",
      "Operator 47: 2.625248482516608\n",
      "Operator 48: -1.16706347243624\n",
      "Operator 49: 3.2087802114225314\n",
      "Operator 50: 2.417560422845038\n",
      "Operator 63: 1.3636612929603749\n",
      "Operator 65: 1.3636612968033364\n",
      "Operator 68: -4.000000000000019\n",
      "Operator 69: -4.0000000000000115\n",
      "Operator 70: -4.000000000000058\n",
      "Operator 71: -4.00000000000002\n",
      "Operator 72: -4.000000000000001\n",
      "Operator 73: -4.000000000000035\n",
      "Operator 74: -4.000000000000021\n",
      "Operator 75: -4.000000000000028\n",
      "Operator 76: -4.000000000000018\n",
      "Operator 77: -2.417560434683073\n",
      "Operator 78: -3.20878021734156\n",
      "Operator 79: 1.1670634594999676\n",
      "Operator 80: -2.6252484855782554\n",
      "Operator 81: 1.086413306269896\n",
      "Operator 82: -2.625248482516607\n",
      "Operator 83: 1.4624371047489149e-08\n",
      "Operator 84: -3.2087802114225283\n",
      "Operator 85: 4.0000000000000115\n",
      "Operator 86: -4.000000000000058\n",
      "Operator 87: 4.000000000000022\n",
      "Operator 88: -4.000000000000001\n",
      "Operator 89: 4.000000000000035\n",
      "Operator 90: -4.000000000000021\n",
      "Operator 91: 4.000000000000028\n",
      "Operator 92: -4.000000000000018\n",
      "Operator 93: 4.000000000000022\n",
      "Operator 94: -3.20878021734156\n",
      "Operator 96: -2.2432916638530407\n",
      "Operator 98: -2.243291657934026\n",
      "Operator 99: -1.4624371047489149e-08\n",
      "Operator 100: -3.2087802114225314\n",
      "Operator 101: 4.000000000000013\n",
      "Operator 102: -4.0000000000000195\n",
      "Operator 103: 4.000000000000019\n",
      "Operator 116: 1.3636612929603749\n",
      "Operator 118: 1.3636612968033364\n",
      "Operator 121: 4.000000000000018\n",
      "Operator 122: 4.0000000000000115\n",
      "Operator 123: 4.000000000000058\n",
      "Operator 124: 4.000000000000022\n",
      "Operator 125: 4.000000000000001\n",
      "Operator 126: 4.000000000000035\n",
      "Operator 127: 4.000000000000021\n",
      "Operator 128: 4.000000000000028\n",
      "Operator 129: 4.000000000000018\n",
      "Operator 130: 2.417560434683073\n",
      "Operator 131: 3.2087802173415625\n",
      "Operator 132: -1.1670634594999676\n",
      "Operator 133: 2.6252484855782554\n",
      "Operator 134: -1.0864133062698944\n",
      "Operator 135: 2.625248482516608\n",
      "Operator 136: -1.4624371047489149e-08\n",
      "Operator 137: 3.2087802114225314\n",
      "Operator 138: -4.0000000000000115\n",
      "Operator 139: -4.000000000000058\n",
      "Operator 140: -4.000000000000022\n",
      "Operator 141: -4.000000000000001\n",
      "Operator 142: -4.000000000000035\n",
      "Operator 143: -4.000000000000021\n",
      "Operator 144: -4.000000000000028\n",
      "Operator 145: -4.000000000000018\n",
      "Operator 146: -4.000000000000022\n",
      "Operator 147: -3.20878021734156\n",
      "Operator 149: -2.6252484855782554\n",
      "Operator 150: 1.0864133001466045\n",
      "Operator 151: -2.625248482516607\n",
      "Operator 152: 1.16706347243624\n",
      "Operator 153: -3.2087802114225283\n",
      "Operator 154: -2.417560422845038\n",
      "Operator 155: -4.000000000000018\n",
      "Operator 156: 4.0000000000000195\n",
      "Operator 157: -4.000000000000018\n",
      "Operator 170: -1.3636612929603755\n",
      "Operator 172: -1.3636612968033353\n",
      "Operator 175: 4.000000000000019\n",
      "Operator 186: 1.5933770382943888\n",
      "Operator 187: -1.5933770382943881\n",
      "Operator 188: 1.7116617852358385\n",
      "Operator 189: -1.711661785235838\n",
      "Operator 190: 1.5933770427847178\n",
      "Operator 191: -1.5933770427847191\n",
      "Operator 204: 0.8241833923620645\n",
      "Operator 205: -1.5933770382943881\n",
      "Operator 206: 0.6252484860672511\n",
      "Operator 207: -1.7116617852358382\n",
      "Operator 208: 0.8241833946847139\n",
      "Operator 209: -1.5933770427847185\n",
      "Operator 220: -1.5933770382943944\n",
      "Operator 221: 0.8241833923620694\n",
      "Operator 222: -1.711661785235842\n",
      "Operator 223: 0.6252484860672542\n",
      "Operator 224: -1.5933770427847198\n",
      "Operator 225: 0.8241833946847105\n",
      "Operator 227: -4.0000000000000195\n",
      "Operator 228: 4.000000000000018\n",
      "Operator 229: -4.0000000000000115\n",
      "Operator 230: 4.000000000000058\n",
      "Operator 231: -4.000000000000022\n",
      "Operator 232: 4.000000000000001\n",
      "Operator 233: -4.000000000000035\n",
      "Operator 234: 4.000000000000021\n",
      "Operator 235: -4.000000000000028\n",
      "Operator 236: 2.4175604346830717\n",
      "Operator 237: -4.000000000000022\n",
      "Operator 238: 1.6597599320897443\n",
      "Operator 240: 1.586674209716959\n",
      "Operator 242: 2.625248482516608\n",
      "Operator 243: 1.4624371047489149e-08\n",
      "Operator 254: 1.5933770382943888\n",
      "Operator 255: -0.8241833923620607\n",
      "Operator 256: 1.7116617852358385\n",
      "Operator 257: -0.6252484860672533\n",
      "Operator 258: 1.5933770427847178\n",
      "Operator 259: -0.8241833946847138\n",
      "Total gradient norm: 40.45774222441775\n",
      "Operators under consideration (1):\n",
      "[234]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000021)]\n",
      "Operator(s) added to ansatz: [234]\n",
      "Gradients: [np.float64(4.000000000000021)]\n",
      "Initial energy: -21.732444564744416\n",
      "Optimizing energy with indices [241, 243, 239, 234]...\n",
      "Starting point: [np.float64(0.5135775295451557), np.float64(0.4608981092770127), np.float64(0.46089810741963144), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -22.560872\n",
      "         Iterations: 4\n",
      "         Function evaluations: 35\n",
      "         Gradient evaluations: 23\n",
      "\n",
      "Current energy: -22.560871689490625\n",
      "(change of -0.8284271247462094)\n",
      "Current ansatz: [241, 243, 239, 234]\n",
      "On iteration 4.\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -4.0000000000000195\n",
      "Operator 1: 4.000000000000066\n",
      "Operator 2: -4.000000000000032\n",
      "Operator 3: 4.000000000000009\n",
      "Operator 4: -3.414213562370371\n",
      "Operator 6: -3.4142135623703638\n",
      "Operator 7: 4.000000000000026\n",
      "Operator 8: -4.000000000000033\n",
      "Operator 9: 3.208780235136122\n",
      "Operator 10: 1.6958944741490096e-07\n",
      "Operator 11: 2.243291969950114\n",
      "Operator 12: -7.181600257810672e-07\n",
      "Operator 13: 2.2432920013392468\n",
      "Operator 14: 7.068126528508856e-08\n",
      "Operator 15: 3.2087802665252374\n",
      "Operator 16: -4.000000000000023\n",
      "Operator 17: 4.000000000000028\n",
      "Operator 18: -4.000000000000026\n",
      "Operator 19: 4.0000000000000195\n",
      "Operator 20: -4.000000000000066\n",
      "Operator 21: 2.828427124740685\n",
      "Operator 22: -4.000000000000009\n",
      "Operator 23: 3.4142135623703673\n",
      "Operator 25: 3.4142135623703638\n",
      "Operator 26: -2.417560470272176\n",
      "Operator 27: 4.000000000000033\n",
      "Operator 28: -1.6597604038437805\n",
      "Operator 29: -1.6958944741490096e-07\n",
      "Operator 30: -1.5866743929223959\n",
      "Operator 31: 7.18160024226755e-07\n",
      "Operator 32: -2.6252486852659933\n",
      "Operator 33: -7.068126528508856e-08\n",
      "Operator 34: 4.0000000000000195\n",
      "Operator 35: 4.000000000000066\n",
      "Operator 36: 4.000000000000032\n",
      "Operator 37: 4.000000000000009\n",
      "Operator 38: 3.414213562370371\n",
      "Operator 40: 3.4142135623703602\n",
      "Operator 41: 2.828427124740682\n",
      "Operator 42: 4.000000000000033\n",
      "Operator 43: 3.208780235136122\n",
      "Operator 44: -1.6958944741490096e-07\n",
      "Operator 45: 2.625248669029783\n",
      "Operator 46: -1.0864127330525528\n",
      "Operator 47: 2.625248685265996\n",
      "Operator 48: -1.1670632331997712\n",
      "Operator 49: 3.2087802665252405\n",
      "Operator 50: 2.417560533050448\n",
      "Operator 63: 1.3636611425863814\n",
      "Operator 65: 1.3636611222067592\n",
      "Operator 68: -4.000000000000026\n",
      "Operator 69: -4.0000000000000195\n",
      "Operator 70: -4.000000000000066\n",
      "Operator 71: -4.000000000000032\n",
      "Operator 72: -2.828427124740669\n",
      "Operator 73: -3.4142135623703673\n",
      "Operator 75: -3.4142135623703638\n",
      "Operator 76: -4.000000000000026\n",
      "Operator 77: -2.417560470272179\n",
      "Operator 78: -3.2087802351361177\n",
      "Operator 79: 1.167063301802118\n",
      "Operator 80: -2.6252486690297836\n",
      "Operator 81: 1.0864127005801203\n",
      "Operator 82: -2.6252486852659933\n",
      "Operator 83: 7.068126528508856e-08\n",
      "Operator 84: -3.2087802665252374\n",
      "Operator 85: 4.0000000000000195\n",
      "Operator 86: -4.000000000000066\n",
      "Operator 87: 4.000000000000032\n",
      "Operator 88: -4.000000000000009\n",
      "Operator 89: 3.4142135623703673\n",
      "Operator 91: 3.4142135623703602\n",
      "Operator 92: -4.000000000000026\n",
      "Operator 93: 4.000000000000033\n",
      "Operator 94: -3.2087802351361177\n",
      "Operator 95: -1.6958944741490096e-07\n",
      "Operator 96: -2.243291969950108\n",
      "Operator 97: 7.181600257810672e-07\n",
      "Operator 98: -2.2432920013392454\n",
      "Operator 99: -7.068126528508856e-08\n",
      "Operator 100: -3.2087802665252405\n",
      "Operator 101: 4.000000000000023\n",
      "Operator 102: -4.000000000000028\n",
      "Operator 103: 4.000000000000026\n",
      "Operator 116: 1.3636611425863814\n",
      "Operator 118: 1.363661122206759\n",
      "Operator 121: 4.000000000000026\n",
      "Operator 122: 4.0000000000000195\n",
      "Operator 123: 4.000000000000066\n",
      "Operator 124: 4.000000000000032\n",
      "Operator 125: 2.828427124740669\n",
      "Operator 126: 3.414213562370371\n",
      "Operator 128: 3.4142135623703602\n",
      "Operator 129: 4.000000000000026\n",
      "Operator 130: 2.417560470272179\n",
      "Operator 131: 3.208780235136122\n",
      "Operator 132: -1.167063301802118\n",
      "Operator 133: 2.625248669029783\n",
      "Operator 134: -1.0864127005801203\n",
      "Operator 135: 2.625248685265996\n",
      "Operator 136: -7.068126528508856e-08\n",
      "Operator 137: 3.2087802665252405\n",
      "Operator 138: -4.0000000000000195\n",
      "Operator 139: -4.000000000000066\n",
      "Operator 140: -4.000000000000032\n",
      "Operator 141: -4.000000000000009\n",
      "Operator 142: -3.4142135623703673\n",
      "Operator 144: -3.4142135623703638\n",
      "Operator 145: -2.828427124740682\n",
      "Operator 146: -4.000000000000033\n",
      "Operator 147: -3.2087802351361177\n",
      "Operator 148: 1.6958944741490096e-07\n",
      "Operator 149: -2.6252486690297836\n",
      "Operator 150: 1.0864127330525528\n",
      "Operator 151: -2.625248685265994\n",
      "Operator 152: 1.1670632331997712\n",
      "Operator 153: -3.2087802665252374\n",
      "Operator 154: -2.417560533050448\n",
      "Operator 155: -4.000000000000026\n",
      "Operator 156: 4.000000000000028\n",
      "Operator 157: -4.000000000000026\n",
      "Operator 170: -1.3636611425863827\n",
      "Operator 172: -1.363661122206758\n",
      "Operator 175: 4.000000000000026\n",
      "Operator 181: 1.414213562375871\n",
      "Operator 182: -1.4142135623758698\n",
      "Operator 186: 1.5933770247949515\n",
      "Operator 187: -1.59337702479495\n",
      "Operator 188: 1.7116616109886242\n",
      "Operator 189: -1.7116616109886231\n",
      "Operator 190: 1.593377000982275\n",
      "Operator 191: -1.5933770009822756\n",
      "Operator 199: 1.414213562375871\n",
      "Operator 200: -1.4142135623758698\n",
      "Operator 204: 0.8241836150667027\n",
      "Operator 205: -1.59337702479495\n",
      "Operator 206: 0.6252484601234564\n",
      "Operator 207: -1.7116616109886236\n",
      "Operator 208: 0.8241836027494567\n",
      "Operator 209: -1.5933770009822756\n",
      "Operator 215: -1.4142135623758811\n",
      "Operator 216: 1.4142135623758751\n",
      "Operator 220: -1.593377024794958\n",
      "Operator 221: 0.8241836150667068\n",
      "Operator 222: -1.7116616109886278\n",
      "Operator 223: 0.6252484601234591\n",
      "Operator 224: -1.5933770009822772\n",
      "Operator 225: 0.8241836027494536\n",
      "Operator 227: -4.000000000000028\n",
      "Operator 228: 4.000000000000026\n",
      "Operator 229: -4.0000000000000195\n",
      "Operator 230: 4.000000000000066\n",
      "Operator 231: -2.828427124740685\n",
      "Operator 232: 4.000000000000009\n",
      "Operator 233: -3.414213562370371\n",
      "Operator 235: -3.4142135623703602\n",
      "Operator 236: 2.417560470272176\n",
      "Operator 237: -4.000000000000033\n",
      "Operator 238: 1.659760403843783\n",
      "Operator 239: 1.6958944741490096e-07\n",
      "Operator 240: 1.5866743929223954\n",
      "Operator 241: -7.18160024226755e-07\n",
      "Operator 242: 2.625248685265996\n",
      "Operator 243: 7.068126528508856e-08\n",
      "Operator 249: 1.414213562375871\n",
      "Operator 250: -1.4142135623758698\n",
      "Operator 254: 1.5933770247949515\n",
      "Operator 255: -0.8241836150666982\n",
      "Operator 256: 1.7116616109886242\n",
      "Operator 257: -0.6252484601234585\n",
      "Operator 258: 1.593377000982275\n",
      "Operator 259: -0.8241836027494567\n",
      "Total gradient norm: 37.51451169045819\n",
      "Operators under consideration (1):\n",
      "[232]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000009)]\n",
      "Operator(s) added to ansatz: [232]\n",
      "Gradients: [np.float64(4.000000000000009)]\n",
      "Initial energy: -22.560871689490625\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232]...\n",
      "Starting point: [np.float64(0.5135774453280143), np.float64(0.460898091985844), np.float64(0.46089810183572044), np.float64(-0.39269908169970147), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -23.495742\n",
      "         Iterations: 11\n",
      "         Function evaluations: 16\n",
      "         Gradient evaluations: 16\n",
      "\n",
      "Current energy: -23.495742393298755\n",
      "(change of -0.9348707038081301)\n",
      "Current ansatz: [241, 243, 239, 234, 232]\n",
      "On iteration 5.\n",
      "\n",
      "*** ADAPT-VQE Iteration 6 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -3.999999999999969\n",
      "Operator 1: 4.000000000000015\n",
      "Operator 2: -3.2645854456159085\n",
      "Operator 4: -2.5291708912089614\n",
      "Operator 6: -3.2645854455930303\n",
      "Operator 7: 3.9999999999999774\n",
      "Operator 8: -3.9999999999999862\n",
      "Operator 9: 3.208780217241749\n",
      "Operator 11: 2.2432916680407446\n",
      "Operator 13: 2.243291667981767\n",
      "Operator 15: 3.2087802171827553\n",
      "Operator 16: -3.999999999999976\n",
      "Operator 17: 3.9999999999999787\n",
      "Operator 18: -3.999999999999977\n",
      "Operator 19: 2.529170891231823\n",
      "Operator 20: -4.000000000000015\n",
      "Operator 21: 2.0641736202103718\n",
      "Operator 23: 2.799588174617337\n",
      "Operator 25: 3.2645854455930303\n",
      "Operator 26: -2.417560434483473\n",
      "Operator 27: 3.9999999999999862\n",
      "Operator 28: -1.659759938916941\n",
      "Operator 30: -1.5866742188129743\n",
      "Operator 32: -2.6252484880874327\n",
      "Operator 34: 3.999999999999969\n",
      "Operator 35: 4.000000000000015\n",
      "Operator 36: 3.2645854456159085\n",
      "Operator 38: 2.799588174617339\n",
      "Operator 39: -0.9299945420565623\n",
      "Operator 40: 3.2645854455930285\n",
      "Operator 41: 2.5291708911860664\n",
      "Operator 42: 3.9999999999999862\n",
      "Operator 43: 3.208780217241749\n",
      "Operator 45: 2.6252484881179416\n",
      "Operator 46: -1.0864132944571845\n",
      "Operator 47: 2.6252484880874336\n",
      "Operator 48: -1.1670634580800892\n",
      "Operator 49: 3.2087802171827584\n",
      "Operator 50: 2.4175604343655297\n",
      "Operator 56: 1.2004118253826563\n",
      "Operator 63: 1.3636612909606713\n",
      "Operator 65: 1.363661290998957\n",
      "Operator 68: -3.999999999999977\n",
      "Operator 69: -3.999999999999969\n",
      "Operator 70: -2.5291708912318533\n",
      "Operator 71: -3.2645854456159062\n",
      "Operator 72: 0.9299945420083945\n",
      "Operator 73: -2.799588174617337\n",
      "Operator 75: -3.2645854455930303\n",
      "Operator 76: -3.9999999999999774\n",
      "Operator 77: -2.4175604344834776\n",
      "Operator 78: -3.2087802172417454\n",
      "Operator 79: 1.1670634579511971\n",
      "Operator 80: -2.6252484881179416\n",
      "Operator 81: 1.0864132945181886\n",
      "Operator 82: -2.6252484880874327\n",
      "Operator 84: -3.2087802171827553\n",
      "Operator 85: 3.999999999999967\n",
      "Operator 86: -4.000000000000015\n",
      "Operator 87: 3.2645854456159062\n",
      "Operator 89: 2.529170891208955\n",
      "Operator 91: 3.2645854455930285\n",
      "Operator 92: -3.9999999999999774\n",
      "Operator 93: 3.9999999999999862\n",
      "Operator 94: -3.2087802172417454\n",
      "Operator 96: -2.243291668040738\n",
      "Operator 98: -2.2432916679817656\n",
      "Operator 100: -3.2087802171827584\n",
      "Operator 101: 3.999999999999976\n",
      "Operator 102: -3.9999999999999787\n",
      "Operator 103: 3.999999999999977\n",
      "Operator 109: 1.2004118253826563\n",
      "Operator 116: 1.3636612909606713\n",
      "Operator 118: 1.363661290998957\n",
      "Operator 121: 3.9999999999999765\n",
      "Operator 122: 3.999999999999967\n",
      "Operator 123: 2.5291708912318533\n",
      "Operator 124: 3.2645854456159085\n",
      "Operator 125: -0.9299945420083953\n",
      "Operator 126: 2.799588174617339\n",
      "Operator 128: 3.2645854455930285\n",
      "Operator 129: 3.9999999999999774\n",
      "Operator 130: 2.4175604344834776\n",
      "Operator 131: 3.208780217241749\n",
      "Operator 132: -1.1670634579511971\n",
      "Operator 133: 2.6252484881179416\n",
      "Operator 134: -1.086413294518189\n",
      "Operator 135: 2.625248488087434\n",
      "Operator 137: 3.2087802171827584\n",
      "Operator 138: -3.999999999999967\n",
      "Operator 139: -4.000000000000015\n",
      "Operator 140: -3.2645854456159062\n",
      "Operator 142: -2.799588174617337\n",
      "Operator 143: 0.9299945420565623\n",
      "Operator 144: -3.2645854455930303\n",
      "Operator 145: -2.5291708911860664\n",
      "Operator 146: -3.9999999999999862\n",
      "Operator 147: -3.2087802172417454\n",
      "Operator 149: -2.6252484881179416\n",
      "Operator 150: 1.0864132944571845\n",
      "Operator 151: -2.6252484880874327\n",
      "Operator 152: 1.1670634580800892\n",
      "Operator 153: -3.2087802171827553\n",
      "Operator 154: -2.4175604343655297\n",
      "Operator 155: -3.9999999999999765\n",
      "Operator 156: 3.9999999999999787\n",
      "Operator 157: -3.9999999999999765\n",
      "Operator 163: -1.2004118253826555\n",
      "Operator 170: -1.3636612909606722\n",
      "Operator 172: -1.363661290998956\n",
      "Operator 175: 3.999999999999977\n",
      "Operator 179: 1.5494591478113788\n",
      "Operator 180: -1.549459147811381\n",
      "Operator 181: 1.5494591478300541\n",
      "Operator 182: -1.549459147830052\n",
      "Operator 186: 1.5933770383700756\n",
      "Operator 187: -1.5933770383700745\n",
      "Operator 188: 1.711661782644499\n",
      "Operator 189: -1.711661782644498\n",
      "Operator 190: 1.5933770384148116\n",
      "Operator 191: -1.5933770384148112\n",
      "Operator 197: 0.9797117434316327\n",
      "Operator 198: -1.549459147811381\n",
      "Operator 199: 0.9797117434611663\n",
      "Operator 200: -1.549459147830052\n",
      "Operator 204: 0.8241833958170186\n",
      "Operator 205: -1.5933770383700745\n",
      "Operator 206: 0.6252484880485782\n",
      "Operator 207: -1.7116617826444978\n",
      "Operator 208: 0.8241833958401596\n",
      "Operator 209: -1.5933770384148112\n",
      "Operator 213: -1.5494591478113813\n",
      "Operator 214: 0.9797117434316416\n",
      "Operator 215: -1.549459147830062\n",
      "Operator 216: 0.9797117434611706\n",
      "Operator 220: -1.5933770383700818\n",
      "Operator 221: 0.8241833958170228\n",
      "Operator 222: -1.7116617826445029\n",
      "Operator 223: 0.6252484880485807\n",
      "Operator 224: -1.5933770384148134\n",
      "Operator 225: 0.8241833958401551\n",
      "Operator 227: -3.9999999999999787\n",
      "Operator 228: 3.9999999999999765\n",
      "Operator 229: -2.529170891231823\n",
      "Operator 230: 4.000000000000015\n",
      "Operator 231: -2.064173620210373\n",
      "Operator 233: -2.799588174617339\n",
      "Operator 235: -3.2645854455930285\n",
      "Operator 236: 2.417560434483473\n",
      "Operator 237: -3.9999999999999862\n",
      "Operator 238: 1.6597599389169424\n",
      "Operator 240: 1.5866742188129737\n",
      "Operator 242: 2.625248488087434\n",
      "Operator 247: 1.5494591478113788\n",
      "Operator 248: -0.9797117434316328\n",
      "Operator 249: 1.5494591478300541\n",
      "Operator 250: -0.9797117434611664\n",
      "Operator 254: 1.5933770383700756\n",
      "Operator 255: -0.8241833958170146\n",
      "Operator 256: 1.711661782644499\n",
      "Operator 257: -0.62524848804858\n",
      "Operator 258: 1.5933770384148114\n",
      "Operator 259: -0.8241833958401583\n",
      "Total gradient norm: 34.55872342422172\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.9999999999999765)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Gradients: [np.float64(3.9999999999999765)]\n",
      "Initial energy: -23.495742393298755\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228]...\n",
      "Starting point: [np.float64(0.513577528292718), np.float64(0.46089810746944987), np.float64(0.46089810745094417), np.float64(-0.4431436457915008), np.float64(-0.4431436457841177), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -24.324170\n",
      "         Iterations: 4\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 24\n",
      "\n",
      "Current energy: -24.324169518045153\n",
      "(change of -0.8284271247463977)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228]\n",
      "On iteration 6.\n",
      "\n",
      "*** ADAPT-VQE Iteration 7 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -3.4142135623692007\n",
      "Operator 1: 4.000000000000048\n",
      "Operator 2: -3.264585451288515\n",
      "Operator 3: 2.0999630251989573e-08\n",
      "Operator 4: -2.5291708941595923\n",
      "Operator 5: -1.3570020567706212e-08\n",
      "Operator 6: -3.2645854428710877\n",
      "Operator 7: 4.000000000000013\n",
      "Operator 8: -4.00000000000002\n",
      "Operator 9: 3.2087802201474007\n",
      "Operator 10: -2.1716963531247487e-08\n",
      "Operator 11: 2.2432916555516225\n",
      "Operator 12: 4.721801172280493e-08\n",
      "Operator 13: 2.2432916559449283\n",
      "Operator 14: -2.2956287537567732e-08\n",
      "Operator 15: 3.208780220540688\n",
      "Operator 16: -4.000000000000006\n",
      "Operator 17: 3.4142135623692034\n",
      "Operator 19: 2.158782399281989\n",
      "Operator 20: -4.000000000000048\n",
      "Operator 21: 2.0641736193540665\n",
      "Operator 22: -2.0999630251989573e-08\n",
      "Operator 23: 2.799588176483009\n",
      "Operator 24: 1.3570020567706212e-08\n",
      "Operator 25: 3.2645854428710877\n",
      "Operator 26: -2.417560440294743\n",
      "Operator 27: 4.00000000000002\n",
      "Operator 28: -1.659759915720697\n",
      "Operator 29: 2.1716963531247487e-08\n",
      "Operator 30: -1.5866742185055118\n",
      "Operator 31: -4.721801172280493e-08\n",
      "Operator 32: -2.625248480519908\n",
      "Operator 33: 2.2956287537567732e-08\n",
      "Operator 34: 3.4142135623691976\n",
      "Operator 35: 2.828427124738425\n",
      "Operator 36: 3.264585451288515\n",
      "Operator 37: 2.0999630251989573e-08\n",
      "Operator 38: 2.79958817648301\n",
      "Operator 39: -0.9299945463461738\n",
      "Operator 40: 3.264585442871085\n",
      "Operator 41: 2.529170885742146\n",
      "Operator 42: 4.00000000000002\n",
      "Operator 43: 3.2087802201474007\n",
      "Operator 44: 2.1716963531247487e-08\n",
      "Operator 45: 2.6252484803164684\n",
      "Operator 46: -1.086413326003264\n",
      "Operator 47: 2.6252484805199092\n",
      "Operator 48: -1.167063457085301\n",
      "Operator 49: 3.208780220540691\n",
      "Operator 50: 2.4175604410813634\n",
      "Operator 56: 1.2004118235170178\n",
      "Operator 63: 1.3636612964869281\n",
      "Operator 65: 1.3636612962315657\n",
      "Operator 69: -3.4142135623692007\n",
      "Operator 70: -2.5291709025770337\n",
      "Operator 71: -3.2645854512885135\n",
      "Operator 72: 0.9299945286113614\n",
      "Operator 73: -2.799588176483009\n",
      "Operator 74: 1.3570020567706212e-08\n",
      "Operator 75: -3.2645854428710877\n",
      "Operator 76: -4.000000000000013\n",
      "Operator 77: -2.4175604402947464\n",
      "Operator 78: -3.2087802201473963\n",
      "Operator 79: 1.1670634579448895\n",
      "Operator 80: -2.6252484803164697\n",
      "Operator 81: 1.0864133255963802\n",
      "Operator 82: -2.625248480519908\n",
      "Operator 83: -2.2956287537567732e-08\n",
      "Operator 84: -3.208780220540688\n",
      "Operator 85: 3.4142135623691976\n",
      "Operator 86: -4.000000000000048\n",
      "Operator 87: 3.2645854512885135\n",
      "Operator 88: -2.0999630251989573e-08\n",
      "Operator 89: 2.529170894159585\n",
      "Operator 90: 1.3570022547553843e-08\n",
      "Operator 91: 3.264585442871086\n",
      "Operator 92: -4.000000000000013\n",
      "Operator 93: 4.00000000000002\n",
      "Operator 94: -3.2087802201473963\n",
      "Operator 95: 2.1716963531247487e-08\n",
      "Operator 96: -2.2432916555516145\n",
      "Operator 97: -4.721801172280493e-08\n",
      "Operator 98: -2.243291655944927\n",
      "Operator 99: 2.2956287537567732e-08\n",
      "Operator 100: -3.208780220540691\n",
      "Operator 101: 4.000000000000006\n",
      "Operator 102: -3.4142135623692034\n",
      "Operator 109: 1.2004118235170178\n",
      "Operator 116: 1.3636612964869281\n",
      "Operator 118: 1.3636612962315655\n",
      "Operator 122: 3.4142135623691976\n",
      "Operator 123: 2.5291709025770337\n",
      "Operator 124: 3.264585451288515\n",
      "Operator 125: -0.9299945286113614\n",
      "Operator 126: 2.79958817648301\n",
      "Operator 127: -1.3570022547553843e-08\n",
      "Operator 128: 3.264585442871086\n",
      "Operator 129: 4.000000000000013\n",
      "Operator 130: 2.4175604402947464\n",
      "Operator 131: 3.2087802201474007\n",
      "Operator 132: -1.1670634579448895\n",
      "Operator 133: 2.6252484803164684\n",
      "Operator 134: -1.0864133255963802\n",
      "Operator 135: 2.625248480519909\n",
      "Operator 136: 2.2956287537567732e-08\n",
      "Operator 137: 3.208780220540691\n",
      "Operator 138: -3.4142135623692007\n",
      "Operator 139: -2.828427124738425\n",
      "Operator 140: -3.2645854512885135\n",
      "Operator 141: -2.0999630251989573e-08\n",
      "Operator 142: -2.799588176483009\n",
      "Operator 143: 0.9299945463461747\n",
      "Operator 144: -3.264585442871087\n",
      "Operator 145: -2.529170885742146\n",
      "Operator 146: -4.00000000000002\n",
      "Operator 147: -3.2087802201473963\n",
      "Operator 148: -2.1716963531247487e-08\n",
      "Operator 149: -2.6252484803164697\n",
      "Operator 150: 1.086413326003264\n",
      "Operator 151: -2.625248480519908\n",
      "Operator 152: 1.1670634570853\n",
      "Operator 153: -3.208780220540688\n",
      "Operator 154: -2.4175604410813634\n",
      "Operator 156: 3.4142135623692034\n",
      "Operator 163: -1.2004118235170167\n",
      "Operator 170: -1.363661296486929\n",
      "Operator 172: -1.3636612962315646\n",
      "Operator 176: -1.414213562376991\n",
      "Operator 179: 1.5494591431817353\n",
      "Operator 180: -1.5494591431817377\n",
      "Operator 181: 1.5494591500515944\n",
      "Operator 182: -1.5494591500515933\n",
      "Operator 186: 1.5933770361658024\n",
      "Operator 187: -1.5933770361658002\n",
      "Operator 188: 1.711661791948956\n",
      "Operator 189: -1.711661791948955\n",
      "Operator 190: 1.5933770358674217\n",
      "Operator 191: -1.593377035867422\n",
      "Operator 193: 1.4142135623769976\n",
      "Operator 194: -1.414213562376991\n",
      "Operator 197: 0.979711738395551\n",
      "Operator 198: -1.5494591431817382\n",
      "Operator 199: 0.9797117492605456\n",
      "Operator 200: -1.5494591500515933\n",
      "Operator 204: 0.8241833824120137\n",
      "Operator 205: -1.5933770361658002\n",
      "Operator 206: 0.6252484946872268\n",
      "Operator 207: -1.7116617919489545\n",
      "Operator 208: 0.8241833822576757\n",
      "Operator 209: -1.593377035867422\n",
      "Operator 210: 1.4142135623770005\n",
      "Operator 213: -1.5494591431817377\n",
      "Operator 214: 0.9797117383955602\n",
      "Operator 215: -1.549459150051601\n",
      "Operator 216: 0.9797117492605509\n",
      "Operator 220: -1.5933770361658077\n",
      "Operator 221: 0.824183382412017\n",
      "Operator 222: -1.7116617919489594\n",
      "Operator 223: 0.625248494687229\n",
      "Operator 224: -1.5933770358674244\n",
      "Operator 225: 0.8241833822576715\n",
      "Operator 227: -3.4142135623692034\n",
      "Operator 229: -2.1587823992819875\n",
      "Operator 230: 4.000000000000048\n",
      "Operator 231: -2.064173619354067\n",
      "Operator 232: 2.0999630251989573e-08\n",
      "Operator 233: -2.79958817648301\n",
      "Operator 234: -1.3570022547553843e-08\n",
      "Operator 235: -3.264585442871086\n",
      "Operator 236: 2.417560440294743\n",
      "Operator 237: -4.00000000000002\n",
      "Operator 238: 1.6597599157206995\n",
      "Operator 239: -2.1716963531247487e-08\n",
      "Operator 240: 1.5866742185055112\n",
      "Operator 241: 4.721801172280493e-08\n",
      "Operator 242: 2.625248480519909\n",
      "Operator 243: -2.2956287537567732e-08\n",
      "Operator 244: -1.414213562376991\n",
      "Operator 247: 1.5494591431817355\n",
      "Operator 248: -0.9797117383955513\n",
      "Operator 249: 1.5494591500515944\n",
      "Operator 250: -0.9797117492605469\n",
      "Operator 254: 1.5933770361658024\n",
      "Operator 255: -0.8241833824120087\n",
      "Operator 256: 1.711661791948956\n",
      "Operator 257: -0.6252484946872281\n",
      "Operator 258: 1.5933770358674217\n",
      "Operator 259: -0.8241833822576746\n",
      "Total gradient norm: 31.83396267232654\n",
      "Operators under consideration (1):\n",
      "[237]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.00000000000002)]\n",
      "Operator(s) added to ansatz: [237]\n",
      "Gradients: [np.float64(-4.00000000000002)]\n",
      "Initial energy: -24.324169518045153\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237]...\n",
      "Starting point: [np.float64(0.5135775327897405), np.float64(0.46089810641574225), np.float64(0.4608981065391626), np.float64(-0.4431436466698624), np.float64(-0.4431436439536143), np.float64(-0.39269908170010354), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -25.307527\n",
      "         Iterations: 12\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 19\n",
      "\n",
      "Current energy: -25.307527173986514\n",
      "(change of -0.9833576559413615)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237]\n",
      "On iteration 7.\n",
      "\n",
      "*** ADAPT-VQE Iteration 8 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -3.4142135600375223\n",
      "Operator 1: 4.000000000000064\n",
      "Operator 2: -3.2645854449274045\n",
      "Operator 4: -2.529170892325065\n",
      "Operator 6: -3.264585447397686\n",
      "Operator 7: 3.1836067595996176\n",
      "Operator 9: 2.120296179469984\n",
      "Operator 11: 1.8733788393970752\n",
      "Operator 13: 2.120296178523257\n",
      "Operator 15: 3.1836067589965604\n",
      "Operator 16: -4.000000000000016\n",
      "Operator 17: 3.414213560037526\n",
      "Operator 19: 2.1587823869485705\n",
      "Operator 20: -4.000000000000064\n",
      "Operator 21: 2.064173622720698\n",
      "Operator 23: 2.7995881753230547\n",
      "Operator 25: 3.264585447397686\n",
      "Operator 26: -1.4910253843723589\n",
      "Operator 28: -1.196309735932776\n",
      "Operator 30: -1.4432270752703504\n",
      "Operator 32: -2.5543359640161927\n",
      "Operator 34: 3.4142135600375187\n",
      "Operator 35: 2.8284271200750544\n",
      "Operator 36: 3.2645854449274045\n",
      "Operator 38: 2.7995881753230565\n",
      "Operator 39: -0.9299945377076826\n",
      "Operator 40: 3.2645854473976845\n",
      "Operator 41: 2.012971389213241\n",
      "Operator 43: 2.554335964502023\n",
      "Operator 44: -1.1482009591754792\n",
      "Operator 45: 2.4386935344876064\n",
      "Operator 46: -1.3794858193671191\n",
      "Operator 47: 2.5543359640161944\n",
      "Operator 48: -1.2585415896477086\n",
      "Operator 49: 3.1836067589965635\n",
      "Operator 50: 2.367213517993097\n",
      "Operator 56: 1.2004118246769866\n",
      "Operator 61: 1.4244214021396475\n",
      "Operator 63: 1.5613064655124365\n",
      "Operator 65: 1.4244214026776691\n",
      "Operator 69: -3.4142135600375223\n",
      "Operator 70: -2.5291708898547984\n",
      "Operator 71: -3.2645854449274037\n",
      "Operator 72: 0.929994542912399\n",
      "Operator 73: -2.7995881753230547\n",
      "Operator 75: -1.9319927014151879\n",
      "Operator 76: -3.183606759599619\n",
      "Operator 77: 1.2585415883030127\n",
      "Operator 78: -2.5543359645020214\n",
      "Operator 79: 1.379485819204298\n",
      "Operator 80: -2.4386935344876073\n",
      "Operator 81: 1.1482009603099315\n",
      "Operator 82: -2.5543359640161927\n",
      "Operator 84: -3.1836067589965604\n",
      "Operator 85: 3.4142135600375187\n",
      "Operator 86: -4.000000000000062\n",
      "Operator 87: 3.264585444927403\n",
      "Operator 89: 2.529170892325058\n",
      "Operator 91: 3.2645854473976845\n",
      "Operator 92: -3.183606759599619\n",
      "Operator 94: -2.1202961794699795\n",
      "Operator 96: -1.8733788393970672\n",
      "Operator 98: -2.120296178523255\n",
      "Operator 100: -3.1836067589965635\n",
      "Operator 101: 4.000000000000016\n",
      "Operator 102: -3.4142135600375267\n",
      "Operator 109: 1.2004118246769866\n",
      "Operator 114: 1.4244214021396475\n",
      "Operator 116: 1.5613064655124365\n",
      "Operator 118: 1.4244214026776691\n",
      "Operator 122: 3.4142135600375187\n",
      "Operator 123: 2.5291708898547975\n",
      "Operator 124: 3.264585444927404\n",
      "Operator 125: -0.929994542912399\n",
      "Operator 126: 2.7995881753230565\n",
      "Operator 128: 1.931992701415187\n",
      "Operator 129: 3.1836067595996176\n",
      "Operator 130: -1.2585415883030127\n",
      "Operator 131: 2.554335964502023\n",
      "Operator 132: -1.3794858192042998\n",
      "Operator 133: 2.4386935344876064\n",
      "Operator 134: -1.1482009603099315\n",
      "Operator 135: 2.554335964016195\n",
      "Operator 137: 3.1836067589965635\n",
      "Operator 138: -3.414213560037522\n",
      "Operator 139: -2.8284271200750544\n",
      "Operator 140: -3.264585444927403\n",
      "Operator 142: -2.7995881753230547\n",
      "Operator 143: 0.9299945377076826\n",
      "Operator 144: -3.264585447397686\n",
      "Operator 145: -2.0129713892132424\n",
      "Operator 147: -2.5543359645020214\n",
      "Operator 148: 1.1482009591754794\n",
      "Operator 149: -2.4386935344876077\n",
      "Operator 150: 1.3794858193671191\n",
      "Operator 151: -2.5543359640161927\n",
      "Operator 152: 1.2585415896477095\n",
      "Operator 153: -3.1836067589965604\n",
      "Operator 154: -2.367213517993097\n",
      "Operator 156: 3.414213560037526\n",
      "Operator 163: -1.200411824676985\n",
      "Operator 168: -1.4244214021396462\n",
      "Operator 170: -1.561306465512438\n",
      "Operator 172: -1.4244214026776678\n",
      "Operator 176: -1.4142135647086884\n",
      "Operator 179: 1.5494591483733484\n",
      "Operator 180: -1.5494591483733522\n",
      "Operator 181: 1.5494591463572427\n",
      "Operator 182: -1.5494591463572411\n",
      "Operator 184: 1.6121647058009225\n",
      "Operator 185: -1.6121647058009312\n",
      "Operator 186: 1.767091658828993\n",
      "Operator 187: -1.7670916588289889\n",
      "Operator 188: 1.7670916590111596\n",
      "Operator 189: -1.7670916590111574\n",
      "Operator 190: 1.6121647062436697\n",
      "Operator 191: -1.612164706243669\n",
      "Operator 193: 1.4142135647086949\n",
      "Operator 194: -1.4142135647086884\n",
      "Operator 197: 0.9797117451850513\n",
      "Operator 198: -1.5494591483733522\n",
      "Operator 199: 0.9797117419964835\n",
      "Operator 200: -0.916975159675926\n",
      "Operator 202: 0.7550488115060662\n",
      "Operator 203: -1.6121647058009312\n",
      "Operator 204: 0.4897812293504969\n",
      "Operator 205: -1.767091658828989\n",
      "Operator 206: 0.4897812293311393\n",
      "Operator 207: -1.767091659011157\n",
      "Operator 208: 0.755048811436402\n",
      "Operator 209: -1.6121647062436693\n",
      "Operator 210: 1.4142135647086977\n",
      "Operator 213: -1.5494591483733517\n",
      "Operator 214: 0.97971174518506\n",
      "Operator 215: -1.54945914635725\n",
      "Operator 216: 0.979711741996489\n",
      "Operator 218: -1.019360012881983\n",
      "Operator 219: 0.7550488115060721\n",
      "Operator 220: -1.7670916588289969\n",
      "Operator 221: 0.4897812293505014\n",
      "Operator 222: -1.7670916590111623\n",
      "Operator 223: 0.48978122933114165\n",
      "Operator 224: -1.6121647062436724\n",
      "Operator 225: 0.7550488114363985\n",
      "Operator 227: -3.4142135600375267\n",
      "Operator 229: -2.1587823869485683\n",
      "Operator 230: 4.000000000000062\n",
      "Operator 231: -2.064173622720698\n",
      "Operator 233: -2.7995881753230565\n",
      "Operator 235: -3.2645854473976845\n",
      "Operator 236: 1.491025384372358\n",
      "Operator 238: 1.1963097359327768\n",
      "Operator 240: 1.44322707527035\n",
      "Operator 242: 2.554335964016195\n",
      "Operator 244: -1.4142135647086884\n",
      "Operator 247: 1.549459148373349\n",
      "Operator 248: -0.9797117451850514\n",
      "Operator 249: 1.5494591463572422\n",
      "Operator 250: -0.9797117419964851\n",
      "Operator 252: 1.019360012881985\n",
      "Operator 253: -0.7550488115060673\n",
      "Operator 254: 1.767091658828993\n",
      "Operator 255: -0.48978122935049584\n",
      "Operator 256: 1.7670916590111598\n",
      "Operator 257: -0.48978122933114093\n",
      "Operator 258: 1.6121647062436697\n",
      "Operator 259: -0.7550488114364015\n",
      "Total gradient norm: 29.055296564376455\n",
      "Operators under consideration (1):\n",
      "[230]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000062)]\n",
      "Operator(s) added to ansatz: [230]\n",
      "Gradients: [np.float64(4.000000000000062)]\n",
      "Initial energy: -25.307527173986514\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230]...\n",
      "Starting point: [np.float64(0.5416899719198818), np.float64(0.468751051750797), np.float64(0.5416899718226407), np.float64(-0.4431436452091639), np.float64(-0.4431436460063057), np.float64(-0.39269908252448044), np.float64(0.4687510515637649), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -26.431604\n",
      "         Iterations: 9\n",
      "         Function evaluations: 93\n",
      "         Gradient evaluations: 78\n",
      "\n",
      "Current energy: -26.431604441371416\n",
      "(change of -1.1240772673849015)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230]\n",
      "On iteration 8.\n",
      "\n",
      "*** ADAPT-VQE Iteration 9 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -2.1202960978698004\n",
      "Operator 1: -1.4257960750801852e-07\n",
      "Operator 2: -1.8733788791843389\n",
      "Operator 3: 1.7298809592297635e-07\n",
      "Operator 4: -2.120296325738439\n",
      "Operator 5: 1.4362157690536036e-07\n",
      "Operator 6: -3.183606826444921\n",
      "Operator 7: 3.1836067518010918\n",
      "Operator 9: 2.120296133155575\n",
      "Operator 10: 1.3507321024453598e-07\n",
      "Operator 11: 1.8733788425743232\n",
      "Operator 12: -1.8382772559721872e-07\n",
      "Operator 13: 2.1202961635331583\n",
      "Operator 14: 2.0776704445779615e-07\n",
      "Operator 15: 3.183606702313339\n",
      "Operator 16: -4.000000000000028\n",
      "Operator 17: 1.4910253012399628\n",
      "Operator 18: 9.398991924327377e-08\n",
      "Operator 19: 1.196309817598014\n",
      "Operator 20: 1.4257960753952486e-07\n",
      "Operator 21: 1.4432271685410205\n",
      "Operator 22: -1.7298809592297635e-07\n",
      "Operator 23: 2.5543360428115602\n",
      "Operator 24: -8.499573424475781e-08\n",
      "Operator 25: 3.183606826444921\n",
      "Operator 26: -1.4910253194102496\n",
      "Operator 28: -1.19630977679595\n",
      "Operator 29: -1.3507321024453598e-07\n",
      "Operator 30: -1.443227007034472\n",
      "Operator 31: 1.8382772559721872e-07\n",
      "Operator 32: -2.5543359621430404\n",
      "Operator 33: -2.0776704445779615e-07\n",
      "Operator 34: 2.5543359213491788\n",
      "Operator 35: -1.148201097033175\n",
      "Operator 36: 2.4386935531217584\n",
      "Operator 37: -1.3794857351028984\n",
      "Operator 38: 2.55433604281156\n",
      "Operator 39: -1.2585414236451289\n",
      "Operator 40: 3.183606826444918\n",
      "Operator 41: 1.8840693420738959\n",
      "Operator 43: 2.5543359380557997\n",
      "Operator 44: -1.14820105671661\n",
      "Operator 45: 2.4386935359756574\n",
      "Operator 46: -1.3794857445699231\n",
      "Operator 47: 2.5543359621430417\n",
      "Operator 48: -1.2585416881076714\n",
      "Operator 49: 3.1836067023133428\n",
      "Operator 50: 2.3672134046266438\n",
      "Operator 52: 1.424421446220487\n",
      "Operator 54: 1.5613064468782745\n",
      "Operator 56: 1.424421324842588\n",
      "Operator 61: 1.4244214236555581\n",
      "Operator 63: 1.5613064640243948\n",
      "Operator 65: 1.4244214216318822\n",
      "Operator 68: 1.258541687249602\n",
      "Operator 69: -2.5543359213491783\n",
      "Operator 70: 1.3794858334880336\n",
      "Operator 71: -2.4386935531217593\n",
      "Operator 72: 1.1482007557233262\n",
      "Operator 73: -2.5543360428115602\n",
      "Operator 74: -1.4362157690536036e-07\n",
      "Operator 75: -1.884069267430084\n",
      "Operator 76: -3.183606751801094\n",
      "Operator 77: 1.2585416185554634\n",
      "Operator 78: -2.554335938055798\n",
      "Operator 79: 1.3794858608768825\n",
      "Operator 80: -2.4386935359756587\n",
      "Operator 81: 1.1482008922351374\n",
      "Operator 82: -2.5543359621430404\n",
      "Operator 83: 2.0776704445779615e-07\n",
      "Operator 84: -3.183606702313339\n",
      "Operator 85: 2.120296097869794\n",
      "Operator 86: 1.4257960741026208e-07\n",
      "Operator 87: 1.8733788791843364\n",
      "Operator 88: -1.7298809592297635e-07\n",
      "Operator 89: 2.1202963257384306\n",
      "Operator 90: -1.4362157690536036e-07\n",
      "Operator 91: 3.183606826444918\n",
      "Operator 92: -3.1836067518010935\n",
      "Operator 94: -2.1202961331555708\n",
      "Operator 95: -1.3507321045141668e-07\n",
      "Operator 96: -1.8733788425743159\n",
      "Operator 97: 1.8382772559721872e-07\n",
      "Operator 98: -2.1202961635331556\n",
      "Operator 99: -2.0776704445779615e-07\n",
      "Operator 100: -3.1836067023133428\n",
      "Operator 101: 4.000000000000028\n",
      "Operator 102: -3.1836067179790195\n",
      "Operator 103: -9.398991939238589e-08\n",
      "Operator 105: 1.424421446220487\n",
      "Operator 107: 1.5613064468782745\n",
      "Operator 109: 1.424421324842588\n",
      "Operator 114: 1.4244214236555581\n",
      "Operator 116: 1.5613064640243945\n",
      "Operator 118: 1.424421421631882\n",
      "Operator 121: -1.258541687249602\n",
      "Operator 122: 2.5543359213491788\n",
      "Operator 123: -1.3794858334880333\n",
      "Operator 124: 2.4386935531217584\n",
      "Operator 125: -1.1482007557233262\n",
      "Operator 126: 2.5543360428115602\n",
      "Operator 127: 1.4362157690536036e-07\n",
      "Operator 128: 1.8840692674300814\n",
      "Operator 129: 3.1836067518010926\n",
      "Operator 130: -1.2585416185554634\n",
      "Operator 131: 2.5543359380558\n",
      "Operator 132: -1.379485860876882\n",
      "Operator 133: 2.4386935359756574\n",
      "Operator 134: -1.1482008922351374\n",
      "Operator 135: 2.5543359621430413\n",
      "Operator 136: -2.0776704445779615e-07\n",
      "Operator 137: 3.1836067023133428\n",
      "Operator 138: -2.5543359213491783\n",
      "Operator 139: 1.148201097033175\n",
      "Operator 140: -2.4386935531217593\n",
      "Operator 141: 1.3794857351028984\n",
      "Operator 142: -2.5543360428115607\n",
      "Operator 143: 1.2585414236451289\n",
      "Operator 144: -3.183606826444921\n",
      "Operator 145: -1.8840693420738965\n",
      "Operator 147: -2.5543359380557993\n",
      "Operator 148: 1.1482010567166099\n",
      "Operator 149: -2.4386935359756587\n",
      "Operator 150: 1.3794857445699216\n",
      "Operator 151: -2.5543359621430404\n",
      "Operator 152: 1.2585416881076714\n",
      "Operator 153: -3.1836067023133383\n",
      "Operator 154: -2.3672134046266438\n",
      "Operator 155: 9.398991931682101e-08\n",
      "Operator 156: 3.1836067179790195\n",
      "Operator 157: 9.398991931682101e-08\n",
      "Operator 159: -1.4244214462204892\n",
      "Operator 161: -1.5613064468782751\n",
      "Operator 163: -1.4244213248425868\n",
      "Operator 168: -1.4244214236555577\n",
      "Operator 170: -1.5613064640243963\n",
      "Operator 172: -1.4244214216318811\n",
      "Operator 175: -9.398991939238589e-08\n",
      "Operator 176: -1.6121647363576213\n",
      "Operator 177: 1.7670916800211147\n",
      "Operator 178: -1.7670916800211172\n",
      "Operator 179: 1.7670916167288304\n",
      "Operator 180: -1.7670916167288326\n",
      "Operator 181: 1.6121646567249668\n",
      "Operator 182: -1.6121646567249661\n",
      "Operator 184: 1.6121647115263942\n",
      "Operator 185: -1.6121647115264026\n",
      "Operator 186: 1.7670916792452669\n",
      "Operator 187: -1.7670916792452627\n",
      "Operator 188: 1.7670916369107208\n",
      "Operator 189: -1.7670916369107177\n",
      "Operator 190: 1.6121647478589325\n",
      "Operator 191: -1.612164747858932\n",
      "Operator 193: 0.7550487935903117\n",
      "Operator 194: -1.6121647363576206\n",
      "Operator 195: 0.4897812597104101\n",
      "Operator 196: -1.7670916800211172\n",
      "Operator 197: 0.4897812246174951\n",
      "Operator 198: -1.7670916167288326\n",
      "Operator 199: 0.7550488525432114\n",
      "Operator 200: -0.9540844863573577\n",
      "Operator 202: 0.7550487831405872\n",
      "Operator 203: -1.6121647115264026\n",
      "Operator 204: 0.48978125358289654\n",
      "Operator 205: -1.7670916792452624\n",
      "Operator 206: 0.4897811796104655\n",
      "Operator 207: -1.7670916369107177\n",
      "Operator 208: 0.7550488645347833\n",
      "Operator 209: -1.612164747858932\n",
      "Operator 210: 0.7550487935903121\n",
      "Operator 211: -1.7670916800211174\n",
      "Operator 212: 0.4897812597104153\n",
      "Operator 213: -1.7670916167288309\n",
      "Operator 214: 0.48978122461749996\n",
      "Operator 215: -1.612164656724973\n",
      "Operator 216: 0.7550488525432174\n",
      "Operator 218: -0.954084578958091\n",
      "Operator 219: 0.7550487831405928\n",
      "Operator 220: -1.7670916792452709\n",
      "Operator 221: 0.48978125358290103\n",
      "Operator 222: -1.767091636910723\n",
      "Operator 223: 0.48978117961046813\n",
      "Operator 224: -1.612164747858935\n",
      "Operator 225: 0.7550488645347795\n",
      "Operator 227: -1.4910253012399628\n",
      "Operator 228: -9.398991911479411e-08\n",
      "Operator 229: -1.1963098175980136\n",
      "Operator 230: -1.425796072974651e-07\n",
      "Operator 231: -1.4432271685410203\n",
      "Operator 232: 1.7298809592297635e-07\n",
      "Operator 233: -2.5543360428115602\n",
      "Operator 234: 8.499573424475781e-08\n",
      "Operator 235: -3.183606826444918\n",
      "Operator 236: 1.491025319410249\n",
      "Operator 238: 1.1963097767959514\n",
      "Operator 239: 1.3507321045141668e-07\n",
      "Operator 240: 1.4432270070344715\n",
      "Operator 241: -1.8382772559721872e-07\n",
      "Operator 242: 2.5543359621430413\n",
      "Operator 243: 2.0776704445779615e-07\n",
      "Operator 244: -0.7550487935903036\n",
      "Operator 245: 1.7670916800211147\n",
      "Operator 246: -0.489781259710413\n",
      "Operator 247: 1.7670916167288304\n",
      "Operator 248: -0.48978122461749507\n",
      "Operator 249: 1.6121646567249668\n",
      "Operator 250: -0.7550488525432147\n",
      "Operator 252: 0.9540845789580921\n",
      "Operator 253: -0.7550487831405883\n",
      "Operator 254: 1.7670916792452664\n",
      "Operator 255: -0.48978125358289537\n",
      "Operator 256: 1.7670916369107208\n",
      "Operator 257: -0.4897811796104675\n",
      "Operator 258: 1.6121647478589325\n",
      "Operator 259: -0.7550488645347826\n",
      "Total gradient norm: 26.06858827618222\n",
      "Operators under consideration (1):\n",
      "[16]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000028)]\n",
      "Operator(s) added to ansatz: [16]\n",
      "Gradients: [np.float64(-4.000000000000028)]\n",
      "Initial energy: -26.431604441371416\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16]...\n",
      "Starting point: [np.float64(0.5416899601227784), np.float64(0.4687510693306481), np.float64(0.541689982720742), np.float64(-0.4687510308322344), np.float64(-0.5416899493497942), np.float64(-0.4687510644720636), np.float64(0.46875105398241723), np.float64(-0.5416899831348908), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -28.048084\n",
      "         Iterations: 18\n",
      "         Function evaluations: 23\n",
      "         Gradient evaluations: 23\n",
      "\n",
      "Current energy: -28.048083651075874\n",
      "(change of -1.6164792097044582)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16]\n",
      "On iteration 9.\n",
      "\n",
      "*** ADAPT-VQE Iteration 10 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -2.1202961849455955\n",
      "Operator 2: -1.8733788488747747\n",
      "Operator 4: -2.1202961837874508\n",
      "Operator 6: -3.1836067596470645\n",
      "Operator 7: 3.140358805290015\n",
      "Operator 9: 1.916574892575283\n",
      "Operator 11: 1.3203286243037446\n",
      "Operator 13: 0.8987768094601204\n",
      "Operator 15: 0.5313034263934618\n",
      "Operator 17: 1.4910253924013586\n",
      "Operator 19: 1.1963097433075367\n",
      "Operator 21: 1.4432270786904455\n",
      "Operator 23: 2.554335967051248\n",
      "Operator 25: 3.1836067596470645\n",
      "Operator 26: -1.2187985122570115\n",
      "Operator 28: -0.66451986006406\n",
      "Operator 30: -0.3921122891768214\n",
      "Operator 32: -0.18516098969012917\n",
      "Operator 34: 2.5543359676669866\n",
      "Operator 35: -1.1482009522180956\n",
      "Operator 36: 2.4386935389264277\n",
      "Operator 37: -1.379485810178564\n",
      "Operator 38: 2.5543359670512484\n",
      "Operator 39: -1.2585415865953853\n",
      "Operator 40: 3.183606759647061\n",
      "Operator 41: 1.858474954829187\n",
      "Operator 43: 2.4425824249717722\n",
      "Operator 44: -1.24398602677578\n",
      "Operator 45: 2.2111744522636836\n",
      "Operator 46: -1.634669942640252\n",
      "Operator 47: 2.0964886385340282\n",
      "Operator 48: -1.822619003459857\n",
      "Operator 49: 2.031323798510521\n",
      "Operator 50: -1.9295367843280489\n",
      "Operator 52: 1.4244213996645798\n",
      "Operator 54: 1.5613064610735894\n",
      "Operator 56: 1.424421400284349\n",
      "Operator 61: 1.514248851388383\n",
      "Operator 63: 1.7737036906393895\n",
      "Operator 65: 1.8940604156887257\n",
      "Operator 67: 1.9606103752397563\n",
      "Operator 68: 1.2585415852344726\n",
      "Operator 69: -2.5543359676669875\n",
      "Operator 70: 1.3794858096992324\n",
      "Operator 71: -2.4386935389264286\n",
      "Operator 72: 1.1482009539289537\n",
      "Operator 73: -2.554335967051248\n",
      "Operator 75: -1.815227000472156\n",
      "Operator 76: -3.140358805290016\n",
      "Operator 77: 1.3955527618705856\n",
      "Operator 78: -2.4425824249717714\n",
      "Operator 79: 1.7068019721919534\n",
      "Operator 80: -2.2111744522636845\n",
      "Operator 81: 1.864041570099554\n",
      "Operator 82: -2.0964886385340264\n",
      "Operator 83: 1.952948683506862\n",
      "Operator 84: -2.031323798510519\n",
      "Operator 85: 2.120296184945589\n",
      "Operator 87: 1.8733788488747714\n",
      "Operator 89: 2.120296183787443\n",
      "Operator 91: 3.183606759647061\n",
      "Operator 92: -3.140358805290016\n",
      "Operator 94: -1.9165748925752788\n",
      "Operator 96: -1.3203286243037367\n",
      "Operator 98: -0.8987768094601176\n",
      "Operator 100: -0.5313034263934671\n",
      "Operator 102: -3.183606760211227\n",
      "Operator 105: 1.4244213996645798\n",
      "Operator 107: 1.5613064610735894\n",
      "Operator 109: 1.424421400284349\n",
      "Operator 114: 1.5142488513883825\n",
      "Operator 116: 1.7737036906393895\n",
      "Operator 118: 1.8940604156887257\n",
      "Operator 120: 1.9606103752397563\n",
      "Operator 121: -1.2585415852344726\n",
      "Operator 122: 2.5543359676669857\n",
      "Operator 123: -1.3794858096992324\n",
      "Operator 124: 2.4386935389264277\n",
      "Operator 125: -1.1482009539289537\n",
      "Operator 126: 2.5543359670512484\n",
      "Operator 128: 1.815227000472154\n",
      "Operator 129: 3.140358805290015\n",
      "Operator 130: -1.3955527618705865\n",
      "Operator 131: 2.442582424971773\n",
      "Operator 132: -1.7068019721919536\n",
      "Operator 133: 2.211174452263684\n",
      "Operator 134: -1.864041570099554\n",
      "Operator 135: 2.0964886385340282\n",
      "Operator 136: -1.952948683506862\n",
      "Operator 137: 2.031323798510521\n",
      "Operator 138: -2.5543359676669875\n",
      "Operator 139: 1.1482009522180954\n",
      "Operator 140: -2.4386935389264286\n",
      "Operator 141: 1.3794858101785645\n",
      "Operator 142: -2.554335967051248\n",
      "Operator 143: 1.2585415865953857\n",
      "Operator 144: -3.1836067596470645\n",
      "Operator 145: -1.858474954829188\n",
      "Operator 147: -2.4425824249717714\n",
      "Operator 148: 1.2439860267757796\n",
      "Operator 149: -2.211174452263684\n",
      "Operator 150: 1.634669942640252\n",
      "Operator 151: -2.0964886385340264\n",
      "Operator 152: 1.822619003459857\n",
      "Operator 153: -2.031323798510519\n",
      "Operator 154: 1.9295367843280489\n",
      "Operator 156: 3.1836067602112266\n",
      "Operator 159: -1.4244213996645825\n",
      "Operator 161: -1.5613064610735896\n",
      "Operator 163: -1.4244214002843476\n",
      "Operator 168: -1.5142488513883818\n",
      "Operator 170: -1.7737036906393913\n",
      "Operator 172: -1.894060415688724\n",
      "Operator 174: -1.9606103752397535\n",
      "Operator 176: -1.6121647053518815\n",
      "Operator 177: 1.7670916562506882\n",
      "Operator 178: -1.7670916562506902\n",
      "Operator 179: 1.7670916565655497\n",
      "Operator 180: -1.7670916565655523\n",
      "Operator 181: 1.6121647057660868\n",
      "Operator 182: -1.612164705766086\n",
      "Operator 184: 1.6430404119185775\n",
      "Operator 185: -1.6430404119185864\n",
      "Operator 186: 1.8432277628767468\n",
      "Operator 187: -1.843227762876744\n",
      "Operator 188: 1.924562689823166\n",
      "Operator 189: -1.9245626898231616\n",
      "Operator 190: 1.9683021246377492\n",
      "Operator 191: -1.9683021246377463\n",
      "Operator 192: 1.9921843813490754\n",
      "Operator 193: 0.7550488152165582\n",
      "Operator 194: -1.6121647053518817\n",
      "Operator 195: 0.4897812313013955\n",
      "Operator 196: -1.76709165625069\n",
      "Operator 197: 0.4897812314658006\n",
      "Operator 198: -1.767091656565552\n",
      "Operator 199: 0.7550488149317451\n",
      "Operator 200: -0.9192231088990633\n",
      "Operator 202: 0.6376771998954984\n",
      "Operator 203: -1.643040411918586\n",
      "Operator 204: 0.2859231138425571\n",
      "Operator 205: -1.8432277628767442\n",
      "Operator 206: 0.1324561573444307\n",
      "Operator 207: -1.9245626898231616\n",
      "Operator 208: 0.047294155890149264\n",
      "Operator 209: -1.9683021246377463\n",
      "Operator 210: 0.7550488152165589\n",
      "Operator 211: -1.7670916562506895\n",
      "Operator 212: 0.48978123130140033\n",
      "Operator 213: -1.7670916565655506\n",
      "Operator 214: 0.4897812314658048\n",
      "Operator 215: -1.6121647057660935\n",
      "Operator 216: 0.7550488149317508\n",
      "Operator 218: -0.9723568689600439\n",
      "Operator 219: 0.6376771998955035\n",
      "Operator 220: -1.8432277628767513\n",
      "Operator 221: 0.28592311384256053\n",
      "Operator 222: -1.924562689823167\n",
      "Operator 223: 0.1324561573444328\n",
      "Operator 224: -1.968302124637751\n",
      "Operator 225: 0.04729415589014868\n",
      "Operator 226: -1.9921843813490776\n",
      "Operator 227: -1.4910253924013581\n",
      "Operator 229: -1.1963097433075363\n",
      "Operator 231: -1.443227078690445\n",
      "Operator 233: -2.5543359670512484\n",
      "Operator 235: -3.183606759647061\n",
      "Operator 236: 1.2187985122570113\n",
      "Operator 238: 0.6645198600640608\n",
      "Operator 240: 0.3921122891768214\n",
      "Operator 242: 0.1851609896901294\n",
      "Operator 244: -0.7550488152165509\n",
      "Operator 245: 1.7670916562506886\n",
      "Operator 246: -0.48978123130139867\n",
      "Operator 247: 1.7670916565655497\n",
      "Operator 248: -0.48978123146580005\n",
      "Operator 249: 1.6121647057660868\n",
      "Operator 250: -0.7550488149317477\n",
      "Operator 252: 0.9723568689600453\n",
      "Operator 253: -0.6376771998954982\n",
      "Operator 254: 1.8432277628767468\n",
      "Operator 255: -0.285923113842555\n",
      "Operator 256: 1.9245626898231656\n",
      "Operator 257: -0.13245615734443203\n",
      "Operator 258: 1.9683021246377492\n",
      "Operator 259: -0.047294155890150125\n",
      "Operator 260: 1.9921843813490758\n",
      "Total gradient norm: 24.683251279709268\n",
      "Operators under consideration (1):\n",
      "[235]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-3.183606759647061)]\n",
      "Operator(s) added to ansatz: [235]\n",
      "Gradients: [np.float64(-3.183606759647061)]\n",
      "Initial energy: -28.048083651075874\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235]...\n",
      "Starting point: [np.float64(0.6476335352424656), np.float64(0.6962606843872362), np.float64(0.586109248387339), np.float64(-0.4687510515490504), np.float64(-0.5416899706144337), np.float64(-0.46875105137407674), np.float64(0.48203605463415894), np.float64(-0.5416899704463637), np.float64(0.7411807621658265), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -28.610519\n",
      "         Iterations: 17\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 26\n",
      "\n",
      "Current energy: -28.610519259784606\n",
      "(change of -0.5624356087087321)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235]\n",
      "On iteration 10.\n",
      "\n",
      "*** ADAPT-VQE Iteration 11 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -2.1834126700019696\n",
      "Operator 2: -2.059207721957951\n",
      "Operator 4: -2.6265921620256956\n",
      "Operator 6: -1.2358988357448004\n",
      "Operator 7: 2.4994595829982624\n",
      "Operator 9: 1.6520137618495654\n",
      "Operator 11: 1.1691119006624593\n",
      "Operator 13: 0.8037270197636944\n",
      "Operator 15: 0.4765183626628817\n",
      "Operator 17: 1.5772086089515942\n",
      "Operator 19: 1.388987234258316\n",
      "Operator 21: 1.9653640179641458\n",
      "Operator 23: 2.833359715408347\n",
      "Operator 24: -0.6120057120078716\n",
      "Operator 25: 1.2358988357448004\n",
      "Operator 26: -0.936732549354953\n",
      "Operator 28: -0.5660943724578502\n",
      "Operator 30: -0.3444022785466956\n",
      "Operator 32: -0.16462686433367224\n",
      "Operator 34: 2.5904086835528326\n",
      "Operator 35: -1.116877768607884\n",
      "Operator 36: 2.52912596682084\n",
      "Operator 37: -1.277201229104206\n",
      "Operator 38: 2.8333597154083447\n",
      "Operator 39: -0.8968577826985964\n",
      "Operator 41: 2.130320468328308\n",
      "Operator 42: -0.7246423625192251\n",
      "Operator 43: 2.330974925776638\n",
      "Operator 44: -1.438746031076395\n",
      "Operator 45: 2.1659680313750833\n",
      "Operator 46: -1.713599147286123\n",
      "Operator 47: 2.0772316307511836\n",
      "Operator 48: -1.8580965278247867\n",
      "Operator 49: 2.0252034357670725\n",
      "Operator 50: -1.9433021945179312\n",
      "Operator 52: 1.393888898119506\n",
      "Operator 54: 1.4683806433878783\n",
      "Operator 56: 1.0625163016556805\n",
      "Operator 57: -0.8100576274095656\n",
      "Operator 58: -0.3923176094379044\n",
      "Operator 59: 0.8750401177617249\n",
      "Operator 61: 1.644473969164323\n",
      "Operator 63: 1.8233471629583529\n",
      "Operator 65: 1.9154409741610394\n",
      "Operator 67: 1.9683442804265305\n",
      "Operator 68: 1.2124081153078508\n",
      "Operator 69: -2.590408683552835\n",
      "Operator 70: 1.2394432020718915\n",
      "Operator 71: -2.52912596682084\n",
      "Operator 72: 0.6687337319292412\n",
      "Operator 73: -2.1687144997510934\n",
      "Operator 74: -1.2636697489579887\n",
      "Operator 75: 0.1670143136601031\n",
      "Operator 76: -2.741399946703079\n",
      "Operator 77: 1.5454924043721365\n",
      "Operator 78: -2.330974925776637\n",
      "Operator 79: 1.7687598198794965\n",
      "Operator 80: -2.165968031375084\n",
      "Operator 81: 1.8910719485339098\n",
      "Operator 82: -2.077231630751182\n",
      "Operator 83: 1.9621529177929924\n",
      "Operator 84: -2.02520343576707\n",
      "Operator 85: 2.1834126700019656\n",
      "Operator 87: 2.0592077219579488\n",
      "Operator 89: 2.6265921620256885\n",
      "Operator 90: -1.2636697489579882\n",
      "Operator 92: -2.499459582998265\n",
      "Operator 94: -1.6520137618495587\n",
      "Operator 96: -1.16911190066245\n",
      "Operator 98: -0.803727019763692\n",
      "Operator 100: -0.4765183626628864\n",
      "Operator 102: -3.196612744603213\n",
      "Operator 105: 1.393888898119506\n",
      "Operator 107: 1.4683806433878783\n",
      "Operator 109: 0.8132728425167445\n",
      "Operator 110: -0.4343560576481188\n",
      "Operator 111: -0.8100576274095612\n",
      "Operator 112: 1.126044164649766\n",
      "Operator 114: 1.644473969164323\n",
      "Operator 116: 1.8233471629583529\n",
      "Operator 118: 1.9154409741610396\n",
      "Operator 120: 1.9683442804265305\n",
      "Operator 121: -1.212408115307851\n",
      "Operator 122: 2.590408683552834\n",
      "Operator 123: -1.2394432020718913\n",
      "Operator 124: 2.52912596682084\n",
      "Operator 125: -0.6687337319292415\n",
      "Operator 126: 2.168714499751091\n",
      "Operator 128: -0.9851731404489661\n",
      "Operator 129: 2.741399946703078\n",
      "Operator 130: -1.5454924043721365\n",
      "Operator 131: 2.330974925776638\n",
      "Operator 132: -1.7687598198794954\n",
      "Operator 133: 2.1659680313750833\n",
      "Operator 134: -1.8910719485339085\n",
      "Operator 135: 2.0772316307511836\n",
      "Operator 136: -1.9621529177929924\n",
      "Operator 137: 2.0252034357670725\n",
      "Operator 138: -2.590408683552835\n",
      "Operator 139: 1.1168777686078841\n",
      "Operator 140: -2.529125966820841\n",
      "Operator 141: 1.2772012291042065\n",
      "Operator 142: -2.833359715408347\n",
      "Operator 143: 0.008889600318876149\n",
      "Operator 144: -1.2358988357448006\n",
      "Operator 145: -2.130320468328307\n",
      "Operator 146: 0.7246423625192251\n",
      "Operator 147: -2.3309749257766375\n",
      "Operator 148: 1.4387460310763964\n",
      "Operator 149: -2.165968031375084\n",
      "Operator 150: 1.7135991472861194\n",
      "Operator 151: -2.077231630751182\n",
      "Operator 152: 1.858096527824785\n",
      "Operator 153: -2.02520343576707\n",
      "Operator 154: 1.9433021945179312\n",
      "Operator 156: 3.196612744603213\n",
      "Operator 159: -1.3938888981195077\n",
      "Operator 161: -1.4683806433878785\n",
      "Operator 163: -1.0625163016556796\n",
      "Operator 166: -0.8750401177617232\n",
      "Operator 168: -1.644473969164322\n",
      "Operator 170: -1.8233471629583549\n",
      "Operator 172: -1.9154409741610383\n",
      "Operator 174: -1.9683442804265279\n",
      "Operator 176: -1.602534848124444\n",
      "Operator 177: 1.7396051009447575\n",
      "Operator 178: -1.7396051009447597\n",
      "Operator 179: 1.6881769806152314\n",
      "Operator 180: -1.6881769806152325\n",
      "Operator 181: 1.2587735928829797\n",
      "Operator 182: 1.5259413421956292\n",
      "Operator 183: -1.0001631006282787\n",
      "Operator 184: 1.7497948428852275\n",
      "Operator 185: -1.7497948428852381\n",
      "Operator 186: 1.879619174614509\n",
      "Operator 187: -1.8796191746145055\n",
      "Operator 188: 1.9401240289350872\n",
      "Operator 189: -1.9401240289350823\n",
      "Operator 190: 1.9745551785288908\n",
      "Operator 191: -1.9745551785288877\n",
      "Operator 192: 1.9937090660520536\n",
      "Operator 193: 0.7906906342890616\n",
      "Operator 194: -1.602534848124444\n",
      "Operator 195: 0.5580900347687973\n",
      "Operator 196: -1.7396051009447597\n",
      "Operator 197: 0.647276182130569\n",
      "Operator 198: -1.2921669903387554\n",
      "Operator 199: 0.67495930755525\n",
      "Operator 200: 1.3590809780812885\n",
      "Operator 201: -1.2870585020047782\n",
      "Operator 202: 0.457647413040119\n",
      "Operator 203: -1.7497948428852381\n",
      "Operator 204: 0.2210767080151324\n",
      "Operator 205: -1.8796191746145055\n",
      "Operator 206: 0.10541118110117131\n",
      "Operator 207: -1.940124028935082\n",
      "Operator 208: 0.03800461079823861\n",
      "Operator 209: -1.9745551785288875\n",
      "Operator 210: 0.7906906342890623\n",
      "Operator 211: -1.7396051009447597\n",
      "Operator 212: 0.5580900347688025\n",
      "Operator 213: -1.688176980615232\n",
      "Operator 214: 0.6472761821305739\n",
      "Operator 215: -1.258773592882985\n",
      "Operator 216: 1.3830816391406635\n",
      "Operator 217: 0.6233330785711496\n",
      "Operator 218: -1.3597518937930624\n",
      "Operator 219: 0.4576474130401227\n",
      "Operator 220: -1.8796191746145121\n",
      "Operator 221: 0.22107670801513618\n",
      "Operator 222: -1.940124028935088\n",
      "Operator 223: 0.10541118110117345\n",
      "Operator 224: -1.974555178528893\n",
      "Operator 225: 0.03800461079823811\n",
      "Operator 226: -1.9937090660520558\n",
      "Operator 227: -1.5772086089515953\n",
      "Operator 229: -1.3889872342583152\n",
      "Operator 231: -1.9653640179641454\n",
      "Operator 233: -2.8333597154083447\n",
      "Operator 236: 0.9367325493549536\n",
      "Operator 238: 0.5660943724578504\n",
      "Operator 240: 0.3444022785466956\n",
      "Operator 242: 0.16462686433367213\n",
      "Operator 244: -0.7906906342890541\n",
      "Operator 245: 1.7396051009447575\n",
      "Operator 246: -0.5580900347688004\n",
      "Operator 247: 1.6881769806152311\n",
      "Operator 248: -0.6472761821305695\n",
      "Operator 249: 0.963492396656616\n",
      "Operator 250: 0.818215696231279\n",
      "Operator 251: -0.48438726259669496\n",
      "Operator 252: 1.3597518937930633\n",
      "Operator 253: -0.4576474130401186\n",
      "Operator 254: 1.8796191746145094\n",
      "Operator 255: -0.22107670801513127\n",
      "Operator 256: 1.9401240289350872\n",
      "Operator 257: -0.10541118110117259\n",
      "Operator 258: 1.9745551785288908\n",
      "Operator 259: -0.03800461079823925\n",
      "Operator 260: 1.9937090660520542\n",
      "Total gradient norm: 23.540452309873096\n",
      "Operators under consideration (1):\n",
      "[156]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.196612744603213)]\n",
      "Operator(s) added to ansatz: [156]\n",
      "Gradients: [np.float64(3.196612744603213)]\n",
      "Initial energy: -28.610519259784606\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156]...\n",
      "Starting point: [np.float64(0.6627430163346413), np.float64(0.7055561968132636), np.float64(0.6110363122247907), np.float64(-0.3403819295036365), np.float64(-0.5024314772467847), np.float64(-0.46470528808763967), np.float64(0.5326119858541937), np.float64(-0.5274009988998862), np.float64(0.7457300568615598), np.float64(0.3495501192470059), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -29.325201\n",
      "         Iterations: 19\n",
      "         Function evaluations: 100\n",
      "         Gradient evaluations: 98\n",
      "\n",
      "Current energy: -29.325200509010898\n",
      "(change of -0.7146812492262917)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156]\n",
      "On iteration 11.\n",
      "\n",
      "*** ADAPT-VQE Iteration 12 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -2.7587607845138176\n",
      "Operator 2: -2.2483264524302973\n",
      "Operator 4: -2.678239173893769\n",
      "Operator 6: -1.2263127514043435\n",
      "Operator 7: 2.495515172858072\n",
      "Operator 9: 1.6502074188926972\n",
      "Operator 11: 1.1680405469977537\n",
      "Operator 13: 0.8030438707420298\n",
      "Operator 15: 0.4761228640759091\n",
      "Operator 19: 1.6309976888132014\n",
      "Operator 21: 2.0546152318891773\n",
      "Operator 23: 2.871927520614282\n",
      "Operator 24: -0.6124258289431044\n",
      "Operator 25: 1.2263127514043435\n",
      "Operator 26: -0.9350756125538191\n",
      "Operator 28: -0.5654341693578697\n",
      "Operator 30: -0.344067949196165\n",
      "Operator 32: -0.16448044463736344\n",
      "Operator 34: 1.9193697906459977\n",
      "Operator 35: -0.5573532003688378\n",
      "Operator 36: 2.631845025789163\n",
      "Operator 37: -1.128114679502095\n",
      "Operator 38: 2.87192752061428\n",
      "Operator 39: -0.8600882167436232\n",
      "Operator 41: 2.1383987520857097\n",
      "Operator 42: -0.7286423295116424\n",
      "Operator 43: 2.3302649966277222\n",
      "Operator 44: -1.4399772733942942\n",
      "Operator 45: 2.165666601251111\n",
      "Operator 46: -1.7141241907754714\n",
      "Operator 47: 2.0771008832938334\n",
      "Operator 48: -1.8583372784760281\n",
      "Operator 49: 2.0251616604015434\n",
      "Operator 50: -1.9433961563929865\n",
      "Operator 52: 0.9587414452053069\n",
      "Operator 54: 1.3680776304995883\n",
      "Operator 56: 1.036823326841428\n",
      "Operator 57: -0.8064008554827915\n",
      "Operator 58: -0.39008145361935687\n",
      "Operator 59: 0.881657955904394\n",
      "Operator 61: 1.6452812614078804\n",
      "Operator 63: 1.823675713591574\n",
      "Operator 65: 1.9155857122675777\n",
      "Operator 67: 1.9683970049419628\n",
      "Operator 68: 0.7905767049972989\n",
      "Operator 69: -2.9206071671701492\n",
      "Operator 70: 1.1348774831308344\n",
      "Operator 71: -2.631845025789164\n",
      "Operator 72: 0.6479496898519044\n",
      "Operator 73: -2.194227692966251\n",
      "Operator 74: -1.266045098522898\n",
      "Operator 75: 0.1784355291941982\n",
      "Operator 76: -2.7391669405934276\n",
      "Operator 77: 1.546446217443088\n",
      "Operator 78: -2.330264996627721\n",
      "Operator 79: 1.7691740641475109\n",
      "Operator 80: -2.1656666012511128\n",
      "Operator 81: 1.8912556266900136\n",
      "Operator 82: -2.0771008832938316\n",
      "Operator 83: 1.9622157242605889\n",
      "Operator 84: -2.0251616604015408\n",
      "Operator 85: 2.7587607845138127\n",
      "Operator 87: 2.248326452430295\n",
      "Operator 89: 2.678239173893763\n",
      "Operator 90: -1.2660450985228981\n",
      "Operator 92: -2.495515172858075\n",
      "Operator 94: -1.650207418892692\n",
      "Operator 96: -1.1680405469977446\n",
      "Operator 98: -0.8030438707420275\n",
      "Operator 100: -0.47612286407591387\n",
      "Operator 102: -1.157244849608169\n",
      "Operator 105: 0.6300674009337418\n",
      "Operator 107: 1.3680776304995876\n",
      "Operator 109: 0.7921601224749049\n",
      "Operator 110: -0.45033031019498126\n",
      "Operator 111: -0.8064008554827875\n",
      "Operator 112: 1.1293535985133696\n",
      "Operator 114: 1.645281261407881\n",
      "Operator 116: 1.8236757135915744\n",
      "Operator 118: 1.9155857122675777\n",
      "Operator 120: 1.968397004941963\n",
      "Operator 121: 0.32926361105058144\n",
      "Operator 122: 2.92060716717015\n",
      "Operator 123: -1.1348774831308337\n",
      "Operator 124: 2.631845025789164\n",
      "Operator 125: -0.6479496898519044\n",
      "Operator 126: 2.194227692966249\n",
      "Operator 128: -0.9884288824423109\n",
      "Operator 129: 2.739166940593427\n",
      "Operator 130: -1.5464462174430853\n",
      "Operator 131: 2.3302649966277227\n",
      "Operator 132: -1.7691740641475124\n",
      "Operator 133: 2.1656666012511114\n",
      "Operator 134: -1.8912556266900138\n",
      "Operator 135: 2.0771008832938334\n",
      "Operator 136: -1.9622157242605915\n",
      "Operator 137: 2.025161660401544\n",
      "Operator 138: -1.9193697906459963\n",
      "Operator 139: 0.5573532003688382\n",
      "Operator 140: -2.631845025789164\n",
      "Operator 141: 1.128114679502095\n",
      "Operator 142: -2.871927520614282\n",
      "Operator 143: -0.049886338825740534\n",
      "Operator 144: -1.2263127514043428\n",
      "Operator 145: -2.1383987520857097\n",
      "Operator 146: 0.7286423295116429\n",
      "Operator 147: -2.330264996627721\n",
      "Operator 148: 1.4399772733942942\n",
      "Operator 149: -2.1656666012511128\n",
      "Operator 150: 1.7141241907754716\n",
      "Operator 151: -2.0771008832938316\n",
      "Operator 152: 1.858337278476026\n",
      "Operator 153: -2.025161660401541\n",
      "Operator 154: 1.9433961563929865\n",
      "Operator 157: -1.5004215281240096\n",
      "Operator 158: 0.8763468309344467\n",
      "Operator 159: -0.958741445205309\n",
      "Operator 161: -1.3680776304995885\n",
      "Operator 163: -1.036823326841427\n",
      "Operator 166: -0.8816579559043924\n",
      "Operator 168: -1.64528126140788\n",
      "Operator 170: -1.8236757135915762\n",
      "Operator 172: -1.9155857122675757\n",
      "Operator 174: -1.9683970049419597\n",
      "Operator 175: 1.5004215281240096\n",
      "Operator 176: -1.162676764237042\n",
      "Operator 177: 1.6491968786087465\n",
      "Operator 178: -1.6491968786087494\n",
      "Operator 179: 1.6590834584330776\n",
      "Operator 180: -1.659083458433079\n",
      "Operator 181: 1.2498748288656674\n",
      "Operator 182: 1.531915852775151\n",
      "Operator 183: -1.0073598664020977\n",
      "Operator 184: 1.75043295908414\n",
      "Operator 185: -1.7504329590841519\n",
      "Operator 186: 1.8798563553885033\n",
      "Operator 187: -1.8798563553884997\n",
      "Operator 188: 1.9402287928693698\n",
      "Operator 189: -1.9402287928693647\n",
      "Operator 190: 1.9745977580661513\n",
      "Operator 191: -1.9745977580661478\n",
      "Operator 192: 1.9937194771959832\n",
      "Operator 193: -0.9163061865749295\n",
      "Operator 194: -0.7640899750735319\n",
      "Operator 195: 0.7493706561003359\n",
      "Operator 196: -1.64919687860875\n",
      "Operator 197: 0.7327212726471861\n",
      "Operator 198: -1.2675831278142533\n",
      "Operator 199: 0.6979860147234012\n",
      "Operator 200: 1.3587420629442009\n",
      "Operator 201: -1.2903705824921103\n",
      "Operator 202: 0.45654325161426124\n",
      "Operator 203: -1.7504329590841519\n",
      "Operator 204: 0.22065091126114228\n",
      "Operator 205: -1.8798563553884997\n",
      "Operator 206: 0.10522860040822835\n",
      "Operator 207: -1.9402287928693642\n",
      "Operator 208: 0.03794128699745353\n",
      "Operator 209: -1.9745977580661482\n",
      "Operator 210: 0.4322598296030684\n",
      "Operator 211: -1.0838221254850795\n",
      "Operator 212: 0.7493706561003411\n",
      "Operator 213: -1.6590834584330787\n",
      "Operator 214: 0.7327212726471916\n",
      "Operator 215: -1.249874828865673\n",
      "Operator 216: 1.3921623690682572\n",
      "Operator 217: 0.6241928305306972\n",
      "Operator 218: -1.366518995189205\n",
      "Operator 219: 0.4565432516142648\n",
      "Operator 220: -1.8798563553885068\n",
      "Operator 221: 0.22065091126114547\n",
      "Operator 222: -1.9402287928693702\n",
      "Operator 223: 0.10522860040823052\n",
      "Operator 224: -1.9745977580661536\n",
      "Operator 225: 0.03794128699745272\n",
      "Operator 226: -1.9937194771959854\n",
      "Operator 227: -0.6546748129400802\n",
      "Operator 228: 1.5004215281240096\n",
      "Operator 229: -1.6309976888132023\n",
      "Operator 231: -2.0546152318891764\n",
      "Operator 233: -2.87192752061428\n",
      "Operator 236: 0.9350756125538197\n",
      "Operator 238: 0.5654341693578702\n",
      "Operator 240: 0.34406794919616474\n",
      "Operator 242: 0.16448044463736378\n",
      "Operator 244: -0.657747747500785\n",
      "Operator 245: 1.083822125485077\n",
      "Operator 246: -0.7493706561003379\n",
      "Operator 247: 1.659083458433078\n",
      "Operator 248: -0.7327212726471863\n",
      "Operator 249: 0.954937038819106\n",
      "Operator 250: 0.8554903389330153\n",
      "Operator 251: -0.48729164699196104\n",
      "Operator 252: 1.3665189951892058\n",
      "Operator 253: -0.45654325161426046\n",
      "Operator 254: 1.8798563553885026\n",
      "Operator 255: -0.22065091126114078\n",
      "Operator 256: 1.9402287928693696\n",
      "Operator 257: -0.10522860040822957\n",
      "Operator 258: 1.9745977580661511\n",
      "Operator 259: -0.037941286997453944\n",
      "Operator 260: 1.9937194771959836\n",
      "Total gradient norm: 23.05288289366013\n",
      "Operators under consideration (1):\n",
      "[122]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.92060716717015)]\n",
      "Operator(s) added to ansatz: [122]\n",
      "Gradients: [np.float64(2.92060716717015)]\n",
      "Initial energy: -29.325200509010898\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122]...\n",
      "Starting point: [np.float64(0.6628509079707963), np.float64(0.7056231710249762), np.float64(0.6112099258143812), np.float64(-0.3375256809096743), np.float64(-0.48914328187008754), np.float64(-0.31018630664160707), np.float64(0.5329415777928005), np.float64(-0.48474600402323437), np.float64(0.745762911915953), np.float64(0.35063288895648265), np.float64(-0.4268613609818978), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -29.719101\n",
      "         Iterations: 18\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "\n",
      "Current energy: -29.719100732923003\n",
      "(change of -0.3939002239121052)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122]\n",
      "On iteration 12.\n",
      "\n",
      "*** ADAPT-VQE Iteration 13 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.6413908921302509\n",
      "Operator 1: 0.959209189009055\n",
      "Operator 2: -2.672632913006959\n",
      "Operator 4: -2.78565677960068\n",
      "Operator 6: -1.206591098488903\n",
      "Operator 7: 2.487413940255497\n",
      "Operator 9: 1.6464902344216346\n",
      "Operator 11: 1.165834226109657\n",
      "Operator 13: 0.8016366291765666\n",
      "Operator 15: 0.47530812369413056\n",
      "Operator 18: -0.7853878947701756\n",
      "Operator 19: 1.049037007162903\n",
      "Operator 20: -0.9592091890090547\n",
      "Operator 21: 2.2730371429351566\n",
      "Operator 23: 2.953240122477827\n",
      "Operator 24: -0.6132279864468282\n",
      "Operator 25: 1.206591098488903\n",
      "Operator 26: -0.9316755074513983\n",
      "Operator 28: -0.5640760692249474\n",
      "Operator 30: -0.3433796336165337\n",
      "Operator 32: -0.1641788993826292\n",
      "Operator 34: -0.7264861446436947\n",
      "Operator 35: -0.3871314289720631\n",
      "Operator 36: 2.4503212060119095\n",
      "Operator 37: -0.7406273871718745\n",
      "Operator 38: 2.953240122477826\n",
      "Operator 39: -0.7809122010623981\n",
      "Operator 41: 2.1546283195904734\n",
      "Operator 42: -0.7368393080958435\n",
      "Operator 43: 2.328806325182648\n",
      "Operator 44: -1.4425067575277994\n",
      "Operator 45: 2.1650466836839866\n",
      "Operator 46: -1.7152039441847342\n",
      "Operator 47: 2.0768318988486323\n",
      "Operator 48: -1.8588325648825883\n",
      "Operator 49: 2.0250757110972746\n",
      "Operator 50: -1.9435894748650941\n",
      "Operator 51: 0.6216602948588887\n",
      "Operator 52: -1.1590588511661195\n",
      "Operator 53: -0.3929236735005347\n",
      "Operator 54: 0.9224606357857444\n",
      "Operator 56: 0.9806852335370592\n",
      "Operator 57: -0.7987453030084812\n",
      "Operator 58: -0.3854304140985011\n",
      "Operator 59: 0.8951621716157121\n",
      "Operator 61: 1.6469392241867657\n",
      "Operator 63: 1.8243513093048538\n",
      "Operator 65: 1.9158834648374747\n",
      "Operator 67: 1.968505479602863\n",
      "Operator 68: -0.23392561227643435\n",
      "Operator 69: -1.7341979944897679\n",
      "Operator 70: 0.15431134137765556\n",
      "Operator 71: -2.8848706403735958\n",
      "Operator 72: 0.6038884229634405\n",
      "Operator 73: -2.2478945806436594\n",
      "Operator 74: -1.2708207653861283\n",
      "Operator 75: 0.20181253939497745\n",
      "Operator 76: -2.734589709377827\n",
      "Operator 77: 1.5484060764862486\n",
      "Operator 78: -2.328806325182646\n",
      "Operator 79: 1.7700260405251114\n",
      "Operator 80: -2.1650466836839883\n",
      "Operator 81: 1.891633513855438\n",
      "Operator 82: -2.0768318988486305\n",
      "Operator 83: 1.9623449403852842\n",
      "Operator 84: -2.0250757110972724\n",
      "Operator 85: 1.2393491115369486\n",
      "Operator 87: 2.6726329130069577\n",
      "Operator 89: 2.785656779600674\n",
      "Operator 90: -1.2708207653861292\n",
      "Operator 92: -2.4874139402555007\n",
      "Operator 94: -1.6464902344216283\n",
      "Operator 96: -1.1658342261096488\n",
      "Operator 98: -0.801636629176564\n",
      "Operator 100: -0.47530812369413555\n",
      "Operator 102: -0.8527883022362711\n",
      "Operator 104: 0.45468517105981365\n",
      "Operator 105: -0.8607255654613427\n",
      "Operator 106: -0.7198580513950913\n",
      "Operator 107: 1.086053370696626\n",
      "Operator 109: 0.7464604740421907\n",
      "Operator 110: -0.4831705403972464\n",
      "Operator 111: -0.7987453030084775\n",
      "Operator 112: 1.1361130086649494\n",
      "Operator 114: 1.6469392241867657\n",
      "Operator 116: 1.824351309304854\n",
      "Operator 118: 1.915883464837475\n",
      "Operator 120: 1.968505479602863\n",
      "Operator 121: 0.8584875136032994\n",
      "Operator 123: -0.8648160491837529\n",
      "Operator 124: 2.8848706403735958\n",
      "Operator 125: -0.6038884229634403\n",
      "Operator 126: 2.247894580643659\n",
      "Operator 128: -0.9950887492742249\n",
      "Operator 129: 2.734589709377827\n",
      "Operator 130: -1.5484060764862475\n",
      "Operator 131: 2.328806325182648\n",
      "Operator 132: -1.7700260405251114\n",
      "Operator 133: 2.165046683683986\n",
      "Operator 134: -1.891633513855436\n",
      "Operator 135: 2.0768318988486323\n",
      "Operator 136: -1.9623449403852842\n",
      "Operator 137: 2.025075711097275\n",
      "Operator 138: -0.4888623215129144\n",
      "Operator 139: -0.6503076567285899\n",
      "Operator 140: -2.4503212060119086\n",
      "Operator 141: 0.7406273871718745\n",
      "Operator 142: -2.953240122477827\n",
      "Operator 143: -0.1743338016554279\n",
      "Operator 144: -1.2065910984889014\n",
      "Operator 145: -2.1546283195904734\n",
      "Operator 146: 0.7368393080958426\n",
      "Operator 147: -2.3288063251826463\n",
      "Operator 148: 1.4425067575277988\n",
      "Operator 149: -2.165046683683988\n",
      "Operator 150: 1.7152039441847347\n",
      "Operator 151: -2.0768318988486305\n",
      "Operator 152: 1.8588325648825883\n",
      "Operator 153: -2.0250757110972724\n",
      "Operator 154: 1.9435894748650941\n",
      "Operator 155: -0.7853878947701761\n",
      "Operator 157: -1.8326424540498594\n",
      "Operator 158: -0.9031471208024872\n",
      "Operator 159: -0.49932363876862584\n",
      "Operator 161: -0.922460635785745\n",
      "Operator 163: -0.9806852335370579\n",
      "Operator 166: -0.8951621716157103\n",
      "Operator 168: -1.6469392241867649\n",
      "Operator 170: -1.8243513093048556\n",
      "Operator 172: -1.9158834648374734\n",
      "Operator 174: -1.9685054796028603\n",
      "Operator 175: 1.6413413561911308\n",
      "Operator 176: 1.3427189942504498\n",
      "Operator 177: 1.7800025510210977\n",
      "Operator 178: -1.158444602048172\n",
      "Operator 179: 1.5925848057901288\n",
      "Operator 180: -1.592584805790131\n",
      "Operator 181: 1.2315642218506824\n",
      "Operator 182: 1.5438789208956047\n",
      "Operator 183: -1.0220248082668517\n",
      "Operator 184: 1.7517425494469911\n",
      "Operator 185: -1.7517425494470036\n",
      "Operator 186: 1.8803439177825574\n",
      "Operator 187: -1.8803439177825534\n",
      "Operator 188: 1.9404442900597645\n",
      "Operator 189: -1.9404442900597587\n",
      "Operator 190: 1.9746853590715525\n",
      "Operator 191: -1.974685359071549\n",
      "Operator 192: 1.9937408970595976\n",
      "Operator 193: -1.3057536188893741\n",
      "Operator 194: 1.0628710123093192\n",
      "Operator 195: 1.3902057258606484\n",
      "Operator 196: -1.3638876457292528\n",
      "Operator 197: 0.9177838621288056\n",
      "Operator 198: -1.212215263805712\n",
      "Operator 199: 0.7449878557835977\n",
      "Operator 200: 1.3577486373690701\n",
      "Operator 201: -1.2971232662283891\n",
      "Operator 202: 0.45427617740445597\n",
      "Operator 203: -1.751742549447004\n",
      "Operator 204: 0.2197754901104786\n",
      "Operator 205: -1.8803439177825534\n",
      "Operator 206: 0.104853021492891\n",
      "Operator 207: -1.9404442900597592\n",
      "Operator 208: 0.03781100350825131\n",
      "Operator 209: -1.9746853590715485\n",
      "Operator 210: -0.16057393472392112\n",
      "Operator 211: 1.2376294596801833\n",
      "Operator 212: 0.7444575259849477\n",
      "Operator 213: -1.3526930002984652\n",
      "Operator 214: 0.9177838621288131\n",
      "Operator 215: -1.2315642218506884\n",
      "Operator 216: 1.40866872860517\n",
      "Operator 217: 0.6259201221667776\n",
      "Operator 218: -1.380226837220432\n",
      "Operator 219: 0.4542761774044598\n",
      "Operator 220: -1.8803439177825618\n",
      "Operator 221: 0.21977549011048228\n",
      "Operator 222: -1.9404442900597654\n",
      "Operator 223: 0.10485302149289283\n",
      "Operator 224: -1.9746853590715547\n",
      "Operator 225: 0.03781100350825059\n",
      "Operator 226: -1.9937408970595993\n",
      "Operator 227: -0.6237332483460685\n",
      "Operator 228: 1.6413413561911312\n",
      "Operator 231: -2.273037142935156\n",
      "Operator 233: -2.953240122477826\n",
      "Operator 236: 0.9316755074513989\n",
      "Operator 238: 0.5640760692249478\n",
      "Operator 240: 0.34337963361653345\n",
      "Operator 242: 0.1641788993826292\n",
      "Operator 244: 0.755130613973487\n",
      "Operator 245: 0.9939002201687035\n",
      "Operator 246: -0.6323195353604633\n",
      "Operator 247: 1.3526930002984634\n",
      "Operator 248: -0.9177838621288064\n",
      "Operator 249: 0.9374200624397615\n",
      "Operator 250: 0.9339107343822822\n",
      "Operator 251: -0.4931727843475723\n",
      "Operator 252: 1.3802268372204334\n",
      "Operator 253: -0.45427617740445575\n",
      "Operator 254: 1.8803439177825574\n",
      "Operator 255: -0.21977549011047792\n",
      "Operator 256: 1.940444290059765\n",
      "Operator 257: -0.10485302149289219\n",
      "Operator 258: 1.974685359071552\n",
      "Operator 259: -0.03781100350825184\n",
      "Operator 260: 1.9937408970595976\n",
      "Total gradient norm: 22.43668993082671\n",
      "Operators under consideration (1):\n",
      "[23]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.953240122477827)]\n",
      "Operator(s) added to ansatz: [23]\n",
      "Gradients: [np.float64(2.953240122477827)]\n",
      "Initial energy: -29.719100732923003\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23]...\n",
      "Starting point: [np.float64(0.6630731319508234), np.float64(0.7057611360464657), np.float64(0.6115673382130176), np.float64(-0.33168910684404257), np.float64(-0.46057054967599464), np.float64(-0.22281661986625922), np.float64(0.5336192256850277), np.float64(-0.3752085053708621), np.float64(0.7458305934531849), np.float64(0.35284660669489615), np.float64(-0.4891882587957476), np.float64(-0.2780033601348083), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -30.099566\n",
      "         Iterations: 19\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "\n",
      "Current energy: -30.0995656814433\n",
      "(change of -0.3804649485202951)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23]\n",
      "On iteration 13.\n",
      "\n",
      "*** ADAPT-VQE Iteration 14 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.638903101170736\n",
      "Operator 1: 0.9818603280611181\n",
      "Operator 2: -3.0049412957550086\n",
      "Operator 3: 0.8858624172342996\n",
      "Operator 4: -0.7206545258094683\n",
      "Operator 6: -0.9278460152051085\n",
      "Operator 7: 2.2883161010696016\n",
      "Operator 9: 1.5520185543395892\n",
      "Operator 11: 1.1090086650959696\n",
      "Operator 13: 0.7651985270039574\n",
      "Operator 15: 0.4541770639611342\n",
      "Operator 18: -0.821274952395203\n",
      "Operator 19: 1.2533490428782896\n",
      "Operator 20: -0.8486389742414323\n",
      "Operator 21: 2.743960254472036\n",
      "Operator 24: -0.6313592043044538\n",
      "Operator 25: 0.9278460152051096\n",
      "Operator 26: -0.8493525889369842\n",
      "Operator 28: -0.5297705944973157\n",
      "Operator 30: -0.3257237292250631\n",
      "Operator 32: -0.15639442597029873\n",
      "Operator 34: -0.7524566007598215\n",
      "Operator 35: -0.355744811627588\n",
      "Operator 36: 2.631353481318902\n",
      "Operator 37: 0.1811367398985233\n",
      "Operator 38: 1.7463045006427924\n",
      "Operator 39: 0.19080146599345865\n",
      "Operator 40: -0.36541421187669126\n",
      "Operator 41: 2.3031309401340545\n",
      "Operator 42: -0.9304356819427335\n",
      "Operator 43: 2.2927584772730816\n",
      "Operator 44: -1.5048801359143433\n",
      "Operator 45: 2.149470564025493\n",
      "Operator 46: -1.7423105839969442\n",
      "Operator 47: 2.070028920670259\n",
      "Operator 48: -1.8713565952861855\n",
      "Operator 49: 2.0228977468329084\n",
      "Operator 50: -1.9484882618962316\n",
      "Operator 51: 0.6510333717622694\n",
      "Operator 52: -1.1595789618532248\n",
      "Operator 53: -0.4760190913824349\n",
      "Operator 54: 0.6331149851461533\n",
      "Operator 56: 0.5547710412055271\n",
      "Operator 57: 0.7089397530473824\n",
      "Operator 58: -0.31406460054068097\n",
      "Operator 59: 1.1298002204286757\n",
      "Operator 61: 1.6875958764150971\n",
      "Operator 63: 1.8412831086919084\n",
      "Operator 65: 1.9234060795064178\n",
      "Operator 67: 1.9712530250359284\n",
      "Operator 68: -0.3220643224435543\n",
      "Operator 69: -1.6843684689042546\n",
      "Operator 70: -0.24125152513087794\n",
      "Operator 71: -2.7041098188855632\n",
      "Operator 72: 0.4634237651231823\n",
      "Operator 73: 0.5247771235089826\n",
      "Operator 74: -1.3950609080479794\n",
      "Operator 75: 0.5875639919426785\n",
      "Operator 76: -2.62598280500887\n",
      "Operator 77: 1.5968843374143455\n",
      "Operator 78: -2.2927584772730816\n",
      "Operator 79: 1.7914559624095194\n",
      "Operator 80: -2.1494705640254947\n",
      "Operator 81: 1.9011938707073934\n",
      "Operator 82: -2.0700289206702576\n",
      "Operator 83: 1.9656189429608752\n",
      "Operator 84: -2.0228977468329057\n",
      "Operator 85: 1.183141775147336\n",
      "Operator 87: 3.0049412957550077\n",
      "Operator 89: 1.1766860891524382\n",
      "Operator 90: -1.727575314265775\n",
      "Operator 92: -2.2883161010696047\n",
      "Operator 94: -1.5520185543395835\n",
      "Operator 96: -1.1090086650959614\n",
      "Operator 98: -0.7651985270039547\n",
      "Operator 100: -0.4541770639611391\n",
      "Operator 102: -0.8321623653201395\n",
      "Operator 104: 0.49372055499124456\n",
      "Operator 105: -0.8462627010562125\n",
      "Operator 106: -0.705200590177083\n",
      "Operator 107: 0.870925897321711\n",
      "Operator 109: 0.3836744190334118\n",
      "Operator 110: 0.3540227114537573\n",
      "Operator 111: -0.5998033699051243\n",
      "Operator 112: 1.288175109908536\n",
      "Operator 114: 1.6875958764150971\n",
      "Operator 116: 1.8412831086919081\n",
      "Operator 118: 1.9234060795064183\n",
      "Operator 120: 1.971253025035928\n",
      "Operator 121: 0.9466083299729748\n",
      "Operator 123: -0.5818319156081593\n",
      "Operator 124: 2.7041098188855637\n",
      "Operator 125: 0.5104433207059675\n",
      "Operator 126: 0.8652466450903649\n",
      "Operator 127: 0.7544924863793923\n",
      "Operator 128: -1.1487045930345503\n",
      "Operator 129: 2.6259828050088716\n",
      "Operator 130: -1.596884337414346\n",
      "Operator 131: 2.2927584772730816\n",
      "Operator 132: -1.7914559624095179\n",
      "Operator 133: 2.149470564025493\n",
      "Operator 134: -1.9011938707073934\n",
      "Operator 135: 2.0700289206702593\n",
      "Operator 136: -1.9656189429608752\n",
      "Operator 137: 2.0228977468329084\n",
      "Operator 138: -0.4117941810052781\n",
      "Operator 139: -0.6965201279060942\n",
      "Operator 140: -2.631353481318903\n",
      "Operator 141: 0.5676963172589639\n",
      "Operator 143: -0.592366434702313\n",
      "Operator 144: -0.48146515857961936\n",
      "Operator 145: -2.3031309401340527\n",
      "Operator 146: 0.930435681942734\n",
      "Operator 147: -2.2927584772730816\n",
      "Operator 148: 1.5048801359143438\n",
      "Operator 149: -2.1494705640254947\n",
      "Operator 150: 1.7423105839969446\n",
      "Operator 151: -2.070028920670257\n",
      "Operator 152: 1.871356595286184\n",
      "Operator 153: -2.0228977468329052\n",
      "Operator 154: 1.9484882618962316\n",
      "Operator 155: -0.8212749523952034\n",
      "Operator 157: -1.8402396315813618\n",
      "Operator 158: -0.9390889695331055\n",
      "Operator 159: -0.4614102238815252\n",
      "Operator 161: -0.6331149851461542\n",
      "Operator 162: 0.4469645018377525\n",
      "Operator 163: 1.146530796914666\n",
      "Operator 164: -0.5503129320715902\n",
      "Operator 166: -1.1298002204286735\n",
      "Operator 168: -1.6875958764150965\n",
      "Operator 170: -1.84128310869191\n",
      "Operator 172: -1.923406079506417\n",
      "Operator 174: -1.9712530250359253\n",
      "Operator 175: 1.6491709877987613\n",
      "Operator 176: 1.3772651340176085\n",
      "Operator 177: 1.740607824617563\n",
      "Operator 178: -1.0964605163585441\n",
      "Operator 179: 1.1548340787478546\n",
      "Operator 180: -1.7986175310946846\n",
      "Operator 181: -1.3157084907270935\n",
      "Operator 182: 1.6939807344311624\n",
      "Operator 183: -1.2669754538348375\n",
      "Operator 184: 1.7834603141032366\n",
      "Operator 185: -1.7834603141032495\n",
      "Operator 186: 1.8924961358208479\n",
      "Operator 187: -1.892496135820843\n",
      "Operator 188: 1.9458778000551082\n",
      "Operator 189: -1.9458778000551025\n",
      "Operator 190: 1.9769032561571622\n",
      "Operator 191: -1.9769032561571591\n",
      "Operator 192: 1.9942837555620156\n",
      "Operator 193: -1.3604061461139616\n",
      "Operator 194: 1.0766299837884457\n",
      "Operator 195: 1.450700276181731\n",
      "Operator 196: -1.1267774053751862\n",
      "Operator 197: 0.7681115586986618\n",
      "Operator 198: -1.2439069184406204\n",
      "Operator 199: -0.7388133433375033\n",
      "Operator 200: 1.219018403851341\n",
      "Operator 201: -1.4445795061677833\n",
      "Operator 202: 0.39894097785719634\n",
      "Operator 203: -1.7834603141032495\n",
      "Operator 204: 0.19790095463962665\n",
      "Operator 205: -1.892496135820843\n",
      "Operator 206: 0.09537391199278389\n",
      "Operator 207: -1.9458778000551027\n",
      "Operator 208: 0.034511180469512986\n",
      "Operator 209: -1.976903256157159\n",
      "Operator 210: -0.18747966776662314\n",
      "Operator 211: 1.2500413434135302\n",
      "Operator 212: 0.8799876422218328\n",
      "Operator 213: -0.9712873201440773\n",
      "Operator 214: -0.6570164837899568\n",
      "Operator 215: -1.6092751387584499\n",
      "Operator 216: 0.7212766569743803\n",
      "Operator 217: 0.5650645429051357\n",
      "Operator 218: -1.5641925080687968\n",
      "Operator 219: 0.3989409778571994\n",
      "Operator 220: -1.892496135820851\n",
      "Operator 221: 0.19790095463963048\n",
      "Operator 222: -1.9458778000551091\n",
      "Operator 223: 0.09537391199278566\n",
      "Operator 224: -1.9769032561571642\n",
      "Operator 225: 0.03451118046951243\n",
      "Operator 226: -1.994283755562018\n",
      "Operator 227: -0.6310823418107618\n",
      "Operator 228: 1.6491709877987613\n",
      "Operator 231: -2.743960254472036\n",
      "Operator 232: 0.6126540915642102\n",
      "Operator 233: -1.7463045006427929\n",
      "Operator 234: 0.3414587657830061\n",
      "Operator 236: 0.8493525889369854\n",
      "Operator 238: 0.5297705944973158\n",
      "Operator 240: 0.3257237292250629\n",
      "Operator 242: 0.15639442597029884\n",
      "Operator 244: 0.8194158771865376\n",
      "Operator 245: 0.9604773414078769\n",
      "Operator 246: -0.7401243646189317\n",
      "Operator 247: 1.1237623014553582\n",
      "Operator 248: -1.4400251670585118\n",
      "Operator 249: -1.162029399624166\n",
      "Operator 250: 1.2605015893789266\n",
      "Operator 251: -0.4955925946869023\n",
      "Operator 252: 1.5641925080687975\n",
      "Operator 253: -0.39894097785719607\n",
      "Operator 254: 1.8924961358208472\n",
      "Operator 255: -0.19790095463962615\n",
      "Operator 256: 1.9458778000551085\n",
      "Operator 257: -0.09537391199278498\n",
      "Operator 258: 1.9769032561571618\n",
      "Operator 259: -0.034511180469513736\n",
      "Operator 260: 1.9942837555620156\n",
      "Total gradient norm: 21.470859078283986\n",
      "Operators under consideration (1):\n",
      "[2]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-3.0049412957550086)]\n",
      "Operator(s) added to ansatz: [2]\n",
      "Gradients: [np.float64(-3.0049412957550086)]\n",
      "Initial energy: -30.0995656814433\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2]...\n",
      "Starting point: [np.float64(0.6688133466711226), np.float64(0.7093367799302188), np.float64(0.6207158918878318), np.float64(-0.2505498112836489), np.float64(-0.3658001829555819), np.float64(-0.21717338176002937), np.float64(0.550576934374107), np.float64(-0.3549980372428464), np.float64(0.7475862292051456), np.float64(0.4035537355713974), np.float64(-0.4931342208975336), np.float64(-0.285776210094701), np.float64(-0.26350236323421194), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -30.545564\n",
      "         Iterations: 19\n",
      "         Function evaluations: 91\n",
      "         Gradient evaluations: 79\n",
      "\n",
      "Current energy: -30.54556444283302\n",
      "(change of -0.4459987613897205)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2]\n",
      "On iteration 14.\n",
      "\n",
      "*** ADAPT-VQE Iteration 15 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.5990735616061522\n",
      "Operator 1: 1.740489311073326\n",
      "Operator 2: 6.413422667587152e-07\n",
      "Operator 3: 1.6905817942744317\n",
      "Operator 4: -0.7013079278109726\n",
      "Operator 5: -3.760366789849758e-07\n",
      "Operator 6: -0.8027909113343124\n",
      "Operator 7: 2.1799343506593107\n",
      "Operator 8: -1.825155299880274e-07\n",
      "Operator 9: 1.4980064726708027\n",
      "Operator 10: 4.171151654562452e-08\n",
      "Operator 11: 1.0758705940866466\n",
      "Operator 12: -3.212637878331428e-07\n",
      "Operator 13: 0.7437807342374867\n",
      "Operator 14: 9.129796740836582e-08\n",
      "Operator 15: 0.4417263227006799\n",
      "Operator 16: -3.863694715278143e-07\n",
      "Operator 17: 2.4880095251424547e-07\n",
      "Operator 18: -0.8993427503478058\n",
      "Operator 19: 1.1918159902133063\n",
      "Operator 20: -0.9393668383623323\n",
      "Operator 21: 0.7927504210063584\n",
      "Operator 22: -0.675020607762448\n",
      "Operator 23: 5.196446333570079e-07\n",
      "Operator 24: -0.6326863134101111\n",
      "Operator 25: 0.8027909113343124\n",
      "Operator 26: -0.8055131632030204\n",
      "Operator 27: 1.825155299880274e-07\n",
      "Operator 28: -0.5103329112618894\n",
      "Operator 29: -4.171151795944957e-08\n",
      "Operator 30: -0.31549057904634803\n",
      "Operator 31: 3.2126378504981403e-07\n",
      "Operator 32: -0.15183972896287534\n",
      "Operator 33: -9.129796740836582e-08\n",
      "Operator 34: -0.9750784659382263\n",
      "Operator 35: 0.7962884377883512\n",
      "Operator 36: 0.2043863799075213\n",
      "Operator 37: 0.7673082498476957\n",
      "Operator 38: 0.875630590623122\n",
      "Operator 39: 0.7269611383152323\n",
      "Operator 40: -0.5490532429021711\n",
      "Operator 41: 2.3348652309768756\n",
      "Operator 42: -1.0293769940468653\n",
      "Operator 43: 2.2730409477430236\n",
      "Operator 44: -1.5388830205290303\n",
      "Operator 45: 2.1407352038191254\n",
      "Operator 46: -1.7574926145151715\n",
      "Operator 47: 2.0661758848831147\n",
      "Operator 48: -1.8784478442737755\n",
      "Operator 49: 2.0216606543075377\n",
      "Operator 50: -1.9512708516954729\n",
      "Operator 51: 0.8956321250081798\n",
      "Operator 52: -0.9703113903490383\n",
      "Operator 53: 0.7080493917283641\n",
      "Operator 54: 0.0298303792491241\n",
      "Operator 55: 0.4237903960351924\n",
      "Operator 56: 0.2651604034245363\n",
      "Operator 57: 0.9035504915767226\n",
      "Operator 58: -0.2753069924377447\n",
      "Operator 59: 1.2367300380314035\n",
      "Operator 61: 1.7095881837310671\n",
      "Operator 63: 1.8507430069164563\n",
      "Operator 65: 1.9276599821155354\n",
      "Operator 67: 1.972812625924853\n",
      "Operator 68: -0.8532984184218447\n",
      "Operator 69: -0.763095211838404\n",
      "Operator 70: -0.8618345829098633\n",
      "Operator 71: -0.33221761652554127\n",
      "Operator 72: -0.714612322511849\n",
      "Operator 73: 0.6890404316150358\n",
      "Operator 74: -1.452503160256105\n",
      "Operator 75: 0.7635580959310522\n",
      "Operator 76: -2.5700774340939647\n",
      "Operator 77: 1.6234499667487876\n",
      "Operator 78: -2.273040947743022\n",
      "Operator 79: 1.8034945083768181\n",
      "Operator 80: -2.1407352038191276\n",
      "Operator 81: 1.9066112523871763\n",
      "Operator 82: -2.066175884883113\n",
      "Operator 83: 1.9674783054249088\n",
      "Operator 84: -2.021660654307535\n",
      "Operator 85: 0.8466291385581322\n",
      "Operator 86: -2.8708774082598335e-07\n",
      "Operator 87: 1.498356439560789\n",
      "Operator 88: 5.074343453282313e-07\n",
      "Operator 89: 0.8528223006011182\n",
      "Operator 90: -1.8208730415073013\n",
      "Operator 91: -3.823512789039705e-07\n",
      "Operator 92: -2.1799343506593134\n",
      "Operator 93: 1.825155299880274e-07\n",
      "Operator 94: -1.4980064726707962\n",
      "Operator 95: -4.171151654562452e-08\n",
      "Operator 96: -1.0758705940866382\n",
      "Operator 97: 3.212637878331428e-07\n",
      "Operator 98: -0.7437807342374841\n",
      "Operator 99: -9.129796740836582e-08\n",
      "Operator 100: -0.4417263227006849\n",
      "Operator 101: 3.863694715278143e-07\n",
      "Operator 102: -0.6994708482291396\n",
      "Operator 103: 3.1546201768524274e-08\n",
      "Operator 104: 0.7919371759127714\n",
      "Operator 105: -0.7095836683635959\n",
      "Operator 106: 0.3973806730168419\n",
      "Operator 107: 0.4800071397440931\n",
      "Operator 108: 0.5364472191267493\n",
      "Operator 109: 0.21184058546326962\n",
      "Operator 110: 0.6284367192444984\n",
      "Operator 111: -0.5044264204974254\n",
      "Operator 112: 1.3613170990091135\n",
      "Operator 114: 1.7095881837310671\n",
      "Operator 116: 1.8507430069164563\n",
      "Operator 118: 1.9276599821155354\n",
      "Operator 120: 1.972812625924853\n",
      "Operator 121: 1.3854031852446855\n",
      "Operator 122: -0.42738079605510765\n",
      "Operator 123: 0.7124527645589276\n",
      "Operator 124: 0.2950662945588891\n",
      "Operator 125: 0.8266823270336643\n",
      "Operator 126: 0.40389577013757205\n",
      "Operator 127: 1.0110954375660368\n",
      "Operator 128: -1.2253875226490416\n",
      "Operator 129: 2.570077434093966\n",
      "Operator 130: -1.6234499667487876\n",
      "Operator 131: 2.2730409477430236\n",
      "Operator 132: -1.8034945083768181\n",
      "Operator 133: 2.1407352038191254\n",
      "Operator 134: -1.9066112523871754\n",
      "Operator 135: 2.0661758848831147\n",
      "Operator 136: -1.9674783054249112\n",
      "Operator 137: 2.0216606543075377\n",
      "Operator 138: 0.12585038010383698\n",
      "Operator 139: -1.011501754490143\n",
      "Operator 140: -0.24064443920047907\n",
      "Operator 141: -0.7386799073852581\n",
      "Operator 142: 0.3965785743930576\n",
      "Operator 143: -1.0635836962782494\n",
      "Operator 144: -0.14189561187549987\n",
      "Operator 145: -2.334865230976874\n",
      "Operator 146: 1.0293769940468647\n",
      "Operator 147: -2.273040947743022\n",
      "Operator 148: 1.5388830205290303\n",
      "Operator 149: -2.1407352038191276\n",
      "Operator 150: 1.7574926145151708\n",
      "Operator 151: -2.066175884883113\n",
      "Operator 152: 1.8784478442737749\n",
      "Operator 153: -2.021660654307535\n",
      "Operator 154: 1.9512708516954729\n",
      "Operator 155: -1.0979769782509963\n",
      "Operator 156: 2.813785410161449e-07\n",
      "Operator 157: -1.8490948659033024\n",
      "Operator 158: -1.1711375394379515\n",
      "Operator 159: -0.20615716391608452\n",
      "Operator 160: -0.47800501927415917\n",
      "Operator 161: -0.06220118395270077\n",
      "Operator 162: -0.6173907243608598\n",
      "Operator 163: 1.001772492892251\n",
      "Operator 164: -0.7475465098301283\n",
      "Operator 166: -1.2367300380314012\n",
      "Operator 168: -1.7095881837310662\n",
      "Operator 170: -1.8507430069164585\n",
      "Operator 172: -1.927659982115534\n",
      "Operator 174: -1.9728126259248506\n",
      "Operator 175: 1.7107338311491547\n",
      "Operator 176: 1.581240640168516\n",
      "Operator 177: 0.5943792314899534\n",
      "Operator 178: -0.43335495639452126\n",
      "Operator 179: 0.568024672609164\n",
      "Operator 180: -0.7015328968941688\n",
      "Operator 181: -1.5244855762189173\n",
      "Operator 182: 1.7450890775705046\n",
      "Operator 183: -1.3739180017201174\n",
      "Operator 184: 1.8002967229238793\n",
      "Operator 185: -1.8002967229238926\n",
      "Operator 186: 1.8992293458764218\n",
      "Operator 187: -1.8992293458764176\n",
      "Operator 188: 1.9489410385689392\n",
      "Operator 189: -1.9489410385689332\n",
      "Operator 190: 1.9781614158332994\n",
      "Operator 191: -1.9781614158332963\n",
      "Operator 192: 1.9945921603104773\n",
      "Operator 193: -1.6324827810617517\n",
      "Operator 194: 1.00506356483649\n",
      "Operator 195: 0.5246436245380874\n",
      "Operator 196: -1.1633611845348857\n",
      "Operator 197: 0.6129864007553665\n",
      "Operator 198: -1.0115780296140395\n",
      "Operator 199: -1.1192488263666491\n",
      "Operator 200: 1.115324671904618\n",
      "Operator 201: -1.5123252535817655\n",
      "Operator 202: 0.3692351393108384\n",
      "Operator 203: -1.8002967229238926\n",
      "Operator 204: 0.18573557013857528\n",
      "Operator 205: -1.8992293458764176\n",
      "Operator 206: 0.09002198358440519\n",
      "Operator 207: -1.9489410385689327\n",
      "Operator 208: 0.03263819820663566\n",
      "Operator 209: -1.9781614158332963\n",
      "Operator 210: -0.4689331655215656\n",
      "Operator 211: 1.1280051961278028\n",
      "Operator 212: -1.471521874743705\n",
      "Operator 213: 0.9005497394806306\n",
      "Operator 214: -1.0379968335915803\n",
      "Operator 215: -1.2175178557294184\n",
      "Operator 216: 0.32745258819074785\n",
      "Operator 217: 0.5257369427800538\n",
      "Operator 218: -1.6355344660183067\n",
      "Operator 219: 0.3692351393108413\n",
      "Operator 220: -1.8992293458764253\n",
      "Operator 221: 0.18573557013857867\n",
      "Operator 222: -1.9489410385689396\n",
      "Operator 223: 0.09002198358440704\n",
      "Operator 224: -1.9781614158333016\n",
      "Operator 225: 0.032638198206635216\n",
      "Operator 226: -1.9945921603104795\n",
      "Operator 227: -0.6184871586365166\n",
      "Operator 228: 1.4012462003251691\n",
      "Operator 229: -3.3254805954829946e-07\n",
      "Operator 230: 0.8147799242217697\n",
      "Operator 231: -0.7551373255409682\n",
      "Operator 232: 0.6929168290066745\n",
      "Operator 233: -1.453621602050804\n",
      "Operator 234: 0.44041642207969206\n",
      "Operator 235: 3.8235127889151e-07\n",
      "Operator 236: 0.8055131632030215\n",
      "Operator 237: -1.825155299880274e-07\n",
      "Operator 238: 0.51033291126189\n",
      "Operator 239: 4.171151795944957e-08\n",
      "Operator 240: 0.3154905790463478\n",
      "Operator 241: -3.2126378504981403e-07\n",
      "Operator 242: 0.15183972896287545\n",
      "Operator 243: 9.129796740836582e-08\n",
      "Operator 244: 1.2081475756269149\n",
      "Operator 245: 0.740020104819199\n",
      "Operator 246: -0.4888060838030732\n",
      "Operator 247: 1.1201053959336056\n",
      "Operator 248: -0.570719714983884\n",
      "Operator 249: -1.1614547213287825\n",
      "Operator 250: 1.5258322087674854\n",
      "Operator 251: -0.4776217603614651\n",
      "Operator 252: 1.6355344660183067\n",
      "Operator 253: -0.36923513931083807\n",
      "Operator 254: 1.8992293458764218\n",
      "Operator 255: -0.18573557013857445\n",
      "Operator 256: 1.9489410385689392\n",
      "Operator 257: -0.09002198358440627\n",
      "Operator 258: 1.9781614158332999\n",
      "Operator 259: -0.03263819820663638\n",
      "Operator 260: 1.9945921603104773\n",
      "Total gradient norm: 20.04368095521377\n",
      "Operators under consideration (1):\n",
      "[76]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.5700774340939647)]\n",
      "Operator(s) added to ansatz: [76]\n",
      "Gradients: [np.float64(-2.5700774340939647)]\n",
      "Initial energy: -30.54556444283302\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76]...\n",
      "Starting point: [np.float64(0.6721752591788646), np.float64(0.7114413450048531), np.float64(0.6260020854435105), np.float64(-0.2155812785039619), np.float64(-0.25334274582158567), np.float64(-0.18107643513124155), np.float64(0.5600549996120524), np.float64(-0.24298587415834497), np.float64(0.7486208656814821), np.float64(0.42871448736376216), np.float64(-0.5240761665066115), np.float64(-0.3533561239072697), np.float64(-0.3233387561638037), np.float64(0.30548607546452794), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -30.811028\n",
      "         Iterations: 22\n",
      "         Function evaluations: 70\n",
      "         Gradient evaluations: 59\n",
      "\n",
      "Current energy: -30.81102788714549\n",
      "(change of -0.26546344431246993)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76]\n",
      "On iteration 15.\n",
      "\n",
      "*** ADAPT-VQE Iteration 16 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.6014910226089794\n",
      "Operator 1: 1.726378603998616\n",
      "Operator 2: 1.047149102629954e-08\n",
      "Operator 3: 1.6269804464215356\n",
      "Operator 4: -0.8110334195120432\n",
      "Operator 6: -1.3055893045100424\n",
      "Operator 7: 1.27097832615558\n",
      "Operator 9: 2.0605774242469854\n",
      "Operator 11: 1.3979297696153359\n",
      "Operator 13: 0.9464643128315243\n",
      "Operator 15: 0.5586009560849594\n",
      "Operator 18: -0.8997828093036458\n",
      "Operator 19: 1.1847926793513095\n",
      "Operator 20: -0.9683402720783738\n",
      "Operator 21: 0.8041227333562082\n",
      "Operator 22: -0.7834355976326275\n",
      "Operator 24: -0.7269375727672879\n",
      "Operator 25: 0.9020375986957342\n",
      "Operator 28: -0.7196480222934137\n",
      "Operator 30: -0.41702025044885643\n",
      "Operator 32: -0.19559139193191155\n",
      "Operator 34: -0.964727445224554\n",
      "Operator 35: 0.761890129322725\n",
      "Operator 36: 0.23295022598368503\n",
      "Operator 37: 0.6476754013840331\n",
      "Operator 38: 1.0253155372409748\n",
      "Operator 39: 0.5961108503724329\n",
      "Operator 40: 0.09631572181504135\n",
      "Operator 41: 1.6238337301931807\n",
      "Operator 42: -0.06181447635671858\n",
      "Operator 43: 2.289407483261069\n",
      "Operator 44: -1.1260525508978743\n",
      "Operator 45: 2.236408607675261\n",
      "Operator 46: -1.5904547431817209\n",
      "Operator 47: 2.1069448218606173\n",
      "Operator 48: -1.8033398523206312\n",
      "Operator 49: 2.0346204381968764\n",
      "Operator 50: -1.92212274152946\n",
      "Operator 51: 0.8843191955957771\n",
      "Operator 52: -0.9824650598187441\n",
      "Operator 53: 0.6946608085263244\n",
      "Operator 54: 0.05010598798016402\n",
      "Operator 55: 0.35041757664466516\n",
      "Operator 56: 0.33932840390424746\n",
      "Operator 57: 0.6006607902418282\n",
      "Operator 58: 0.0548543790940534\n",
      "Operator 59: 0.7936411727600977\n",
      "Operator 61: 1.4324372902770686\n",
      "Operator 63: 1.745656271923893\n",
      "Operator 65: 1.882397882197497\n",
      "Operator 67: 1.9564368886803931\n",
      "Operator 68: -0.8332082675757302\n",
      "Operator 69: -0.8080796531926848\n",
      "Operator 70: -0.8177641719291577\n",
      "Operator 71: -0.46078217391012155\n",
      "Operator 72: -0.5748112161830661\n",
      "Operator 73: 0.44811667249266784\n",
      "Operator 74: -0.9468476760956615\n",
      "Operator 75: 0.40644263072428793\n",
      "Operator 76: 1.2447870994603672e-08\n",
      "Operator 77: 1.3050832074860832\n",
      "Operator 78: -2.509552930681605\n",
      "Operator 79: 1.672341196910561\n",
      "Operator 80: -2.236408607675262\n",
      "Operator 81: 1.8493823148109867\n",
      "Operator 82: -2.1069448218606164\n",
      "Operator 83: 1.9479886196481007\n",
      "Operator 84: -2.0346204381968747\n",
      "Operator 85: 0.8596373580127479\n",
      "Operator 87: 1.5331319264630758\n",
      "Operator 89: 0.8654948924911254\n",
      "Operator 90: -1.6985102505812288\n",
      "Operator 91: -1.4236942993176505e-08\n",
      "Operator 92: -0.853108427619557\n",
      "Operator 93: 0.6621969551990409\n",
      "Operator 94: -2.06057742424698\n",
      "Operator 96: -1.3979297696153279\n",
      "Operator 98: -0.9464643128315211\n",
      "Operator 100: -0.558600956084964\n",
      "Operator 102: -0.7048619651454733\n",
      "Operator 104: 0.7785147310883702\n",
      "Operator 105: -0.7167565608773572\n",
      "Operator 106: 0.3589702879144405\n",
      "Operator 107: 0.514438521386719\n",
      "Operator 108: 0.4890712331934881\n",
      "Operator 109: 0.31708011696833993\n",
      "Operator 110: 0.41621320189679634\n",
      "Operator 111: 0.2375462940203909\n",
      "Operator 112: 0.9077577820880697\n",
      "Operator 114: 1.3067796305742072\n",
      "Operator 116: 1.745656271923893\n",
      "Operator 118: 1.8823978821974974\n",
      "Operator 120: 1.9564368886803933\n",
      "Operator 121: 1.3710572830955121\n",
      "Operator 122: -0.4041193173471458\n",
      "Operator 123: 0.6503818131695731\n",
      "Operator 124: 0.38816310649020314\n",
      "Operator 125: 0.6329210849803981\n",
      "Operator 126: 0.8674719845077865\n",
      "Operator 127: 0.7176327356510614\n",
      "Operator 128: -0.372360184049499\n",
      "Operator 129: 1.9629673866071418\n",
      "Operator 130: -0.917638879442121\n",
      "Operator 131: 2.509552930681607\n",
      "Operator 132: -1.6723411969105606\n",
      "Operator 133: 2.2364086076752616\n",
      "Operator 134: -1.8493823148109876\n",
      "Operator 135: 2.1069448218606177\n",
      "Operator 136: -1.9479886196481007\n",
      "Operator 137: 2.034620438196877\n",
      "Operator 138: 0.10288719033317514\n",
      "Operator 139: -0.9987701883539755\n",
      "Operator 140: -0.3027057248311922\n",
      "Operator 141: -0.7010813031731662\n",
      "Operator 142: 0.35070433400512013\n",
      "Operator 143: -0.7088477354438603\n",
      "Operator 144: -0.40144333938744114\n",
      "Operator 145: 0.19300882090000188\n",
      "Operator 146: 0.8876898323224534\n",
      "Operator 147: -2.2894074832610674\n",
      "Operator 148: 1.1260525508978743\n",
      "Operator 149: -2.236408607675262\n",
      "Operator 150: 1.5904547431817178\n",
      "Operator 151: -2.1069448218606164\n",
      "Operator 152: 1.803339852320628\n",
      "Operator 153: -2.0346204381968747\n",
      "Operator 154: 1.92212274152946\n",
      "Operator 155: -1.0859535095206656\n",
      "Operator 157: -1.8505550943575009\n",
      "Operator 158: -1.1616784946998227\n",
      "Operator 159: -0.21454322100617274\n",
      "Operator 160: -0.45531989293840924\n",
      "Operator 161: -0.10616588395182694\n",
      "Operator 162: -0.5298131347189436\n",
      "Operator 163: 1.036017490768848\n",
      "Operator 164: -0.4192801654850521\n",
      "Operator 165: -0.22233074464458474\n",
      "Operator 166: 0.9864621367711058\n",
      "Operator 167: 0.6439395715266547\n",
      "Operator 168: -1.432437290277067\n",
      "Operator 170: -1.7456562719238953\n",
      "Operator 172: -1.8823978821974956\n",
      "Operator 174: -1.9564368886803902\n",
      "Operator 175: 1.7079286453387739\n",
      "Operator 176: 1.5737462669822948\n",
      "Operator 177: 0.6399049012468669\n",
      "Operator 178: -0.46833362090050834\n",
      "Operator 179: 0.7086233325252687\n",
      "Operator 180: -0.8362000103508852\n",
      "Operator 181: -1.4607820610998095\n",
      "Operator 182: 1.2141832151227085\n",
      "Operator 183: -1.4001426671124317\n",
      "Operator 184: -0.9993207507374879\n",
      "Operator 185: -1.572218985257535\n",
      "Operator 186: 1.8221854636139736\n",
      "Operator 187: -1.822185463613971\n",
      "Operator 188: 1.9160028512813818\n",
      "Operator 189: -1.916002851281376\n",
      "Operator 190: 1.9649217963727215\n",
      "Operator 191: -1.964921796372718\n",
      "Operator 192: 1.9913636179231546\n",
      "Operator 193: -1.6235565749021514\n",
      "Operator 194: 1.0118741643554547\n",
      "Operator 195: 0.5690845826877777\n",
      "Operator 196: -1.216900251765634\n",
      "Operator 197: 0.7363153571550383\n",
      "Operator 198: -1.2437888428069153\n",
      "Operator 199: -0.9301264221986483\n",
      "Operator 200: 1.0176075397563384\n",
      "Operator 201: -1.8626547725703224\n",
      "Operator 202: -0.18886092107924798\n",
      "Operator 203: -1.4342992595083848\n",
      "Operator 204: 0.32297294864704573\n",
      "Operator 205: -1.822185463613971\n",
      "Operator 206: 0.14726910725078624\n",
      "Operator 207: -1.916002851281376\n",
      "Operator 208: 0.052307699669080554\n",
      "Operator 209: -1.9649217963727177\n",
      "Operator 210: -0.45471236069481985\n",
      "Operator 211: 1.1384717367879897\n",
      "Operator 212: -1.4570284677677858\n",
      "Operator 213: 0.8897203701915345\n",
      "Operator 214: -0.914073443548117\n",
      "Operator 215: -1.3126894306483523\n",
      "Operator 216: 0.6659374373124821\n",
      "Operator 217: -0.32589711466505555\n",
      "Operator 218: -1.774511498389581\n",
      "Operator 219: 0.4577459826180667\n",
      "Operator 220: -1.6623379348903873\n",
      "Operator 221: 0.32297294864704973\n",
      "Operator 222: -1.9160028512813834\n",
      "Operator 223: 0.14726910725078818\n",
      "Operator 224: -1.9649217963727237\n",
      "Operator 225: 0.05230769966907983\n",
      "Operator 226: -1.9913636179231566\n",
      "Operator 227: -0.6205286801220611\n",
      "Operator 228: 1.4151294886200185\n",
      "Operator 230: 0.8223065436032859\n",
      "Operator 231: -0.7347493104433737\n",
      "Operator 232: 0.7365379825706664\n",
      "Operator 233: -1.4195132688959884\n",
      "Operator 234: 0.5776725201200663\n",
      "Operator 235: -0.5520851916477747\n",
      "Operator 236: 0.8091379998868022\n",
      "Operator 237: -0.662196955199041\n",
      "Operator 238: 0.7196480222934145\n",
      "Operator 240: 0.4170202504488565\n",
      "Operator 242: 0.19559139193191144\n",
      "Operator 244: 1.1932737961560795\n",
      "Operator 245: 0.749046536125632\n",
      "Operator 246: -0.5193760412515877\n",
      "Operator 247: 1.1448620514715016\n",
      "Operator 248: -0.6361218182992612\n",
      "Operator 249: -1.2491343496134948\n",
      "Operator 250: 1.3985629879729857\n",
      "Operator 251: -0.7267603242946317\n",
      "Operator 252: -1.0254195784191342\n",
      "Operator 253: -0.5017620413080036\n",
      "Operator 254: 1.662337934890384\n",
      "Operator 255: -0.32297294864704396\n",
      "Operator 256: 1.9160028512813818\n",
      "Operator 257: -0.14726910725078726\n",
      "Operator 258: 1.9649217963727215\n",
      "Operator 259: -0.052307699669081\n",
      "Operator 260: 1.9913636179231544\n",
      "Total gradient norm: 18.98973788133158\n",
      "Operators under consideration (1):\n",
      "[78]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.509552930681605)]\n",
      "Operator(s) added to ansatz: [78]\n",
      "Gradients: [np.float64(-2.509552930681605)]\n",
      "Initial energy: -30.81102788714549\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78]...\n",
      "Starting point: [np.float64(0.639974829666894), np.float64(0.6916148680190136), np.float64(0.5729636544792939), np.float64(-0.2534152699864059), np.float64(-0.26696198232752005), np.float64(-0.18253544452112064), np.float64(0.45224456283072195), np.float64(-0.24709321158750597), np.float64(0.7389153578789928), np.float64(0.34264197034540267), np.float64(-0.5226478878244499), np.float64(-0.35022947458647313), np.float64(-0.29681397507370266), np.float64(0.29712847135628323), np.float64(0.2109933689881767), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -31.068770\n",
      "         Iterations: 23\n",
      "         Function evaluations: 38\n",
      "         Gradient evaluations: 38\n",
      "\n",
      "Current energy: -31.068769505317977\n",
      "(change of -0.25774161817248853)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78]\n",
      "On iteration 16.\n",
      "\n",
      "*** ADAPT-VQE Iteration 17 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.6024157338784517\n",
      "Operator 1: 1.7207915806150305\n",
      "Operator 3: 1.6004255990514606\n",
      "Operator 4: -0.8573108071982323\n",
      "Operator 6: -1.4616528108631872\n",
      "Operator 7: 1.0539724570451146\n",
      "Operator 8: -0.5186560005844865\n",
      "Operator 9: 1.2654796928486223\n",
      "Operator 11: 1.9992583872454475\n",
      "Operator 13: 1.28909661483894\n",
      "Operator 15: 0.7504650884722768\n",
      "Operator 18: -0.899788560035695\n",
      "Operator 19: 1.181333675864662\n",
      "Operator 20: -0.9783201573154411\n",
      "Operator 21: 0.8059143248011504\n",
      "Operator 22: -0.8221383795587993\n",
      "Operator 24: -0.7915036957540921\n",
      "Operator 25: 0.856098055289841\n",
      "Operator 30: -0.6212751930175808\n",
      "Operator 32: -0.27343081613571907\n",
      "Operator 34: -0.9607318454604138\n",
      "Operator 35: 0.7486227043673401\n",
      "Operator 36: 0.24400660694191728\n",
      "Operator 37: 0.6008306324411644\n",
      "Operator 38: 1.0845913680836339\n",
      "Operator 39: 0.5425857114059077\n",
      "Operator 40: 0.32905413952393303\n",
      "Operator 41: 1.372881025438059\n",
      "Operator 42: 0.6501042922918864\n",
      "Operator 43: 1.6283558615033353\n",
      "Operator 44: -0.13525843109150457\n",
      "Operator 45: 2.2601355031791677\n",
      "Operator 46: -1.1635539043831806\n",
      "Operator 47: 2.197505501979159\n",
      "Operator 48: -1.6359178712817943\n",
      "Operator 49: 2.0624141698297334\n",
      "Operator 50: -1.8596289845882552\n",
      "Operator 51: 0.879949418323961\n",
      "Operator 52: -0.9871017646765858\n",
      "Operator 53: 0.6895358725094085\n",
      "Operator 54: 0.05880410516120622\n",
      "Operator 55: 0.3212388761243915\n",
      "Operator 56: 0.37230652690925836\n",
      "Operator 57: 0.491414185070412\n",
      "Operator 58: 0.17832444424061336\n",
      "Operator 59: 0.5178742305739135\n",
      "Operator 60: 0.18005555641054752\n",
      "Operator 61: 0.9534632300124115\n",
      "Operator 63: 1.4625747086518806\n",
      "Operator 65: 1.7796798444775015\n",
      "Operator 67: 1.9210295049526867\n",
      "Operator 68: -0.8253120667745784\n",
      "Operator 69: -0.8253182853159473\n",
      "Operator 70: -0.7993690696459679\n",
      "Operator 71: -0.5095406901730206\n",
      "Operator 72: -0.5106198363189105\n",
      "Operator 73: 0.3583711017203519\n",
      "Operator 74: -0.7251155349712111\n",
      "Operator 75: -0.07747400422566629\n",
      "Operator 76: 0.267238032035911\n",
      "Operator 77: 1.171624037281016\n",
      "Operator 79: 1.3444283879114556\n",
      "Operator 80: -2.477127141944755\n",
      "Operator 81: 1.7227971843143648\n",
      "Operator 82: -2.1975055019791574\n",
      "Operator 83: 1.9061005355806326\n",
      "Operator 84: -2.0624141698297307\n",
      "Operator 85: 0.8648052537260107\n",
      "Operator 87: 1.5471709715602464\n",
      "Operator 89: 0.8688442649843036\n",
      "Operator 90: -1.623006850412493\n",
      "Operator 92: -0.889210033150708\n",
      "Operator 93: 0.7725733622549955\n",
      "Operator 94: -0.8322653210930221\n",
      "Operator 95: 0.6510639748615217\n",
      "Operator 96: -1.9992583872454417\n",
      "Operator 98: -1.2890966148389373\n",
      "Operator 100: -0.7504650884722815\n",
      "Operator 102: -0.7069630184124023\n",
      "Operator 104: 0.7733028151680238\n",
      "Operator 105: -0.7195527278465066\n",
      "Operator 106: 0.3433810785482164\n",
      "Operator 107: 0.5286195404398593\n",
      "Operator 108: 0.469926290424341\n",
      "Operator 109: 0.3661782906299438\n",
      "Operator 110: 0.3373514294531962\n",
      "Operator 111: 0.3416377340834094\n",
      "Operator 112: 0.661525805259527\n",
      "Operator 113: 0.24322397006975877\n",
      "Operator 114: 0.835697732215288\n",
      "Operator 116: 1.3344559385356594\n",
      "Operator 118: 1.7796798444775017\n",
      "Operator 120: 1.9210295049526867\n",
      "Operator 121: 1.3653447135397945\n",
      "Operator 122: -0.3953203018586007\n",
      "Operator 123: 0.6252036773996603\n",
      "Operator 124: 0.42181198184560825\n",
      "Operator 125: 0.5504582027322731\n",
      "Operator 126: 1.0447029584542848\n",
      "Operator 127: 0.5940382365068109\n",
      "Operator 128: 0.12734875146577657\n",
      "Operator 129: 1.5270805586552598\n",
      "Operator 130: 0.07315812017866523\n",
      "Operator 131: 1.956720574870904\n",
      "Operator 132: -0.9703067497697602\n",
      "Operator 133: 2.477127141944756\n",
      "Operator 134: -1.7227971843143648\n",
      "Operator 135: 2.197505501979159\n",
      "Operator 136: -1.9061005355806326\n",
      "Operator 137: 2.062414169829733\n",
      "Operator 138: 0.09391866017257168\n",
      "Operator 139: -0.9938288944280805\n",
      "Operator 140: -0.327831981589764\n",
      "Operator 141: -0.6862548329798361\n",
      "Operator 142: 0.3338295822587601\n",
      "Operator 143: -0.54869602010655\n",
      "Operator 144: -0.49761624582141567\n",
      "Operator 145: 0.25402196875493993\n",
      "Operator 146: 0.6424417479711879\n",
      "Operator 147: 0.3143338300636997\n",
      "Operator 148: 0.9672509169562316\n",
      "Operator 149: -2.2601355031791677\n",
      "Operator 150: 1.1635539043831806\n",
      "Operator 151: -2.1975055019791574\n",
      "Operator 152: 1.6359178712817957\n",
      "Operator 153: -2.0624141698297307\n",
      "Operator 154: 1.8596289845882552\n",
      "Operator 155: -1.0812893513079456\n",
      "Operator 157: -1.8510693948082353\n",
      "Operator 158: -1.1579933483399496\n",
      "Operator 159: -0.21785951935516512\n",
      "Operator 160: -0.4466403242939925\n",
      "Operator 161: -0.12325963482981617\n",
      "Operator 162: -0.4963014184420337\n",
      "Operator 163: 1.0460843883055646\n",
      "Operator 164: -0.3020845010193094\n",
      "Operator 165: -0.35496067410989324\n",
      "Operator 166: 1.0951545250964403\n",
      "Operator 167: 1.1061115633907401\n",
      "Operator 168: 0.9575677055494689\n",
      "Operator 169: 0.6512314683872313\n",
      "Operator 170: -1.4625747086518825\n",
      "Operator 172: -1.7796798444774995\n",
      "Operator 174: -1.9210295049526833\n",
      "Operator 175: 1.7068449325215105\n",
      "Operator 176: 1.5708060677683031\n",
      "Operator 177: 0.6573569377762002\n",
      "Operator 178: -0.48170584351016094\n",
      "Operator 179: 0.7616794200221613\n",
      "Operator 180: -0.8882430658482552\n",
      "Operator 181: -1.4321017837388363\n",
      "Operator 182: 0.9911014709987769\n",
      "Operator 183: -1.16706516010125\n",
      "Operator 184: -1.3713555017615477\n",
      "Operator 185: -1.8721420256922134\n",
      "Operator 186: -0.9637788041558293\n",
      "Operator 187: -1.5911035484290943\n",
      "Operator 188: 1.8384406346097633\n",
      "Operator 189: -1.8384406346097588\n",
      "Operator 190: 1.9360754010480283\n",
      "Operator 191: -1.9360754010480243\n",
      "Operator 192: 1.9844573242476418\n",
      "Operator 193: -1.6199993594724704\n",
      "Operator 194: 1.014383905105329\n",
      "Operator 195: 0.5860539998513544\n",
      "Operator 196: -1.2362868819303015\n",
      "Operator 197: 0.7806916819260457\n",
      "Operator 198: -1.3337055469100196\n",
      "Operator 199: -0.856594272162528\n",
      "Operator 200: 0.9300693558302491\n",
      "Operator 201: -1.6032791913274846\n",
      "Operator 202: -0.515636072606026\n",
      "Operator 203: -1.5284099843551142\n",
      "Operator 204: -0.1748511205203152\n",
      "Operator 205: -1.451725895755072\n",
      "Operator 206: 0.2793675536628404\n",
      "Operator 207: -1.8384406346097588\n",
      "Operator 208: 0.09485347419200285\n",
      "Operator 209: -1.9360754010480243\n",
      "Operator 210: -0.4492473732838812\n",
      "Operator 211: 1.1424127192579858\n",
      "Operator 212: -1.451412946228122\n",
      "Operator 213: 0.8835782700743068\n",
      "Operator 214: -0.8622478362839201\n",
      "Operator 215: -1.352080446578252\n",
      "Operator 216: 0.766084676394126\n",
      "Operator 217: -0.5922357440131765\n",
      "Operator 218: -1.3036596536282608\n",
      "Operator 219: -0.38529771781583333\n",
      "Operator 220: -1.8070446987823736\n",
      "Operator 221: 0.43103970533344704\n",
      "Operator 222: -1.6773967223606643\n",
      "Operator 223: 0.2793675536628426\n",
      "Operator 224: -1.936075401048031\n",
      "Operator 225: 0.09485347419200157\n",
      "Operator 226: -1.9844573242476433\n",
      "Operator 227: -0.6212817248055982\n",
      "Operator 228: 1.4203409496080077\n",
      "Operator 230: 0.8238892438892949\n",
      "Operator 231: -0.7242229198097953\n",
      "Operator 232: 0.7442859169254946\n",
      "Operator 233: -1.4003462771552657\n",
      "Operator 234: 0.6831252164689193\n",
      "Operator 235: -0.6797796086082573\n",
      "Operator 236: 1.0801734829340535\n",
      "Operator 237: -1.2180499411423056\n",
      "Operator 238: 0.7704461678438881\n",
      "Operator 239: -0.6510639748615217\n",
      "Operator 240: 0.6212751930175808\n",
      "Operator 242: 0.2734308161357194\n",
      "Operator 244: 1.187407934782633\n",
      "Operator 245: 0.7525759583036058\n",
      "Operator 246: -0.5308191525259818\n",
      "Operator 247: 1.154756007144624\n",
      "Operator 248: -0.6566569023186604\n",
      "Operator 249: -1.2688668534562204\n",
      "Operator 250: 1.3401791239445944\n",
      "Operator 251: -0.7379280467693254\n",
      "Operator 252: -1.2051305334193674\n",
      "Operator 253: -1.2092273524723514\n",
      "Operator 254: -1.0948080309873705\n",
      "Operator 255: -0.47242307013691265\n",
      "Operator 256: 1.6773967223606618\n",
      "Operator 257: -0.2793675536628416\n",
      "Operator 258: 1.9360754010480279\n",
      "Operator 259: -0.09485347419200368\n",
      "Operator 260: 1.984457324247642\n",
      "Total gradient norm: 17.979865151264367\n",
      "Operators under consideration (1):\n",
      "[133]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.477127141944756)]\n",
      "Operator(s) added to ansatz: [133]\n",
      "Gradients: [np.float64(2.477127141944756)]\n",
      "Initial energy: -31.068769505317977\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133]...\n",
      "Starting point: [np.float64(0.5830478533888119), np.float64(0.658642432687595), np.float64(0.45995886309770173), np.float64(-0.269708780605288), np.float64(-0.27257753715886085), np.float64(-0.18310413156407018), np.float64(0.3582697477050952), np.float64(-0.24872346022039282), np.float64(0.723022589639001), np.float64(0.3060468103592101), np.float64(-0.5220964873554963), np.float64(-0.3490227678529039), np.float64(-0.2868530212962177), np.float64(0.2939167308021053), np.float64(0.25114062802044046), np.float64(0.2108408766545441), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -31.312966\n",
      "         Iterations: 25\n",
      "         Function evaluations: 37\n",
      "         Gradient evaluations: 37\n",
      "\n",
      "Current energy: -31.31296617959942\n",
      "(change of -0.24419667428144365)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133]\n",
      "On iteration 17.\n",
      "\n",
      "*** ADAPT-VQE Iteration 18 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.6027455404707387\n",
      "Operator 1: 1.718777413059938\n",
      "Operator 3: 1.5907376916820706\n",
      "Operator 4: -0.874697783635899\n",
      "Operator 6: -1.5188154677455104\n",
      "Operator 7: 0.9437399176764474\n",
      "Operator 8: -0.6807968136712703\n",
      "Operator 9: 1.1033977564346242\n",
      "Operator 11: 0.8742952309330498\n",
      "Operator 12: -0.6162042050896862\n",
      "Operator 13: 1.8858294351921607\n",
      "Operator 15: 1.0627331360386187\n",
      "Operator 18: -0.8997664538068326\n",
      "Operator 19: 1.1799789423249982\n",
      "Operator 20: -0.9816714147805884\n",
      "Operator 21: 0.8060497916228719\n",
      "Operator 22: -0.8346336784993811\n",
      "Operator 24: -0.8047254620348605\n",
      "Operator 25: 0.8379386021636743\n",
      "Operator 29: 0.5134692731768649\n",
      "Operator 30: -0.7108563071315708\n",
      "Operator 31: 0.6162042050896862\n",
      "Operator 32: -0.423824211837767\n",
      "Operator 34: -0.9593019615521519\n",
      "Operator 35: 0.7438830973991174\n",
      "Operator 36: 0.24796824383859867\n",
      "Operator 37: 0.5841145493997254\n",
      "Operator 38: 1.1061804625121046\n",
      "Operator 39: 0.5231010357791726\n",
      "Operator 40: 0.4193600102552558\n",
      "Operator 41: 1.2516052315921664\n",
      "Operator 42: 0.8784427416059515\n",
      "Operator 43: 1.4058923371114012\n",
      "Operator 44: 0.20410522823683958\n",
      "Operator 45: -0.17660959966412815\n",
      "Operator 46: -1.0104456975106304\n",
      "Operator 47: 2.223317858419947\n",
      "Operator 48: -1.2253081912004014\n",
      "Operator 49: 2.124831351377869\n",
      "Operator 50: -1.7193729268863578\n",
      "Operator 51: 0.878385170145626\n",
      "Operator 52: -0.9887529138012645\n",
      "Operator 53: 0.6877078950933668\n",
      "Operator 54: 0.0620353388196379\n",
      "Operator 55: 0.3105796117143834\n",
      "Operator 56: 0.3848113205385064\n",
      "Operator 57: 0.45315946858934636\n",
      "Operator 58: 0.23735346989425204\n",
      "Operator 59: 0.427046465209841\n",
      "Operator 60: 0.2878261592538651\n",
      "Operator 61: 0.705253250019332\n",
      "Operator 62: 0.25220049496444435\n",
      "Operator 63: -0.9671348718705609\n",
      "Operator 64: -0.1684088513470799\n",
      "Operator 65: 1.391477591000294\n",
      "Operator 67: 1.8399746067171197\n",
      "Operator 68: -0.8224657955679269\n",
      "Operator 69: -0.8314657776318939\n",
      "Operator 70: -0.792572381048734\n",
      "Operator 71: -0.5267600345223561\n",
      "Operator 72: -0.48580810918812944\n",
      "Operator 73: 0.32862928701050664\n",
      "Operator 74: -0.6367890680436588\n",
      "Operator 75: -0.2530047483364149\n",
      "Operator 76: 0.36628830005573537\n",
      "Operator 77: 0.790110295953922\n",
      "Operator 78: 0.14645258124648122\n",
      "Operator 79: 0.5056172684489311\n",
      "Operator 80: -1.9963274316151867\n",
      "Operator 81: 1.080853541686245\n",
      "Operator 82: -2.417921145348471\n",
      "Operator 83: 1.8114877791415966\n",
      "Operator 84: -2.1248313513778667\n",
      "Operator 85: 0.8666763297278489\n",
      "Operator 87: 1.5522930238066823\n",
      "Operator 89: 0.8697974971959945\n",
      "Operator 90: -1.5937149364630816\n",
      "Operator 92: -0.8919150821583268\n",
      "Operator 93: 0.8043672899453685\n",
      "Operator 94: -0.8594626466666779\n",
      "Operator 95: 1.1706893034452874\n",
      "Operator 96: -1.2694139942736804\n",
      "Operator 98: -1.8858294351921585\n",
      "Operator 100: -1.0627331360386236\n",
      "Operator 102: -0.7077178459494724\n",
      "Operator 104: 0.7714330174806836\n",
      "Operator 105: -0.7205577430685293\n",
      "Operator 106: 0.33768262837943186\n",
      "Operator 107: 0.5338297756326436\n",
      "Operator 108: 0.4629069459844476\n",
      "Operator 109: 0.3846388894238711\n",
      "Operator 110: 0.31068338054829747\n",
      "Operator 111: 0.3814004878263808\n",
      "Operator 112: 0.569486335799458\n",
      "Operator 113: 0.3226928136525029\n",
      "Operator 114: 0.5578122066346314\n",
      "Operator 115: 0.05823107078054464\n",
      "Operator 116: -0.9472980094460066\n",
      "Operator 117: -0.6365147293445933\n",
      "Operator 118: 1.5132712930886156\n",
      "Operator 120: 1.8399746067171199\n",
      "Operator 121: 1.3632748567691\n",
      "Operator 122: -0.3922000916377746\n",
      "Operator 123: 0.6160108040814384\n",
      "Operator 124: 0.4334133558414661\n",
      "Operator 125: 0.519744108048538\n",
      "Operator 126: 1.1050926665666587\n",
      "Operator 127: 0.5406309490578792\n",
      "Operator 128: 0.3180362980925883\n",
      "Operator 129: 1.33453299040935\n",
      "Operator 130: 0.6249670904990516\n",
      "Operator 131: 1.5726282456792062\n",
      "Operator 132: -0.6178621675375291\n",
      "Operator 134: -1.4140834783411569\n",
      "Operator 135: 2.4179211453484735\n",
      "Operator 136: -1.8114877791415966\n",
      "Operator 137: 2.124831351377869\n",
      "Operator 138: 0.09069360457963435\n",
      "Operator 139: -0.9920568812825461\n",
      "Operator 140: -0.3370056162526224\n",
      "Operator 141: -0.6809081063716984\n",
      "Operator 142: 0.32796103440701196\n",
      "Operator 143: -0.49081335914999413\n",
      "Operator 144: -0.5312271260205883\n",
      "Operator 145: 0.28023994364241134\n",
      "Operator 146: 0.5530606909825031\n",
      "Operator 147: 0.39412557303587836\n",
      "Operator 148: 0.23817826652051555\n",
      "Operator 149: -1.6808211178685897\n",
      "Operator 150: 0.20910988285820253\n",
      "Operator 151: -2.223317858419945\n",
      "Operator 152: 1.2253081912004014\n",
      "Operator 153: -2.1248313513778667\n",
      "Operator 154: 1.7193729268863578\n",
      "Operator 155: -1.0796169864577345\n",
      "Operator 157: -1.8512466952287125\n",
      "Operator 158: -1.1566695875558421\n",
      "Operator 159: -0.2190571272673073\n",
      "Operator 160: -0.443546991051553\n",
      "Operator 161: -0.12934228160136013\n",
      "Operator 162: -0.48439504216762064\n",
      "Operator 163: 1.0493247690993663\n",
      "Operator 164: -0.25669617965818975\n",
      "Operator 165: -0.4141726017639984\n",
      "Operator 166: 1.0960886700465413\n",
      "Operator 167: 1.1420185104646265\n",
      "Operator 168: 1.0833539182667518\n",
      "Operator 169: -0.24050874470439113\n",
      "Operator 170: -0.9965785399145548\n",
      "Operator 172: -1.3914775910002932\n",
      "Operator 174: -1.8399746067171165\n",
      "Operator 175: 1.7064569637666382\n",
      "Operator 176: 1.5697471179284637\n",
      "Operator 177: 0.6635794024118934\n",
      "Operator 178: -0.4864705401640783\n",
      "Operator 179: 0.7803417975289961\n",
      "Operator 180: -0.9069246580528143\n",
      "Operator 181: -1.4211645563283608\n",
      "Operator 182: 0.898963178451555\n",
      "Operator 183: -1.066847625944717\n",
      "Operator 184: -1.4789634209452363\n",
      "Operator 185: -1.729837006101854\n",
      "Operator 186: -1.2250249580693877\n",
      "Operator 187: 0.9706685294413009\n",
      "Operator 188: 2.0815717208179083\n",
      "Operator 189: -1.4890797647563798\n",
      "Operator 190: 1.868909408258557\n",
      "Operator 191: -1.868909408258554\n",
      "Operator 192: 1.9690356296420288\n",
      "Operator 193: -1.6187100511386114\n",
      "Operator 194: 1.0152645495967374\n",
      "Operator 195: 0.5920951161664076\n",
      "Operator 196: -1.2429744397757312\n",
      "Operator 197: 0.7959220175604297\n",
      "Operator 198: -1.3644205513827075\n",
      "Operator 199: -0.8270428184565384\n",
      "Operator 200: 0.8735475708248563\n",
      "Operator 201: -1.5051237877301227\n",
      "Operator 202: -0.7314059138870641\n",
      "Operator 203: -1.2265613575476002\n",
      "Operator 204: -0.42244261386347937\n",
      "Operator 205: 0.9729014981275226\n",
      "Operator 206: 1.0691235211785082\n",
      "Operator 207: -1.619416421578939\n",
      "Operator 208: 0.19224107363872195\n",
      "Operator 209: -1.868909408258554\n",
      "Operator 210: -0.4472950978071047\n",
      "Operator 211: 1.1438086753937116\n",
      "Operator 212: -1.449403162408125\n",
      "Operator 213: 0.8810960955936145\n",
      "Operator 214: -0.8429970234843924\n",
      "Operator 215: -1.3667152674671952\n",
      "Operator 216: 0.7957036127393766\n",
      "Operator 217: -0.7068608134206996\n",
      "Operator 218: -1.1279021695968532\n",
      "Operator 219: -0.6545348970426152\n",
      "Operator 220: -1.6081457959366632\n",
      "Operator 221: 0.7672311610846032\n",
      "Operator 222: 0.9530933883084967\n",
      "Operator 223: 0.42846464792971095\n",
      "Operator 224: -1.71849262791052\n",
      "Operator 225: 0.19224107363871962\n",
      "Operator 226: -1.9690356296420308\n",
      "Operator 227: -0.6215461416945588\n",
      "Operator 228: 1.4221828205019584\n",
      "Operator 230: 0.8242391353714283\n",
      "Operator 231: -0.7199715452268518\n",
      "Operator 232: 0.7451403063964223\n",
      "Operator 233: -1.387554077663629\n",
      "Operator 234: 0.7178526265084194\n",
      "Operator 235: -0.7240257069998377\n",
      "Operator 236: 1.2552039419525478\n",
      "Operator 237: -1.2758402255271863\n",
      "Operator 238: 1.0592893562393253\n",
      "Operator 239: -0.7814581485498282\n",
      "Operator 242: 0.4238242118377672\n",
      "Operator 244: 1.185290547127751\n",
      "Operator 245: 0.7538456736773238\n",
      "Operator 246: -0.5348607796609209\n",
      "Operator 247: 1.158348319375592\n",
      "Operator 248: -0.6631914060716202\n",
      "Operator 249: -1.2734250096835948\n",
      "Operator 250: 1.3187139598632098\n",
      "Operator 251: -0.725442892160734\n",
      "Operator 252: -1.2438341402064235\n",
      "Operator 253: -1.3157072635287002\n",
      "Operator 254: -1.295771247137706\n",
      "Operator 255: 0.2560945907130783\n",
      "Operator 256: 1.832889244173944\n",
      "Operator 257: -0.393980219444438\n",
      "Operator 258: 1.7184926279105177\n",
      "Operator 259: -0.19224107363872273\n",
      "Operator 260: 1.969035629642029\n",
      "Total gradient norm: 16.868054832946125\n",
      "Operators under consideration (1):\n",
      "[82]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.417921145348471)]\n",
      "Operator(s) added to ansatz: [82]\n",
      "Gradients: [np.float64(-2.417921145348471)]\n",
      "Initial energy: -31.31296617959942\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82]...\n",
      "Starting point: [np.float64(0.47182735859756614), np.float64(0.6033622986092937), np.float64(0.36660485967261247), np.float64(-0.2758619347253064), np.float64(-0.2746428781411001), np.float64(-0.18330845148538694), np.float64(0.3207384934950616), np.float64(-0.2493134545883229), np.float64(0.6973007723572042), np.float64(0.2931087150504688), np.float64(-0.5218991277688272), np.float64(-0.34859096976356), np.float64(-0.2833766460662374), np.float64(0.2927710192266623), np.float64(0.2675982577750564), np.float64(0.2469070914595235), np.float64(-0.20197414706870379), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -31.541742\n",
      "         Iterations: 28\n",
      "         Function evaluations: 183\n",
      "         Gradient evaluations: 165\n",
      "\n",
      "Current energy: -31.541742337270136\n",
      "(change of -0.22877615767071546)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82]\n",
      "On iteration 18.\n",
      "\n",
      "*** ADAPT-VQE Iteration 19 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.6028640197970101\n",
      "Operator 1: 1.7180514052190348\n",
      "Operator 3: 1.5872359545251942\n",
      "Operator 4: -0.881081598978779\n",
      "Operator 6: -1.5395321185364064\n",
      "Operator 7: 0.9009084106973604\n",
      "Operator 8: -0.7453439070417651\n",
      "Operator 9: 1.0116890808748715\n",
      "Operator 10: 2.988582625023047e-08\n",
      "Operator 11: 0.919877406795295\n",
      "Operator 12: -1.105199745241584\n",
      "Operator 13: 1.284397750028872\n",
      "Operator 14: 1.204273736288286e-08\n",
      "Operator 15: 1.6250394597053746\n",
      "Operator 16: -2.010064292790048e-08\n",
      "Operator 18: -0.8997552736448362\n",
      "Operator 19: 1.1794755303610818\n",
      "Operator 20: -0.9828441965417021\n",
      "Operator 21: 0.8060218652056587\n",
      "Operator 22: -0.838874488747628\n",
      "Operator 23: 1.636750993979931e-08\n",
      "Operator 24: -0.8074743957881545\n",
      "Operator 25: 0.8280722556310867\n",
      "Operator 26: 2.211692298498673e-08\n",
      "Operator 27: -1.2280160983149983e-08\n",
      "Operator 28: 2.364447997215921e-08\n",
      "Operator 29: 0.6322972491419415\n",
      "Operator 30: -1.0267308391386805\n",
      "Operator 31: 0.7393551957069731\n",
      "Operator 33: -1.204273736288286e-08\n",
      "Operator 34: -0.9587876870018914\n",
      "Operator 35: 0.7421800287070318\n",
      "Operator 36: 0.24939378152040498\n",
      "Operator 37: 0.5781187210047477\n",
      "Operator 38: 1.1140086003758758\n",
      "Operator 39: 0.5160569187561385\n",
      "Operator 40: 0.45302445297263627\n",
      "Operator 41: 1.2043933280827326\n",
      "Operator 42: 0.963012170656226\n",
      "Operator 43: 1.2933357179849003\n",
      "Operator 44: 0.32576125514250304\n",
      "Operator 45: -0.2273053180816231\n",
      "Operator 46: -0.3184983626182607\n",
      "Operator 47: 1.7368886215060477\n",
      "Operator 48: -0.3163315640834805\n",
      "Operator 49: 2.1195969630370772\n",
      "Operator 50: -1.3492353873483438\n",
      "Operator 51: 0.8778225135210087\n",
      "Operator 52: -0.9893456619221963\n",
      "Operator 53: 0.687051235283995\n",
      "Operator 54: 0.06321263918265715\n",
      "Operator 55: 0.30670904097166024\n",
      "Operator 56: 0.3894079110302032\n",
      "Operator 57: 0.43953647999634693\n",
      "Operator 58: 0.2600127945673831\n",
      "Operator 59: 0.3949156671156112\n",
      "Operator 60: 0.3374518550717145\n",
      "Operator 61: 0.6098260621840889\n",
      "Operator 62: 0.3477448938612269\n",
      "Operator 63: -1.0850850445353957\n",
      "Operator 64: 0.00029816203692091954\n",
      "Operator 65: 0.9520518545228013\n",
      "Operator 67: 1.6132218726428822\n",
      "Operator 68: -0.8214393956348913\n",
      "Operator 69: -0.8336736986622877\n",
      "Operator 70: -0.7900984750251003\n",
      "Operator 71: -0.5329156732149161\n",
      "Operator 72: -0.47661142939912315\n",
      "Operator 73: 0.31839996460067355\n",
      "Operator 74: -0.6034438769779561\n",
      "Operator 75: -0.31256782144510903\n",
      "Operator 76: 0.4117716421574485\n",
      "Operator 77: 0.6455880367641526\n",
      "Operator 78: 0.20590858488418018\n",
      "Operator 79: 0.023624746314204977\n",
      "Operator 80: -1.6593293863941918\n",
      "Operator 81: 0.7803573539699405\n",
      "Operator 82: 1.2515416916509895e-08\n",
      "Operator 83: 1.555838748741118\n",
      "Operator 84: -2.2898117948803005\n",
      "Operator 85: 0.867352199141186\n",
      "Operator 86: -4.3673046033492574e-08\n",
      "Operator 87: 1.5541491125037479\n",
      "Operator 88: -3.5459557822561685e-08\n",
      "Operator 89: 0.870106786080054\n",
      "Operator 90: -1.5831136034001139\n",
      "Operator 92: -0.891579735812186\n",
      "Operator 93: 0.8138428796132927\n",
      "Operator 94: -0.8587047190990098\n",
      "Operator 95: 1.3304528816412524\n",
      "Operator 96: -1.124766396164396\n",
      "Operator 98: -0.8609267757268932\n",
      "Operator 99: 0.5810252378652339\n",
      "Operator 100: -1.6250394597053774\n",
      "Operator 101: 2.010064292790048e-08\n",
      "Operator 102: -0.7079897160051116\n",
      "Operator 103: 2.1892706050705326e-08\n",
      "Operator 104: 0.7707599018994702\n",
      "Operator 105: -0.720919809234693\n",
      "Operator 106: 0.33561645415912644\n",
      "Operator 107: 0.5357222592456283\n",
      "Operator 108: 0.46035640246358817\n",
      "Operator 109: 0.39136030307914244\n",
      "Operator 110: 0.3013834375315814\n",
      "Operator 111: 0.3955842373518895\n",
      "Operator 112: 0.5371811281563361\n",
      "Operator 113: 0.35713590367621734\n",
      "Operator 114: 0.46391410487215606\n",
      "Operator 115: 0.12492143210283509\n",
      "Operator 116: -1.0593706710209334\n",
      "Operator 117: 0.19868513462964393\n",
      "Operator 118: 1.0682085322208483\n",
      "Operator 120: 1.4933018467299783\n",
      "Operator 121: 1.3625270206058286\n",
      "Operator 122: -0.39108183984488576\n",
      "Operator 123: 0.6126796884679265\n",
      "Operator 124: 0.4375197669939758\n",
      "Operator 125: 0.5085287346941296\n",
      "Operator 126: 1.1261867324758137\n",
      "Operator 127: 0.5195173341374784\n",
      "Operator 128: 0.38571142547227977\n",
      "Operator 129: 1.2516341662608916\n",
      "Operator 130: 0.831783342104875\n",
      "Operator 131: 1.4008702847901826\n",
      "Operator 132: -0.1310946278554581\n",
      "Operator 133: -0.1298308366018931\n",
      "Operator 134: -0.6345868527232339\n",
      "Operator 135: 2.018089685937644\n",
      "Operator 136: -1.2865959864391219\n",
      "Operator 137: 2.289811794880301\n",
      "Operator 138: 0.0895315937001723\n",
      "Operator 139: -0.9914191179159575\n",
      "Operator 140: -0.34033030828216704\n",
      "Operator 141: -0.6789800368670706\n",
      "Operator 142: 0.3258765480099981\n",
      "Operator 143: -0.47022554201363315\n",
      "Operator 144: -0.54322090495567\n",
      "Operator 145: 0.290506264392057\n",
      "Operator 146: 0.5222752524103763\n",
      "Operator 147: 0.4285519836714091\n",
      "Operator 148: -0.014613664261497721\n",
      "Operator 149: -1.4910837586548658\n",
      "Operator 150: -0.12681859824071567\n",
      "Operator 151: 0.15561754655493643\n",
      "Operator 152: 1.0973361891210607\n",
      "Operator 153: -2.1195969630370763\n",
      "Operator 154: 1.3492353873483438\n",
      "Operator 155: -1.0790150983558713\n",
      "Operator 157: -1.8513095958140728\n",
      "Operator 158: -1.1561928187689963\n",
      "Operator 159: -0.21948925395306074\n",
      "Operator 160: -0.44243624199865705\n",
      "Operator 161: -0.13152172785337907\n",
      "Operator 162: -0.4801263522740086\n",
      "Operator 163: 1.0504501430582744\n",
      "Operator 164: -0.23966855718888372\n",
      "Operator 165: -0.4369040724514559\n",
      "Operator 166: 1.0920619830540383\n",
      "Operator 167: 1.1472952100243905\n",
      "Operator 168: 1.1048759393972107\n",
      "Operator 169: -0.35706160478233223\n",
      "Operator 170: -0.6951825121484216\n",
      "Operator 171: -0.03595189487153582\n",
      "Operator 172: 0.90300433104008\n",
      "Operator 173: 0.6328673822122246\n",
      "Operator 174: -1.6132218726428795\n",
      "Operator 175: 1.7063174180022922\n",
      "Operator 176: 1.569365361404779\n",
      "Operator 177: 0.6658139437802071\n",
      "Operator 178: -0.48818130317654507\n",
      "Operator 179: 0.7870006608932939\n",
      "Operator 180: -0.9136571173902568\n",
      "Operator 181: -1.417134238239527\n",
      "Operator 182: 0.8636725945152681\n",
      "Operator 183: -1.0293916612048004\n",
      "Operator 184: -1.5164051917436518\n",
      "Operator 185: -1.6661772377041348\n",
      "Operator 186: -1.3117842362557839\n",
      "Operator 187: 1.1927385894273121\n",
      "Operator 188: 1.5879184252115626\n",
      "Operator 189: -1.5966888267640669\n",
      "Operator 190: -0.8418383427770993\n",
      "Operator 191: -1.6727214293923878\n",
      "Operator 192: 1.928858977108841\n",
      "Operator 193: -1.618244163811621\n",
      "Operator 194: 1.0155789314952863\n",
      "Operator 195: 0.5942633921520543\n",
      "Operator 196: -1.245341823354285\n",
      "Operator 197: 0.8013012945641563\n",
      "Operator 198: -1.375148840466645\n",
      "Operator 199: -0.815731154580563\n",
      "Operator 200: 0.8493013984652145\n",
      "Operator 201: -1.4643208060357822\n",
      "Operator 202: -0.8179380336381589\n",
      "Operator 203: -1.1156249373251592\n",
      "Operator 204: -0.5977481980618611\n",
      "Operator 205: 1.1528994177700382\n",
      "Operator 206: 1.0251141079972022\n",
      "Operator 207: -1.9635478006425235\n",
      "Operator 208: -0.07754489997579952\n",
      "Operator 209: -1.5483784604806272\n",
      "Operator 210: -0.44659340692866234\n",
      "Operator 211: 1.1443088300017978\n",
      "Operator 212: -1.4486804769971542\n",
      "Operator 213: 0.8801656358084138\n",
      "Operator 214: -0.8359683688904723\n",
      "Operator 215: -1.3720628021614962\n",
      "Operator 216: 0.8053593452955347\n",
      "Operator 217: -0.7493794889119494\n",
      "Operator 218: -1.0585987158784986\n",
      "Operator 219: -0.7735623515261408\n",
      "Operator 220: -1.5203419216942007\n",
      "Operator 221: 0.8016329080259049\n",
      "Operator 222: 1.1684464702173205\n",
      "Operator 223: -0.20262081865810053\n",
      "Operator 224: -1.8951865678965714\n",
      "Operator 225: 0.2962977443196603\n",
      "Operator 226: -1.7854758365503227\n",
      "Operator 227: -0.6216405658874381\n",
      "Operator 228: 1.4228420878437547\n",
      "Operator 230: 0.8243343160123634\n",
      "Operator 231: -0.7183704412881853\n",
      "Operator 232: 0.7451478612416674\n",
      "Operator 233: -1.381684869565146\n",
      "Operator 234: 0.729049250032644\n",
      "Operator 235: -0.7370426733708962\n",
      "Operator 236: 1.3084568607263205\n",
      "Operator 237: -1.2939828469911079\n",
      "Operator 238: 1.246029174184241\n",
      "Operator 239: -0.7676683793983408\n",
      "Operator 241: -0.4721460812338757\n",
      "Operator 242: 0.5334623085762732\n",
      "Operator 243: -0.581025237865235\n",
      "Operator 244: 1.1845265755793637\n",
      "Operator 245: 0.7543032163523884\n",
      "Operator 246: -0.536307211731988\n",
      "Operator 247: 1.1596474484161268\n",
      "Operator 248: -0.665424447128703\n",
      "Operator 249: -1.27470721296128\n",
      "Operator 250: 1.3110167885546866\n",
      "Operator 251: -0.7178700665870232\n",
      "Operator 252: -1.2512231049679876\n",
      "Operator 253: -1.3415811160294577\n",
      "Operator 254: -1.3385088479799732\n",
      "Operator 255: 0.4793769058099192\n",
      "Operator 256: 1.6435602146645274\n",
      "Operator 257: -0.7672719623325788\n",
      "Operator 258: -0.880449485196465\n",
      "Operator 259: -0.32009201823324435\n",
      "Operator 260: 1.7854758365503225\n",
      "Total gradient norm: 15.72423382428935\n",
      "Operators under consideration (1):\n",
      "[137]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.289811794880301)]\n",
      "Operator(s) added to ansatz: [137]\n",
      "Gradients: [np.float64(2.289811794880301)]\n",
      "Initial energy: -31.541742337270136\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137]...\n",
      "Starting point: [np.float64(0.3806675262425695), np.float64(0.4953051740707521), np.float64(0.3284756397447266), np.float64(-0.27812390558027955), np.float64(-0.27539344561005064), np.float64(-0.18338204310214226), np.float64(0.30737601849061025), np.float64(-0.24952653375375833), np.float64(0.6516382819762727), np.float64(0.28855038998894256), np.float64(-0.5218281402625671), np.float64(-0.34843567568196004), np.float64(-0.28214164755781673), np.float64(0.2923595401575518), np.float64(0.27402110040991245), np.float64(0.26215525907570686), np.float64(-0.23533980333755386), np.float64(0.1940043830528884), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -31.735383\n",
      "         Iterations: 26\n",
      "         Function evaluations: 95\n",
      "         Gradient evaluations: 83\n",
      "\n",
      "Current energy: -31.735383152921763\n",
      "(change of -0.1936408156516265)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137]\n",
      "On iteration 19.\n",
      "\n",
      "*** ADAPT-VQE Iteration 20 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.6029017119365366\n",
      "Operator 1: 1.7178199734963755\n",
      "Operator 3: 1.5861191350431394\n",
      "Operator 4: -0.8831303435467968\n",
      "Operator 5: 5.4747675374161876e-08\n",
      "Operator 6: -1.5461419995029262\n",
      "Operator 7: 0.8870567370820528\n",
      "Operator 8: -0.7666491535559665\n",
      "Operator 9: 0.9797556449806227\n",
      "Operator 10: -2.0493017347133483e-08\n",
      "Operator 11: 0.925954411380557\n",
      "Operator 12: -1.242317656324147\n",
      "Operator 13: 1.194097251806178\n",
      "Operator 15: 0.772572456721025\n",
      "Operator 16: -0.48269929848752113\n",
      "Operator 17: 2.5404709264233478e-08\n",
      "Operator 18: -0.8997513381909628\n",
      "Operator 19: 1.1793133649872167\n",
      "Operator 20: -0.9832137786480044\n",
      "Operator 21: 0.8060038987985343\n",
      "Operator 22: -0.8401926389459007\n",
      "Operator 23: 3.106207695012774e-08\n",
      "Operator 24: -0.8080891139172139\n",
      "Operator 25: 0.8243711576148747\n",
      "Operator 27: 2.9520437889437527e-08\n",
      "Operator 28: -3.644123359628093e-08\n",
      "Operator 29: 0.6740689593419703\n",
      "Operator 30: -1.208711971214425\n",
      "Operator 31: 0.7338178617215725\n",
      "Operator 33: 0.3516406959147521\n",
      "Operator 34: -0.9586239118694794\n",
      "Operator 35: 0.7416377682574443\n",
      "Operator 36: 0.2498478744014868\n",
      "Operator 37: 0.5762115350619486\n",
      "Operator 38: 1.1165094207264536\n",
      "Operator 39: 0.513810001426495\n",
      "Operator 40: 0.46388782134724915\n",
      "Operator 41: 1.189054843070956\n",
      "Operator 42: 0.9901923080431331\n",
      "Operator 43: 1.2543101707479476\n",
      "Operator 44: 0.3640716073497421\n",
      "Operator 45: -0.24720083753301952\n",
      "Operator 46: -0.10334525307685653\n",
      "Operator 47: 1.605429374129172\n",
      "Operator 48: -0.02299217961610045\n",
      "Operator 49: -0.12358309325426098\n",
      "Operator 50: -1.345536243437575\n",
      "Operator 51: 0.8776433040633884\n",
      "Operator 52: -0.9895343311266985\n",
      "Operator 53: 0.6868421902627233\n",
      "Operator 54: 0.06358926539489465\n",
      "Operator 55: 0.3054718340020538\n",
      "Operator 56: 0.39088318616441176\n",
      "Operator 57: 0.4352147703446374\n",
      "Operator 58: 0.26732971514137716\n",
      "Operator 59: 0.38477079540807\n",
      "Operator 60: 0.354488782830099\n",
      "Operator 61: 0.5795247926183593\n",
      "Operator 62: 0.384253495192142\n",
      "Operator 63: -1.0970097856072791\n",
      "Operator 64: 0.05439554454883269\n",
      "Operator 65: 0.7566645002050135\n",
      "Operator 66: 0.1607141803795665\n",
      "Operator 67: -0.7185642627505846\n",
      "Operator 68: -0.8211121861489328\n",
      "Operator 69: -0.8343765013990193\n",
      "Operator 70: -0.7893071812376743\n",
      "Operator 71: -0.53487144204397\n",
      "Operator 72: -0.4736504477494751\n",
      "Operator 73: 0.31520273178331604\n",
      "Operator 74: -0.5926270872301129\n",
      "Operator 75: -0.3308999336490387\n",
      "Operator 76: 0.4278966780258898\n",
      "Operator 77: 0.6009418607550449\n",
      "Operator 78: 0.2307714770708849\n",
      "Operator 79: -0.14799506225586498\n",
      "Operator 80: -1.5276492023261434\n",
      "Operator 81: 0.3673291479966578\n",
      "Operator 82: 0.09795264766836388\n",
      "Operator 83: 1.0074802658861062\n",
      "Operator 84: -2.0475672351670413\n",
      "Operator 85: 0.8675677726403905\n",
      "Operator 86: 4.431766980641557e-08\n",
      "Operator 87: 1.5547418387706757\n",
      "Operator 88: 2.6464983260234015e-08\n",
      "Operator 89: 0.8702015124444566\n",
      "Operator 90: -1.5797440324444412\n",
      "Operator 91: 2.6586021774523923e-08\n",
      "Operator 92: -0.8913312733770518\n",
      "Operator 93: 0.8165744752187911\n",
      "Operator 94: -0.8572371116840819\n",
      "Operator 95: 1.3846361052599208\n",
      "Operator 96: -1.0482076336804254\n",
      "Operator 97: 1.6759281111052404e-08\n",
      "Operator 98: -0.9142773315980592\n",
      "Operator 99: 0.9631491908806059\n",
      "Operator 100: -1.2947002688288953\n",
      "Operator 101: 1.3709065882494542e-08\n",
      "Operator 102: -0.7080763733108257\n",
      "Operator 103: 2.3034709370759745e-08\n",
      "Operator 104: 0.7705454453277846\n",
      "Operator 105: -0.7210352103013384\n",
      "Operator 106: 0.3349565151794903\n",
      "Operator 107: 0.5363271044666649\n",
      "Operator 108: 0.4595410323069068\n",
      "Operator 109: 0.3935079700178803\n",
      "Operator 110: 0.29845883967610914\n",
      "Operator 111: 0.40006266004867014\n",
      "Operator 112: 0.5270847415943809\n",
      "Operator 113: 0.36895139646747444\n",
      "Operator 114: 0.43394486045630787\n",
      "Operator 115: 0.15489123918220948\n",
      "Operator 116: -1.0748442594888217\n",
      "Operator 117: 0.2942972412669011\n",
      "Operator 118: 0.809469424268164\n",
      "Operator 119: 0.0074294552906292236\n",
      "Operator 120: -0.7331911921087833\n",
      "Operator 121: 1.3622884388525383\n",
      "Operator 122: -0.390726194087743\n",
      "Operator 123: 0.6116159407007482\n",
      "Operator 124: 0.438819693500435\n",
      "Operator 125: 0.5049375968284576\n",
      "Operator 126: 1.1328225262985148\n",
      "Operator 127: 0.5125418448325254\n",
      "Operator 128: 0.4069966675702522\n",
      "Operator 129: 1.2232689377575496\n",
      "Operator 130: 0.8964858246295629\n",
      "Operator 131: 1.3350423005154102\n",
      "Operator 132: 0.035870420370673936\n",
      "Operator 133: -0.17366255705265232\n",
      "Operator 134: -0.23183110682845856\n",
      "Operator 135: 1.773451113225605\n",
      "Operator 136: -1.1982087626102245\n",
      "Operator 137: 2.9442131399548543e-08\n",
      "Operator 138: 0.08916126295448522\n",
      "Operator 139: -0.9912158784598127\n",
      "Operator 140: -0.34139201648332596\n",
      "Operator 141: -0.6783653797001385\n",
      "Operator 142: 0.32521583763842626\n",
      "Operator 143: -0.46371254425527614\n",
      "Operator 144: -0.5470311405974545\n",
      "Operator 145: 0.2938824795220942\n",
      "Operator 146: 0.5127308917933939\n",
      "Operator 147: 0.44044083475136153\n",
      "Operator 148: -0.10287875702616747\n",
      "Operator 149: -1.4028299843675545\n",
      "Operator 150: -0.23625723141952273\n",
      "Operator 151: 0.19342397740284756\n",
      "Operator 152: 0.5467786452666838\n",
      "Operator 153: -1.8167604533624462\n",
      "Operator 154: 0.623233451343733\n",
      "Operator 155: -1.078823359435305\n",
      "Operator 156: 2.893569967550308e-08\n",
      "Operator 157: -1.8513295289141465\n",
      "Operator 158: -1.1560409031176753\n",
      "Operator 159: -0.2196270379020735\n",
      "Operator 160: -0.4420827024648585\n",
      "Operator 161: -0.13221470717819772\n",
      "Operator 162: -0.4787685597481158\n",
      "Operator 163: 1.0508044837465735\n",
      "Operator 164: -0.234154738090313\n",
      "Operator 165: -0.4442843340818404\n",
      "Operator 166: 1.090355661010531\n",
      "Operator 167: 1.1481430875153937\n",
      "Operator 168: 1.1084826412985567\n",
      "Operator 169: -0.397624872493233\n",
      "Operator 170: -0.6010922756850318\n",
      "Operator 171: -0.08065866475096622\n",
      "Operator 172: 1.0257919477592972\n",
      "Operator 173: -0.10190108753021254\n",
      "Operator 174: -1.2714027143505366\n",
      "Operator 175: 1.7062729628705753\n",
      "Operator 176: 1.569243690260371\n",
      "Operator 177: 0.6665252356873232\n",
      "Operator 178: -0.48872584954534903\n",
      "Operator 179: 0.7891147894249027\n",
      "Operator 180: -0.915803020464729\n",
      "Operator 181: -1.4158395170779499\n",
      "Operator 182: 0.8521667386655829\n",
      "Operator 183: -1.0173646988297413\n",
      "Operator 184: -1.5283054004295833\n",
      "Operator 185: -1.6449301932621467\n",
      "Operator 186: -1.337429235501155\n",
      "Operator 187: 1.2639871702491385\n",
      "Operator 188: 1.4131356689536823\n",
      "Operator 189: -1.4256597091731946\n",
      "Operator 190: -1.0726940292871538\n",
      "Operator 191: 0.6940254050267936\n",
      "Operator 192: 2.2419554945644773\n",
      "Operator 193: -1.618095521954462\n",
      "Operator 194: 1.0156788006733368\n",
      "Operator 195: 0.5949534600284696\n",
      "Operator 196: -1.246091310049887\n",
      "Operator 197: 0.803002759055078\n",
      "Operator 198: -1.3785230509915127\n",
      "Operator 199: -0.8120383731726175\n",
      "Operator 200: 0.8411250976493838\n",
      "Operator 201: -1.4504626367166193\n",
      "Operator 202: -0.8458675434767404\n",
      "Operator 203: -1.0771447970274344\n",
      "Operator 204: -0.6602475061958204\n",
      "Operator 205: 1.2036487794118085\n",
      "Operator 206: 0.9814019833045413\n",
      "Operator 207: -1.7633331809438675\n",
      "Operator 208: -0.21438780028009258\n",
      "Operator 209: 0.7194452502923985\n",
      "Operator 210: -0.4463699715348972\n",
      "Operator 211: 1.1444679217327156\n",
      "Operator 212: -1.448450353470828\n",
      "Operator 213: 0.8798650512053132\n",
      "Operator 214: -0.833717598680627\n",
      "Operator 215: -1.373775853002527\n",
      "Operator 216: 0.8083135218009461\n",
      "Operator 217: -0.76294961564278\n",
      "Operator 218: -1.0357841578655183\n",
      "Operator 219: -0.813067310650607\n",
      "Operator 220: -1.4912173366402761\n",
      "Operator 221: 0.8010775540437793\n",
      "Operator 222: 1.218732837937847\n",
      "Operator 223: -0.373401128481174\n",
      "Operator 224: -1.7451751769174901\n",
      "Operator 225: 0.6870305312377899\n",
      "Operator 226: 0.6517606135110707\n",
      "Operator 227: -0.6216705828812081\n",
      "Operator 228: 1.4230516685006234\n",
      "Operator 229: 1.8004490548485307e-08\n",
      "Operator 230: 0.8243609968771334\n",
      "Operator 231: -0.7178520873630652\n",
      "Operator 232: 0.7451141838413025\n",
      "Operator 233: -1.3796461473319293\n",
      "Operator 234: 0.7324153792040513\n",
      "Operator 235: -0.7406579588508581\n",
      "Operator 236: 1.323284596446511\n",
      "Operator 237: -1.2953388945610236\n",
      "Operator 238: 1.3006220396685342\n",
      "Operator 239: -0.7640120703446294\n",
      "Operator 241: -0.5746650421400994\n",
      "Operator 242: 0.8113031798561108\n",
      "Operator 243: -0.6857132355146518\n",
      "Operator 244: 1.184282987171417\n",
      "Operator 245: 0.754449079684189\n",
      "Operator 246: -0.536767095459226\n",
      "Operator 247: 1.1600620298206605\n",
      "Operator 248: -0.6661220146841619\n",
      "Operator 249: -1.2750742723123965\n",
      "Operator 250: 1.3085739721743663\n",
      "Operator 251: -0.7150629493106153\n",
      "Operator 252: -1.2526847042348872\n",
      "Operator 253: -1.3479091461863526\n",
      "Operator 254: -1.346494812174858\n",
      "Operator 255: 0.5712973971034844\n",
      "Operator 256: 1.5677532294017635\n",
      "Operator 257: -0.8162455207166377\n",
      "Operator 258: -1.087241665719148\n",
      "Operator 259: 0.07610689647741797\n",
      "Operator 260: 2.027087622060594\n",
      "Total gradient norm: 14.704535920010844\n",
      "Operators under consideration (1):\n",
      "[192]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.2419554945644773)]\n",
      "Operator(s) added to ansatz: [192]\n",
      "Gradients: [np.float64(2.2419554945644773)]\n",
      "Initial energy: -31.735383152921763\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192]...\n",
      "Starting point: [np.float64(0.34692856856943294), np.float64(0.4194521678879744), np.float64(0.3161249295042665), np.float64(-0.27885006909838367), np.float64(-0.275633366255738), np.float64(-0.18340549434366912), np.float64(0.30319330617933826), np.float64(-0.24959450077668321), np.float64(0.5694620323652799), np.float64(0.2871137840001579), np.float64(-0.5218055282452141), np.float64(-0.34838621897564237), np.float64(-0.28175025647396834), np.float64(0.29222856845231754), np.float64(0.27613416648015393), np.float64(0.26740525035608614), np.float64(-0.24793899737205596), np.float64(0.2206929214396816), np.float64(-0.17271188305106222), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -31.917631\n",
      "         Iterations: 26\n",
      "         Function evaluations: 73\n",
      "         Gradient evaluations: 61\n",
      "\n",
      "Current energy: -31.917631223341424\n",
      "(change of -0.18224807041966073)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192]\n",
      "On iteration 20.\n",
      "\n",
      "*** ADAPT-VQE Iteration 21 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.6028943901238708\n",
      "Operator 1: 1.7178765956507207\n",
      "Operator 2: 7.734640956238799e-07\n",
      "Operator 3: 1.5863888496506529\n",
      "Operator 4: -0.8826339831319403\n",
      "Operator 5: -4.193591708315917e-08\n",
      "Operator 6: -1.544544659814063\n",
      "Operator 7: 0.8904128835766103\n",
      "Operator 8: -0.7614823714397762\n",
      "Operator 9: 0.9876361214466819\n",
      "Operator 10: 2.6174125323097927e-07\n",
      "Operator 11: 0.9248685610051967\n",
      "Operator 12: -1.2159805917307724\n",
      "Operator 13: 1.2242554519062472\n",
      "Operator 14: 0.004817082049568673\n",
      "Operator 15: 0.5500818940960213\n",
      "Operator 16: 0.1892915041295874\n",
      "Operator 17: 4.905751112005419e-07\n",
      "Operator 18: -0.8997523534751551\n",
      "Operator 19: 1.1793536066360113\n",
      "Operator 20: -0.9831249987996231\n",
      "Operator 21: 0.8060082024783666\n",
      "Operator 22: -0.8398751501327093\n",
      "Operator 23: -6.072529072422694e-07\n",
      "Operator 24: -0.8079513198036012\n",
      "Operator 25: 0.8252856909166955\n",
      "Operator 26: -6.778435695039466e-07\n",
      "Operator 27: 6.390832625215887e-08\n",
      "Operator 28: -4.995200996396893e-08\n",
      "Operator 29: 0.6615822761894758\n",
      "Operator 30: -1.1465462246981528\n",
      "Operator 31: 0.6780710881500571\n",
      "Operator 32: -0.1464204343505304\n",
      "Operator 33: 0.2789831459748151\n",
      "Operator 34: -0.9586618728954573\n",
      "Operator 35: 0.7417703170022734\n",
      "Operator 36: 0.2497377320357626\n",
      "Operator 37: 0.576672160559089\n",
      "Operator 38: 1.1159041458548504\n",
      "Operator 39: 0.5143532641159827\n",
      "Operator 40: 0.46125694474998286\n",
      "Operator 41: 1.1927745031267158\n",
      "Operator 42: 0.983624782602454\n",
      "Operator 43: 1.263910667289663\n",
      "Operator 44: 0.35485016356619226\n",
      "Operator 45: -0.2423624892404469\n",
      "Operator 46: -0.1459969229696911\n",
      "Operator 47: 1.6424327159578431\n",
      "Operator 48: -0.07704284445866469\n",
      "Operator 49: -0.5057987544229763\n",
      "Operator 50: -1.1983862779523529\n",
      "Operator 51: 0.8776860994239026\n",
      "Operator 52: -0.9894879461834937\n",
      "Operator 53: 0.6868927094797083\n",
      "Operator 54: 0.06349804467043468\n",
      "Operator 55: 0.3057712302184029\n",
      "Operator 56: 0.39052612717676666\n",
      "Operator 57: 0.43625844309199086\n",
      "Operator 58: 0.2655570521509931\n",
      "Operator 59: 0.38721587658246853\n",
      "Operator 60: 0.3503174617881706\n",
      "Operator 61: 0.5868552287395101\n",
      "Operator 62: 0.37538089986736367\n",
      "Operator 63: -1.0943308237124472\n",
      "Operator 64: 0.0360577780444589\n",
      "Operator 65: 0.7701705867076449\n",
      "Operator 66: 0.17593540770592614\n",
      "Operator 67: -1.005166466855858\n",
      "Operator 68: -0.8211915655332019\n",
      "Operator 69: -0.8342075015618935\n",
      "Operator 70: -0.7894989632206287\n",
      "Operator 71: -0.5343983521794899\n",
      "Operator 72: -0.4743670754381334\n",
      "Operator 73: 0.31597347661963865\n",
      "Operator 74: -0.5952490613202202\n",
      "Operator 75: -0.3264957032236675\n",
      "Operator 76: 0.4239416826475294\n",
      "Operator 77: 0.611705245605567\n",
      "Operator 78: 0.22472948336533038\n",
      "Operator 79: -0.10523131130174632\n",
      "Operator 80: -1.551403980815258\n",
      "Operator 81: 0.5100752533353541\n",
      "Operator 82: 0.25353714903504054\n",
      "Operator 83: 1.2356176333127449\n",
      "Operator 84: 0.28115095123213774\n",
      "Operator 85: 0.8675170220044511\n",
      "Operator 86: -1.53518436360635e-06\n",
      "Operator 87: 1.5545978803159475\n",
      "Operator 88: 8.246104549325104e-07\n",
      "Operator 89: 0.8701782903978277\n",
      "Operator 90: -1.5805581649717249\n",
      "Operator 91: -3.2309250267422725e-07\n",
      "Operator 92: -0.8913983259402911\n",
      "Operator 93: 0.8159274600587043\n",
      "Operator 94: -0.8576430707205732\n",
      "Operator 95: 1.3716674821239303\n",
      "Operator 96: -1.069415799535458\n",
      "Operator 97: 3.3957016276983806e-08\n",
      "Operator 98: -0.9038276801153347\n",
      "Operator 99: 0.8711170350264636\n",
      "Operator 100: 0.012113591222384671\n",
      "Operator 101: 2.0561850952705114e-07\n",
      "Operator 102: -0.7080558557997421\n",
      "Operator 103: 1.0147122818660037e-06\n",
      "Operator 104: 0.7705969007372189\n",
      "Operator 105: -0.7210069183646157\n",
      "Operator 106: 0.3351162289122449\n",
      "Operator 107: 0.5361803747523339\n",
      "Operator 108: 0.45973854901370537\n",
      "Operator 109: 0.3929886276715686\n",
      "Operator 110: 0.29916413809994624\n",
      "Operator 111: 0.3989815974095865\n",
      "Operator 112: 0.5295164467932257\n",
      "Operator 113: 0.36606541862608655\n",
      "Operator 114: 0.4411216148756933\n",
      "Operator 115: 0.14721483438988148\n",
      "Operator 116: -1.0728001760056514\n",
      "Operator 117: 0.263729525540097\n",
      "Operator 118: 0.8539689898419702\n",
      "Operator 119: 0.11983798477574274\n",
      "Operator 120: -0.9689980333595849\n",
      "Operator 121: 1.3623465615473402\n",
      "Operator 122: -0.3908104057007443\n",
      "Operator 123: 0.6118744388875915\n",
      "Operator 124: 0.43850481309462197\n",
      "Operator 125: 0.5058059243332609\n",
      "Operator 126: 1.1312220418510512\n",
      "Operator 127: 0.5142380647643294\n",
      "Operator 128: 0.40186433381087416\n",
      "Operator 129: 1.230196084341678\n",
      "Operator 130: 0.8808827688694474\n",
      "Operator 131: 1.3511029236417114\n",
      "Operator 132: -0.0062450546554110465\n",
      "Operator 133: -0.16908030431370008\n",
      "Operator 134: -0.34816529913531313\n",
      "Operator 135: 1.6351681880921913\n",
      "Operator 136: -1.0830025743823746\n",
      "Operator 137: -0.41034241241189007\n",
      "Operator 138: 0.0892495701181707\n",
      "Operator 139: -0.9912655153559251\n",
      "Operator 140: -0.34113533371823174\n",
      "Operator 141: -0.6785138333397849\n",
      "Operator 142: 0.32537619008101754\n",
      "Operator 143: -0.4652845358256025\n",
      "Operator 144: -0.5461103528846547\n",
      "Operator 145: 0.2930614765587108\n",
      "Operator 146: 0.5150268650557869\n",
      "Operator 147: 0.4375361744522737\n",
      "Operator 148: -0.08158650585615282\n",
      "Operator 149: -1.4263497681032091\n",
      "Operator 150: -0.21012945344722103\n",
      "Operator 151: 0.18770447453068528\n",
      "Operator 152: 0.66507298327506\n",
      "Operator 153: 0.46621554267802967\n",
      "Operator 154: 1.2248702387577604\n",
      "Operator 155: -1.0788698544212163\n",
      "Operator 156: 5.587499316561662e-07\n",
      "Operator 157: -1.8513251306629317\n",
      "Operator 158: -1.1560766472951893\n",
      "Operator 159: -0.21959368331842222\n",
      "Operator 160: -0.4421679391410764\n",
      "Operator 161: -0.1320472429098145\n",
      "Operator 162: -0.4790968881094563\n",
      "Operator 163: 1.0507193182371606\n",
      "Operator 164: -0.23549086222540855\n",
      "Operator 165: -0.4424948896417828\n",
      "Operator 166: 1.0907881585883619\n",
      "Operator 167: 1.147989084630124\n",
      "Operator 168: 1.1077770157645588\n",
      "Operator 169: -0.38748809474305\n",
      "Operator 170: -0.6216865781486678\n",
      "Operator 171: -0.06804784433431099\n",
      "Operator 172: 1.0313627290389908\n",
      "Operator 173: 0.012724883797276184\n",
      "Operator 174: 0.6092540021087174\n",
      "Operator 175: 1.7062839604854934\n",
      "Operator 176: 1.5692720895262195\n",
      "Operator 177: 0.6663525561951085\n",
      "Operator 178: -0.4885940156802072\n",
      "Operator 179: 0.7886041979468452\n",
      "Operator 180: -0.9152843793288712\n",
      "Operator 181: -1.4161533818791345\n",
      "Operator 182: 0.8549581506052137\n",
      "Operator 183: -1.0202761110088312\n",
      "Operator 184: -1.5254365612228065\n",
      "Operator 185: -1.6501258643224526\n",
      "Operator 186: -1.3313200027815897\n",
      "Operator 187: 1.2467109425152425\n",
      "Operator 188: 1.4469847584367757\n",
      "Operator 189: -1.4834438969062456\n",
      "Operator 190: -1.0834574846454839\n",
      "Operator 191: 0.46911808237215596\n",
      "Operator 192: -2.3462947399264818e-07\n",
      "Operator 193: -1.618131407032541\n",
      "Operator 194: 1.0156542079896884\n",
      "Operator 195: 0.5947859842135256\n",
      "Operator 196: -1.245909417662315\n",
      "Operator 197: 0.8025921668876661\n",
      "Operator 198: -1.3777098039315567\n",
      "Operator 199: -0.8129347061854559\n",
      "Operator 200: 0.8431199971497848\n",
      "Operator 201: -1.453842110968579\n",
      "Operator 202: -0.8390947310290924\n",
      "Operator 203: -1.0864211699992947\n",
      "Operator 204: -0.6445193960075155\n",
      "Operator 205: 1.1905653306262332\n",
      "Operator 206: 0.9856662188166734\n",
      "Operator 207: -1.6833458716794198\n",
      "Operator 208: -0.1744799536820646\n",
      "Operator 209: 0.5239022087612977\n",
      "Operator 210: -0.44642344624515773\n",
      "Operator 211: 1.1444287662340642\n",
      "Operator 212: -1.4485064372100092\n",
      "Operator 213: 0.8799384774430669\n",
      "Operator 214: -0.8342624441181916\n",
      "Operator 215: -1.3733613723697962\n",
      "Operator 216: 0.8076048125763722\n",
      "Operator 217: -0.7596692157350438\n",
      "Operator 218: -1.0413200061568464\n",
      "Operator 219: -0.8034327050878433\n",
      "Operator 220: -1.4983336481350396\n",
      "Operator 221: 0.8014838637276415\n",
      "Operator 222: 1.2068741530436398\n",
      "Operator 223: -0.32281778000445843\n",
      "Operator 224: -1.727097490557035\n",
      "Operator 225: 0.6891777685483411\n",
      "Operator 226: 0.09564831083121522\n",
      "Operator 227: -0.6216637683862682\n",
      "Operator 228: 1.423001118116641\n",
      "Operator 229: -1.7553553097737762e-06\n",
      "Operator 230: 0.8243558938726834\n",
      "Operator 231: -0.7179768920719674\n",
      "Operator 232: 0.7451234990450855\n",
      "Operator 233: -1.3801455318885352\n",
      "Operator 234: 0.7316102897925281\n",
      "Operator 235: -0.7398054899299364\n",
      "Operator 236: 1.319773928987359\n",
      "Operator 237: -1.295038583117958\n",
      "Operator 238: 1.2870650636826744\n",
      "Operator 239: -0.7619128570801954\n",
      "Operator 240: -2.4321829226450756e-07\n",
      "Operator 241: -0.5162173482525201\n",
      "Operator 242: 0.7771022101713949\n",
      "Operator 243: -0.6504996186772443\n",
      "Operator 244: 1.184341249872927\n",
      "Operator 245: 0.7544135870948311\n",
      "Operator 246: -0.5366558170656563\n",
      "Operator 247: 1.159962449063981\n",
      "Operator 248: -0.6659540463697082\n",
      "Operator 249: -1.2749877114048844\n",
      "Operator 250: 1.3091640876053052\n",
      "Operator 251: -0.7157583253550113\n",
      "Operator 252: -1.2523687753084278\n",
      "Operator 253: -1.3464634683577845\n",
      "Operator 254: -1.3447954077455297\n",
      "Operator 255: 0.54741302114244\n",
      "Operator 256: 1.5875861967756901\n",
      "Operator 257: -0.7995803884465461\n",
      "Operator 258: -1.0206610287560343\n",
      "Operator 259: -0.23092762529595895\n",
      "Operator 260: -0.19473925548817733\n",
      "Total gradient norm: 14.045833129099059\n",
      "Operators under consideration (1):\n",
      "[157]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.8513251306629317)]\n",
      "Operator(s) added to ansatz: [157]\n",
      "Gradients: [np.float64(-1.8513251306629317)]\n",
      "Initial energy: -31.917631223341424\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157]...\n",
      "Starting point: [np.float64(0.3556489844947949), np.float64(0.4460729004399043), np.float64(0.3191314382998713), np.float64(-0.27867433011969717), np.float64(-0.2755753678767013), np.float64(-0.1833998131051209), np.float64(0.3042013141155622), np.float64(-0.24957798001068962), np.float64(0.629937274448405), np.float64(0.2874603263535949), np.float64(-0.5218108992882429), np.float64(-0.34839801142260046), np.float64(-0.281844818688781), np.float64(0.2922602857571371), np.float64(0.2756209073003314), np.float64(0.26612492403330057), np.float64(-0.24495867417503142), np.float64(0.21885378513755027), np.float64(-0.19129116806771565), np.float64(-0.16162886882882121), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -32.046410\n",
      "         Iterations: 30\n",
      "         Function evaluations: 43\n",
      "         Gradient evaluations: 43\n",
      "\n",
      "Current energy: -32.046409535955945\n",
      "(change of -0.12877831261452144)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157]\n",
      "On iteration 21.\n",
      "\n",
      "*** ADAPT-VQE Iteration 22 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.22859150724153918\n",
      "Operator 1: 1.70327354307648\n",
      "Operator 3: 1.5722379152159627\n",
      "Operator 4: -0.8830514313392159\n",
      "Operator 6: -1.5470975708567978\n",
      "Operator 7: 0.890259786524467\n",
      "Operator 8: -0.7616282070665535\n",
      "Operator 9: 0.9876189133643047\n",
      "Operator 11: 0.9246849295983776\n",
      "Operator 12: -1.2161519087937216\n",
      "Operator 13: 1.2242744439523587\n",
      "Operator 14: 0.0048157351079824995\n",
      "Operator 15: 0.5500899223525029\n",
      "Operator 16: 0.18929307448686217\n",
      "Operator 17: 0.1387585542719491\n",
      "Operator 18: -0.4092529296186972\n",
      "Operator 19: 0.9260221826554447\n",
      "Operator 20: -0.948439690777636\n",
      "Operator 21: 0.8107013786004171\n",
      "Operator 22: -0.8228059561151753\n",
      "Operator 24: -0.8071458771263939\n",
      "Operator 25: 0.8282565125487742\n",
      "Operator 29: 0.6616784578722529\n",
      "Operator 30: -1.1464997379837216\n",
      "Operator 31: 0.6782184306380624\n",
      "Operator 32: -0.1464263189990228\n",
      "Operator 33: 0.2790006398199074\n",
      "Operator 34: -0.8873515831475306\n",
      "Operator 35: 0.5954608788754466\n",
      "Operator 36: 0.3480535832719784\n",
      "Operator 37: 0.5467884631078521\n",
      "Operator 38: 1.1438018003308377\n",
      "Operator 39: 0.49920355952911255\n",
      "Operator 40: 0.4667908536578693\n",
      "Operator 41: 1.1880718366831204\n",
      "Operator 42: 0.9865478213741616\n",
      "Operator 43: 1.262416406182267\n",
      "Operator 44: 0.35594490547170354\n",
      "Operator 45: -0.2425715323731562\n",
      "Operator 46: -0.14558780049827083\n",
      "Operator 47: 1.6422868480646464\n",
      "Operator 48: -0.07683389178762856\n",
      "Operator 49: -0.5057865602102598\n",
      "Operator 50: -1.1983017124514799\n",
      "Operator 51: 0.8858620297264648\n",
      "Operator 52: -0.6562760862618573\n",
      "Operator 53: 0.6511121073018493\n",
      "Operator 54: 0.09611017153755003\n",
      "Operator 55: 0.29351540757726424\n",
      "Operator 56: 0.39965134152291204\n",
      "Operator 57: 0.43294918696798546\n",
      "Operator 58: 0.26758548349625744\n",
      "Operator 59: 0.38564472481873746\n",
      "Operator 60: 0.3509203987977816\n",
      "Operator 61: 0.5863095806793162\n",
      "Operator 62: 0.37561068769934325\n",
      "Operator 63: -1.0943698165768407\n",
      "Operator 64: 0.03610511384996308\n",
      "Operator 65: 0.7700408867833406\n",
      "Operator 66: 0.17596857409299316\n",
      "Operator 67: -1.0051905161048202\n",
      "Operator 68: -0.24579803003348846\n",
      "Operator 69: -0.6195303163526837\n",
      "Operator 70: -0.7304176903228197\n",
      "Operator 71: -0.5504154484130156\n",
      "Operator 72: -0.4469151709611242\n",
      "Operator 73: 0.3132492885375363\n",
      "Operator 74: -0.5924338891100845\n",
      "Operator 75: -0.3314046525212516\n",
      "Operator 76: 0.42456553769772043\n",
      "Operator 77: 0.611152829134459\n",
      "Operator 78: 0.2248719166576329\n",
      "Operator 79: -0.10554719094904837\n",
      "Operator 80: -1.551188791835384\n",
      "Operator 81: 0.5097764524149593\n",
      "Operator 82: 0.2535530822191762\n",
      "Operator 83: 1.2355319334609869\n",
      "Operator 84: 0.28111364098701047\n",
      "Operator 85: 1.0501400029531531\n",
      "Operator 87: 1.5772561508397125\n",
      "Operator 89: 0.8787564982731306\n",
      "Operator 90: -1.5757679587567173\n",
      "Operator 92: -0.889924526475312\n",
      "Operator 93: 0.817038477470309\n",
      "Operator 94: -0.8569965376434836\n",
      "Operator 95: 1.372082256239096\n",
      "Operator 96: -1.0694163904334673\n",
      "Operator 98: -0.903778685196376\n",
      "Operator 99: 0.8711940698035876\n",
      "Operator 100: 0.01211029517004214\n",
      "Operator 102: -0.17832711649928956\n",
      "Operator 104: 0.560321516838981\n",
      "Operator 105: -0.06590427237974714\n",
      "Operator 106: 0.2764587688266512\n",
      "Operator 107: 0.5476930622907379\n",
      "Operator 108: 0.44110271815939334\n",
      "Operator 109: 0.39930417585405725\n",
      "Operator 110: 0.29404191875342306\n",
      "Operator 111: 0.40205189574569355\n",
      "Operator 112: 0.5281102472431344\n",
      "Operator 113: 0.36691447388391685\n",
      "Operator 114: 0.44053603871833436\n",
      "Operator 115: 0.14746574702191412\n",
      "Operator 116: -1.0727820376957642\n",
      "Operator 117: 0.26382588893846926\n",
      "Operator 118: 0.8538555664070329\n",
      "Operator 119: 0.11986715627334948\n",
      "Operator 120: -0.9690127048639419\n",
      "Operator 121: 0.235499615395309\n",
      "Operator 122: -0.14231786245200592\n",
      "Operator 123: 0.5826365431584392\n",
      "Operator 124: 0.4793005459071136\n",
      "Operator 125: 0.49625116234964306\n",
      "Operator 126: 1.1416750011132175\n",
      "Operator 127: 0.5061075418175021\n",
      "Operator 128: 0.4037578559703525\n",
      "Operator 129: 1.2283053619776538\n",
      "Operator 130: 0.8823587255371963\n",
      "Operator 131: 1.350391658377907\n",
      "Operator 132: -0.005534752087902092\n",
      "Operator 133: -0.16912282582335705\n",
      "Operator 134: -0.3479977334377931\n",
      "Operator 135: 1.6351062917547674\n",
      "Operator 136: -1.0828905022472608\n",
      "Operator 137: -0.41031428214205756\n",
      "Operator 138: 0.30892502771570346\n",
      "Operator 139: -0.8103660358344158\n",
      "Operator 140: -0.4169071981580171\n",
      "Operator 141: -0.6323081827585407\n",
      "Operator 142: 0.31194492341660196\n",
      "Operator 143: -0.4527684388315475\n",
      "Operator 144: -0.5543295511800683\n",
      "Operator 145: 0.2952719109603054\n",
      "Operator 146: 0.5131297376753705\n",
      "Operator 147: 0.4384363348127938\n",
      "Operator 148: -0.08252316955707305\n",
      "Operator 149: -1.4258547021810242\n",
      "Operator 150: -0.2105739014942589\n",
      "Operator 151: 0.1877657687867022\n",
      "Operator 152: 0.6648822667280243\n",
      "Operator 153: 0.4662026953365354\n",
      "Operator 154: 1.2247869628619412\n",
      "Operator 155: -0.4868756456244379\n",
      "Operator 156: 0.1597767969032074\n",
      "Operator 158: -0.8436666442167722\n",
      "Operator 159: -0.20706607064591492\n",
      "Operator 160: -0.5219507728386543\n",
      "Operator 161: -0.15243662406170905\n",
      "Operator 162: -0.4728664410823801\n",
      "Operator 163: 1.056091239715135\n",
      "Operator 164: -0.23166844585267368\n",
      "Operator 165: -0.44354501123678236\n",
      "Operator 166: 1.089778258876036\n",
      "Operator 167: 1.1483985594190291\n",
      "Operator 168: 1.1077041035514492\n",
      "Operator 169: -0.38777447099996337\n",
      "Operator 170: -0.6214633709666715\n",
      "Operator 171: -0.06811225599498696\n",
      "Operator 172: 1.0313971742708747\n",
      "Operator 173: 0.01270064089685391\n",
      "Operator 174: 0.6092431965356926\n",
      "Operator 175: 0.5264858252858263\n",
      "Operator 176: 0.7655489465766172\n",
      "Operator 177: 0.7202975773434567\n",
      "Operator 178: -0.575982777782963\n",
      "Operator 179: 0.8092875935650987\n",
      "Operator 180: -0.9448228315914283\n",
      "Operator 181: -1.4103749829134937\n",
      "Operator 182: 0.8514317778676647\n",
      "Operator 183: -1.0152170360255885\n",
      "Operator 184: -1.5266826984654869\n",
      "Operator 185: -1.6493896011967522\n",
      "Operator 186: -1.3317564233913841\n",
      "Operator 187: 1.2468929856318618\n",
      "Operator 188: 1.4467636571470555\n",
      "Operator 189: -1.483227718252221\n",
      "Operator 190: -1.0835540767649168\n",
      "Operator 191: 0.46916260499870843\n",
      "Operator 193: -0.42738582283612625\n",
      "Operator 194: -0.3187902944053857\n",
      "Operator 195: 0.6653529942716085\n",
      "Operator 196: -1.263332857222232\n",
      "Operator 197: 0.8155047133365405\n",
      "Operator 198: -1.3849898906612177\n",
      "Operator 199: -0.8036952883586224\n",
      "Operator 200: 0.8413272784051242\n",
      "Operator 201: -1.4524548751583568\n",
      "Operator 202: -0.840921089697871\n",
      "Operator 203: -1.0851927494316689\n",
      "Operator 204: -0.6451593566248144\n",
      "Operator 205: 1.1906454438342973\n",
      "Operator 206: 0.985677906936452\n",
      "Operator 207: -1.6832575992850107\n",
      "Operator 208: -0.1745303333731561\n",
      "Operator 209: 0.5239472107857309\n",
      "Operator 210: -0.8300897794898564\n",
      "Operator 211: 1.083680149609382\n",
      "Operator 212: -1.358324044447981\n",
      "Operator 213: 0.850804081372061\n",
      "Operator 214: -0.8184136578257364\n",
      "Operator 215: -1.38768435809265\n",
      "Operator 216: 0.8144522667669025\n",
      "Operator 217: -0.7624961693548942\n",
      "Operator 218: -1.038861083755655\n",
      "Operator 219: -0.8046976304368971\n",
      "Operator 220: -1.4975239166663041\n",
      "Operator 221: 0.8010824518153056\n",
      "Operator 222: 1.2069965403711493\n",
      "Operator 223: -0.3229346039237284\n",
      "Operator 224: -1.7269785767704617\n",
      "Operator 225: 0.68915528103611\n",
      "Operator 226: 0.09566011569633481\n",
      "Operator 227: -0.15486862518540162\n",
      "Operator 228: 0.44254804761203065\n",
      "Operator 229: -0.20325981254929737\n",
      "Operator 230: 0.814152152328087\n",
      "Operator 231: -0.7455892717645752\n",
      "Operator 232: 0.7417309974674998\n",
      "Operator 233: -1.3860994144296568\n",
      "Operator 234: 0.7259641930860518\n",
      "Operator 235: -0.7404634369040233\n",
      "Operator 236: 1.3188048632867058\n",
      "Operator 237: -1.2959572206684495\n",
      "Operator 238: 1.2867170119988347\n",
      "Operator 239: -0.7623373941749618\n",
      "Operator 241: -0.5162625863292586\n",
      "Operator 242: 0.777122963165094\n",
      "Operator 243: -0.650572288567195\n",
      "Operator 244: 0.4702565144103792\n",
      "Operator 245: 0.8159973985576583\n",
      "Operator 246: -0.6009658262619288\n",
      "Operator 247: 1.2053507231827296\n",
      "Operator 248: -0.6913357875961053\n",
      "Operator 249: -1.274404947528809\n",
      "Operator 250: 1.3031263402932984\n",
      "Operator 251: -0.7116733481246544\n",
      "Operator 252: -1.252895812250832\n",
      "Operator 253: -1.3460515749860726\n",
      "Operator 254: -1.345143860039607\n",
      "Operator 255: 0.5477545522779124\n",
      "Operator 256: 1.587268983706561\n",
      "Operator 257: -0.7994772152278882\n",
      "Operator 258: -1.0207472258296217\n",
      "Operator 259: -0.23086367193249335\n",
      "Operator 260: -0.19475906214232053\n",
      "Total gradient norm: 13.244113426427596\n",
      "Operators under consideration (1):\n",
      "[224]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.7269785767704617)]\n",
      "Operator(s) added to ansatz: [224]\n",
      "Gradients: [np.float64(-1.7269785767704617)]\n",
      "Initial energy: -32.046409535955945\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224]...\n",
      "Starting point: [np.float64(0.3556122730203422), np.float64(0.44605307288089163), np.float64(0.31904887657279357), np.float64(-0.27969895461787425), np.float64(-0.27863025154964755), np.float64(-0.1450851035502366), np.float64(0.3039990283401061), np.float64(-0.25936202004260855), np.float64(0.6299296198779495), np.float64(0.28690437464607677), np.float64(-0.5030165936161448), np.float64(-0.32764882286461716), np.float64(-0.2802008126865192), np.float64(0.2862311122280275), np.float64(0.27591341572566913), np.float64(0.2662323063780439), np.float64(-0.24499450973803694), np.float64(0.2188677251575395), np.float64(-0.19129439230703074), np.float64(-0.1616288107713406), np.float64(0.14044360503747672), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -32.134363\n",
      "         Iterations: 32\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 51\n",
      "\n",
      "Current energy: -32.13436347742718\n",
      "(change of -0.08795394147123403)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224]\n",
      "On iteration 22.\n",
      "\n",
      "*** ADAPT-VQE Iteration 23 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.22862178553122461\n",
      "Operator 1: 1.7036452682244194\n",
      "Operator 3: 1.5740845428181174\n",
      "Operator 4: -0.8797181768041635\n",
      "Operator 6: -1.5363026650737603\n",
      "Operator 7: 0.912751857454247\n",
      "Operator 8: -0.7264849323555946\n",
      "Operator 9: 1.0355298053507962\n",
      "Operator 11: 1.0982121044581066\n",
      "Operator 12: -1.0522803364601048\n",
      "Operator 13: 0.48787018345029887\n",
      "Operator 14: -0.05392078259864519\n",
      "Operator 15: 0.5685421677746982\n",
      "Operator 16: 0.11580195836540952\n",
      "Operator 17: 0.13881721084833465\n",
      "Operator 18: -0.40931234639090125\n",
      "Operator 19: 0.92620419927495\n",
      "Operator 20: -0.9478156179227879\n",
      "Operator 21: 0.8107397147132817\n",
      "Operator 22: -0.820682587643383\n",
      "Operator 24: -0.8061029135659025\n",
      "Operator 25: 0.8344084316960857\n",
      "Operator 29: 0.537976522682466\n",
      "Operator 30: -1.2768256790905617\n",
      "Operator 31: 0.5728177746454037\n",
      "Operator 32: -0.13701052240436284\n",
      "Operator 33: 0.24470412383297013\n",
      "Operator 34: -0.8875410302418921\n",
      "Operator 35: 0.5963186022176148\n",
      "Operator 36: 0.34740898708030654\n",
      "Operator 37: 0.5498985235279645\n",
      "Operator 38: 1.1397917399377029\n",
      "Operator 39: 0.5028876483478795\n",
      "Operator 40: 0.4490700078241734\n",
      "Operator 41: 1.213012693160104\n",
      "Operator 42: 0.9418028959621075\n",
      "Operator 43: 1.3228223723838068\n",
      "Operator 44: 0.2926441185562786\n",
      "Operator 45: 0.015794787326710732\n",
      "Operator 46: -0.31278348606727946\n",
      "Operator 47: 0.34225465377162323\n",
      "Operator 48: -0.6700386085363594\n",
      "Operator 49: -0.5851622522979085\n",
      "Operator 50: -1.403371332937617\n",
      "Operator 51: 0.8860075099151361\n",
      "Operator 52: -0.6561764652940278\n",
      "Operator 53: 0.6513907256064876\n",
      "Operator 54: 0.0954564240617898\n",
      "Operator 55: 0.29547972834951935\n",
      "Operator 56: 0.3972109995444065\n",
      "Operator 57: 0.43998876502005313\n",
      "Operator 58: 0.25566535876806407\n",
      "Operator 59: 0.40230512574346483\n",
      "Operator 60: 0.3236473134989667\n",
      "Operator 61: 0.6346149065661268\n",
      "Operator 62: 0.2989476820188451\n",
      "Operator 63: -0.9276759960292067\n",
      "Operator 64: -0.2517530958914389\n",
      "Operator 65: -0.3983918357860606\n",
      "Operator 66: -0.1586446691136012\n",
      "Operator 67: -1.0062902961929032\n",
      "Operator 68: -0.24618806050582065\n",
      "Operator 69: -0.6185476542966387\n",
      "Operator 70: -0.7316722991465805\n",
      "Operator 71: -0.5472614758496782\n",
      "Operator 72: -0.45175107828589195\n",
      "Operator 73: 0.31845047106960755\n",
      "Operator 74: -0.6100958904893922\n",
      "Operator 75: -0.30147521814285916\n",
      "Operator 76: 0.39786621494006935\n",
      "Operator 77: 0.6813535311755736\n",
      "Operator 78: 0.1725263934470738\n",
      "Operator 79: 0.1335846716833068\n",
      "Operator 80: -1.622235865637195\n",
      "Operator 81: 0.6760753573425642\n",
      "Operator 82: 0.3495453059139403\n",
      "Operator 83: 1.361640417419173\n",
      "Operator 84: 0.17643954966510994\n",
      "Operator 85: 1.0498607293021456\n",
      "Operator 87: 1.5763277635594586\n",
      "Operator 89: 0.8786170062232296\n",
      "Operator 90: -1.5812956513360552\n",
      "Operator 92: -0.8902813234369773\n",
      "Operator 93: 0.8124736042145226\n",
      "Operator 94: -0.8590189959198629\n",
      "Operator 95: 1.2656948492065347\n",
      "Operator 96: -1.2948319291792483\n",
      "Operator 97: -0.02363968222384876\n",
      "Operator 98: -0.8832073343885498\n",
      "Operator 99: 0.32880343512857135\n",
      "Operator 100: -0.1571232775848746\n",
      "Operator 102: -0.1783587276703311\n",
      "Operator 104: 0.5606407105532449\n",
      "Operator 105: -0.0659931341591252\n",
      "Operator 106: 0.27741842456244\n",
      "Operator 107: 0.5466939284468271\n",
      "Operator 108: 0.4423847758829934\n",
      "Operator 109: 0.39576313115705825\n",
      "Operator 110: 0.2987820071700028\n",
      "Operator 111: 0.39471532380344776\n",
      "Operator 112: 0.544570644631229\n",
      "Operator 113: 0.3475244319592677\n",
      "Operator 114: 0.49288577944056844\n",
      "Operator 115: 0.10001124407999366\n",
      "Operator 116: -1.0069794056011296\n",
      "Operator 117: 0.22876474650751868\n",
      "Operator 118: -0.07720832627544248\n",
      "Operator 119: -0.7428728434610118\n",
      "Operator 120: -0.9222944004657887\n",
      "Operator 121: 0.23589541589561885\n",
      "Operator 122: -0.14286073026579368\n",
      "Operator 123: 0.5843776015811777\n",
      "Operator 124: 0.4772230600954209\n",
      "Operator 125: 0.502131211366945\n",
      "Operator 126: 1.1308694807489457\n",
      "Operator 127: 0.5174658023247058\n",
      "Operator 128: 0.3690213941706003\n",
      "Operator 129: 1.2747837560839603\n",
      "Operator 130: 0.7786563247761471\n",
      "Operator 131: 1.473671617047137\n",
      "Operator 132: -0.18170621700356754\n",
      "Operator 133: -0.09567885180275489\n",
      "Operator 134: -0.6239333558892467\n",
      "Operator 135: 0.391340592971384\n",
      "Operator 136: -1.4752119403016688\n",
      "Operator 137: -0.43064133576565977\n",
      "Operator 138: 0.3093952295589524\n",
      "Operator 139: -0.8106647285804425\n",
      "Operator 140: -0.41524265715897785\n",
      "Operator 141: -0.6333048733745031\n",
      "Operator 142: 0.31297660013648276\n",
      "Operator 143: -0.4634345477663527\n",
      "Operator 144: -0.5481350049862601\n",
      "Operator 145: 0.289742686095359\n",
      "Operator 146: 0.5286649092493327\n",
      "Operator 147: 0.41876439947694927\n",
      "Operator 148: 0.08432505177256325\n",
      "Operator 149: -1.63567372635003\n",
      "Operator 150: -0.012158590095347137\n",
      "Operator 151: 0.23795507530767407\n",
      "Operator 152: 0.7358637306107052\n",
      "Operator 153: 0.5023521390416057\n",
      "Operator 154: 1.3471712825870092\n",
      "Operator 155: -0.48707595363370804\n",
      "Operator 156: 0.1598247901520986\n",
      "Operator 158: -0.8438535170376465\n",
      "Operator 159: -0.20678937203136974\n",
      "Operator 160: -0.5224936247522367\n",
      "Operator 161: -0.15124313691189506\n",
      "Operator 162: -0.4750539008263082\n",
      "Operator 163: 1.0555570680727477\n",
      "Operator 164: -0.24062397086068832\n",
      "Operator 165: -0.43152608703078454\n",
      "Operator 166: 1.092306300199814\n",
      "Operator 167: 1.1459553735400838\n",
      "Operator 168: 1.0995583812796978\n",
      "Operator 169: -0.2597983638263177\n",
      "Operator 170: -0.7276655153146885\n",
      "Operator 171: -0.0380277778973632\n",
      "Operator 172: 1.048231548579452\n",
      "Operator 173: 0.0038002551396824347\n",
      "Operator 174: 0.7119690258316222\n",
      "Operator 175: 0.526650476640223\n",
      "Operator 176: 0.7657417265722286\n",
      "Operator 177: 0.7192408819605356\n",
      "Operator 178: -0.5751984249767669\n",
      "Operator 179: 0.8058888522376582\n",
      "Operator 180: -0.9413743650747086\n",
      "Operator 181: -1.4124941763290328\n",
      "Operator 182: 0.8702191698969531\n",
      "Operator 183: -1.0347859138314832\n",
      "Operator 184: -1.5068599509363163\n",
      "Operator 185: -1.6824423000475368\n",
      "Operator 186: -1.2897022704974148\n",
      "Operator 187: 0.9740355190924993\n",
      "Operator 188: 1.5693028038996109\n",
      "Operator 189: -0.6325562759243998\n",
      "Operator 190: -0.32702235482167535\n",
      "Operator 191: 0.42880890380337355\n",
      "Operator 192: 0.1835280448340333\n",
      "Operator 193: -0.4276861651098467\n",
      "Operator 194: -0.318626122240534\n",
      "Operator 195: 0.6643804174131823\n",
      "Operator 196: -1.2621192902505558\n",
      "Operator 197: 0.8128347907402365\n",
      "Operator 198: -1.3794539313274048\n",
      "Operator 199: -0.809682228114595\n",
      "Operator 200: 0.8546597598366303\n",
      "Operator 201: -1.475218553970505\n",
      "Operator 202: -0.7962340751052521\n",
      "Operator 203: -1.1559418458834063\n",
      "Operator 204: -0.5676382826399246\n",
      "Operator 205: 1.0587982755662795\n",
      "Operator 206: 0.9848266897060847\n",
      "Operator 207: -0.745259073423381\n",
      "Operator 208: 0.6219222695613886\n",
      "Operator 209: 0.427141775545306\n",
      "Operator 210: -0.8302146858025464\n",
      "Operator 211: 1.0835029942331693\n",
      "Operator 212: -1.358671963280293\n",
      "Operator 213: 0.8513829845118572\n",
      "Operator 214: -0.8220488070594032\n",
      "Operator 215: -1.3848824334228858\n",
      "Operator 216: 0.8096861766416217\n",
      "Operator 217: -0.7403679128604173\n",
      "Operator 218: -1.076257980170321\n",
      "Operator 219: -0.7424535372146975\n",
      "Operator 220: -1.5427033257801332\n",
      "Operator 221: 0.8145574715119243\n",
      "Operator 222: 0.9735693925867863\n",
      "Operator 223: -0.22524979078711205\n",
      "Operator 225: 0.8175834662440282\n",
      "Operator 226: 0.15420143837354328\n",
      "Operator 227: -0.15491502339587176\n",
      "Operator 228: 0.44256863988733275\n",
      "Operator 229: -0.20337091852773725\n",
      "Operator 230: 0.8141076739217482\n",
      "Operator 231: -0.7464919653527342\n",
      "Operator 232: 0.7417852602656677\n",
      "Operator 233: -1.3894540706915928\n",
      "Operator 234: 0.7204984074870284\n",
      "Operator 235: -0.7345602660211762\n",
      "Operator 236: 1.2954713206817323\n",
      "Operator 237: -1.3026749161287299\n",
      "Operator 238: 1.23860467375362\n",
      "Operator 239: -0.7129383992068815\n",
      "Operator 240: 0.3494326076883943\n",
      "Operator 241: -0.44947791968504236\n",
      "Operator 242: 0.357941236245814\n",
      "Operator 243: -0.08057589091055228\n",
      "Operator 244: 0.4705667987636472\n",
      "Operator 245: 0.8158189663428916\n",
      "Operator 246: -0.6003878235514917\n",
      "Operator 247: 1.204698072616901\n",
      "Operator 248: -0.690288108545534\n",
      "Operator 249: -1.273852010080186\n",
      "Operator 250: 1.3071097963021403\n",
      "Operator 251: -0.7162264215317562\n",
      "Operator 252: -1.2503370451765714\n",
      "Operator 253: -1.335303443695948\n",
      "Operator 254: -1.3321585425389681\n",
      "Operator 255: 0.34968066990185687\n",
      "Operator 256: 1.6353468163219662\n",
      "Operator 257: -0.9072768295373626\n",
      "Operator 258: -0.24661512557110152\n",
      "Operator 259: -0.4305292108672409\n",
      "Operator 260: -0.16216010106292833\n",
      "Total gradient norm: 12.727347438370936\n",
      "Operators under consideration (1):\n",
      "[1]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(1.7036452682244194)]\n",
      "Operator(s) added to ansatz: [1]\n",
      "Gradients: [np.float64(1.7036452682244194)]\n",
      "Initial energy: -32.13436347742718\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1]...\n",
      "Starting point: [np.float64(0.3902211124719444), np.float64(0.5089692637769752), np.float64(0.33825993301562607), np.float64(-0.2785121500428507), np.float64(-0.2782381611675435), np.float64(-0.14506874572160608), np.float64(0.3107955084719085), np.float64(-0.259254873338344), np.float64(0.6419901554891293), np.float64(0.2892507711844318), np.float64(-0.5030370079872584), np.float64(-0.32771389759592146), np.float64(-0.2808358754996743), np.float64(0.28643751911301385), np.float64(0.2724616453946721), np.float64(0.2574710306678202), np.float64(-0.21590772490619517), np.float64(0.21445892077181758), np.float64(-0.1856953890018225), np.float64(-0.1526691196611565), np.float64(0.14043132479969975), np.float64(0.10270581938876079), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -32.284400\n",
      "         Iterations: 30\n",
      "         Function evaluations: 139\n",
      "         Gradient evaluations: 124\n",
      "\n",
      "Current energy: -32.28439986183398\n",
      "(change of -0.15003638440680334)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1]\n",
      "On iteration 23.\n",
      "\n",
      "*** ADAPT-VQE Iteration 24 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.32613783815334685\n",
      "Operator 1: 1.4218181418742312e-07\n",
      "Operator 2: -0.12697245668849438\n",
      "Operator 3: 1.5842785634724148\n",
      "Operator 4: -0.8803516726773561\n",
      "Operator 5: -3.854268505497426e-08\n",
      "Operator 6: -1.541065037148182\n",
      "Operator 7: 0.9124986829411743\n",
      "Operator 8: -0.7267646050412329\n",
      "Operator 9: 1.0355183209628118\n",
      "Operator 10: -1.0968406452187091e-07\n",
      "Operator 11: 1.0979703108493066\n",
      "Operator 12: -1.0526007755185591\n",
      "Operator 13: 0.4880372617008276\n",
      "Operator 14: -0.05392325026935385\n",
      "Operator 15: 0.568575786575727\n",
      "Operator 16: 0.11581598975725171\n",
      "Operator 17: 0.20930450364089434\n",
      "Operator 18: -0.46894832607891856\n",
      "Operator 19: 0.2863515076948375\n",
      "Operator 20: -0.17221855520337886\n",
      "Operator 21: 0.9006369236591719\n",
      "Operator 22: -0.8359087203247464\n",
      "Operator 23: 5.172557317167297e-08\n",
      "Operator 24: -0.804906732553515\n",
      "Operator 25: 0.8399883935173922\n",
      "Operator 26: -1.0817266570349063e-07\n",
      "Operator 27: 1.8456355851769912e-07\n",
      "Operator 28: -4.0534765627556616e-07\n",
      "Operator 29: 0.5381542113575517\n",
      "Operator 30: -1.2769111481807558\n",
      "Operator 31: 0.5730771451840523\n",
      "Operator 32: -0.1370514356681904\n",
      "Operator 33: 0.24474458854187564\n",
      "Operator 34: -0.7646384830910762\n",
      "Operator 35: -0.05161341522842603\n",
      "Operator 36: -0.41769950419328594\n",
      "Operator 37: 0.28270911605603577\n",
      "Operator 38: 1.1505957871589163\n",
      "Operator 39: 0.4728016754754068\n",
      "Operator 40: 0.4568870472746177\n",
      "Operator 41: 1.2046919236443436\n",
      "Operator 42: 0.9468320013347709\n",
      "Operator 43: 1.3203237518442994\n",
      "Operator 44: 0.2945992401301305\n",
      "Operator 45: 0.015435514193011543\n",
      "Operator 46: -0.3120049113299673\n",
      "Operator 47: 0.3423367814343648\n",
      "Operator 48: -0.6696049484510637\n",
      "Operator 49: -0.5851312947143525\n",
      "Operator 50: -1.4031617729709804\n",
      "Operator 51: 0.8252681198600035\n",
      "Operator 52: -0.12247127221768486\n",
      "Operator 53: 0.5310157018426092\n",
      "Operator 54: -0.5497007941880387\n",
      "Operator 55: 0.2697384516148528\n",
      "Operator 56: 0.40846784546501996\n",
      "Operator 57: 0.43340663571001264\n",
      "Operator 58: 0.2591781862264891\n",
      "Operator 59: 0.39949177687226833\n",
      "Operator 60: 0.3246362982968227\n",
      "Operator 61: 0.6336145092025829\n",
      "Operator 62: 0.2993071403646345\n",
      "Operator 63: -0.9278694547539705\n",
      "Operator 64: -0.2516485184598587\n",
      "Operator 65: -0.39828206512698205\n",
      "Operator 66: -0.1585942800448169\n",
      "Operator 67: -1.0063614902473166\n",
      "Operator 68: -0.1426822633060792\n",
      "Operator 69: 0.16942392938674078\n",
      "Operator 70: 0.12828253538033899\n",
      "Operator 71: -0.6606322851076565\n",
      "Operator 72: -0.4530610313406045\n",
      "Operator 73: 0.31443585971401483\n",
      "Operator 74: -0.6053756257765247\n",
      "Operator 75: -0.3104040591504875\n",
      "Operator 76: 0.3988924998689821\n",
      "Operator 77: 0.6803043135111808\n",
      "Operator 78: 0.1727283866606743\n",
      "Operator 79: 0.13295561641102507\n",
      "Operator 80: -1.6219255396518224\n",
      "Operator 81: 0.6755448930894303\n",
      "Operator 82: 0.34947543906668194\n",
      "Operator 83: 1.3614620169830918\n",
      "Operator 84: 0.17640705570430787\n",
      "Operator 85: 0.29535567519043116\n",
      "Operator 86: -1.2851632524866068e-07\n",
      "Operator 87: 0.9817139696991248\n",
      "Operator 88: -1.1041115261895261e-07\n",
      "Operator 89: 0.901055987545148\n",
      "Operator 90: -1.5737836318643965\n",
      "Operator 91: -5.339278961052546e-08\n",
      "Operator 92: -0.8878665433506401\n",
      "Operator 93: 0.8144000141880237\n",
      "Operator 94: -0.8579477352646667\n",
      "Operator 95: 1.2664741580678107\n",
      "Operator 96: -1.2948823808198835\n",
      "Operator 97: -0.023640082232734595\n",
      "Operator 98: -0.8831901883920594\n",
      "Operator 99: 0.3289892679270112\n",
      "Operator 100: -0.1571180459497872\n",
      "Operator 101: -2.499522295806855e-07\n",
      "Operator 102: -0.17840794753745795\n",
      "Operator 103: -2.8428109002254133e-07\n",
      "Operator 104: 0.7491989031188915\n",
      "Operator 105: 0.137109669808666\n",
      "Operator 106: 0.29643040746288374\n",
      "Operator 107: -0.2340471837982861\n",
      "Operator 108: 0.4778365412630286\n",
      "Operator 109: 0.40906224200022423\n",
      "Operator 110: 0.28715497989607797\n",
      "Operator 111: 0.3997869962233602\n",
      "Operator 112: 0.5421441552320261\n",
      "Operator 113: 0.34892518934728745\n",
      "Operator 114: 0.491781230562607\n",
      "Operator 115: 0.10036229363146018\n",
      "Operator 116: -1.0070413859232463\n",
      "Operator 117: 0.22890529945560092\n",
      "Operator 118: -0.07711603575673642\n",
      "Operator 119: -0.7426742143388463\n",
      "Operator 120: -0.9223539963598528\n",
      "Operator 121: 0.14328208409346282\n",
      "Operator 122: -0.1517366396866922\n",
      "Operator 123: -0.1696737515530794\n",
      "Operator 124: -0.16037380277576796\n",
      "Operator 125: 0.4871076847577299\n",
      "Operator 126: 1.1541364228003728\n",
      "Operator 127: 0.5048834098605872\n",
      "Operator 128: 0.3723352946286145\n",
      "Operator 129: 1.2716709454615605\n",
      "Operator 130: 0.7813104259430139\n",
      "Operator 131: 1.4725226575400028\n",
      "Operator 132: -0.18041477094131858\n",
      "Operator 133: -0.09573935227056418\n",
      "Operator 134: -0.6235473224110439\n",
      "Operator 135: 0.3916015269654927\n",
      "Operator 136: -1.4749948792874503\n",
      "Operator 137: -0.4305921297874593\n",
      "Operator 138: 0.7875437207464333\n",
      "Operator 139: 0.09974525969960683\n",
      "Operator 140: -0.3756039626022667\n",
      "Operator 141: -0.48488364133523604\n",
      "Operator 142: 0.31659467323808677\n",
      "Operator 143: -0.43421840369830944\n",
      "Operator 144: -0.5609482165714728\n",
      "Operator 145: 0.2937247656742968\n",
      "Operator 146: 0.5254199005683198\n",
      "Operator 147: 0.4202695457014801\n",
      "Operator 148: 0.08263926627624019\n",
      "Operator 149: -1.634912469365434\n",
      "Operator 150: -0.012986102410832267\n",
      "Operator 151: 0.23792180825739767\n",
      "Operator 152: 0.7354994414998012\n",
      "Operator 153: 0.5023174458158152\n",
      "Operator 154: 1.3469815493854842\n",
      "Operator 155: -0.5292008018494813\n",
      "Operator 156: 0.17926440625883194\n",
      "Operator 157: -2.9886001384516515e-07\n",
      "Operator 158: -0.7377607201897258\n",
      "Operator 159: -0.12730062683684254\n",
      "Operator 160: -0.522520845500824\n",
      "Operator 161: -0.34250832670634296\n",
      "Operator 162: -0.4249591829596008\n",
      "Operator 163: 1.0586269338687628\n",
      "Operator 164: -0.23449481300790193\n",
      "Operator 165: -0.4332751974523861\n",
      "Operator 166: 1.0906089889114265\n",
      "Operator 167: 1.1467134958971932\n",
      "Operator 168: 1.099509174336522\n",
      "Operator 169: -0.26023997692557876\n",
      "Operator 170: -0.7272228821889128\n",
      "Operator 171: -0.03806902854555852\n",
      "Operator 172: 1.0482662875809994\n",
      "Operator 173: 0.0037558202876314672\n",
      "Operator 174: 0.7119665109029455\n",
      "Operator 175: 0.5274313534539627\n",
      "Operator 176: 0.5988152835052624\n",
      "Operator 177: -0.18032863317419978\n",
      "Operator 178: 0.34852058092578597\n",
      "Operator 179: 0.9265624035274203\n",
      "Operator 180: -0.947584557992921\n",
      "Operator 181: -1.4017667436377805\n",
      "Operator 182: 0.863986360273199\n",
      "Operator 183: -1.0257570382476653\n",
      "Operator 184: -1.50901151347067\n",
      "Operator 185: -1.6811745536543619\n",
      "Operator 186: -1.2904960122941458\n",
      "Operator 187: 0.9744517671632504\n",
      "Operator 188: 1.5689415482474696\n",
      "Operator 189: -0.632514244594342\n",
      "Operator 190: -0.32719040358677554\n",
      "Operator 191: 0.42890556105329136\n",
      "Operator 192: 0.1834701609990712\n",
      "Operator 193: -0.3665767449272035\n",
      "Operator 194: -0.4152171155620473\n",
      "Operator 195: -0.16596798216444983\n",
      "Operator 196: -0.13197856953845052\n",
      "Operator 197: 0.7701297689005497\n",
      "Operator 198: -1.3962384953898883\n",
      "Operator 199: -0.7892452023519474\n",
      "Operator 200: 0.8515283218905059\n",
      "Operator 201: -1.4728686054000897\n",
      "Operator 202: -0.7992580406286749\n",
      "Operator 203: -1.1537704344208661\n",
      "Operator 204: -0.5687075222483533\n",
      "Operator 205: 1.0590211498559852\n",
      "Operator 206: 0.9849286550262267\n",
      "Operator 207: -0.7454291138659233\n",
      "Operator 208: 0.6217452598872496\n",
      "Operator 209: 0.4272404623619731\n",
      "Operator 210: -0.7536251516733986\n",
      "Operator 211: 0.0441544847871801\n",
      "Operator 212: -0.32879765886365797\n",
      "Operator 213: 1.1694877030174502\n",
      "Operator 214: -0.7452975244268606\n",
      "Operator 215: -1.3871027295702565\n",
      "Operator 216: 0.8198330236200166\n",
      "Operator 217: -0.7445307392992758\n",
      "Operator 218: -1.0718197082554741\n",
      "Operator 219: -0.744551722850745\n",
      "Operator 220: -1.541271645300244\n",
      "Operator 221: 0.81401574068126\n",
      "Operator 222: 0.9739006341898285\n",
      "Operator 223: -0.2255283176949912\n",
      "Operator 224: 2.512427824535868e-07\n",
      "Operator 225: 0.8175734421955779\n",
      "Operator 226: 0.15421465135304846\n",
      "Operator 227: -0.2086138500543281\n",
      "Operator 228: 0.4674836744631995\n",
      "Operator 229: -0.3134684080969287\n",
      "Operator 230: 0.21681490136245019\n",
      "Operator 231: -0.12875391408012538\n",
      "Operator 232: 0.7390985734808457\n",
      "Operator 233: -1.4050280918395415\n",
      "Operator 234: 0.7120997125703852\n",
      "Operator 235: -0.7357357319587905\n",
      "Operator 236: 1.2939838246266575\n",
      "Operator 237: -1.304357036354045\n",
      "Operator 238: 1.2381254599924123\n",
      "Operator 239: -0.7136706631462792\n",
      "Operator 240: 0.34948542183639\n",
      "Operator 241: -0.4495634070103476\n",
      "Operator 242: 0.3580668325473777\n",
      "Operator 243: -0.08074116435526435\n",
      "Operator 244: 0.7680602668783123\n",
      "Operator 245: -0.0929304525527095\n",
      "Operator 246: -0.010462356663772363\n",
      "Operator 247: 1.2794057418940414\n",
      "Operator 248: -0.6715160322010432\n",
      "Operator 249: -1.2648003544140254\n",
      "Operator 250: 1.2931866061911705\n",
      "Operator 251: -0.7090247701800922\n",
      "Operator 252: -1.251269635458425\n",
      "Operator 253: -1.334681532918865\n",
      "Operator 254: -1.3328762316858382\n",
      "Operator 255: 0.350208306072401\n",
      "Operator 256: 1.6348139847252319\n",
      "Operator 257: -0.907159184203626\n",
      "Operator 258: -0.24671150533505748\n",
      "Operator 259: -0.43039316404009864\n",
      "Operator 260: -0.16219841189591078\n",
      "Total gradient norm: 12.06849325773794\n",
      "Operators under consideration (1):\n",
      "[185]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.6811745536543619)]\n",
      "Operator(s) added to ansatz: [185]\n",
      "Gradients: [np.float64(-1.6811745536543619)]\n",
      "Initial energy: -32.28439986183398\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185]...\n",
      "Starting point: [np.float64(0.39014562253580853), np.float64(0.5089233036277099), np.float64(0.3381068821649718), np.float64(-0.2803876210731423), np.float64(-0.28554285603486534), np.float64(-0.14466619884111426), np.float64(0.31044109595372893), np.float64(-0.16581209944153213), np.float64(0.641970955401989), np.float64(0.2883169173256794), np.float64(-0.5018609236123178), np.float64(-0.3324710861039368), np.float64(-0.2786581666216287), np.float64(0.28943212065075885), np.float64(0.27296387902611746), np.float64(0.2576529644545359), np.float64(-0.215968834163268), np.float64(0.2144789126656048), np.float64(-0.18570234718331563), np.float64(-0.15267105423931115), np.float64(0.14488076735770397), np.float64(0.10269018587501287), np.float64(-0.17468641033887927), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -32.386539\n",
      "         Iterations: 33\n",
      "         Function evaluations: 46\n",
      "         Gradient evaluations: 46\n",
      "\n",
      "Current energy: -32.38653862700273\n",
      "(change of -0.1021387651687462)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185]\n",
      "On iteration 24.\n",
      "\n",
      "*** ADAPT-VQE Iteration 25 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.3267902228462607\n",
      "Operator 1: 5.179536791242768e-08\n",
      "Operator 2: -0.12767234096617983\n",
      "Operator 3: 1.5959164203383223\n",
      "Operator 4: -0.8599469548009007\n",
      "Operator 6: -1.4761865697885233\n",
      "Operator 7: 1.0947607170108844\n",
      "Operator 8: 0.21135288443076122\n",
      "Operator 9: 1.0063146621113055\n",
      "Operator 10: -0.023725628512785833\n",
      "Operator 11: 1.1201783381257973\n",
      "Operator 12: -1.029336158614216\n",
      "Operator 13: 0.47699263195010755\n",
      "Operator 14: -0.05337363821115204\n",
      "Operator 15: 0.5652009260397027\n",
      "Operator 16: 0.11499745452907817\n",
      "Operator 17: 0.20933315084340443\n",
      "Operator 18: -0.4689522268852472\n",
      "Operator 19: 0.2881394601812062\n",
      "Operator 20: -0.17327907978911042\n",
      "Operator 21: 0.9021218749542778\n",
      "Operator 22: -0.8205491692177187\n",
      "Operator 24: -0.7838010178256902\n",
      "Operator 25: 0.8268143459267666\n",
      "Operator 26: -0.05165885130023103\n",
      "Operator 28: 0.11165953673716285\n",
      "Operator 29: 0.5424090394990151\n",
      "Operator 30: -1.2686761722414988\n",
      "Operator 31: 0.5560519749073229\n",
      "Operator 32: -0.13344602563195504\n",
      "Operator 33: 0.24114651322092362\n",
      "Operator 34: -0.7655439442804062\n",
      "Operator 35: -0.04938715253115022\n",
      "Operator 36: -0.41999950448528944\n",
      "Operator 37: 0.3042878451014597\n",
      "Operator 38: 1.1257906927927235\n",
      "Operator 39: 0.49694833606401534\n",
      "Operator 40: 0.35358587772268746\n",
      "Operator 41: 1.3862533436586117\n",
      "Operator 42: 0.14591519436950035\n",
      "Operator 43: 0.22557209356586444\n",
      "Operator 44: 0.09733044810308493\n",
      "Operator 45: -0.053860435746741\n",
      "Operator 46: -0.40248391750146806\n",
      "Operator 47: 0.3337112949056884\n",
      "Operator 48: -0.7067761650439819\n",
      "Operator 49: -0.5877057275238273\n",
      "Operator 50: -1.4216629386318864\n",
      "Operator 51: 0.8259413025788325\n",
      "Operator 52: -0.12226444130613971\n",
      "Operator 53: 0.5328714569664096\n",
      "Operator 54: -0.5498134689419066\n",
      "Operator 55: 0.28138108173303766\n",
      "Operator 56: 0.3929603540168616\n",
      "Operator 57: 0.4777950356163695\n",
      "Operator 58: 0.17050655531285192\n",
      "Operator 59: 0.5230960535636979\n",
      "Operator 60: 0.34568597185133565\n",
      "Operator 61: -0.5900163957412863\n",
      "Operator 62: 0.2500951095453614\n",
      "Operator 63: -0.9267707074835646\n",
      "Operator 64: -0.25975511948933283\n",
      "Operator 65: -0.4060172847276027\n",
      "Operator 66: -0.16163304461978747\n",
      "Operator 67: -0.999688879247758\n",
      "Operator 68: -0.14499539328430774\n",
      "Operator 69: 0.1723722019430517\n",
      "Operator 70: 0.12028514564960271\n",
      "Operator 71: -0.6410229249136481\n",
      "Operator 72: -0.4832832162966487\n",
      "Operator 73: 0.34995397376932147\n",
      "Operator 74: -0.7079295416249389\n",
      "Operator 75: -0.07603061037255499\n",
      "Operator 76: 0.41377602554885035\n",
      "Operator 77: 0.5748432323268763\n",
      "Operator 78: 0.3152452616083905\n",
      "Operator 79: 0.16093311283427048\n",
      "Operator 80: -1.6500564006820229\n",
      "Operator 81: 0.716661427867707\n",
      "Operator 82: 0.3550257007523097\n",
      "Operator 83: 1.3776041639402412\n",
      "Operator 84: 0.180421982354127\n",
      "Operator 85: 0.29660007397887533\n",
      "Operator 87: 0.9753672338875886\n",
      "Operator 89: 0.9000781251613682\n",
      "Operator 90: -1.6106747898713403\n",
      "Operator 92: -0.8857764992687794\n",
      "Operator 93: 0.7291637899000906\n",
      "Operator 94: -0.05253151264500704\n",
      "Operator 95: 1.2230259859445405\n",
      "Operator 96: -1.2883302442899862\n",
      "Operator 97: -0.02380011841933767\n",
      "Operator 98: -0.8855093016809894\n",
      "Operator 99: 0.3152522184618851\n",
      "Operator 100: -0.15646545336539758\n",
      "Operator 102: -0.17855808276437\n",
      "Operator 103: -1.0197957644550227e-08\n",
      "Operator 104: 0.7500706850025751\n",
      "Operator 105: 0.13602211385872523\n",
      "Operator 106: 0.30136945443210733\n",
      "Operator 107: -0.23657680318814606\n",
      "Operator 108: 0.4862606177355774\n",
      "Operator 109: 0.3858689350814299\n",
      "Operator 110: 0.31837088530964375\n",
      "Operator 111: 0.348378582416777\n",
      "Operator 112: 0.6208724606916802\n",
      "Operator 113: 0.2590448949961566\n",
      "Operator 114: -0.5848295645536201\n",
      "Operator 115: -0.111554172820241\n",
      "Operator 116: -0.9880208758987158\n",
      "Operator 117: 0.2191697566915759\n",
      "Operator 118: -0.08050019530824015\n",
      "Operator 119: -0.756239130018081\n",
      "Operator 120: -0.9171097049393322\n",
      "Operator 121: 0.14558249750636196\n",
      "Operator 122: -0.15509020382875943\n",
      "Operator 123: -0.16112300106450164\n",
      "Operator 124: -0.16985985137594123\n",
      "Operator 125: 0.5245584077657421\n",
      "Operator 126: 1.0819533281164313\n",
      "Operator 127: 0.5645673796232674\n",
      "Operator 128: 0.13222889302225138\n",
      "Operator 129: 1.3251846177832154\n",
      "Operator 130: 0.05330535008861964\n",
      "Operator 131: 0.26936060304998843\n",
      "Operator 132: -0.2626131045794832\n",
      "Operator 133: -0.09176428124376262\n",
      "Operator 134: -0.6582791103351935\n",
      "Operator 135: 0.37474088046768383\n",
      "Operator 136: -1.4928087152007614\n",
      "Operator 137: -0.435230280214983\n",
      "Operator 138: 0.7879981446429687\n",
      "Operator 139: 0.09661482502326012\n",
      "Operator 140: -0.36575907693281273\n",
      "Operator 141: -0.49225370491565323\n",
      "Operator 142: 0.3231786801988019\n",
      "Operator 143: -0.505707377146543\n",
      "Operator 144: -0.5213606994180726\n",
      "Operator 145: 0.2636698553181223\n",
      "Operator 146: 0.6055433653029845\n",
      "Operator 147: 0.47818280806617275\n",
      "Operator 148: 0.12146103789897814\n",
      "Operator 149: -1.5806908683031087\n",
      "Operator 150: 0.06875614516097345\n",
      "Operator 151: 0.24280960056540152\n",
      "Operator 152: 0.7698423387024393\n",
      "Operator 153: 0.5056574323883666\n",
      "Operator 154: 1.3641860420110206\n",
      "Operator 155: -0.5299473961589739\n",
      "Operator 156: 0.17939649155288814\n",
      "Operator 157: -9.297334701462943e-08\n",
      "Operator 158: -0.7388564963298438\n",
      "Operator 159: -0.1264184606535216\n",
      "Operator 160: -0.5253206658228782\n",
      "Operator 161: -0.3337099274949109\n",
      "Operator 162: -0.43789813668383226\n",
      "Operator 163: 1.0556484184111792\n",
      "Operator 164: -0.28556213389845925\n",
      "Operator 165: -0.3605539542710723\n",
      "Operator 166: 1.1079604616796574\n",
      "Operator 167: 0.28848285800293505\n",
      "Operator 168: 1.204764848767507\n",
      "Operator 169: -0.25235712797239057\n",
      "Operator 170: -0.750052597391055\n",
      "Operator 171: -0.03449311837772654\n",
      "Operator 172: 1.0430541029877367\n",
      "Operator 173: 0.008035301821730179\n",
      "Operator 174: 0.7117423640292055\n",
      "Operator 175: 0.5282153777723158\n",
      "Operator 176: 0.600177215829139\n",
      "Operator 177: -0.18261989209511653\n",
      "Operator 178: 0.35127607157813245\n",
      "Operator 179: 0.903819070096354\n",
      "Operator 180: -0.9254493956391323\n",
      "Operator 181: -1.4152830313728213\n",
      "Operator 182: 0.9699334002600919\n",
      "Operator 183: -1.1547029143134613\n",
      "Operator 184: -1.3718017299019354\n",
      "Operator 186: -1.1912244211127871\n",
      "Operator 187: 0.9669171362966091\n",
      "Operator 188: 1.6070856567062917\n",
      "Operator 189: -0.6338495898331704\n",
      "Operator 190: -0.315348981585758\n",
      "Operator 191: 0.4199672509878215\n",
      "Operator 192: 0.1875502211418656\n",
      "Operator 193: -0.36826997272942297\n",
      "Operator 194: -0.4136868991508494\n",
      "Operator 195: -0.17005290946142573\n",
      "Operator 196: -0.12828217213968535\n",
      "Operator 197: 0.7516598678678368\n",
      "Operator 198: -1.3584022735480463\n",
      "Operator 199: -0.8223275669991299\n",
      "Operator 200: 0.9168845280466268\n",
      "Operator 201: -1.4799312643292242\n",
      "Operator 202: -0.6103378221968336\n",
      "Operator 203: 0.2564969886928694\n",
      "Operator 204: -0.41550054222438504\n",
      "Operator 205: 1.0222531346188237\n",
      "Operator 206: 0.9767720807040259\n",
      "Operator 207: -0.7353071888923772\n",
      "Operator 208: 0.6337049839576079\n",
      "Operator 209: 0.4185408712632682\n",
      "Operator 210: -0.7542083847062884\n",
      "Operator 211: 0.043713936707293365\n",
      "Operator 212: -0.3295065247924352\n",
      "Operator 213: 1.1690090626322087\n",
      "Operator 214: -0.766682563108056\n",
      "Operator 215: -1.3696491697880326\n",
      "Operator 216: 0.7864530063584525\n",
      "Operator 217: -0.5795873301800973\n",
      "Operator 218: -1.5691507927655834\n",
      "Operator 219: 0.5036893993490413\n",
      "Operator 220: -0.7494018793370261\n",
      "Operator 221: 0.7585686605974586\n",
      "Operator 222: 0.9603610085667985\n",
      "Operator 223: -0.19741500785943217\n",
      "Operator 225: 0.8175337446184708\n",
      "Operator 226: 0.15267223562307564\n",
      "Operator 227: -0.20865637949097662\n",
      "Operator 228: 0.4675209569853653\n",
      "Operator 229: -0.31481993768526556\n",
      "Operator 230: 0.21681664407445178\n",
      "Operator 231: -0.1299649584938366\n",
      "Operator 232: 0.7381818259212967\n",
      "Operator 233: -1.4183984429866918\n",
      "Operator 234: 0.6655879662575165\n",
      "Operator 235: -0.6567929480885825\n",
      "Operator 236: 1.3989361904928768\n",
      "Operator 237: -0.5498448852948219\n",
      "Operator 238: 0.345717079483016\n",
      "Operator 239: -0.6841029962212613\n",
      "Operator 240: 0.344431003453035\n",
      "Operator 241: -0.44212689709330033\n",
      "Operator 242: 0.3487581242218688\n",
      "Operator 243: -0.0691674138772207\n",
      "Operator 244: 0.7683581252028509\n",
      "Operator 245: -0.09155390216935647\n",
      "Operator 246: -0.006315260271001548\n",
      "Operator 247: 1.2745807818916661\n",
      "Operator 248: -0.6650016982316562\n",
      "Operator 249: -1.2602856348892022\n",
      "Operator 250: 1.3193139203074011\n",
      "Operator 251: -0.7207796947515643\n",
      "Operator 252: -1.1947926322672373\n",
      "Operator 253: -0.25954723287917947\n",
      "Operator 254: -1.277192542559826\n",
      "Operator 255: 0.3012502087287822\n",
      "Operator 256: 1.6061722327991068\n",
      "Operator 257: -0.9118881058880848\n",
      "Operator 258: -0.23962331038647233\n",
      "Operator 259: -0.442207058024751\n",
      "Operator 260: -0.15900561802199364\n",
      "Total gradient norm: 11.33027867394717\n",
      "Operators under consideration (1):\n",
      "[80]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.6500564006820229)]\n",
      "Operator(s) added to ansatz: [80]\n",
      "Gradients: [np.float64(-1.6500564006820229)]\n",
      "Initial energy: -32.38653862700273\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80]...\n",
      "Starting point: [np.float64(0.3971296323719247), np.float64(0.5128842313668421), np.float64(0.3558957272049836), np.float64(-0.2729999167774262), np.float64(-0.2829893165547951), np.float64(-0.14458993261001576), np.float64(0.3929904103094641), np.float64(-0.1656002451671888), np.float64(0.6437229756900003), np.float64(0.3041137272019705), np.float64(-0.5019637617375127), np.float64(-0.3327507813179127), np.float64(-0.2827836818754194), np.float64(0.2906549083249454), np.float64(0.25542660129356876), np.float64(0.2600265770156605), np.float64(-0.21332671677280074), np.float64(0.2127175833328914), np.float64(-0.1850873005604498), np.float64(-0.1525633409953573), np.float64(0.14479998213881543), np.float64(0.10373937862846205), np.float64(-0.1743044995009492), np.float64(0.12145329816643455), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -32.487622\n",
      "         Iterations: 34\n",
      "         Function evaluations: 54\n",
      "         Gradient evaluations: 54\n",
      "\n",
      "Current energy: -32.487621520412134\n",
      "(change of -0.10108289340940502)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80]\n",
      "On iteration 25.\n",
      "\n",
      "*** ADAPT-VQE Iteration 26 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.32683757215068326\n",
      "Operator 1: 4.9561683628657205e-08\n",
      "Operator 2: -0.12772235993451267\n",
      "Operator 3: 1.596751732943055\n",
      "Operator 4: -0.858510030991357\n",
      "Operator 6: -1.471658320323604\n",
      "Operator 7: 1.1023153497129163\n",
      "Operator 8: 0.21300042801094016\n",
      "Operator 9: 1.042802687565732\n",
      "Operator 10: -0.0419214027002387\n",
      "Operator 11: 0.5555643008650839\n",
      "Operator 12: -0.4553103204624057\n",
      "Operator 13: 0.6464558597606158\n",
      "Operator 14: -0.04502006912124267\n",
      "Operator 15: 0.5429826327447779\n",
      "Operator 16: 0.11712554051213235\n",
      "Operator 17: 0.20933521643982544\n",
      "Operator 18: -0.46895218301655595\n",
      "Operator 19: 0.28826731915252995\n",
      "Operator 20: -0.17335315495211803\n",
      "Operator 21: 0.9022087191397055\n",
      "Operator 22: -0.8193766756739336\n",
      "Operator 24: -0.7816740926732656\n",
      "Operator 25: 0.8245403687319706\n",
      "Operator 26: -0.05515666622133295\n",
      "Operator 27: 0.035610136313181294\n",
      "Operator 28: 0.08476770094537185\n",
      "Operator 29: 0.09535114906583335\n",
      "Operator 30: -0.44287347528920573\n",
      "Operator 31: 0.12986861005618802\n",
      "Operator 32: -0.19760138052484896\n",
      "Operator 33: 0.2230125174168885\n",
      "Operator 34: -0.7656084955303969\n",
      "Operator 35: -0.049226417783668604\n",
      "Operator 36: -0.4201647900639659\n",
      "Operator 37: 0.30584671884471637\n",
      "Operator 38: 1.124020675669505\n",
      "Operator 39: 0.49868006602260057\n",
      "Operator 40: 0.3465580939652017\n",
      "Operator 41: 1.3950655056915564\n",
      "Operator 42: 0.13525441330478594\n",
      "Operator 43: 0.23519632308262584\n",
      "Operator 44: 0.09354277038850524\n",
      "Operator 45: -0.07338262354829041\n",
      "Operator 46: -0.6458740423312546\n",
      "Operator 47: 0.16293639103519048\n",
      "Operator 48: -0.8619071793107405\n",
      "Operator 49: -0.5833517713047545\n",
      "Operator 50: -1.503869189564898\n",
      "Operator 51: 0.8259894168284845\n",
      "Operator 52: -0.12224919884552939\n",
      "Operator 53: 0.5330049191914306\n",
      "Operator 54: -0.549817019133505\n",
      "Operator 55: 0.28221026962319107\n",
      "Operator 56: 0.3918671657468338\n",
      "Operator 57: 0.4809991457201859\n",
      "Operator 58: 0.16583787859575547\n",
      "Operator 59: 0.5289574294067818\n",
      "Operator 60: 0.33802276969308254\n",
      "Operator 61: -0.6055926968045062\n",
      "Operator 62: 0.28081979291430514\n",
      "Operator 63: -0.581355852072565\n",
      "Operator 64: -0.36572304981280945\n",
      "Operator 65: -0.23991726517363532\n",
      "Operator 66: -0.2072984694367971\n",
      "Operator 67: -0.9599866309243603\n",
      "Operator 68: -0.14516102750598664\n",
      "Operator 69: 0.17258543954965172\n",
      "Operator 70: 0.11971483419741424\n",
      "Operator 71: -0.6396002827812035\n",
      "Operator 72: -0.48539399759640117\n",
      "Operator 73: 0.35263304936278167\n",
      "Operator 74: -0.7148639357578074\n",
      "Operator 75: -0.058002498441424424\n",
      "Operator 76: 0.41424958595109335\n",
      "Operator 77: 0.6067418240629799\n",
      "Operator 78: 0.4512017893629984\n",
      "Operator 79: 0.8445941007513343\n",
      "Operator 80: 1.4512071265383294e-07\n",
      "Operator 81: 1.1194290814600802\n",
      "Operator 82: 0.09915566552774953\n",
      "Operator 83: 1.4630038375849381\n",
      "Operator 84: 0.22547140006667366\n",
      "Operator 85: 0.2966893682744411\n",
      "Operator 87: 0.9749146530405945\n",
      "Operator 89: 0.8999997485222299\n",
      "Operator 90: -1.6133281097883514\n",
      "Operator 92: -0.885322144673431\n",
      "Operator 93: 0.7267623619708748\n",
      "Operator 94: -0.06577635921272967\n",
      "Operator 95: 0.8601662145256393\n",
      "Operator 96: -0.5638172699740152\n",
      "Operator 97: -0.015770332101049712\n",
      "Operator 98: -1.0000932370576026\n",
      "Operator 99: 0.2626789020172361\n",
      "Operator 100: -0.13498192252560476\n",
      "Operator 101: 5.8780210594426767e-08\n",
      "Operator 102: -0.17856887637318053\n",
      "Operator 103: -1.0614977008494009e-08\n",
      "Operator 104: 0.7501331402153704\n",
      "Operator 105: 0.13594409555253717\n",
      "Operator 106: 0.30172244172998397\n",
      "Operator 107: -0.23675681076651478\n",
      "Operator 108: 0.48685985641928814\n",
      "Operator 109: 0.38421450783541833\n",
      "Operator 110: 0.32069226504588744\n",
      "Operator 111: 0.3445903090301101\n",
      "Operator 112: 0.628809229665874\n",
      "Operator 113: 0.2556734981088635\n",
      "Operator 114: -0.5854251249058247\n",
      "Operator 115: 0.10871137473815601\n",
      "Operator 116: -0.6208025936780067\n",
      "Operator 117: 0.18389316856870436\n",
      "Operator 118: -0.10019257838367021\n",
      "Operator 119: -0.7361916233227035\n",
      "Operator 120: -0.8920055576267281\n",
      "Operator 121: 0.1457472402105034\n",
      "Operator 122: -0.15533215563998465\n",
      "Operator 123: -0.1605134375886697\n",
      "Operator 124: -0.17055595820777364\n",
      "Operator 125: 0.527216170309064\n",
      "Operator 126: 1.0765883971800576\n",
      "Operator 127: 0.5683340134066438\n",
      "Operator 128: 0.11471584104539491\n",
      "Operator 129: 1.3322635958905815\n",
      "Operator 130: 0.007320046492660055\n",
      "Operator 131: 0.21093977998069854\n",
      "Operator 132: -0.4164698036923963\n",
      "Operator 133: -0.25706926808145475\n",
      "Operator 134: -0.840092883435325\n",
      "Operator 135: 0.5009749919585492\n",
      "Operator 136: -1.5898820016162414\n",
      "Operator 137: -0.4606120389752063\n",
      "Operator 138: 0.7880307315527839\n",
      "Operator 139: 0.09638993585888934\n",
      "Operator 140: -0.3650561158932821\n",
      "Operator 141: -0.4927819318779186\n",
      "Operator 142: 0.3236589833497593\n",
      "Operator 143: -0.5109286002135125\n",
      "Operator 144: -0.5184872274281257\n",
      "Operator 145: 0.2617485002358094\n",
      "Operator 146: 0.6138057941293936\n",
      "Operator 147: 0.4867233156183577\n",
      "Operator 148: 0.4741673475311076\n",
      "Operator 149: -0.2336582358888104\n",
      "Operator 150: 0.7894074609483033\n",
      "Operator 151: 0.39881083587043975\n",
      "Operator 152: 0.8842357668256993\n",
      "Operator 153: 0.5020228557784726\n",
      "Operator 154: 1.452100572970769\n",
      "Operator 155: -0.5300010297764386\n",
      "Operator 156: 0.17940599358896137\n",
      "Operator 157: -9.264969258460098e-08\n",
      "Operator 158: -0.7389348258449235\n",
      "Operator 159: -0.1263550212733063\n",
      "Operator 160: -0.5255211369673132\n",
      "Operator 161: -0.3330750156232082\n",
      "Operator 162: -0.43883358360469665\n",
      "Operator 163: 1.0554269850879943\n",
      "Operator 164: -0.2890112530761409\n",
      "Operator 165: -0.35567419039459325\n",
      "Operator 166: 1.1078484446166799\n",
      "Operator 167: 0.28448256637519775\n",
      "Operator 168: 1.2246105200067299\n",
      "Operator 169: 0.25419442957765204\n",
      "Operator 170: 0.304195881934875\n",
      "Operator 171: 0.558491082750377\n",
      "Operator 172: 0.7767959449389095\n",
      "Operator 173: 0.02895699286499085\n",
      "Operator 174: 0.7029124340895909\n",
      "Operator 175: 0.5282716715553797\n",
      "Operator 176: 0.6002745344545412\n",
      "Operator 177: -0.1827858450606895\n",
      "Operator 178: 0.3514733309038221\n",
      "Operator 179: 0.9021683060436928\n",
      "Operator 180: -0.9238592456655741\n",
      "Operator 181: -1.4162356230387239\n",
      "Operator 182: 0.9769335920683603\n",
      "Operator 183: -1.1638038129121524\n",
      "Operator 184: -1.36615066803749\n",
      "Operator 185: -1.2225914871003356e-08\n",
      "Operator 186: -1.2346893450061933\n",
      "Operator 187: 0.10615539687143315\n",
      "Operator 188: 0.2721979684265801\n",
      "Operator 189: -0.7605171839551275\n",
      "Operator 190: -0.08281077080202842\n",
      "Operator 191: 0.370615096094872\n",
      "Operator 192: 0.17830767441064882\n",
      "Operator 193: -0.3683912986767526\n",
      "Operator 194: -0.41357675397415594\n",
      "Operator 195: -0.17034600294355662\n",
      "Operator 196: -0.12801180171075083\n",
      "Operator 197: 0.7503090748849522\n",
      "Operator 198: -1.3555905741798508\n",
      "Operator 199: -0.8245141771535769\n",
      "Operator 200: 0.9205008712060165\n",
      "Operator 201: -1.483198330939876\n",
      "Operator 202: -0.5903686819131696\n",
      "Operator 203: 0.24383895044734388\n",
      "Operator 204: -0.40576233526863376\n",
      "Operator 205: 0.2845404280477846\n",
      "Operator 206: 0.4688461516615225\n",
      "Operator 207: -0.5992658654885464\n",
      "Operator 208: 0.6289872687028887\n",
      "Operator 209: 0.3682245841607554\n",
      "Operator 210: -0.7542500348981833\n",
      "Operator 211: 0.04368161834269246\n",
      "Operator 212: -0.3295584742646075\n",
      "Operator 213: 1.1689665888662617\n",
      "Operator 214: -0.768199136933372\n",
      "Operator 215: -1.368413778316938\n",
      "Operator 216: 0.7838265816152014\n",
      "Operator 217: -0.5702693055946095\n",
      "Operator 218: -1.5740302041854421\n",
      "Operator 219: 0.5407918127759023\n",
      "Operator 220: -0.7204281936219845\n",
      "Operator 221: 0.22811544409462559\n",
      "Operator 222: 0.21421350407522072\n",
      "Operator 223: -0.07006813008939076\n",
      "Operator 224: 1.421370644667665e-07\n",
      "Operator 225: 0.8263973308941595\n",
      "Operator 226: 0.1247541565239139\n",
      "Operator 227: -0.20865943959192634\n",
      "Operator 228: 0.4675232843182331\n",
      "Operator 229: -0.3149167398309119\n",
      "Operator 230: 0.21681534568312966\n",
      "Operator 231: -0.13004961467714354\n",
      "Operator 232: 0.7380399606986582\n",
      "Operator 233: -1.4190094385156837\n",
      "Operator 234: 0.6618469717925579\n",
      "Operator 235: -0.6509271161272437\n",
      "Operator 236: 1.3776896239159224\n",
      "Operator 237: -0.5572764119865219\n",
      "Operator 238: 0.3702117532401325\n",
      "Operator 239: -0.7026471840554466\n",
      "Operator 240: 0.25230254446392947\n",
      "Operator 241: -0.34991849664493135\n",
      "Operator 242: 0.3620913008753596\n",
      "Operator 243: -0.029209373647761636\n",
      "Operator 244: 0.7683795795510866\n",
      "Operator 245: -0.09145520629731166\n",
      "Operator 246: -0.006018479542871399\n",
      "Operator 247: 1.274235797708776\n",
      "Operator 248: -0.6645076786357541\n",
      "Operator 249: -1.259875197640135\n",
      "Operator 250: 1.3212052580416584\n",
      "Operator 251: -0.7208397169222033\n",
      "Operator 252: -1.1892497239645428\n",
      "Operator 253: -0.2779138677390451\n",
      "Operator 254: -1.2519353998087734\n",
      "Operator 255: -0.2381017042251693\n",
      "Operator 256: 0.2730954883490271\n",
      "Operator 257: -0.8592064563679973\n",
      "Operator 258: -0.2892457924466721\n",
      "Operator 259: -0.45894419701027384\n",
      "Operator 260: -0.12089793867467079\n",
      "Total gradient norm: 10.53786758556983\n",
      "Operators under consideration (1):\n",
      "[90]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.6133281097883514)]\n",
      "Operator(s) added to ansatz: [90]\n",
      "Gradients: [np.float64(-1.6133281097883514)]\n",
      "Initial energy: -32.487621520412134\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80, 90]...\n",
      "Starting point: [np.float64(0.4189945399299991), np.float64(0.529818744807291), np.float64(0.367488675326105), np.float64(-0.27247982923467956), np.float64(-0.2828072399281933), np.float64(-0.14458446829328095), np.float64(0.39604317953910056), np.float64(-0.16558505974841586), np.float64(0.6526923450315127), np.float64(0.3052790695077383), np.float64(-0.5019711387223144), np.float64(-0.33277086602081285), np.float64(-0.2830848456746696), np.float64(0.29074309520204883), np.float64(0.25434040644973005), np.float64(0.2601167401907478), np.float64(-0.15931543252312594), np.float64(0.18681407016646792), np.float64(-0.18148287004591748), np.float64(-0.15248866494744828), np.float64(0.14479419445973482), np.float64(0.09945365272531391), np.float64(-0.17427726160799153), np.float64(0.12232820939361654), np.float64(0.12124769005029454), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -32.628602\n",
      "         Iterations: 33\n",
      "         Function evaluations: 61\n",
      "         Gradient evaluations: 57\n",
      "\n",
      "Current energy: -32.62860158881879\n",
      "(change of -0.14098006840665533)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80, 90]\n",
      "On iteration 26.\n",
      "\n",
      "*** ADAPT-VQE Iteration 27 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.32771699517714714\n",
      "Operator 1: 1.0471588981000868e-07\n",
      "Operator 2: -0.12853033209854994\n",
      "Operator 3: 1.671628920310933\n",
      "Operator 4: -0.1012279238366676\n",
      "Operator 5: -1.7436319750604004e-08\n",
      "Operator 6: -0.7826194948995522\n",
      "Operator 7: 1.1002202816436313\n",
      "Operator 8: 0.214513043860174\n",
      "Operator 9: 1.0415025568411709\n",
      "Operator 10: -0.04142409795616159\n",
      "Operator 11: 0.5556802649459947\n",
      "Operator 12: -0.45519021428787715\n",
      "Operator 13: 0.6462076298151336\n",
      "Operator 14: -0.045010537977215076\n",
      "Operator 15: 0.5429097502410465\n",
      "Operator 16: 0.11710922671029594\n",
      "Operator 17: 0.20936867721317576\n",
      "Operator 18: -0.4689088658485494\n",
      "Operator 19: 0.29019924603688363\n",
      "Operator 20: -0.17404223953848968\n",
      "Operator 21: 0.8719911345331239\n",
      "Operator 22: -0.8410113906935441\n",
      "Operator 23: 0.13534480753874306\n",
      "Operator 24: -0.18853213869908175\n",
      "Operator 25: 0.15215034665683858\n",
      "Operator 26: -0.05461051619405037\n",
      "Operator 27: 0.03574627840875623\n",
      "Operator 28: 0.08558988538619336\n",
      "Operator 29: 0.09483624768422075\n",
      "Operator 30: -0.44265796875528723\n",
      "Operator 31: 0.12980972953773998\n",
      "Operator 32: -0.19751424678419205\n",
      "Operator 33: 0.22295238375434412\n",
      "Operator 34: -0.7665557594778667\n",
      "Operator 35: -0.046465052947133524\n",
      "Operator 36: -0.4229045356968442\n",
      "Operator 37: 0.3937689444374973\n",
      "Operator 38: 0.5871598469236919\n",
      "Operator 39: -0.1562686407594515\n",
      "Operator 40: 0.28965167443131723\n",
      "Operator 41: 1.2456598901803733\n",
      "Operator 42: 0.11632609932860219\n",
      "Operator 43: 0.22458917603927625\n",
      "Operator 44: 0.0891672309299554\n",
      "Operator 45: -0.07398153366704899\n",
      "Operator 46: -0.6474543192229492\n",
      "Operator 47: 0.16289207531080183\n",
      "Operator 48: -0.8625165928232024\n",
      "Operator 49: -0.5834040816511544\n",
      "Operator 50: -1.5041714781456297\n",
      "Operator 51: 0.8267176081677694\n",
      "Operator 52: -0.12193847730476588\n",
      "Operator 53: 0.5351812664685471\n",
      "Operator 54: -0.5494563389661007\n",
      "Operator 55: 0.5094677611113045\n",
      "Operator 56: 0.3142999546627109\n",
      "Operator 57: 0.38860235517849284\n",
      "Operator 58: 0.25276140009299997\n",
      "Operator 59: 0.5961316266696179\n",
      "Operator 60: 0.33519538777823177\n",
      "Operator 61: -0.6055832286921567\n",
      "Operator 62: 0.27978379910559903\n",
      "Operator 63: -0.5812090818177971\n",
      "Operator 64: -0.36586794179919196\n",
      "Operator 65: -0.24001136350752086\n",
      "Operator 66: -0.20733845660915246\n",
      "Operator 67: -0.9598745143235856\n",
      "Operator 68: -0.14777236017831016\n",
      "Operator 69: 0.17630620634240565\n",
      "Operator 70: 0.11134636315870042\n",
      "Operator 71: -0.611696193277596\n",
      "Operator 72: -0.37969884290884004\n",
      "Operator 73: 0.3719725536240619\n",
      "Operator 74: 0.11438633358577799\n",
      "Operator 75: 0.6305888012273562\n",
      "Operator 76: 0.41999172101163773\n",
      "Operator 77: 0.6092295763121305\n",
      "Operator 78: 0.45238960329782063\n",
      "Operator 79: 0.845854471683927\n",
      "Operator 80: 3.107720778666005e-07\n",
      "Operator 81: 1.1199231092302142\n",
      "Operator 82: 0.09928945840570594\n",
      "Operator 83: 1.4632656966158883\n",
      "Operator 84: 0.22554345619860777\n",
      "Operator 85: 0.2981460816710723\n",
      "Operator 86: -9.1146139493542e-08\n",
      "Operator 87: 0.968975655729993\n",
      "Operator 88: 9.028928114665839e-08\n",
      "Operator 89: 0.9637194226870851\n",
      "Operator 90: 1.4852472641877277e-08\n",
      "Operator 91: 0.09392151625134029\n",
      "Operator 92: -0.9225432654660575\n",
      "Operator 93: 0.7325019728145097\n",
      "Operator 94: -0.06457015401894461\n",
      "Operator 95: 0.8593007674052918\n",
      "Operator 96: -0.5637788611105122\n",
      "Operator 97: -0.01566713498233007\n",
      "Operator 98: -1.0000474818803191\n",
      "Operator 99: 0.2624798131754873\n",
      "Operator 100: -0.13496588278914814\n",
      "Operator 101: 1.0625456023284558e-07\n",
      "Operator 102: -0.17874228467046827\n",
      "Operator 103: -3.009493959593712e-07\n",
      "Operator 104: 0.7511161291865365\n",
      "Operator 105: 0.13468355819915656\n",
      "Operator 106: 0.30688217425992154\n",
      "Operator 107: -0.23950301033128407\n",
      "Operator 108: 0.4095462981350658\n",
      "Operator 109: 0.5671080437659912\n",
      "Operator 110: 0.3493920114143444\n",
      "Operator 111: 0.46570313521402107\n",
      "Operator 112: 0.6063918270385585\n",
      "Operator 113: 0.24824050314496024\n",
      "Operator 114: -0.5856318273001526\n",
      "Operator 115: 0.10770597704517981\n",
      "Operator 116: -0.6205660911531357\n",
      "Operator 117: 0.1838514685529839\n",
      "Operator 118: -0.1002632436958091\n",
      "Operator 119: -0.7363956001613973\n",
      "Operator 120: -0.8919129139184129\n",
      "Operator 121: 0.1483463011360072\n",
      "Operator 122: -0.15946092143012117\n",
      "Operator 123: -0.15165866239149145\n",
      "Operator 124: -0.1866276321658495\n",
      "Operator 125: 0.47684459910895827\n",
      "Operator 126: 0.4038022900201242\n",
      "Operator 127: -0.11146631792085325\n",
      "Operator 128: 0.18589243601511743\n",
      "Operator 129: 1.3531649796203786\n",
      "Operator 130: 0.013142517161588034\n",
      "Operator 131: 0.2072300137812718\n",
      "Operator 132: -0.4178569849225148\n",
      "Operator 133: -0.25683993449204917\n",
      "Operator 134: -0.8405950879438824\n",
      "Operator 135: 0.5006500339339893\n",
      "Operator 136: -1.5901469127016372\n",
      "Operator 137: -0.4606894416646302\n",
      "Operator 138: 0.788537008900738\n",
      "Operator 139: 0.09273779683835813\n",
      "Operator 140: -0.35507510075049514\n",
      "Operator 141: -0.5013792544251641\n",
      "Operator 142: 0.1847055915633033\n",
      "Operator 143: 0.1653617622774849\n",
      "Operator 144: 0.34425242916530274\n",
      "Operator 145: 0.48718328426207613\n",
      "Operator 146: 0.6505255927834628\n",
      "Operator 147: 0.49657587076049037\n",
      "Operator 148: 0.47772827549383967\n",
      "Operator 149: -0.2328809720553608\n",
      "Operator 150: 0.7909195000820033\n",
      "Operator 151: 0.398748545170042\n",
      "Operator 152: 0.8848162889088815\n",
      "Operator 153: 0.5020974332316777\n",
      "Operator 154: 1.4523819465946977\n",
      "Operator 155: -0.5308652028262212\n",
      "Operator 156: 0.17956134855145756\n",
      "Operator 157: -8.866108802685346e-08\n",
      "Operator 158: -0.7401366039881487\n",
      "Operator 159: -0.125300810037714\n",
      "Operator 160: -0.528652114187326\n",
      "Operator 161: -0.3109984851840837\n",
      "Operator 162: -0.4983958783848959\n",
      "Operator 163: 0.5189127287406421\n",
      "Operator 164: -0.3932437185164702\n",
      "Operator 165: 0.4015121338190726\n",
      "Operator 166: 1.1262916519674424\n",
      "Operator 167: 0.2847209520426752\n",
      "Operator 168: 1.2241151264821166\n",
      "Operator 169: 0.2542442824961151\n",
      "Operator 170: 0.30410421067839266\n",
      "Operator 171: 0.5585851923494347\n",
      "Operator 172: 0.7766466908145719\n",
      "Operator 173: 0.02901525233289948\n",
      "Operator 174: 0.7029089052654371\n",
      "Operator 175: 0.5291728770948284\n",
      "Operator 176: 0.6017624830400276\n",
      "Operator 177: -0.18572953814682872\n",
      "Operator 178: 0.3545967827787237\n",
      "Operator 179: 0.8324715238875191\n",
      "Operator 180: -0.8296733782331684\n",
      "Operator 181: -0.2817457834271394\n",
      "Operator 182: -0.10923386892952242\n",
      "Operator 183: -1.545694580999307\n",
      "Operator 184: -1.3631673328285818\n",
      "Operator 185: 7.388839205663991e-08\n",
      "Operator 186: -1.2322966995492117\n",
      "Operator 187: 0.10576995626238125\n",
      "Operator 188: 0.27245132369609565\n",
      "Operator 189: -0.7604992635541459\n",
      "Operator 190: -0.08263543992585892\n",
      "Operator 191: 0.37046723807654053\n",
      "Operator 192: 0.17837127090480445\n",
      "Operator 193: -0.370307826937994\n",
      "Operator 194: -0.41173334440456427\n",
      "Operator 195: -0.1749395160674725\n",
      "Operator 196: -0.12177489680013379\n",
      "Operator 197: 0.6702471593276979\n",
      "Operator 198: -1.3067501857655321\n",
      "Operator 199: 0.07261132836841017\n",
      "Operator 200: -0.2890797659431971\n",
      "Operator 201: -1.4171472396609124\n",
      "Operator 202: -0.5690451077646256\n",
      "Operator 203: 0.24617191449188836\n",
      "Operator 204: -0.4034499276444569\n",
      "Operator 205: 0.28400435274384817\n",
      "Operator 206: 0.468910532191099\n",
      "Operator 207: -0.599079171770285\n",
      "Operator 208: 0.6291451942588844\n",
      "Operator 209: 0.36808086544793134\n",
      "Operator 210: -0.7548683819828521\n",
      "Operator 211: 0.04303577156512002\n",
      "Operator 212: -0.33053615944601555\n",
      "Operator 213: 1.1672251280330737\n",
      "Operator 214: -1.1612048133958202\n",
      "Operator 215: -0.4674907378963762\n",
      "Operator 216: 0.06393058937772596\n",
      "Operator 217: -0.6319258002273829\n",
      "Operator 218: -1.4998833561890201\n",
      "Operator 219: 0.5353396680979947\n",
      "Operator 220: -0.7136689930388076\n",
      "Operator 221: 0.22863716569697037\n",
      "Operator 222: 0.21403452025304598\n",
      "Operator 223: -0.06962427358743314\n",
      "Operator 224: 1.0429231717759188e-07\n",
      "Operator 225: 0.8263702285139705\n",
      "Operator 226: 0.12473391541609363\n",
      "Operator 227: -0.20870673942703455\n",
      "Operator 228: 0.46751350178053797\n",
      "Operator 229: -0.31641959894690824\n",
      "Operator 230: 0.21630013539615411\n",
      "Operator 231: -0.15205175027988432\n",
      "Operator 232: 0.8486128416818197\n",
      "Operator 233: -0.8900591264021611\n",
      "Operator 234: 0.12210999542518464\n",
      "Operator 235: -0.7148170794204527\n",
      "Operator 236: 1.3986335723233525\n",
      "Operator 237: -0.563401393063337\n",
      "Operator 238: 0.3674928542483169\n",
      "Operator 239: -0.7020090816828759\n",
      "Operator 240: 0.2522233713502763\n",
      "Operator 241: -0.3499163498908896\n",
      "Operator 242: 0.36192033979010396\n",
      "Operator 243: -0.02905397388992627\n",
      "Operator 244: 0.7687195985456858\n",
      "Operator 245: -0.08988983634399579\n",
      "Operator 246: -0.0017755157734414522\n",
      "Operator 247: 1.2692698279483574\n",
      "Operator 248: -0.6660085366695143\n",
      "Operator 249: 0.1259075625683625\n",
      "Operator 250: 0.24972886994728738\n",
      "Operator 251: -1.1075803131203497\n",
      "Operator 252: -1.2447300835208768\n",
      "Operator 253: -0.288770830245858\n",
      "Operator 254: -1.2529601940353958\n",
      "Operator 255: -0.23876383066558082\n",
      "Operator 256: 0.2727285926396162\n",
      "Operator 257: -0.8591281598450444\n",
      "Operator 258: -0.28904961453893446\n",
      "Operator 259: -0.45913414230709837\n",
      "Operator 260: -0.12085897326560438\n",
      "Total gradient norm: 9.613475598433398\n",
      "Operators under consideration (1):\n",
      "[3]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(1.671628920310933)]\n",
      "Operator(s) added to ansatz: [3]\n",
      "Gradients: [np.float64(1.671628920310933)]\n",
      "Initial energy: -32.62860158881879\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80, 90, 3]...\n",
      "Starting point: [np.float64(0.41911322605734), np.float64(0.5298858359559419), np.float64(0.3678094081907906), np.float64(-0.17246272466659276), np.float64(-0.2802758812133141), np.float64(-0.14449758627078857), np.float64(0.3970869238589247), np.float64(-0.16534353366750115), np.float64(0.6527230895157901), np.float64(0.314548032903459), np.float64(-0.5020888829098533), np.float64(-0.3330939967094922), np.float64(-0.2902136870748929), np.float64(0.29226671102338364), np.float64(0.2579542684346828), np.float64(0.2602833901651608), np.float64(-0.15928513492010127), np.float64(0.18679097329064712), np.float64(-0.18147351330563521), np.float64(-0.1524875443594312), np.float64(0.14470279296246896), np.float64(0.09946991218419937), np.float64(-0.1738699189764695), np.float64(0.12273946693253705), np.float64(0.12125364232790688), np.float64(0.17166441940640934), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -32.780695\n",
      "         Iterations: 29\n",
      "         Function evaluations: 78\n",
      "         Gradient evaluations: 72\n",
      "\n",
      "Current energy: -32.78069512995788\n",
      "(change of -0.15209354113908802)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80, 90, 3]\n",
      "On iteration 27.\n",
      "\n",
      "*** ADAPT-VQE Iteration 28 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.32047225110467215\n",
      "Operator 1: -4.294612183514124e-07\n",
      "Operator 2: -0.19536057630308604\n",
      "Operator 3: -1.9211288929589234e-07\n",
      "Operator 4: -0.16684300526145454\n",
      "Operator 5: -1.0457666759227967e-07\n",
      "Operator 6: -0.7777193047726323\n",
      "Operator 7: 1.1002961162135332\n",
      "Operator 8: 0.21408009227077646\n",
      "Operator 9: 1.0419761700241077\n",
      "Operator 10: -0.04138000338362691\n",
      "Operator 11: 0.5556009672046567\n",
      "Operator 12: -0.4553255811128786\n",
      "Operator 13: 0.6466620531761381\n",
      "Operator 14: -0.04501839434350249\n",
      "Operator 15: 0.5430042731792406\n",
      "Operator 16: 0.11713771348115251\n",
      "Operator 17: 0.20852674946446204\n",
      "Operator 18: -0.4629524477639748\n",
      "Operator 19: 0.33367087286506114\n",
      "Operator 20: -0.2455716388350566\n",
      "Operator 21: 0.2588348905072876\n",
      "Operator 22: -0.21503242682849735\n",
      "Operator 23: 0.24561530048606367\n",
      "Operator 24: -0.18049765504389997\n",
      "Operator 25: 0.14607550285647378\n",
      "Operator 26: -0.05447073010161498\n",
      "Operator 27: 0.03565426791870623\n",
      "Operator 28: 0.0849883288019454\n",
      "Operator 29: 0.09499951154478001\n",
      "Operator 30: -0.44293869017054505\n",
      "Operator 31: 0.12990078130020521\n",
      "Operator 32: -0.19766117244508588\n",
      "Operator 33: 0.22303385817473734\n",
      "Operator 34: -0.7666083031150347\n",
      "Operator 35: -0.06127828011833988\n",
      "Operator 36: -0.29663143916825635\n",
      "Operator 37: -0.28222057737435535\n",
      "Operator 38: -0.23652886185612357\n",
      "Operator 39: -0.32102557838102863\n",
      "Operator 40: 0.2815270750315723\n",
      "Operator 41: 1.2239488281489554\n",
      "Operator 42: 0.12684357962368514\n",
      "Operator 43: 0.22404918988605313\n",
      "Operator 44: 0.09414297866150323\n",
      "Operator 45: -0.07449247844832772\n",
      "Operator 46: -0.6455872425076418\n",
      "Operator 47: 0.1629086263715635\n",
      "Operator 48: -0.8616683258116116\n",
      "Operator 49: -0.583326603106733\n",
      "Operator 50: -1.5037581683891825\n",
      "Operator 51: 0.8254925804731739\n",
      "Operator 52: -0.12983071750607245\n",
      "Operator 53: 0.4973317074976604\n",
      "Operator 54: 0.04852978507314287\n",
      "Operator 55: 0.445695488227641\n",
      "Operator 56: 0.06779383349053136\n",
      "Operator 57: 0.3245580646658861\n",
      "Operator 58: 0.25992117936359077\n",
      "Operator 59: 0.5921266301195948\n",
      "Operator 60: 0.33712923074257095\n",
      "Operator 61: -0.6051230045864323\n",
      "Operator 62: 0.28072529723585543\n",
      "Operator 63: -0.5815568970570404\n",
      "Operator 64: -0.36567869140264697\n",
      "Operator 65: -0.2397985157760473\n",
      "Operator 66: -0.20728165298924078\n",
      "Operator 67: -0.9600219306728011\n",
      "Operator 68: -0.13402031498376335\n",
      "Operator 69: 0.1845567880403126\n",
      "Operator 70: 0.2676645933403417\n",
      "Operator 71: 0.2124329022238107\n",
      "Operator 72: 0.3003718592832318\n",
      "Operator 73: 0.2440527866566448\n",
      "Operator 74: 0.13252958026554917\n",
      "Operator 75: 0.6316478633226152\n",
      "Operator 76: 0.42229640062122487\n",
      "Operator 77: 0.6066948153081811\n",
      "Operator 78: 0.452144259403823\n",
      "Operator 79: 0.844476993177576\n",
      "Operator 80: -1.3796011910034081e-06\n",
      "Operator 81: 1.1192189456819799\n",
      "Operator 82: 0.09899885306393541\n",
      "Operator 83: 1.4629166486861356\n",
      "Operator 84: 0.22546618777500305\n",
      "Operator 85: 0.3205224096995903\n",
      "Operator 86: -1.3024178271460463e-07\n",
      "Operator 87: 0.19414766636997338\n",
      "Operator 88: 1.7165738948864462e-07\n",
      "Operator 89: 0.1942150580840845\n",
      "Operator 90: -4.906958416925739e-07\n",
      "Operator 91: 0.11944006982997123\n",
      "Operator 92: -0.9178576709873613\n",
      "Operator 93: 0.7370855123181501\n",
      "Operator 94: -0.06461764894365671\n",
      "Operator 95: 0.8610926572868164\n",
      "Operator 96: -0.5637872503978149\n",
      "Operator 97: -0.0157881675743073\n",
      "Operator 98: -1.0001605411090484\n",
      "Operator 99: 0.2627805106603882\n",
      "Operator 100: -0.13497112139414846\n",
      "Operator 101: -2.260631622624965e-07\n",
      "Operator 102: -0.1785147202652686\n",
      "Operator 103: -1.4743258708316276e-07\n",
      "Operator 104: 0.7365846025583422\n",
      "Operator 105: 0.12951608838256246\n",
      "Operator 106: 0.45522543597249554\n",
      "Operator 107: 0.0887522573219951\n",
      "Operator 108: 0.435102331632803\n",
      "Operator 109: 0.058251197111511256\n",
      "Operator 110: 0.5288070076726354\n",
      "Operator 111: 0.47573111096374066\n",
      "Operator 112: 0.598383433662458\n",
      "Operator 113: 0.2512101870814386\n",
      "Operator 114: -0.5845625422630292\n",
      "Operator 115: 0.10899468270087727\n",
      "Operator 116: -0.6208219306334583\n",
      "Operator 117: 0.1839220094011789\n",
      "Operator 118: -0.10010703153340043\n",
      "Operator 119: -0.7360442321822073\n",
      "Operator 120: -0.8920408574639627\n",
      "Operator 121: 0.13401931094426925\n",
      "Operator 122: -0.18458447496541264\n",
      "Operator 123: -0.2675879470520611\n",
      "Operator 124: -0.21167683867027434\n",
      "Operator 125: -0.30236782928804556\n",
      "Operator 126: -0.2609650718173405\n",
      "Operator 127: -0.08596997465494435\n",
      "Operator 128: 0.21165975603640333\n",
      "Operator 129: 1.3473783566462594\n",
      "Operator 130: 0.020609806308756952\n",
      "Operator 131: 0.20910174182927324\n",
      "Operator 132: -0.41489494434083746\n",
      "Operator 133: -0.25717262140214636\n",
      "Operator 134: -0.8399059477509332\n",
      "Operator 135: 0.5012410285531987\n",
      "Operator 136: -1.589779252749991\n",
      "Operator 137: -0.4605891804122592\n",
      "Operator 138: 0.7665708653358104\n",
      "Operator 139: 0.061202048988533875\n",
      "Operator 140: 0.29779109595695913\n",
      "Operator 141: 0.28381515136888535\n",
      "Operator 142: 0.20941825192108102\n",
      "Operator 143: 0.28542311358911143\n",
      "Operator 144: 0.36765452940209725\n",
      "Operator 145: 0.5048054164060578\n",
      "Operator 146: 0.6445421121451431\n",
      "Operator 147: 0.4989814219572744\n",
      "Operator 148: 0.47439340385382633\n",
      "Operator 149: -0.23226559965094057\n",
      "Operator 150: 0.7890854032311162\n",
      "Operator 151: 0.3988785650704145\n",
      "Operator 152: 0.8840308224307215\n",
      "Operator 153: 0.501991342709146\n",
      "Operator 154: 1.4520054081699538\n",
      "Operator 155: -0.5261535067605424\n",
      "Operator 156: 0.1785133233853582\n",
      "Operator 157: 1.9632014439108225e-07\n",
      "Operator 158: -0.7366032970528344\n",
      "Operator 159: -0.12953138325390523\n",
      "Operator 160: -0.45488664240863924\n",
      "Operator 161: -0.08800176261164303\n",
      "Operator 162: -0.442215764572486\n",
      "Operator 163: -0.07727551797589882\n",
      "Operator 164: -0.3621610782005791\n",
      "Operator 165: 0.41699054161700977\n",
      "Operator 166: 1.125963611462496\n",
      "Operator 167: 0.28497942190772857\n",
      "Operator 168: 1.2236827992811232\n",
      "Operator 169: 0.25392272726332255\n",
      "Operator 170: 0.3042103500430064\n",
      "Operator 171: 0.5585347467755816\n",
      "Operator 172: 0.7767422724385777\n",
      "Operator 173: 0.02893965008446211\n",
      "Operator 174: 0.7029067335065472\n",
      "Operator 175: 0.5261564166818885\n",
      "Operator 176: 0.5988696949958698\n",
      "Operator 177: -0.16939194500675842\n",
      "Operator 178: 0.15316002140070548\n",
      "Operator 179: -0.09831376824098376\n",
      "Operator 180: 0.10512710728619139\n",
      "Operator 181: -0.07589818423805769\n",
      "Operator 182: -0.1303523348174105\n",
      "Operator 183: -1.5419613191146095\n",
      "Operator 184: -1.3682104210908033\n",
      "Operator 185: -7.603897729432057e-08\n",
      "Operator 186: -1.2345977766642793\n",
      "Operator 187: 0.10643926960306119\n",
      "Operator 188: 0.2721767718609729\n",
      "Operator 189: -0.7605314922795742\n",
      "Operator 190: -0.08284016313716694\n",
      "Operator 191: 0.37066269440659066\n",
      "Operator 192: 0.1782642952625629\n",
      "Operator 193: -0.36110602566382766\n",
      "Operator 194: -0.40394739859304285\n",
      "Operator 195: -0.12318339444996673\n",
      "Operator 196: -0.2593669352322433\n",
      "Operator 197: -0.1564465298219378\n",
      "Operator 198: -0.20632358771327167\n",
      "Operator 199: -0.20049648195093805\n",
      "Operator 200: -0.330034251717917\n",
      "Operator 201: -1.4003497253663622\n",
      "Operator 202: -0.5749913573484569\n",
      "Operator 203: 0.2468661321383693\n",
      "Operator 204: -0.40633453009047843\n",
      "Operator 205: 0.28491891809810294\n",
      "Operator 206: 0.4688608560740866\n",
      "Operator 207: -0.5993628863288959\n",
      "Operator 208: 0.6288713202781029\n",
      "Operator 209: 0.3682742087474267\n",
      "Operator 210: -0.7554522301295684\n",
      "Operator 211: 0.05837881647309823\n",
      "Operator 212: -0.28291583620926447\n",
      "Operator 213: -0.1867426651603583\n",
      "Operator 214: -0.17428102561949846\n",
      "Operator 215: -0.20967194072297593\n",
      "Operator 216: 0.04319327580057178\n",
      "Operator 217: -0.6353774841420198\n",
      "Operator 218: -1.487454330927764\n",
      "Operator 219: 0.530545470037374\n",
      "Operator 220: -0.7142796753668622\n",
      "Operator 221: 0.22726358349955744\n",
      "Operator 222: 0.21473480870538303\n",
      "Operator 223: -0.07018144334182505\n",
      "Operator 224: 1.019444067843455e-06\n",
      "Operator 225: 0.8264023658008934\n",
      "Operator 226: 0.12475158780386401\n",
      "Operator 227: -0.20852787096873993\n",
      "Operator 228: 0.46295482239192853\n",
      "Operator 229: -0.33362961456911727\n",
      "Operator 230: 0.24550325521397362\n",
      "Operator 231: -0.2598801728720203\n",
      "Operator 232: 0.21653035709508273\n",
      "Operator 233: -0.21965363547165798\n",
      "Operator 234: 0.14858924921603542\n",
      "Operator 235: -0.7351088170279786\n",
      "Operator 236: 1.3965465202306135\n",
      "Operator 237: -0.5684786264144284\n",
      "Operator 238: 0.36934301960103766\n",
      "Operator 239: -0.7036855535906988\n",
      "Operator 240: 0.25231198361529267\n",
      "Operator 241: -0.3499192046175248\n",
      "Operator 242: 0.36219239540910914\n",
      "Operator 243: -0.029298769135264503\n",
      "Operator 244: 0.7554285647761045\n",
      "Operator 245: -0.05830091465396102\n",
      "Operator 246: 0.2834123425061114\n",
      "Operator 247: 0.18432816318246012\n",
      "Operator 248: 0.1642801214250919\n",
      "Operator 249: 0.2673215819288831\n",
      "Operator 250: 0.18938143138383212\n",
      "Operator 251: -1.1049859923251788\n",
      "Operator 252: -1.2511160015493485\n",
      "Operator 253: -0.2871881139732526\n",
      "Operator 254: -1.2556004729006525\n",
      "Operator 255: -0.23791875520582556\n",
      "Operator 256: 0.2722534548881712\n",
      "Operator 257: -0.8591300748304651\n",
      "Operator 258: -0.28934773070774533\n",
      "Operator 259: -0.458860887663077\n",
      "Operator 260: -0.12090527274946565\n",
      "Total gradient norm: 8.638568263296554\n",
      "Operators under consideration (1):\n",
      "[136]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.589779252749991)]\n",
      "Operator(s) added to ansatz: [136]\n",
      "Gradients: [np.float64(-1.589779252749991)]\n",
      "Initial energy: -32.78069512995788\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80, 90, 3, 136]...\n",
      "Starting point: [np.float64(0.4189513892557905), np.float64(0.529792910965033), np.float64(0.3674193218365681), np.float64(-0.1708208866704886), np.float64(-0.1789357621971177), np.float64(-0.14505547650020695), np.float64(0.3962723467083204), np.float64(-0.17235081172716793), np.float64(0.6526818473821931), np.float64(0.3129444932688231), np.float64(-0.5015405083763016), np.float64(-0.3317432124621617), np.float64(-0.2972111547078968), np.float64(0.2993239180271731), np.float64(0.2592407140740486), np.float64(0.2606544526569747), np.float64(-0.1593542199519631), np.float64(0.18681638210627646), np.float64(-0.1814860319037225), np.float64(-0.15248987062480698), np.float64(0.1450551265510903), np.float64(0.09944112455905117), np.float64(-0.17233634115591656), np.float64(0.12256479282800216), np.float64(0.1212787349499057), np.float64(0.179199037770458), np.float64(-0.17930096294039488), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -32.866632\n",
      "         Iterations: 35\n",
      "         Function evaluations: 154\n",
      "         Gradient evaluations: 140\n",
      "\n",
      "Current energy: -32.86663174180196\n",
      "(change of -0.08593661184408319)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80, 90, 3, 136]\n",
      "On iteration 28.\n",
      "\n",
      "*** ADAPT-VQE Iteration 29 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.32051781142480607\n",
      "Operator 1: 3.531472687473558e-07\n",
      "Operator 2: -0.19555879617051236\n",
      "Operator 3: 1.5790472707104642e-07\n",
      "Operator 4: -0.16827625471307656\n",
      "Operator 5: 2.0875402034245482e-07\n",
      "Operator 6: -0.7706807854814068\n",
      "Operator 7: 1.1101025392623654\n",
      "Operator 8: 0.2211228207146835\n",
      "Operator 9: 1.0624989855309575\n",
      "Operator 10: -0.05576683966902059\n",
      "Operator 11: 0.5559683609163913\n",
      "Operator 12: -0.320834061944631\n",
      "Operator 13: 0.6835509535186521\n",
      "Operator 14: -0.07749687165827118\n",
      "Operator 15: 0.4444626754502996\n",
      "Operator 16: 0.047710801040518454\n",
      "Operator 17: 0.20852946199176614\n",
      "Operator 18: -0.46295881352164836\n",
      "Operator 19: 0.3337368127252731\n",
      "Operator 20: -0.24559489886753938\n",
      "Operator 21: 0.2590180396340484\n",
      "Operator 22: -0.21513905502249173\n",
      "Operator 23: 0.2466062499216365\n",
      "Operator 24: -0.1801681252981403\n",
      "Operator 25: 0.14487662935130927\n",
      "Operator 26: -0.056870610525838555\n",
      "Operator 27: 0.034435284817991754\n",
      "Operator 28: 0.08283328529773493\n",
      "Operator 29: 0.08942501422719033\n",
      "Operator 30: -0.3609441510439749\n",
      "Operator 31: 0.12848518116030286\n",
      "Operator 32: -0.31291719590462813\n",
      "Operator 33: 0.15828783442202116\n",
      "Operator 34: -0.7666588910670968\n",
      "Operator 35: -0.06113426856826551\n",
      "Operator 36: -0.29670728640304633\n",
      "Operator 37: -0.2816006653622966\n",
      "Operator 38: -0.2361662364027084\n",
      "Operator 39: -0.3174386711448931\n",
      "Operator 40: 0.271747606611713\n",
      "Operator 41: 1.2362485615075867\n",
      "Operator 42: 0.10769838949787974\n",
      "Operator 43: 0.2289209321114397\n",
      "Operator 44: 0.06084748436378806\n",
      "Operator 45: -0.020331357861617987\n",
      "Operator 46: -0.81688101205783\n",
      "Operator 47: 0.016255506173991817\n",
      "Operator 48: -0.9619217797245495\n",
      "Operator 49: -0.10803890624421536\n",
      "Operator 50: -0.239158885136551\n",
      "Operator 51: 0.8255316405218474\n",
      "Operator 52: -0.12981046249547126\n",
      "Operator 53: 0.49741799640786744\n",
      "Operator 54: 0.0485175160031929\n",
      "Operator 55: 0.44587127825587874\n",
      "Operator 56: 0.06816252724209546\n",
      "Operator 57: 0.32810563247203706\n",
      "Operator 58: 0.2532414150250343\n",
      "Operator 59: 0.6023279020822999\n",
      "Operator 60: 0.3235324770327543\n",
      "Operator 61: -0.6121005451175691\n",
      "Operator 62: 0.25237219426257823\n",
      "Operator 63: -0.505884083200754\n",
      "Operator 64: -0.5146514661656025\n",
      "Operator 65: -0.3427013883552733\n",
      "Operator 66: 0.0887154713985585\n",
      "Operator 67: -0.34878519059925717\n",
      "Operator 68: -0.13416643224411215\n",
      "Operator 69: 0.18471562651538814\n",
      "Operator 70: 0.26707251353333883\n",
      "Operator 71: 0.21302541914237347\n",
      "Operator 72: 0.2980607213608306\n",
      "Operator 73: 0.24780673538481393\n",
      "Operator 74: 0.1257115378583536\n",
      "Operator 75: 0.6493520510827634\n",
      "Operator 76: 0.41160215575580916\n",
      "Operator 77: 0.6460509772042183\n",
      "Operator 78: 0.44482808143964403\n",
      "Operator 79: 0.999232565345429\n",
      "Operator 80: -3.08774176753802e-08\n",
      "Operator 81: 1.3004709632784954\n",
      "Operator 82: -0.08581359436934405\n",
      "Operator 83: 0.14230053217814176\n",
      "Operator 84: -0.15316562506891862\n",
      "Operator 85: 0.3205676521815134\n",
      "Operator 86: 3.2461257489305173e-07\n",
      "Operator 87: 0.1943679634404645\n",
      "Operator 88: 4.524091394878091e-08\n",
      "Operator 89: 0.19521909984449123\n",
      "Operator 90: 2.651815291319131e-07\n",
      "Operator 91: 0.12008026227227092\n",
      "Operator 92: -0.9167982796144208\n",
      "Operator 93: 0.7342408628826429\n",
      "Operator 94: -0.06367776046291962\n",
      "Operator 95: 0.8320612779773182\n",
      "Operator 96: -0.5680789241520947\n",
      "Operator 97: 0.02833383295523406\n",
      "Operator 98: -0.9217267707587351\n",
      "Operator 99: 0.19147186976833125\n",
      "Operator 100: -0.2965772430800816\n",
      "Operator 101: -0.012526337209839308\n",
      "Operator 102: -0.17852355052107072\n",
      "Operator 103: -1.1372522279451402e-07\n",
      "Operator 104: 0.7366503674466975\n",
      "Operator 105: 0.1294609143177601\n",
      "Operator 106: 0.4553981650777555\n",
      "Operator 107: 0.08846281907503342\n",
      "Operator 108: 0.4357288171337531\n",
      "Operator 109: 0.05687795882556665\n",
      "Operator 110: 0.5313655774034257\n",
      "Operator 111: 0.4702898783386723\n",
      "Operator 112: 0.6088871123864035\n",
      "Operator 113: 0.2425192020123515\n",
      "Operator 114: -0.5868398129110087\n",
      "Operator 115: 0.09447038255053952\n",
      "Operator 116: -0.5697625386668925\n",
      "Operator 117: 0.0763275372552888\n",
      "Operator 118: -0.20129407234583513\n",
      "Operator 119: -0.6348384947839549\n",
      "Operator 120: -0.21674793333655412\n",
      "Operator 121: 0.13416546282662933\n",
      "Operator 122: -0.18474343775022867\n",
      "Operator 123: -0.26699724994222157\n",
      "Operator 124: -0.21228272626429792\n",
      "Operator 125: -0.30002331849992314\n",
      "Operator 126: -0.26438058324740366\n",
      "Operator 127: -0.07956836080927329\n",
      "Operator 128: 0.18851207855708435\n",
      "Operator 129: 1.368294603754587\n",
      "Operator 130: -0.032202213404091545\n",
      "Operator 131: 0.2285706233092765\n",
      "Operator 132: -0.553046100729949\n",
      "Operator 133: -0.1777531388369898\n",
      "Operator 134: -1.1630248988050877\n",
      "Operator 135: 0.37235986161741574\n",
      "Operator 136: -6.240602686460464e-07\n",
      "Operator 137: -0.048636295802266215\n",
      "Operator 138: 0.7666216345227548\n",
      "Operator 139: 0.061059293227967874\n",
      "Operator 140: 0.29784689091153405\n",
      "Operator 141: 0.2831674860882356\n",
      "Operator 142: 0.20948753160332806\n",
      "Operator 143: 0.28241103190254047\n",
      "Operator 144: 0.3697480008373905\n",
      "Operator 145: 0.5004526688479447\n",
      "Operator 146: 0.6556088032893748\n",
      "Operator 147: 0.5013140334319277\n",
      "Operator 148: 0.5296483958396768\n",
      "Operator 149: -0.2007367077510742\n",
      "Operator 150: 0.8824882460384043\n",
      "Operator 151: 0.23481530338998832\n",
      "Operator 152: 1.0419298928258354\n",
      "Operator 153: 0.09905409163584292\n",
      "Operator 154: 0.1571642824424248\n",
      "Operator 155: -0.5262010756345541\n",
      "Operator 156: 0.17852211393755013\n",
      "Operator 157: 4.650611640233393e-08\n",
      "Operator 158: -0.7366689695014128\n",
      "Operator 159: -0.12947617963805108\n",
      "Operator 160: -0.45506537756620996\n",
      "Operator 161: -0.0877248951646161\n",
      "Operator 162: -0.44272918611035156\n",
      "Operator 163: -0.07557358179586936\n",
      "Operator 164: -0.36655081144942553\n",
      "Operator 165: 0.42019777431288635\n",
      "Operator 166: 1.1228549465110735\n",
      "Operator 167: 0.27821941568205916\n",
      "Operator 168: 1.2144874288347747\n",
      "Operator 169: 0.30008311442572483\n",
      "Operator 170: 0.29962340172590485\n",
      "Operator 171: 0.5888802003345444\n",
      "Operator 172: 0.7401144392983875\n",
      "Operator 173: 0.013339215654158602\n",
      "Operator 174: 0.21904202413077764\n",
      "Operator 175: 0.5262040051007386\n",
      "Operator 176: 0.5989495365025357\n",
      "Operator 177: -0.16954182129988166\n",
      "Operator 178: 0.15342983119126874\n",
      "Operator 179: -0.09888946505746103\n",
      "Operator 180: 0.10581117350937849\n",
      "Operator 181: -0.0799470421007802\n",
      "Operator 182: -0.12253937581284503\n",
      "Operator 183: -1.5501171019871172\n",
      "Operator 184: -1.3559639651055748\n",
      "Operator 186: -1.2092064189250062\n",
      "Operator 187: -0.006042730777877186\n",
      "Operator 188: 0.29997163548342176\n",
      "Operator 189: -0.5550830619887349\n",
      "Operator 190: -0.08387621411505078\n",
      "Operator 191: 0.22372545597866628\n",
      "Operator 192: 0.1937124577720394\n",
      "Operator 193: -0.36121184365555425\n",
      "Operator 194: -0.4038703508943944\n",
      "Operator 195: -0.12346051705982122\n",
      "Operator 196: -0.2589784217675803\n",
      "Operator 197: -0.15744393532189627\n",
      "Operator 198: -0.20435482316581854\n",
      "Operator 199: -0.2050866133430892\n",
      "Operator 200: -0.31911867659247245\n",
      "Operator 201: -1.4109340188530302\n",
      "Operator 202: -0.551663841333724\n",
      "Operator 203: 0.23646427582019308\n",
      "Operator 204: -0.34067478757210234\n",
      "Operator 205: 0.2003076008923121\n",
      "Operator 206: 0.49806124251064815\n",
      "Operator 207: -0.36731267809074586\n",
      "Operator 208: 0.1353998986812095\n",
      "Operator 209: 0.2313243285808379\n",
      "Operator 210: -0.7554838920667378\n",
      "Operator 211: 0.05833676398639889\n",
      "Operator 212: -0.2829197220923227\n",
      "Operator 213: -0.18684563804517906\n",
      "Operator 214: -0.17401436510232945\n",
      "Operator 215: -0.21108598554366828\n",
      "Operator 216: 0.03974756102585544\n",
      "Operator 217: -0.6222554292744374\n",
      "Operator 218: -1.4983277701056612\n",
      "Operator 219: 0.5639531440421194\n",
      "Operator 220: -0.7064020241870123\n",
      "Operator 221: 0.2178774527201477\n",
      "Operator 222: 0.09898451195368076\n",
      "Operator 223: 0.16525594166304203\n",
      "Operator 224: 0.07390152670337388\n",
      "Operator 225: 0.5150135167485979\n",
      "Operator 226: 0.10970751281250268\n",
      "Operator 227: -0.20853061544653428\n",
      "Operator 228: 0.46296120326224355\n",
      "Operator 229: -0.33369574010096376\n",
      "Operator 230: 0.2455277227862793\n",
      "Operator 231: -0.260046361572106\n",
      "Operator 232: 0.21660755431121584\n",
      "Operator 233: -0.22100118183771753\n",
      "Operator 234: 0.1490221008432469\n",
      "Operator 235: -0.7300756138047544\n",
      "Operator 236: 1.3760053679918043\n",
      "Operator 237: -0.5613573151393545\n",
      "Operator 238: 0.3476073152695905\n",
      "Operator 239: -0.7154477667398496\n",
      "Operator 240: 0.24274158196175108\n",
      "Operator 241: -0.2573791445823131\n",
      "Operator 242: 0.6133402451449361\n",
      "Operator 243: -0.08339442632394421\n",
      "Operator 244: 0.7554604327055473\n",
      "Operator 245: -0.058258911309590794\n",
      "Operator 246: 0.28340612983558505\n",
      "Operator 247: 0.18447329934310283\n",
      "Operator 248: 0.1641718088896327\n",
      "Operator 249: 0.26783949033691884\n",
      "Operator 250: 0.19012626086123596\n",
      "Operator 251: -1.1021210959731969\n",
      "Operator 252: -1.245891244236079\n",
      "Operator 253: -0.2884823462601146\n",
      "Operator 254: -1.2396869133128678\n",
      "Operator 255: -0.299356315332964\n",
      "Operator 256: 0.20282091006418634\n",
      "Operator 257: -0.6966568263066258\n",
      "Operator 258: -0.2193074203246087\n",
      "Operator 259: -0.461905809051702\n",
      "Operator 260: -0.13565827124985266\n",
      "Total gradient norm: 7.934373416171516\n",
      "Operators under consideration (1):\n",
      "[183]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.5501171019871172)]\n",
      "Operator(s) added to ansatz: [183]\n",
      "Gradients: [np.float64(-1.5501171019871172)]\n",
      "Initial energy: -32.86663174180196\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80, 90, 3, 136, 183]...\n",
      "Starting point: [np.float64(0.44772813951841656), np.float64(0.5988606909414205), np.float64(0.37854167570578745), np.float64(-0.17060785712145027), np.float64(-0.17885954303337243), np.float64(-0.1450505200150729), np.float64(0.3995927896705844), np.float64(-0.1723310838447041), np.float64(0.6799812425681863), np.float64(0.31445852250551964), np.float64(-0.5015469244511898), np.float64(-0.3317605483745721), np.float64(-0.2974630084816323), np.float64(0.2993835377428154), np.float64(0.257373321505662), np.float64(0.25702905732361775), np.float64(-0.1499816202819622), np.float64(0.1621556640570982), np.float64(-0.17978515274352636), np.float64(-0.12850885191742822), np.float64(0.14505016011900326), np.float64(0.11257457475480442), np.float64(-0.1723166933550256), np.float64(0.12272428218083693), np.float64(0.1237390432654314), np.float64(0.17885523922536375), np.float64(-0.1792182900507845), np.float64(0.10614753953102293), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -32.950631\n",
      "         Iterations: 39\n",
      "         Function evaluations: 140\n",
      "         Gradient evaluations: 123\n",
      "\n",
      "Current energy: -32.95063102081166\n",
      "(change of -0.08399927900970283)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80, 90, 3, 136, 183]\n",
      "On iteration 29.\n",
      "\n",
      "*** ADAPT-VQE Iteration 30 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: -0.3217527841922354\n",
      "Operator 1: 1.263988336740185e-08\n",
      "Operator 2: -0.20322518554978886\n",
      "Operator 3: 7.62489267536005e-08\n",
      "Operator 4: -0.16282456610319382\n",
      "Operator 5: 0.22564584484680555\n",
      "Operator 6: 0.02965861618207158\n",
      "Operator 7: 1.1080211648843428\n",
      "Operator 8: 0.23364220917347645\n",
      "Operator 9: 1.0454117851225466\n",
      "Operator 10: -0.05332492804239399\n",
      "Operator 11: 0.5566844940149238\n",
      "Operator 12: -0.31883523778455514\n",
      "Operator 13: 0.6748659444033491\n",
      "Operator 14: -0.07692890882225561\n",
      "Operator 15: 0.4419144465782189\n",
      "Operator 16: 0.046696410158929655\n",
      "Operator 17: 0.20860359920523752\n",
      "Operator 18: -0.4631284546727349\n",
      "Operator 19: 0.3357490136532435\n",
      "Operator 20: -0.2463520116644623\n",
      "Operator 21: 0.260031488616402\n",
      "Operator 22: -0.20631245382683555\n",
      "Operator 23: 0.322008020322999\n",
      "Operator 24: -0.38168439127813636\n",
      "Operator 25: 0.1744332498413465\n",
      "Operator 26: 0.021457906339943343\n",
      "Operator 27: 0.04461840437959469\n",
      "Operator 28: 0.09764453239391696\n",
      "Operator 29: 0.0852782584744372\n",
      "Operator 30: -0.355963492447955\n",
      "Operator 31: 0.1276782073624105\n",
      "Operator 32: -0.30938516897772295\n",
      "Operator 33: 0.15695603759998036\n",
      "Operator 34: -0.7681851014558239\n",
      "Operator 35: -0.05711450945088097\n",
      "Operator 36: -0.29697466955547047\n",
      "Operator 37: -0.2611777056626791\n",
      "Operator 38: -0.27393235533364035\n",
      "Operator 39: -0.13599153319673113\n",
      "Operator 40: -0.3141277999028169\n",
      "Operator 41: 0.24491149501046\n",
      "Operator 42: -0.05624062041769681\n",
      "Operator 43: 0.11582000381415049\n",
      "Operator 44: -0.03371198698786711\n",
      "Operator 45: -0.021720314330018576\n",
      "Operator 46: -0.854896319861739\n",
      "Operator 47: 0.013426529350608243\n",
      "Operator 48: -0.9782466382027146\n",
      "Operator 49: -0.10754673746286147\n",
      "Operator 50: -0.2393363711222715\n",
      "Operator 51: 0.8266928971803604\n",
      "Operator 52: -0.12929061542451792\n",
      "Operator 53: 0.49938887048835157\n",
      "Operator 54: 0.05018279369024445\n",
      "Operator 55: 0.46307606034604853\n",
      "Operator 56: -0.011129015953433928\n",
      "Operator 57: 0.5348347381715934\n",
      "Operator 58: 0.1607798210208665\n",
      "Operator 59: -0.5180351633572652\n",
      "Operator 60: 0.28601421319828424\n",
      "Operator 61: -0.6416689579721859\n",
      "Operator 62: 0.2338397257205791\n",
      "Operator 63: -0.4999334731626074\n",
      "Operator 64: -0.5173207778857083\n",
      "Operator 65: -0.3462236523380578\n",
      "Operator 66: 0.0883426151468824\n",
      "Operator 67: -0.345179003831613\n",
      "Operator 68: -0.13838900029903894\n",
      "Operator 69: 0.1892809545647732\n",
      "Operator 70: 0.2500891595951653\n",
      "Operator 71: 0.2304846404491272\n",
      "Operator 72: 0.2216345647964948\n",
      "Operator 73: 0.27268372045000944\n",
      "Operator 74: 0.024544850246160103\n",
      "Operator 75: 0.5029061700233242\n",
      "Operator 76: 0.5203610153460213\n",
      "Operator 77: 0.6668956908998538\n",
      "Operator 78: 0.4611280348576094\n",
      "Operator 79: 1.0261476157090597\n",
      "Operator 80: 4.2714524209312386e-08\n",
      "Operator 81: 1.3130042829638147\n",
      "Operator 82: -0.08079674033908363\n",
      "Operator 83: 0.14207030441767596\n",
      "Operator 84: -0.1540454824238588\n",
      "Operator 85: 0.3219854206825652\n",
      "Operator 87: 0.19753829643394497\n",
      "Operator 89: 0.3107627473382415\n",
      "Operator 90: -2.4002090385510503e-08\n",
      "Operator 91: 0.10069854387056876\n",
      "Operator 92: -0.2539436493095023\n",
      "Operator 93: 0.6916413802807395\n",
      "Operator 94: -0.05637089716878639\n",
      "Operator 95: 0.8049267479346938\n",
      "Operator 96: -0.5675505589739067\n",
      "Operator 97: 0.030280945997885493\n",
      "Operator 98: -0.9169927839915506\n",
      "Operator 99: 0.18706017988251766\n",
      "Operator 100: -0.2951029939251474\n",
      "Operator 101: -0.011803863400171095\n",
      "Operator 102: -0.17877840863638106\n",
      "Operator 103: 8.834409981339775e-08\n",
      "Operator 104: 0.7385123602227077\n",
      "Operator 105: 0.12783648021342878\n",
      "Operator 106: 0.4612456509278412\n",
      "Operator 107: 0.08211880555066489\n",
      "Operator 108: 0.4341832795784729\n",
      "Operator 109: -0.038978939347399204\n",
      "Operator 110: 0.5398040969253276\n",
      "Operator 111: 0.47745844254606995\n",
      "Operator 112: -0.36661627128967694\n",
      "Operator 113: 0.2401537364683116\n",
      "Operator 114: -0.6075027822188999\n",
      "Operator 115: 0.07047113490615753\n",
      "Operator 116: -0.5636475014187579\n",
      "Operator 117: 0.07557355868267461\n",
      "Operator 118: -0.20356339085704836\n",
      "Operator 119: -0.6398173290490424\n",
      "Operator 120: -0.21341160178380217\n",
      "Operator 121: 0.13838438527510394\n",
      "Operator 122: -0.18940919550626586\n",
      "Operator 123: -0.24973360625029373\n",
      "Operator 124: -0.22700727352613967\n",
      "Operator 125: -0.23119201608907025\n",
      "Operator 126: -0.40182463009001057\n",
      "Operator 127: -0.04117225046717572\n",
      "Operator 128: -0.36911019692650815\n",
      "Operator 129: 0.3662001885520854\n",
      "Operator 130: -0.11439984871023777\n",
      "Operator 131: 0.17147157284380612\n",
      "Operator 132: -0.6010792899435229\n",
      "Operator 133: -0.17296209933927414\n",
      "Operator 134: -1.1768572402133501\n",
      "Operator 135: 0.3605365385843374\n",
      "Operator 136: -6.222166540961368e-07\n",
      "Operator 137: -0.048367957086229735\n",
      "Operator 138: 0.7680115790885969\n",
      "Operator 139: 0.0567620520856816\n",
      "Operator 140: 0.30240197568054017\n",
      "Operator 141: 0.26871019451355427\n",
      "Operator 142: 0.13041909217037045\n",
      "Operator 143: 0.08023292582226144\n",
      "Operator 144: 0.36792143966041735\n",
      "Operator 145: 0.5593448837738538\n",
      "Operator 146: 0.628801872499386\n",
      "Operator 147: 0.5520235656689176\n",
      "Operator 148: 0.5993196418286004\n",
      "Operator 149: -0.1999643970454032\n",
      "Operator 150: 0.9193356598983191\n",
      "Operator 151: 0.23331356734616748\n",
      "Operator 152: 1.056721624279633\n",
      "Operator 153: 0.09857880691766235\n",
      "Operator 154: 0.1568576697357193\n",
      "Operator 155: -0.5275707089400207\n",
      "Operator 156: 0.17877191405370318\n",
      "Operator 157: 3.575225102081525e-08\n",
      "Operator 158: -0.7385990244961134\n",
      "Operator 159: -0.12790733788843\n",
      "Operator 160: -0.45966001775256515\n",
      "Operator 161: -0.07860253747943971\n",
      "Operator 162: -0.47144641374245605\n",
      "Operator 163: -0.06305052169466346\n",
      "Operator 164: -0.5598268797687479\n",
      "Operator 165: -0.4069414499381902\n",
      "Operator 166: 1.2126830237300634\n",
      "Operator 167: 0.26972320637070757\n",
      "Operator 168: 1.2108539153481876\n",
      "Operator 169: 0.30284506997003713\n",
      "Operator 170: 0.2955777457056397\n",
      "Operator 171: 0.5893311386946958\n",
      "Operator 172: 0.7373225963170229\n",
      "Operator 173: 0.014428344657261609\n",
      "Operator 174: 0.21674244967193596\n",
      "Operator 175: 0.5275841844875493\n",
      "Operator 176: 0.6013041075284128\n",
      "Operator 177: -0.17367877228123182\n",
      "Operator 178: 0.15978963860547327\n",
      "Operator 179: -0.12000966646000984\n",
      "Operator 180: 0.1645957978267012\n",
      "Operator 181: -0.07203606447115424\n",
      "Operator 182: 0.06630614834418912\n",
      "Operator 184: -1.2593328237997996\n",
      "Operator 185: 0.04966942196482084\n",
      "Operator 186: -1.1621509789828106\n",
      "Operator 187: -0.015565976736784032\n",
      "Operator 188: 0.3072917384504547\n",
      "Operator 189: -0.5531313334500093\n",
      "Operator 190: -0.08081489565696778\n",
      "Operator 191: 0.22115231411445824\n",
      "Operator 192: 0.19520219885671927\n",
      "Operator 193: -0.3642743754361346\n",
      "Operator 194: -0.40161586821787276\n",
      "Operator 195: -0.13133074124420996\n",
      "Operator 196: -0.24928649542308823\n",
      "Operator 197: -0.1916653755197253\n",
      "Operator 198: -0.11760667126004241\n",
      "Operator 199: -0.17138675885777757\n",
      "Operator 200: -0.21966248723858972\n",
      "Operator 201: -0.2280213677373492\n",
      "Operator 202: -0.4538763299752212\n",
      "Operator 203: 0.23867526573987302\n",
      "Operator 204: -0.2849319806265531\n",
      "Operator 205: 0.18476750574151057\n",
      "Operator 206: 0.4990021724699404\n",
      "Operator 207: -0.36229595118439106\n",
      "Operator 208: 0.13840169178382383\n",
      "Operator 209: 0.22882757896072065\n",
      "Operator 210: -0.756443221090156\n",
      "Operator 211: 0.057250032700984554\n",
      "Operator 212: -0.2822057218185019\n",
      "Operator 213: -0.1942247692912415\n",
      "Operator 214: -0.18444028667750736\n",
      "Operator 215: -0.04623097184154275\n",
      "Operator 216: -0.38722046911770214\n",
      "Operator 217: 0.40423663496709983\n",
      "Operator 218: -0.7685093761058388\n",
      "Operator 219: 0.5526281725161064\n",
      "Operator 220: -0.6177555012518713\n",
      "Operator 221: 0.23648877606432006\n",
      "Operator 222: 0.09044324932252709\n",
      "Operator 223: 0.17373962711610194\n",
      "Operator 224: 0.07427414121594397\n",
      "Operator 225: 0.5157077467889716\n",
      "Operator 226: 0.10943944441040432\n",
      "Operator 227: -0.20860882344706955\n",
      "Operator 228: 0.4631394228525401\n",
      "Operator 229: -0.3355560438317122\n",
      "Operator 230: 0.24603898762070364\n",
      "Operator 231: -0.26509460661205103\n",
      "Operator 232: 0.21429868010738296\n",
      "Operator 233: -0.21326489688122774\n",
      "Operator 234: 0.2845414254437253\n",
      "Operator 235: -0.19799476964304158\n",
      "Operator 236: 0.5824953768840437\n",
      "Operator 237: -0.5123905227585606\n",
      "Operator 238: 0.30410543679510144\n",
      "Operator 239: -0.6908757877832472\n",
      "Operator 240: 0.24031852046038155\n",
      "Operator 241: -0.2569844351907\n",
      "Operator 242: 0.6066938690013007\n",
      "Operator 243: -0.07965858074723446\n",
      "Operator 244: 0.7563336289084606\n",
      "Operator 245: -0.05688767866811924\n",
      "Operator 246: 0.28452556363949516\n",
      "Operator 247: 0.1828402417094896\n",
      "Operator 248: 0.13141722985903787\n",
      "Operator 249: 0.45021725384250455\n",
      "Operator 250: 0.30233354476616414\n",
      "Operator 251: -0.16690812280858558\n",
      "Operator 252: -1.1633345326348172\n",
      "Operator 253: -0.2445174877212536\n",
      "Operator 254: -1.2040926613400615\n",
      "Operator 255: -0.31193802756111044\n",
      "Operator 256: 0.20666313553915538\n",
      "Operator 257: -0.6949643007925297\n",
      "Operator 258: -0.214600844965336\n",
      "Operator 259: -0.4652696839453335\n",
      "Operator 260: -0.13501977972870102\n",
      "Total gradient norm: 6.992827766431862\n",
      "Operators under consideration (1):\n",
      "[81]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(1.3130042829638147)]\n",
      "Operator(s) added to ansatz: [81]\n",
      "Gradients: [np.float64(1.3130042829638147)]\n",
      "Initial energy: -32.95063102081166\n",
      "Optimizing energy with indices [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80, 90, 3, 136, 183, 81]...\n",
      "Starting point: [np.float64(0.4510316133796156), np.float64(0.6005375100932389), np.float64(0.38618916174529916), np.float64(-0.14550197654825733), np.float64(-0.17583143656276207), np.float64(-0.1449079161057591), np.float64(0.41806661562808656), np.float64(-0.17178846823427577), np.float64(0.6807655252812042), np.float64(0.3814364137172754), np.float64(-0.5017326989322503), np.float64(-0.332261941448724), np.float64(-0.3041068154646971), np.float64(0.3011143512512571), np.float64(0.25775017751245966), np.float64(0.25429899314467275), np.float64(-0.1490831215698709), np.float64(0.16173363936289675), np.float64(-0.17963966229023853), np.float64(-0.12839831158160714), np.float64(0.14490628902640768), np.float64(0.1130059958427109), np.float64(-0.1717213386366086), np.float64(0.12941475048071552), np.float64(0.12335601598253461), np.float64(0.18739675196753952), np.float64(-0.1775448144274594), np.float64(0.10644527757476581), np.float64(0.1082163663646102), np.float64(0.0)]\n",
      "         Current function value: -33.021499\n",
      "         Iterations: 36\n",
      "         Function evaluations: 111\n",
      "         Gradient evaluations: 99\n",
      "\n",
      "Current energy: -33.02149870901131\n",
      "(change of -0.07086768819964817)\n",
      "Current ansatz: [241, 243, 239, 234, 232, 228, 237, 230, 16, 235, 156, 122, 23, 2, 76, 78, 133, 82, 137, 192, 157, 224, 1, 185, 80, 90, 3, 136, 183, 81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2551: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2566: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    }
   ],
   "source": [
    "# Now go to the larger size.\n",
    "new_l = 5 * l\n",
    "print(f\"new_l = {new_l}\")\n",
    "j_xy = 1\n",
    "j_z = 1\n",
    "h = XXZHamiltonian(\n",
    "    j_xy, j_z, new_l,\n",
    "    store_ref_vector=False,\n",
    "    diag_mode=\"quimb\", max_mpo_bond=max_mpo_bond, max_mps_bond=dmrg_mps_bond\n",
    ")\n",
    "dmrg_energy = h.ground_energy\n",
    "exact_energy = h.ground_energy\n",
    "print(f\"Got DMRG energy {dmrg_energy:4.5e}\")\n",
    "\n",
    "h_of = h.operator\n",
    "h_cirq = of.transforms.qubit_operator_to_pauli_sum(h_of)\n",
    "h_qiskit = cirq_pauli_sum_to_qiskit_pauli_op(h_cirq)\n",
    "\n",
    "tiled_pool = TiledPauliPool(n=new_l, source_ops=source_ops)\n",
    "num_ops = len(tiled_pool.operators)\n",
    "print(f\"Tiled pool has {num_ops} operators.\")\n",
    "\n",
    "tn_adapt = TensorNetAdapt(\n",
    "    pool=tiled_pool,\n",
    "    custom_hamiltonian=h,\n",
    "    verbose=True,\n",
    "    threshold=10**-5,\n",
    "    max_adapt_iter=30,\n",
    "    max_opt_iter=10000,\n",
    "    sel_criterion=\"gradient\",\n",
    "    recycle_hessian=False,\n",
    "    rand_degenerate=True,\n",
    "    max_mpo_bond=max_mpo_bond,\n",
    "    max_mps_bond=adapt_mps_bond\n",
    ")\n",
    "tn_adapt.initialize()\n",
    "nq = tn_adapt.n\n",
    "\n",
    "circuits = []\n",
    "adapt_energies = []\n",
    "for i in range(30):\n",
    "    print(f\"On iteration {i}.\")\n",
    "    tn_adapt.run_iteration()\n",
    "    data = tn_adapt.data\n",
    "    circuit = data.get_circuit(\n",
    "        tiled_pool, indices=tn_adapt.indices, coefficients=tn_adapt.coefficients,\n",
    "        include_ref=True\n",
    "    )\n",
    "    circuit.measure_all()\n",
    "    circuits.append(circuit)\n",
    "    adapt_energies.append(tn_adapt.energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cc70396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "16\n",
      "23\n",
      "30\n",
      "37\n",
      "44\n",
      "51\n",
      "58\n",
      "63\n",
      "70\n",
      "75\n",
      "82\n",
      "89\n",
      "94\n",
      "101\n",
      "108\n",
      "115\n",
      "122\n",
      "129\n",
      "136\n",
      "141\n",
      "148\n",
      "153\n",
      "160\n",
      "167\n",
      "172\n",
      "177\n",
      "184\n",
      "191\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "for circuit in circuits:\n",
    "    print(circuit.depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "572ff26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Energy error')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adapt_errors = abs(np.array(adapt_energies) - exact_energy)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(adapt_errors)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68f30093",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_errors = np.abs(np.array(adapt_energies) - exact_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020ff13",
   "metadata": {},
   "source": [
    "## Get circuit expectation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c6c2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_model = NoiseModel.from_backend(backend)\n",
    "simulator_energies = []\n",
    "for circuit in circuits:\n",
    "    sim = AerSimulator(method=\"matrix_product_state\", noise_model=noise_model, matrix_product_state_max_bond_dimension=adapt_mps_bond)\n",
    "    estimator = BackendEstimator(backend=sim)\n",
    "    # The circuit needs to be transpiled to the AerSimulator target\n",
    "    pass_manager = generate_preset_pass_manager(3, sim)\n",
    "    isa_circuit = pass_manager.run(circuit)\n",
    "    isa_circuit = RemoveFinalMeasurements()(isa_circuit)\n",
    "    pub = (isa_circuit, h_qiskit)\n",
    "    job = estimator.run([pub])\n",
    "    result = job.result()\n",
    "    pub_result = result[0]\n",
    "    exact_value = float(pub_result.data.evs)\n",
    "    simulator_energies.append(exact_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1c3064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simualtor_errors = np.abs(np.array(simulator_energies) - exact_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a265c33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Energy error')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(adapt_errors, label=\"ADAPT\")\n",
    "ax.plot(simualtor_errors, label=\"Simulator\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965f4a6",
   "metadata": {},
   "source": [
    "## Carry out SQD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0a71f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# spin_a_layout = list(range(0, 12))\n",
    "# spin_b_layout = [12, 13, 14, 15, 19, 35, 34, 33, 32, 31, 30, 29]\n",
    "# initial_layout = spin_a_layout + spin_b_layout\n",
    "initial_layout = range(nq)\n",
    "\n",
    "# sim = AerSimulator.from_backend(computer, method=\"matrix_product_state\")\n",
    "sim = AerSimulator(method=\"matrix_product_state\", noise_model=noise_model, matrix_product_state_max_bond_dimension=4 * adapt_mps_bond)\n",
    "\n",
    "pass_manager = generate_preset_pass_manager(\n",
    "    optimization_level=3, backend=sim, initial_layout=initial_layout[:nq]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9b18ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_per_circuit = 1_000\n",
    "num_shots = len(circuits) * shots_per_circuit\n",
    "sampler = Sampler(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbb1145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On circuit 0/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'measure': 20, 'rz': 16, 'sx': 14, 'x': 10, 'cz': 6, 'barrier': 2})\n",
      "On circuit 1/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 32, 'sx': 28, 'measure': 20, 'cz': 12, 'x': 11, 'barrier': 3})\n",
      "On circuit 2/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 48, 'sx': 42, 'measure': 20, 'cz': 18, 'x': 12, 'barrier': 4})\n",
      "On circuit 3/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 64, 'sx': 56, 'cz': 24, 'measure': 20, 'x': 13, 'barrier': 5})\n",
      "On circuit 4/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 80, 'sx': 70, 'cz': 30, 'measure': 20, 'x': 14, 'barrier': 6})\n",
      "On circuit 5/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 96, 'sx': 84, 'cz': 36, 'measure': 20, 'x': 15, 'barrier': 7})\n",
      "On circuit 6/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 112, 'sx': 98, 'cz': 42, 'measure': 20, 'x': 16, 'barrier': 8})\n",
      "On circuit 7/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 128, 'sx': 112, 'cz': 48, 'measure': 20, 'x': 17, 'barrier': 9})\n",
      "On circuit 8/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 135, 'sx': 116, 'cz': 50, 'measure': 20, 'x': 18, 'barrier': 10})\n",
      "On circuit 9/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 151, 'sx': 130, 'cz': 56, 'measure': 20, 'x': 19, 'barrier': 11})\n",
      "On circuit 10/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 160, 'sx': 138, 'cz': 58, 'x': 22, 'measure': 20, 'barrier': 12})\n",
      "On circuit 11/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 170, 'sx': 146, 'cz': 62, 'x': 23, 'measure': 20, 'barrier': 13})\n",
      "On circuit 12/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 181, 'sx': 156, 'cz': 68, 'x': 24, 'measure': 20, 'barrier': 14})\n",
      "On circuit 13/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 190, 'sx': 160, 'cz': 70, 'x': 23, 'measure': 20, 'barrier': 15})\n",
      "On circuit 14/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 195, 'sx': 164, 'cz': 74, 'x': 32, 'measure': 20, 'barrier': 16})\n",
      "On circuit 15/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 204, 'sx': 168, 'cz': 78, 'x': 35, 'measure': 20, 'barrier': 17})\n",
      "On circuit 16/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 213, 'sx': 174, 'cz': 82, 'x': 34, 'measure': 20, 'barrier': 18})\n",
      "On circuit 17/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 222, 'sx': 182, 'cz': 86, 'x': 27, 'measure': 20, 'barrier': 19})\n",
      "On circuit 18/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 230, 'sx': 190, 'cz': 90, 'x': 32, 'barrier': 20, 'measure': 20})\n",
      "On circuit 19/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 241, 'sx': 198, 'cz': 94, 'x': 41, 'barrier': 21, 'measure': 20})\n",
      "On circuit 20/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 249, 'sx': 208, 'cz': 96, 'x': 36, 'barrier': 22, 'measure': 20})\n",
      "On circuit 21/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 259, 'sx': 214, 'cz': 100, 'x': 40, 'barrier': 23, 'measure': 20})\n",
      "On circuit 22/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 267, 'sx': 222, 'cz': 102, 'x': 35, 'barrier': 24, 'measure': 20})\n",
      "On circuit 23/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 278, 'sx': 226, 'cz': 106, 'x': 48, 'barrier': 25, 'measure': 20})\n",
      "On circuit 24/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 285, 'sx': 234, 'cz': 110, 'x': 43, 'barrier': 26, 'measure': 20})\n",
      "On circuit 25/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 292, 'sx': 242, 'cz': 112, 'x': 46, 'barrier': 27, 'measure': 20})\n",
      "On circuit 26/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 301, 'sx': 246, 'cz': 114, 'x': 49, 'barrier': 28, 'measure': 20})\n",
      "On circuit 27/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 312, 'sx': 256, 'cz': 118, 'x': 48, 'barrier': 29, 'measure': 20})\n",
      "On circuit 28/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 323, 'sx': 264, 'cz': 122, 'x': 45, 'barrier': 30, 'measure': 20})\n",
      "On circuit 29/30\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 330, 'sx': 268, 'cz': 126, 'x': 52, 'barrier': 31, 'measure': 20})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bit_arrays = []\n",
    "counts_list = []\n",
    "for i, circuit in enumerate(circuits):\n",
    "    print(f\"On circuit {i}/{len(circuits)}\")\n",
    "    pass_manager.pre_init = ffsim.qiskit.PRE_INIT\n",
    "    to_run = pass_manager.run(circuit)\n",
    "    print(f\"Gate counts (w/ pre-init passes): {to_run.count_ops()}\")\n",
    "    # job = sim.run(to_run)\n",
    "    # counts = job.result().data()['counts']\n",
    "    # bit_array = BitArray.from_counts(counts, num_bits=circuit.num_qubits)\n",
    "    # counts1 = bit_array.get_counts()\n",
    "    job = sampler.run((circuit,), shots=num_shots)\n",
    "    data = job.result()[0].data\n",
    "    bit_array = data['meas']\n",
    "    counts1 = bit_array.get_counts()\n",
    "    counts_list.append(counts1)\n",
    "    bit_arrays.append(deepcopy(bit_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77f6310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = []\n",
    "errors = []\n",
    "\n",
    "for bit_array in bit_arrays[1:]:\n",
    "    bit_matrix = bit_array.to_bool_array()\n",
    "    eigvals, eigvecs = solve_qubit(bit_matrix, h_qiskit, k=1)\n",
    "    min_energy = np.min(eigvals)\n",
    "    err = abs(min_energy - exact_energy)\n",
    "    energies.append(min_energy)\n",
    "    errors.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8500129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Energy error')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(errors)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01421e02",
   "metadata": {},
   "source": [
    "## Concatenate mulitple rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bc992e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_combine_bit_arrays(bit_arrays: List[BitArray], total_shots: int) -> BitArray:\n",
    "    \"\"\"Combine several bit arrays by choosing the same number of shots from each of them.\n",
    "    Choose the shots randomly from each one.\"\"\"\n",
    "\n",
    "    shots_per_circuit = [total_shots // len(bit_arrays)] * len(bit_arrays)\n",
    "    difference = total_shots - sum(shots_per_circuit)\n",
    "    i = 0\n",
    "    while i < difference:\n",
    "        shots_per_circuit[i] += 1\n",
    "        i += 1\n",
    "    assert sum(shots_per_circuit) == total_shots\n",
    "\n",
    "    random_bit_matrices: List[np.ndarray] = []\n",
    "    num_bits = bit_arrays[0].num_bits\n",
    "    for i, bit_array in enumerate(bit_arrays):\n",
    "        assert bit_array.num_shots >= shots_per_circuit[i]\n",
    "        assert bit_array.num_bits == num_bits\n",
    "        bit_matrix = bit_array.to_bool_array()\n",
    "        random_inds = random.sample(list(range(bit_matrix.shape[0])), shots_per_circuit[i])\n",
    "        random_bit_matrix = bit_matrix[random_inds, :]\n",
    "        random_bit_matrices.append(random_bit_matrix.copy())\n",
    "    total_random_bits = np.vstack(random_bit_matrices)\n",
    "    assert total_random_bits.shape[0] == total_shots\n",
    "    return BitArray.from_bool_array(total_random_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2e3f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_energies = []\n",
    "stacked_errors = []\n",
    "\n",
    "for i in range(2, len(counts_list) + 1):\n",
    "    # all_counts = collections.Counter()\n",
    "    # tuple_of_counts = tuple(counts_list[:i])\n",
    "    # assert len(tuple_of_counts) == i\n",
    "    # for counts in tuple_of_counts:\n",
    "    #     for bitstring, count in counts.items():\n",
    "    #         all_counts[bitstring] += count\n",
    "\n",
    "    # bit_array = qiskit.primitives.BitArray.from_counts(all_counts, num_bits=circuits[0].num_qubits)\n",
    "    bit_array = randomly_combine_bit_arrays(bit_arrays[:i], num_shots)\n",
    "\n",
    "    bit_matrix = bit_array.to_bool_array()\n",
    "    eigvals, eigvecs = solve_qubit(bit_matrix, h_qiskit, k=1)\n",
    "    min_energy = np.min(eigvals)\n",
    "    err = abs(min_energy - exact_energy)\n",
    "    stacked_energies.append(min_energy)\n",
    "    stacked_errors.append(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6263d499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Energy error')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(stacked_errors)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb9a1bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x32b91dbd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adapt_rel_errors = adapt_errors / abs(exact_energy)\n",
    "rel_errors = np.array(errors) / abs(exact_energy)\n",
    "stacked_rel_errors = np.array(stacked_errors) / abs(exact_energy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(adapt_rel_errors, '.', label=\"ADAPT\")\n",
    "ax.plot(rel_errors, '.', label=\"SQD\")\n",
    "ax.plot(stacked_rel_errors, '.', label=\"iSQD\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd058369",
   "metadata": {},
   "source": [
    "## How many did we keep?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e16e09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_kept = []\n",
    "total_shots = []\n",
    "for bit_array in bit_arrays:\n",
    "    bit_matrix = bit_array.to_bool_array()\n",
    "    original_size = bit_matrix.shape[0]\n",
    "    bit_matrix = sort_and_remove_duplicates(bit_matrix)\n",
    "    new_size = bit_matrix.shape[0]\n",
    "    num_kept.append(new_size)\n",
    "    total_shots.append(original_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11b61c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratio_kept = np.array(num_kept) / np.array(total_shots)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Number of basis states', color=color)\n",
    "ax1.plot(num_kept, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second Axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Fraction of shots kept', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(ratio_kept, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f225920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qasm_strs = []\n",
    "for circuit in circuits:\n",
    "    # print(circuit.num_qubits)\n",
    "    # isa_circuit = pass_manager.run(circuit)\n",
    "    # print(isa_circuit.num_qubits)\n",
    "    isa_circuit = circuit\n",
    "    qasm_str = dumps(isa_circuit)\n",
    "    qasm_strs.append(qasm_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4a60674",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"data/xxz_output.hdf5\", \"w\")\n",
    "f.create_dataset(\"qasm_strs\", data=qasm_strs)\n",
    "f.create_dataset(\"exact_energy\", data=exact_energy)\n",
    "f.create_dataset(\"adapt_errors\", data=np.array(adapt_errors))\n",
    "f.create_dataset(\"sqd_errors\", data=np.array(errors))\n",
    "f.create_dataset(\"isqd_errors\", data=np.array(stacked_errors))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc0a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapt",
   "language": "python",
   "name": "adapt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
